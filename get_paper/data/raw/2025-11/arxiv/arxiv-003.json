{
  "source": "arxiv",
  "fetched_at": "2025-11-22T12:42:27.663213+00:00",
  "payload": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/bk6XitNox3nd5SLj31oUUMhHQ1s</id>\n  <title>arXiv Query: search_query=(ti:agent OR ti:\"tool use\" OR ti:tool-augmented OR ti:planning OR ti:multi-agent OR ti:autonomous OR ti:toolformer OR ti:\"tool learning\" OR abs:agent OR abs:\"tool use\" OR abs:tool-augmented OR abs:planning OR abs:multi-agent OR abs:autonomous OR abs:toolformer OR abs:\"tool learning\") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.MA) AND (ti:Google OR ti:DeepMind OR ti:Microsoft OR ti:OpenAI OR ti:Meta OR ti:Apple OR ti:Stanford OR ti:MIT OR ti:CMU OR ti:Berkeley OR ti:Oxford OR ti:Harvard OR ti:Tsinghua OR ti:\"Peking University\" OR ti:PKU OR ti:USTC OR ti:SJTU OR ti:Princeton OR ti:UCLA OR ti:UCSD OR ti:\"ETH Zurich\" OR ti:NUS OR ti:NTU OR abs:Google OR abs:DeepMind OR abs:Microsoft OR abs:OpenAI OR abs:Meta OR abs:Apple OR abs:Stanford OR abs:MIT OR abs:CMU OR abs:Berkeley OR abs:Oxford OR abs:Harvard OR abs:Tsinghua OR abs:\"Peking University\" OR abs:PKU OR abs:USTC OR abs:SJTU OR abs:Princeton OR abs:UCLA OR abs:UCSD OR abs:\"ETH Zurich\" OR abs:NUS OR abs:NTU)&amp;id_list=&amp;start=150&amp;max_results=50</title>\n  <updated>2025-11-22T12:42:27Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=(ti:agent+OR+(ti:%22tool+use%22+OR+(ti:tool-augmented+OR+(ti:planning+OR+(ti:multi-agent+OR+(ti:autonomous+OR+(ti:toolformer+OR+(ti:%22tool+learning%22+OR+(abs:agent+OR+(abs:%22tool+use%22+OR+(abs:tool-augmented+OR+(abs:planning+OR+(abs:multi-agent+OR+(abs:autonomous+OR+(abs:toolformer+OR+abs:%22tool+learning%22)))))))))))))))+AND+((cat:cs.AI+OR+(cat:cs.LG+OR+cat:cs.MA))+AND+(ti:Google+OR+(ti:DeepMind+OR+(ti:Microsoft+OR+(ti:OpenAI+OR+(ti:Meta+OR+(ti:Apple+OR+(ti:Stanford+OR+(ti:MIT+OR+(ti:CMU+OR+(ti:Berkeley+OR+(ti:Oxford+OR+(ti:Harvard+OR+(ti:Tsinghua+OR+(ti:%22Peking+University%22+OR+(ti:PKU+OR+(ti:USTC+OR+(ti:SJTU+OR+(ti:Princeton+OR+(ti:UCLA+OR+(ti:UCSD+OR+(ti:%22ETH+Zurich%22+OR+(ti:NUS+OR+(ti:NTU+OR+(abs:Google+OR+(abs:DeepMind+OR+(abs:Microsoft+OR+(abs:OpenAI+OR+(abs:Meta+OR+(abs:Apple+OR+(abs:Stanford+OR+(abs:MIT+OR+(abs:CMU+OR+(abs:Berkeley+OR+(abs:Oxford+OR+(abs:Harvard+OR+(abs:Tsinghua+OR+(abs:%22Peking+University%22+OR+(abs:PKU+OR+(abs:USTC+OR+(abs:SJTU+OR+(abs:Princeton+OR+(abs:UCLA+OR+(abs:UCSD+OR+(abs:%22ETH+Zurich%22+OR+(abs:NUS+OR+abs:NTU))))))))))))))))))))))))))))))))))))))))))))))&amp;start=150&amp;max_results=50&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>50</opensearch:itemsPerPage>\n  <opensearch:totalResults>2708</opensearch:totalResults>\n  <opensearch:startIndex>150</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2509.23462v1</id>\n    <title>Generative Evolutionary Meta-Solver (GEMS): Scalable Surrogate-Free Multi-Agent Learning</title>\n    <updated>2025-09-27T19:23:38Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.23462v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.23462v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Scalable multi-agent reinforcement learning (MARL) remains a central challenge for AI. Existing population-based methods, like Policy-Space Response Oracles, PSRO, require storing explicit policy populations and constructing full payoff matrices, incurring quadratic computation and linear memory costs. We present Generative Evolutionary Meta-Solver (GEMS), a surrogate-free framework that replaces explicit populations with a compact set of latent anchors and a single amortized generator. Instead of exhaustively constructing the payoff matrix, GEMS relies on unbiased Monte Carlo rollouts, multiplicative-weights meta-dynamics, and a model-free empirical-Bernstein UCB oracle to adaptively expand the policy set. Best responses are trained within the generator using an advantage-based trust-region objective, eliminating the need to store and train separate actors. We evaluated GEMS in a variety of Two-player and Multi-Player games such as the Deceptive Messages Game, Kuhn Poker and Multi-Particle environment. We find that GEMS is up to ~6x faster, has 1.3x less memory usage than PSRO, while also reaps higher rewards simultaneously. These results demonstrate that GEMS retains the game theoretic guarantees of PSRO, while overcoming its fundamental inefficiencies, hence enabling scalable multi-agent learning in multiple domains.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-27T19:23:38Z</published>\n    <arxiv:comment>Under review</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Alakh Sharma</name>\n    </author>\n    <author>\n      <name>Gaurish Trivedi</name>\n    </author>\n    <author>\n      <name>Kartikey Bhandari</name>\n    </author>\n    <author>\n      <name>Yash Sinha</name>\n    </author>\n    <author>\n      <name>Dhruv Kumar</name>\n    </author>\n    <author>\n      <name>Pratik Narang</name>\n    </author>\n    <author>\n      <name>Jagat Sesh Challa</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.21907v1</id>\n    <title>A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs</title>\n    <updated>2025-09-26T05:44:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.21907v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.21907v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Understanding the qualitative intent of citations is essential for a comprehensive assessment of academic research, a task that poses unique challenges for agglutinative languages like Turkish. This paper introduces a systematic methodology and a foundational dataset to address this problem. We first present a new, publicly available dataset of Turkish citation intents, created with a purpose-built annotation tool. We then evaluate the performance of standard In-Context Learning (ICL) with Large Language Models (LLMs), demonstrating that its effectiveness is limited by inconsistent results caused by manually designed prompts. To address this core limitation, we introduce a programmable classification pipeline built on the DSPy framework, which automates prompt optimization systematically. For final classification, we employ a stacked generalization ensemble to aggregate outputs from multiple optimized models, ensuring stable and reliable predictions. This ensemble, with an XGBoost meta-model, achieves a state-of-the-art accuracy of 91.3\\%. Ultimately, this study provides the Turkish NLP community and the broader academic circles with a foundational dataset and a robust classification framework paving the way for future qualitative citation studies.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-26T05:44:04Z</published>\n    <arxiv:comment>Submitted to IEEE UBMK 2025 International Conference on Computer Science and Engineering</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <arxiv:journal_ref>In Proceedings of the 10th International Conference on Computer Science and Engineering (UBMK) 1 (2025) 509-514</arxiv:journal_ref>\n    <author>\n      <name>Kemal Sami Karaca</name>\n    </author>\n    <author>\n      <name>Bahaeddin Eravcı</name>\n    </author>\n    <arxiv:doi>10.1109/UBMK67458.2025.11207038</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1109/UBMK67458.2025.11207038\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.21842v1</id>\n    <title>DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents</title>\n    <updated>2025-09-26T04:03:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.21842v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.21842v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Travel planning (TP) agent has recently worked as an emerging building block to interact with external tools and resources for travel itinerary generation, ensuring enjoyable user experience. Despite its benefits, existing studies rely on hand craft prompt and fixed agent workflow, hindering more flexible and autonomous TP agent. This paper proposes DeepTravel, an end to end agentic reinforcement learning framework for building autonomous travel planning agent, capable of autonomously planning, executing tools, and reflecting on tool responses to explore, verify, and refine intermediate actions in multi step reasoning. To achieve this, we first construct a robust sandbox environment by caching transportation, accommodation and POI data, facilitating TP agent training without being constrained by real world APIs limitations (e.g., inconsistent outputs). Moreover, we develop a hierarchical reward modeling system, where a trajectory level verifier first checks spatiotemporal feasibility and filters unsatisfied travel itinerary, and then the turn level verifier further validate itinerary detail consistency with tool responses, enabling efficient and precise reward service. Finally, we propose the reply augmented reinforcement learning method that enables TP agent to periodically replay from a failures experience buffer, emerging notable agentic capacity. We deploy trained TP agent on DiDi Enterprise Solutions App and conduct comprehensive online and offline evaluations, demonstrating that DeepTravel enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-26T04:03:52Z</published>\n    <arxiv:comment>Under review</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Yansong Ning</name>\n    </author>\n    <author>\n      <name>Rui Liu</name>\n    </author>\n    <author>\n      <name>Jun Wang</name>\n    </author>\n    <author>\n      <name>Kai Chen</name>\n    </author>\n    <author>\n      <name>Wei Li</name>\n    </author>\n    <author>\n      <name>Jun Fang</name>\n    </author>\n    <author>\n      <name>Kan Zheng</name>\n    </author>\n    <author>\n      <name>Naiqiang Tan</name>\n    </author>\n    <author>\n      <name>Hao Liu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.02328v1</id>\n    <title>AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering</title>\n    <updated>2025-09-26T01:22:25Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.02328v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.02328v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise in medical visual question answering (Med-VQA). However, when deployed in low-resource settings where abundant labeled data are unavailable, existing Med-MLLMs commonly fail due to their medical reasoning capability bottlenecks: (i) the intrinsic reasoning bottleneck that ignores the details from the medical image; (ii) the extrinsic reasoning bottleneck that fails to incorporate specialized medical knowledge. To address those limitations, we propose AMANDA, a training-free agentic framework that performs medical knowledge augmentation via LLM agents. Specifically, our intrinsic medical knowledge augmentation focuses on coarse-to-fine question decomposition for comprehensive diagnosis, while extrinsic medical knowledge augmentation grounds the reasoning process via biomedical knowledge graph retrieval. Extensive experiments across eight Med-VQA benchmarks demonstrate substantial improvements in both zero-shot and few-shot Med-VQA settings. The code is available at https://github.com/REAL-Lab-NU/AMANDA.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-26T01:22:25Z</published>\n    <arxiv:comment>EMNLP Findings</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Ziqing Wang</name>\n    </author>\n    <author>\n      <name>Chengsheng Mao</name>\n    </author>\n    <author>\n      <name>Xiaole Wen</name>\n    </author>\n    <author>\n      <name>Yuan Luo</name>\n    </author>\n    <author>\n      <name>Kaize Ding</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.21542v1</id>\n    <title>Psychological and behavioural responses in human-agent vs. human-human interactions: a systematic review and meta-analysis</title>\n    <updated>2025-09-25T20:29:36Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.21542v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.21542v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Interactive intelligent agents are being integrated across society. Despite achieving human-like capabilities, humans' responses to these agents remain poorly understood, with research fragmented across disciplines. We conducted a first systematic synthesis comparing a range of psychological and behavioural responses in matched human-agent vs. human-human dyadic interactions. A total of 162 eligible studies (146 contributed to the meta-analysis; 468 effect sizes) were included in the systematic review and meta-analysis, which integrated frequentist and Bayesian approaches. Our results indicate that individuals exhibited less prosocial behaviour and moral engagement when interacting with agents vs. humans. They attributed less agency and responsibility to agents, perceiving them as less competent, likeable, and socially present. In contrast, individuals' social alignment (i.e., alignment or adaptation of internal states and behaviours with partners), trust in partners, personal agency, task performance, and interaction experiences were generally comparable when interacting with agents vs. humans. We observed high effect-size heterogeneity for many subjective responses (i.e., social perceptions of partners, subjective trust, and interaction experiences), suggesting context-dependency of partner effects. By examining the characteristics of studies, participants, partners, interaction scenarios, and response measures, we also identified several moderators shaping partner effects. Overall, functional behaviours and interactive experiences with agents can resemble those with humans, whereas fundamental social attributions and moral/prosocial concerns lag in human-agent interactions. Agents are thus afforded instrumental value on par with humans but lack comparable intrinsic value, providing practical implications for agent design and regulation.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-25T20:29:36Z</published>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Jianan Zhou</name>\n    </author>\n    <author>\n      <name>Fleur Corbett</name>\n    </author>\n    <author>\n      <name>Joori Byun</name>\n    </author>\n    <author>\n      <name>Talya Porat</name>\n    </author>\n    <author>\n      <name>Nejra van Zalk</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.21224v1</id>\n    <title>What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns</title>\n    <updated>2025-09-25T14:29:49Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.21224v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.21224v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce an architecture for studying the behavior of large language model (LLM) agents in the absence of externally imposed tasks. Our continuous reason and act framework, using persistent memory and self-feedback, enables sustained autonomous operation. We deployed this architecture across 18 runs using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents spontaneously organize into three distinct behavioral patterns: (1) systematic production of multi-cycle projects, (2) methodological self-inquiry into their own cognitive processes, and (3) recursive conceptualization of their own nature. These tendencies proved highly model-specific, with some models deterministically adopting a single pattern across all runs. A cross-model assessment further reveals that models exhibit stable, divergent biases when evaluating these emergent behaviors in themselves and others. These findings provide the first systematic documentation of unprompted LLM agent behavior, establishing a baseline for predicting actions during task ambiguity, error recovery, or extended autonomous operation in deployed systems.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-25T14:29:49Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Stefan Szeider</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.21207v1</id>\n    <title>From Physics to Machine Learning and Back: Part II - Learning and Observational Bias in PHM</title>\n    <updated>2025-09-25T14:15:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.21207v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.21207v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Prognostics and Health Management ensures the reliability, safety, and efficiency of complex engineered systems by enabling fault detection, anticipating equipment failures, and optimizing maintenance activities throughout an asset lifecycle. However, real-world PHM presents persistent challenges: sensor data is often noisy or incomplete, available labels are limited, and degradation behaviors and system interdependencies can be highly complex and nonlinear. Physics-informed machine learning has emerged as a promising approach to address these limitations by embedding physical knowledge into data-driven models. This review examines how incorporating learning and observational biases through physics-informed modeling and data strategies can guide models toward physically consistent and reliable predictions. Learning biases embed physical constraints into model training through physics-informed loss functions and governing equations, or by incorporating properties like monotonicity. Observational biases influence data selection and synthesis to ensure models capture realistic system behavior through virtual sensing for estimating unmeasured states, physics-based simulation for data augmentation, and multi-sensor fusion strategies. The review then examines how these approaches enable the transition from passive prediction to active decision-making through reinforcement learning, which allows agents to learn maintenance policies that respect physical constraints while optimizing operational objectives. This closes the loop between model-based predictions, simulation, and actual system operation, empowering adaptive decision-making. Finally, the review addresses the critical challenge of scaling PHM solutions from individual assets to fleet-wide deployment. Fast adaptation methods including meta-learning and few-shot learning are reviewed alongside domain generalization techniques ...</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-25T14:15:43Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Olga Fink</name>\n    </author>\n    <author>\n      <name>Ismail Nejjar</name>\n    </author>\n    <author>\n      <name>Vinay Sharma</name>\n    </author>\n    <author>\n      <name>Keivan Faghih Niresi</name>\n    </author>\n    <author>\n      <name>Han Sun</name>\n    </author>\n    <author>\n      <name>Hao Dong</name>\n    </author>\n    <author>\n      <name>Chenghao Xu</name>\n    </author>\n    <author>\n      <name>Amaury Wei</name>\n    </author>\n    <author>\n      <name>Arthur Bizzi</name>\n    </author>\n    <author>\n      <name>Raffael Theiler</name>\n    </author>\n    <author>\n      <name>Yuan Tian</name>\n    </author>\n    <author>\n      <name>Leandro Von Krannichfeldt</name>\n    </author>\n    <author>\n      <name>Zhan Ma</name>\n    </author>\n    <author>\n      <name>Sergei Garmaev</name>\n    </author>\n    <author>\n      <name>Zepeng Zhang</name>\n    </author>\n    <author>\n      <name>Mengjie Zhao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.20754v1</id>\n    <title>Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning</title>\n    <updated>2025-09-25T05:22:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.20754v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.20754v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Navigating complex environments requires robots to effectively store observations as memories and leverage them to answer human queries about spatial locations, which is a critical yet underexplored research challenge. While prior work has made progress in constructing robotic memory, few have addressed the principled mechanisms needed for efficient memory retrieval and integration. To bridge this gap, we propose Meta-Memory, a large language model (LLM)-driven agent that constructs a high-density memory representation of the environment. The key innovation of Meta-Memory lies in its capacity to retrieve and integrate relevant memories through joint reasoning over semantic and spatial modalities in response to natural language location queries, thereby empowering robots with robust and accurate spatial reasoning capabilities. To evaluate its performance, we introduce SpaceLocQA, a large-scale dataset encompassing diverse real-world spatial question-answering scenarios. Experimental results show that Meta-Memory significantly outperforms state-of-the-art methods on both the SpaceLocQA and the public NaVQA benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world robotic platforms, demonstrating its practical utility in complex environments. Project page: https://itsbaymax.github.io/meta-memory.github.io/ .</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-25T05:22:52Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Yufan Mao</name>\n    </author>\n    <author>\n      <name>Hanjing Ye</name>\n    </author>\n    <author>\n      <name>Wenlong Dong</name>\n    </author>\n    <author>\n      <name>Chengjie Zhang</name>\n    </author>\n    <author>\n      <name>Hong Zhang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.20502v1</id>\n    <title>MARS: toward more efficient multi-agent collaboration for LLM reasoning</title>\n    <updated>2025-09-24T19:24:33Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.20502v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.20502v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) have achieved impressive results in natural language understanding, yet their reasoning capabilities remain limited when operating as single agents. Multi-Agent Debate (MAD) has been proposed to address this limitation by enabling collaborative reasoning among multiple models in a round-table debate manner. While effective, MAD introduces substantial computational overhead due to the number of agents involved and the frequent communication required. In this paper, we propose MARS (Multi-Agent Review System), a role-based collaboration framework inspired by the review process. In MARS, an author agent generates an initial solution, reviewer agents provide decisions and comments independently, and a meta-reviewer integrates the feedback to make the final decision and guide further revision. This design enhances reasoning quality while avoiding costly reviewer-to-reviewer interactions, thereby controlling token consumption and inference time. We compared MARS with both MAD and other state-of-the-art reasoning strategies across multiple benchmarks. Extensive experiments with different LLMs show that MARS matches the accuracy of MAD while reducing both token usage and inference time by approximately 50\\%. Code is available at https://github.com/xwang97/MARS.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-24T19:24:33Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Xiao Wang</name>\n    </author>\n    <author>\n      <name>Jia Wang</name>\n    </author>\n    <author>\n      <name>Yijie Wang</name>\n    </author>\n    <author>\n      <name>Pengtao Dang</name>\n    </author>\n    <author>\n      <name>Sha Cao</name>\n    </author>\n    <author>\n      <name>Chi Zhang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.19705v1</id>\n    <title>Causal Machine Learning for Surgical Interventions</title>\n    <updated>2025-09-24T02:31:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.19705v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.19705v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Surgical decision-making is complex and requires understanding causal relationships between patient characteristics, interventions, and outcomes. In high-stakes settings like spinal fusion or scoliosis correction, accurate estimation of individualized treatment effects (ITEs) remains limited due to the reliance on traditional statistical methods that struggle with complex, heterogeneous data. In this study, we develop a multi-task meta-learning framework, X-MultiTask, for ITE estimation that models each surgical decision (e.g., anterior vs. posterior approach, surgery vs. no surgery) as a distinct task while learning shared representations across tasks. To strengthen causal validity, we incorporate the inverse probability weighting (IPW) into the training objective. We evaluate our approach on two datasets: (1) a public spinal fusion dataset (1,017 patients) to assess the effect of anterior vs. posterior approaches on complication severity; and (2) a private AIS dataset (368 patients) to analyze the impact of posterior spinal fusion (PSF) vs. non-surgical management on patient-reported outcomes (PROs). Our model achieves the highest average AUC (0.84) in the anterior group and maintains competitive performance in the posterior group (0.77). It outperforms baselines in treatment effect estimation with the lowest overall $ε_{\\text{NN-PEHE}}$ (0.2778) and $ε_{\\text{ATE}}$ (0.0763). Similarly, when predicting PROs in AIS, X-MultiTask consistently shows superior performance across all domains, with $ε_{\\text{NN-PEHE}}$ = 0.2551 and $ε_{\\text{ATE}}$ = 0.0902. By providing robust, patient-specific causal estimates, X-MultiTask offers a powerful tool to advance personalized surgical care and improve patient outcomes. The code is available at https://github.com/Wizaaard/X-MultiTask.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.AP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ME\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-24T02:31:43Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>J. Ben Tamo</name>\n    </author>\n    <author>\n      <name>Nishant S. Chouhan</name>\n    </author>\n    <author>\n      <name>Micky C. Nnamdi</name>\n    </author>\n    <author>\n      <name>Yining Yuan</name>\n    </author>\n    <author>\n      <name>Shreya S. Chivilkar</name>\n    </author>\n    <author>\n      <name>Wenqi Shi</name>\n    </author>\n    <author>\n      <name>Steven W. Hwang</name>\n    </author>\n    <author>\n      <name>B. Randall Brenn</name>\n    </author>\n    <author>\n      <name>May D. Wang</name>\n    </author>\n    <arxiv:doi>10.26599/BDMA.2025.9020093</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.26599/BDMA.2025.9020093\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.19696v2</id>\n    <title>Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks</title>\n    <updated>2025-09-29T11:22:15Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.19696v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.19696v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Learning methods excel at motion generation in the information domain but are not primarily designed for physical interaction in the energy domain. Impedance Control shapes physical interaction but requires task-aware tuning by selecting feasible impedance parameters. We present Diffusion-Based Impedance Learning, a framework that combines both domains. A Transformer-based Diffusion Model with cross-attention to external wrenches reconstructs a simulated Zero-Force Trajectory (sZFT). This captures both translational and rotational task-space behavior. For rotations, we introduce a novel SLERP-based quaternion noise scheduler that ensures geometric consistency. The reconstructed sZFT is then passed to an energy-based estimator that updates stiffness and damping parameters. A directional rule is applied that reduces impedance along non task axes while preserving rigidity along task directions. Training data were collected for a parkour scenario and robotic-assisted therapy tasks using teleoperation with Apple Vision Pro. With only tens of thousands of samples, the model achieved sub-millimeter positional accuracy and sub-degree rotational accuracy. Its compact model size enabled real-time torque control and autonomous stiffness adaptation on a KUKA LBR iiwa robot. The controller achieved smooth parkour traversal within force and velocity limits and 30/30 success rates for cylindrical, square, and star peg insertions without any peg-specific demonstrations in the training data set. All code for the Transformer-based Diffusion Model, the robot controller, and the Apple Vision Pro telemanipulation framework is publicly available. These results mark an important step towards Physical AI, fusing model-based control for physical interaction with learning-based methods for trajectory generation.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-24T02:07:17Z</published>\n    <arxiv:comment>15 pages, 12 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Noah Geiger</name>\n    </author>\n    <author>\n      <name>Tamim Asfour</name>\n    </author>\n    <author>\n      <name>Neville Hogan</name>\n    </author>\n    <author>\n      <name>Johannes Lachner</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.19533v1</id>\n    <title>Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation</title>\n    <updated>2025-09-23T19:57:29Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.19533v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.19533v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Security vulnerabilities in Internet-of-Things devices, mobile platforms, and autonomous systems remain critical. Traditional mutation-based fuzzers -- while effectively explore code paths -- primarily perform byte- or bit-level edits without semantic reasoning. Coverage-guided tools such as AFL++ use dictionaries, grammars, and splicing heuristics to impose shallow structural constraints, leaving deeper protocol logic, inter-field dependencies, and domain-specific semantics unaddressed. Conversely, reasoning-capable large language models (LLMs) can leverage pretraining knowledge to understand input formats, respect complex constraints, and propose targeted mutations, much like an experienced reverse engineer or testing expert. However, lacking ground truth for \"correct\" mutation reasoning makes supervised fine-tuning impractical, motivating explorations of off-the-shelf LLMs via prompt-based few-shot learning. To bridge this gap, we present an open-source microservices framework that integrates reasoning LLMs with AFL++ on Google's FuzzBench, tackling asynchronous execution and divergent hardware demands (GPU- vs. CPU-intensive) of LLMs and fuzzers. We evaluate four research questions: (R1) How can reasoning LLMs be integrated into the fuzzing mutation loop? (R2) Do few-shot prompts yield higher-quality mutations than zero-shot? (R3) Can prompt engineering with off-the-shelf models improve fuzzing directly? and (R4) Which open-source reasoning LLMs perform best under prompt-only conditions? Experiments with Llama3.3, Deepseek-r1-Distill-Llama-70B, QwQ-32B, and Gemma3 highlight Deepseek as the most promising. Mutation effectiveness depends more on prompt complexity and model choice than shot count. Response latency and throughput bottlenecks remain key obstacles, offering directions for future work.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-23T19:57:29Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Mengdi Lu</name>\n    </author>\n    <author>\n      <name>Steven Ding</name>\n    </author>\n    <author>\n      <name>Furkan Alaca</name>\n    </author>\n    <author>\n      <name>Philippe Charland</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.19136v2</id>\n    <title>On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language</title>\n    <updated>2025-10-01T09:32:15Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.19136v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.19136v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The use of natural language (NL) test cases for validating graphical user interface (GUI) applications is emerging as a promising direction to manually written executable test scripts, which are costly to develop and difficult to maintain. Recent advances in large language models (LLMs) have opened the possibility of the direct execution of NL test cases by LLM agents. This paper investigates this direction, focusing on the impact on NL test case unsoundness and on test case execution consistency. NL test cases are inherently unsound, as they may yield false failures due to ambiguous instructions or unpredictable agent behaviour. Furthermore, repeated executions of the same NL test case may lead to inconsistent outcomes, undermining test reliability. To address these challenges, we propose an algorithm for executing NL test cases with guardrail mechanisms and specialised agents that dynamically verify the correct execution of each test step. We introduce measures to evaluate the capabilities of LLMs in test execution and one measure to quantify execution consistency. We propose a definition of weak unsoundness to characterise contexts in which NL test case execution remains acceptable, with respect to the industrial quality levels Six Sigma. Our experimental evaluation with eight publicly available LLMs, ranging from 3B to 70B parameters, demonstrates both the potential and current limitations of current LLM agents for GUI testing. Our experiments show that Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case execution with high execution consistency (above the level 3-sigma). We provide prototype tools, test suites, and results.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-23T15:20:40Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Sébastien Salva</name>\n    </author>\n    <author>\n      <name>Redha Taguelmimt</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.20388v1</id>\n    <title>Can You Trust Your Copilot? A Privacy Scorecard for AI Coding Assistants</title>\n    <updated>2025-09-22T21:45:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.20388v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.20388v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The rapid integration of AI-powered coding assistants into developer workflows has raised significant privacy and trust concerns. As developers entrust proprietary code to services like OpenAI's GPT, Google's Gemini, and GitHub Copilot, the unclear data handling practices of these tools create security and compliance risks. This paper addresses this challenge by introducing and applying a novel, expert-validated privacy scorecard. The methodology involves a detailed analysis of four document types; from legal policies to external audits; to score five leading assistants against 14 weighted criteria. A legal expert and a data protection officer refined these criteria and their weighting. The results reveal a distinct hierarchy of privacy protections, with a 20-point gap between the highest- and lowest-ranked tools. The analysis uncovers common industry weaknesses, including the pervasive use of opt-out consent for model training and a near-universal failure to filter secrets from user prompts proactively. The resulting scorecard provides actionable guidance for developers and organizations, enabling evidence-based tool selection. This work establishes a new benchmark for transparency and advocates for a shift towards more user-centric privacy standards in the AI industry.</summary>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-22T21:45:45Z</published>\n    <arxiv:primary_category term=\"cs.CR\"/>\n    <author>\n      <name>Amir AL-Maamari</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.18420v1</id>\n    <title>Instruction-Following Evaluation in Function Calling for Large Language Models</title>\n    <updated>2025-09-22T21:04:39Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.18420v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.18420v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Function calling is a core capability of large language models, essential for AI agents. Existing benchmarks such as the Berkeley Function Calling Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench (arXiv:2501.12851) evaluate argument correctness but do not test adherence to format instructions embedded in parameter descriptions, such as enclosing values in double quotes or using ISO date formats.\n  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911) that assesses precise instruction following in function calling. IFEval-FC encodes verifiable formats directly within JSON schema descriptions, for example specifying that a value must not contain punctuation. It includes 750 test cases, each consisting of a function with an embedded format for one of its input parameters and a corresponding user query. Evaluation is fully algorithmic, ensuring objectivity, reproducibility, and scalability.\n  Our results show that even state-of-the-art proprietary models, including GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules, highlighting a practical limitation for real-world agent systems. The complete codebase and data are publicly available at https://github.com/Skripkon/IFEval-FC.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-22T21:04:39Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Nikolai Skripko</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.22704v1</id>\n    <title>Intelligent Load Balancing in Cloud Computer Systems</title>\n    <updated>2025-09-22T19:39:08Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.22704v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.22704v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Cloud computing is an established technology allowing users to share resources on a large scale, never before seen in IT history. A cloud system connects multiple individual servers in order to process related tasks in several environments at the same time. Clouds are typically more cost-effective than single computers of comparable computing performance. The sheer physical size of the system itself means that thousands of machines may be involved. The focus of this research was to design a strategy to dynamically allocate tasks without overloading Cloud nodes which would result in system stability being maintained at minimum cost. This research has added the following new contributions to the state of knowledge: (i) a novel taxonomy and categorisation of three classes of schedulers, namely OS-level, Cluster and Big Data, which highlight their unique evolution and underline their different objectives; (ii) an abstract model of cloud resources utilisation is specified, including multiple types of resources and consideration of task migration costs; (iii) a virtual machine live migration was experimented with in order to create a formula which estimates the network traffic generated by this process; (iv) a high-fidelity Cloud workload simulator, based on a month-long workload traces from Google's computing cells, was created; (v) two possible approaches to resource management were proposed and examined in the practical part of the manuscript: the centralised metaheuristic load balancer and the decentralised agent-based system. The project involved extensive experiments run on the University of Westminster HPC cluster, and the promising results are presented together with detailed discussions and a conclusion.</summary>\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-22T19:39:08Z</published>\n    <arxiv:comment>A thesis submitted in partial fulfilment of the requirements of the University of Westminster for the degree of Doctor of Philosophy</arxiv:comment>\n    <arxiv:primary_category term=\"cs.DC\"/>\n    <author>\n      <name>Leszek Sliwko</name>\n    </author>\n    <arxiv:doi>10.34737/qq4w7</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.34737/qq4w7\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.18230v1</id>\n    <title>Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces</title>\n    <updated>2025-09-22T13:14:47Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.18230v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.18230v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Controlling desktop applications via software remains a fundamental yet under-served problem. Existing multi-modal large language models (MLLMs) ingest screenshots and task instructions to generate keystrokes and mouse events, but they suffer from prohibitive inference latency, poor sample efficiency on long-horizon sparse-reward tasks, and infeasible on-device deployment. We introduce a lightweight hierarchical reinforcement learning framework, ComputerAgent, that formulates OS control as a two-level option process (manager and subpolicy), employs a triple-modal state encoder (screenshot, task ID, numeric state) to handle visual and contextual diversity, integrates meta-actions with an early-stop mechanism to reduce wasted interactions, and uses a compact vision backbone plus small policy networks for on-device inference (15M parameters). On a suite of 135 real-world desktop tasks, ComputerAgent attains 92.1% success on simple tasks (&lt;8 steps) and 58.8% on hard tasks (&gt;=8 steps), matching or exceeding 200B-parameter MLLM baselines on simple scenarios while reducing model size by over four orders of magnitude and halving inference time. These results demonstrate that hierarchical RL offers a practical, scalable alternative to monolithic MLLM-based automation for computer control.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-22T13:14:47Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Zihan Dong</name>\n    </author>\n    <author>\n      <name>Xinyu Fan</name>\n    </author>\n    <author>\n      <name>Zixiang Tang</name>\n    </author>\n    <author>\n      <name>Yunqing Li</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.17158v1</id>\n    <title>ARE: Scaling Up Agent Environments and Evaluations</title>\n    <updated>2025-09-21T16:59:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.17158v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.17158v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. ARE provides simple abstractions to build complex and diverse environments, each with their own rules, tools, content, and verifiers, helping to bridge the gap between model development and real-world deployment. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities. Beyond search and execution, Gaia2 requires agents to handle ambiguities and noise, adapt to dynamic environments, collaborate with other agents, and operate under temporal constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new failure modes that are invisible in static settings. Our experiments show that no system dominates across the intelligence spectrum: stronger reasoning often comes at the cost of efficiency, and budget scaling curves plateau, highlighting the need for new architectures and adaptive compute strategies. Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2 to other environments, empowering the community to rapidly create new benchmarks tailored to their domains. In AI's second half, progress increasingly depends on defining meaningful tasks and robust evaluations to drive frontier capabilities forward.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-21T16:59:45Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Pierre Andrews</name>\n    </author>\n    <author>\n      <name>Amine Benhalloum</name>\n    </author>\n    <author>\n      <name>Gerard Moreno-Torres Bertran</name>\n    </author>\n    <author>\n      <name>Matteo Bettini</name>\n    </author>\n    <author>\n      <name>Amar Budhiraja</name>\n    </author>\n    <author>\n      <name>Ricardo Silveira Cabral</name>\n    </author>\n    <author>\n      <name>Virginie Do</name>\n    </author>\n    <author>\n      <name>Romain Froger</name>\n    </author>\n    <author>\n      <name>Emilien Garreau</name>\n    </author>\n    <author>\n      <name>Jean-Baptiste Gaya</name>\n    </author>\n    <author>\n      <name>Hugo Laurençon</name>\n    </author>\n    <author>\n      <name>Maxime Lecanu</name>\n    </author>\n    <author>\n      <name>Kunal Malkan</name>\n    </author>\n    <author>\n      <name>Dheeraj Mekala</name>\n    </author>\n    <author>\n      <name>Pierre Ménard</name>\n    </author>\n    <author>\n      <name>Grégoire Mialon</name>\n    </author>\n    <author>\n      <name>Ulyana Piterbarg</name>\n    </author>\n    <author>\n      <name>Mikhail Plekhanov</name>\n    </author>\n    <author>\n      <name>Mathieu Rita</name>\n    </author>\n    <author>\n      <name>Andrey Rusakov</name>\n    </author>\n    <author>\n      <name>Thomas Scialom</name>\n    </author>\n    <author>\n      <name>Vladislav Vorotilov</name>\n    </author>\n    <author>\n      <name>Mengjue Wang</name>\n    </author>\n    <author>\n      <name>Ian Yu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.16336v3</id>\n    <title>Neural Atlas Graphs for Dynamic Scene Decomposition and Editing</title>\n    <updated>2025-11-17T13:07:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.16336v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.16336v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Learning editable high-resolution scene representations for dynamic scenes is an open problem with applications across the domains from autonomous driving to creative editing - the most successful approaches today make a trade-off between editability and supporting scene complexity: neural atlases represent dynamic scenes as two deforming image layers, foreground and background, which are editable in 2D, but break down when multiple objects occlude and interact. In contrast, scene graph models make use of annotated data such as masks and bounding boxes from autonomous-driving datasets to capture complex 3D spatial relationships, but their implicit volumetric node representations are challenging to edit view-consistently. We propose Neural Atlas Graphs (NAGs), a hybrid high-resolution scene representation, where every graph node is a view-dependent neural atlas, facilitating both 2D appearance editing and 3D ordering and positioning of scene elements. Fit at test-time, NAGs achieve state-of-the-art quantitative results on the Waymo Open Dataset - by 5 dB PSNR increase compared to existing methods - and make environmental editing possible in high resolution and visual quality - creating counterfactual driving scenarios with new backgrounds and edited vehicle appearance. We find that the method also generalizes beyond driving scenes and compares favorably - by more than 7 dB in PSNR - to recent matting and video editing baselines on the DAVIS video dataset with a diverse set of human and animal-centric scenes.\n  Project Page: https://princeton-computational-imaging.github.io/nag/</summary>\n    <category term=\"cs.GR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-19T18:24:41Z</published>\n    <arxiv:primary_category term=\"cs.GR\"/>\n    <author>\n      <name>Jan Philipp Schneider</name>\n    </author>\n    <author>\n      <name>Pratik Singh Bisht</name>\n    </author>\n    <author>\n      <name>Ilya Chugunov</name>\n    </author>\n    <author>\n      <name>Andreas Kolb</name>\n    </author>\n    <author>\n      <name>Michael Moeller</name>\n    </author>\n    <author>\n      <name>Felix Heide</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.15730v1</id>\n    <title>A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation</title>\n    <updated>2025-09-19T08:01:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.15730v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.15730v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Robotic process automation (RPA) is a lightweight approach to automating business processes using software robots that emulate user actions at the graphical user interface level. While RPA has gained popularity for its cost-effective and timely automation of rule-based, well-structured tasks, its symbolic nature has inherent limitations when approaching more complex tasks currently performed by human agents. Machine learning concepts enabling intelligent RPA provide an opportunity to broaden the range of automatable tasks. In this paper, we conduct a literature review to explore the connections between RPA and machine learning and organize the joint concept intelligent RPA into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML integration and RPA-ML interaction. Together, they comprise eight dimensions: architecture and ecosystem, capabilities, data basis, intelligence level, and technical depth of integration as well as deployment environment, lifecycle phase, and user-robot relation.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-19T08:01:27Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <arxiv:journal_ref>Business Process Management Forum. BPM 2024. Lecture Notes in Business Information Processing, vol 526. pp. 319-336</arxiv:journal_ref>\n    <author>\n      <name>Lukas Laakmann</name>\n    </author>\n    <author>\n      <name>Seyyid A. Ciftci</name>\n    </author>\n    <author>\n      <name>Christian Janiesch</name>\n    </author>\n    <arxiv:doi>10.1007/978-3-031-70418-5_19</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1007/978-3-031-70418-5_19\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.15541v1</id>\n    <title>Stress Testing Deliberative Alignment for Anti-Scheming Training</title>\n    <updated>2025-09-19T02:49:56Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.15541v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.15541v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Highly capable AI systems could secretly pursue misaligned goals -- what we call \"scheming\". Because a scheming AI would deliberately try to hide its misaligned goals and actions, measuring and mitigating scheming requires different strategies than are typically used in ML. We propose that assessing anti-scheming interventions requires at least (1) testing propensity to scheme on far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming is driven by situational awareness, and (3) checking for robustness to pre-existing misaligned goals. We use a broad category of \"covert actions\" -- such as secretly breaking rules or intentionally underperforming in tests -- as a proxy for scheming, and design evaluations for covert actions. We then stress-test deliberative alignment as a case study for anti-scheming. Across 26 OOD evaluations (180+ environments), deliberative alignment reduces covert action rates (OpenAI o3: 13%-&gt;0.4%) but does not fully eliminate them. Our mitigation is also able to largely stop agents from pursuing a hidden goal previously trained into the model, but we still find misbehavior after additional red-teaming. We find that models' chain-of-thought (CoT) often demonstrates awareness of being evaluated for alignment, and show causal evidence that this awareness decreases covert behavior, while unawareness increases it. Therefore, we cannot exclude that the observed reductions in covert action rates are at least partially driven by situational awareness. While we rely on human-legible CoT for training, studying situational awareness, and demonstrating clear evidence of misalignment, our ability to rely on this degrades as models continue to depart from reasoning in standard English. We encourage research into alignment mitigations for scheming and their assessment, especially for the adversarial case of deceptive alignment, which this paper does not address.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-19T02:49:56Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Bronson Schoen</name>\n    </author>\n    <author>\n      <name>Evgenia Nitishinskaya</name>\n    </author>\n    <author>\n      <name>Mikita Balesni</name>\n    </author>\n    <author>\n      <name>Axel Højmark</name>\n    </author>\n    <author>\n      <name>Felix Hofstätter</name>\n    </author>\n    <author>\n      <name>Jérémy Scheurer</name>\n    </author>\n    <author>\n      <name>Alexander Meinke</name>\n    </author>\n    <author>\n      <name>Jason Wolfe</name>\n    </author>\n    <author>\n      <name>Teun van der Weij</name>\n    </author>\n    <author>\n      <name>Alex Lloyd</name>\n    </author>\n    <author>\n      <name>Nicholas Goldowsky-Dill</name>\n    </author>\n    <author>\n      <name>Angela Fan</name>\n    </author>\n    <author>\n      <name>Andrei Matveiakin</name>\n    </author>\n    <author>\n      <name>Rusheb Shah</name>\n    </author>\n    <author>\n      <name>Marcus Williams</name>\n    </author>\n    <author>\n      <name>Amelia Glaese</name>\n    </author>\n    <author>\n      <name>Boaz Barak</name>\n    </author>\n    <author>\n      <name>Wojciech Zaremba</name>\n    </author>\n    <author>\n      <name>Marius Hobbhahn</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.15291v1</id>\n    <title>The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI</title>\n    <updated>2025-09-18T17:24:08Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.15291v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.15291v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart transportation networks has increased significantly in the last few years. Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to be a very promising approach by several authors. However, a problem with using Reinforcement Learning in Traffic Signal Control is the reliability of the trained RL agents due to the dynamically changing distribution of the input data with respect to the distribution of the data used for training. This presents a major challenge and a reliability problem for the trained network of AI agents and could have very undesirable and even detrimental consequences if a suitable solution is not found. Several researchers have tried to address this problem using different approaches. In particular, Meta Reinforcement Learning (Meta RL) promises to be an effective solution. In this paper, we evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and show that, while under certain conditions MetaLight can indeed lead to reasonably good results, under some other conditions it might not perform well (with errors of up to 22%), suggesting that Meta RL schemes are often not robust enough and can even pose major reliability problems.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-18T17:24:08Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Federico Taschin</name>\n    </author>\n    <author>\n      <name>Abderrahmane Lazaraq</name>\n    </author>\n    <author>\n      <name>Ozan K. Tonguz</name>\n    </author>\n    <author>\n      <name>Inci Ozgunes</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.13527v1</id>\n    <title>Meta-Learning Linear Models for Molecular Property Prediction</title>\n    <updated>2025-09-16T20:41:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.13527v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.13527v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Chemists in search of structure-property relationships face great challenges due to limited high quality, concordant datasets. Machine learning (ML) has significantly advanced predictive capabilities in chemical sciences, but these modern data-driven approaches have increased the demand for data. In response to the growing demand for explainable AI (XAI) and to bridge the gap between predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear Algorithm for Meta-Learning that preserves interpretability while improving the prediction accuracy across multiple properties. While most approaches treat each chemical prediction task in isolation, LAMeL leverages a meta-learning framework to identify shared model parameters across related tasks, even if those tasks do not share data, allowing it to learn a common functional manifold that serves as a more informed starting point for new unseen tasks. Our method delivers performance improvements ranging from 1.1- to 25-fold over standard ridge regression, depending on the domain of the dataset. While the degree of performance enhancement varies across tasks, LAMeL consistently outperforms or matches traditional linear methods, making it a reliable tool for chemical property prediction where both accuracy and interpretability are critical.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"physics.chem-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-16T20:41:45Z</published>\n    <arxiv:comment>26 pages, 16 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Yulia Pimonova</name>\n    </author>\n    <author>\n      <name>Michael G. Taylor</name>\n    </author>\n    <author>\n      <name>Alice Allen</name>\n    </author>\n    <author>\n      <name>Ping Yang</name>\n    </author>\n    <author>\n      <name>Nicholas Lubbers</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.14279v1</id>\n    <title>Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization</title>\n    <updated>2025-09-16T11:08:30Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.14279v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.14279v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-16T11:08:30Z</published>\n    <arxiv:comment>62 pages, 10 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Robert Tjarko Lange</name>\n    </author>\n    <author>\n      <name>Qi Sun</name>\n    </author>\n    <author>\n      <name>Aaditya Prasad</name>\n    </author>\n    <author>\n      <name>Maxence Faldor</name>\n    </author>\n    <author>\n      <name>Yujin Tang</name>\n    </author>\n    <author>\n      <name>David Ha</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.12838v2</id>\n    <title>Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models</title>\n    <updated>2025-09-30T12:31:07Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.12838v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.12838v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>It is crucial to efficiently execute instructions such as \"Find an apple and a banana\" or \"Get ready for a field trip,\" which require searching for multiple objects or understanding context-dependent commands. This study addresses the challenging problem of determining which robot should be assigned to which part of a task when each robot possesses different situational on-site knowledge-specifically, spatial concepts learned from the area designated to it by the user. We propose a task planning framework that leverages large language models (LLMs) and spatial concepts to decompose natural language instructions into subtasks and allocate them to multiple robots. We designed a novel few-shot prompting strategy that enables LLMs to infer required objects from ambiguous commands and decompose them into appropriate subtasks. In our experiments, the proposed method achieved 47/50 successful assignments, outperforming random (28/50) and commonsense-based assignment (26/50). Furthermore, we conducted qualitative evaluations using two actual mobile manipulators. The results demonstrated that our framework could handle instructions, including those involving ad hoc categories such as \"Get ready for a field trip,\" by successfully performing task decomposition, assignment, sequential planning, and execution.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-16T09:00:25Z</published>\n    <arxiv:comment>Submitted to AROB-ISBC 2026 (Journal Track option)</arxiv:comment>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Kento Murata</name>\n    </author>\n    <author>\n      <name>Shoichi Hasegawa</name>\n    </author>\n    <author>\n      <name>Tomochika Ishikawa</name>\n    </author>\n    <author>\n      <name>Yoshinobu Hagiwara</name>\n    </author>\n    <author>\n      <name>Akira Taniguchi</name>\n    </author>\n    <author>\n      <name>Lotfi El Hafi</name>\n    </author>\n    <author>\n      <name>Tadahiro Taniguchi</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.13372v1</id>\n    <title>Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging</title>\n    <updated>2025-09-16T04:47:25Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.13372v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.13372v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Fontan palliation for univentricular congenital heart disease progresses to hemodynamic failure with complex flow patterns poorly characterized by conventional 2D imaging. Current assessment relies on fluoroscopic angiography, providing limited 3D geometric information essential for computational fluid dynamics (CFD) analysis and surgical planning.\n  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash (2.5B parameters) for systematic, iterative processing of fluoroscopic angiograms through transformer-based neural architecture. The pipeline encompasses medical image preprocessing, vascular segmentation, contrast enhancement, artifact removal, and virtual hemodynamic flow visualization within 2D projections. Final views were processed through Tencent's Hunyuan3D-2mini (384M parameters) for stereolithography file generation.\n  The pipeline successfully generated geometrically optimized 2D projections from single-view angiograms after 16 processing steps using a custom web interface. Initial iterations contained hallucinated vascular features requiring iterative refinement to achieve anatomically faithful representations. Final projections demonstrated accurate preservation of complex Fontan geometry with enhanced contrast suitable for 3D conversion. AI-generated virtual flow visualization identified stagnation zones in central connections and flow patterns in branch arteries. Complete processing required under 15 minutes with second-level API response times.\n  This approach demonstrates clinical feasibility of generating CFD-suitable geometries from routine angiographic data, enabling 3D generation and rapid virtual flow visualization for cursory insights prior to full CFD simulation. While requiring refinement cycles for accuracy, this establishes foundation for democratizing advanced geometric and hemodynamic analysis using readily available imaging data.</summary>\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.ET\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"q-bio.QM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-16T04:47:25Z</published>\n    <arxiv:primary_category term=\"eess.IV\"/>\n    <author>\n      <name>Prahlad G Menon</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.12443v3</id>\n    <title>From Legacy Fortran to Portable Kokkos: An Autonomous Agentic AI Workflow</title>\n    <updated>2025-11-17T03:45:19Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.12443v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.12443v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Scientific applications continue to rely on legacy Fortran codebases originally developed for homogeneous, CPU-based systems. As High-Performance Computing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many accelerators lack native Fortran bindings, creating an urgent need to modernize legacy codes for portability. Frameworks like Kokkos provide performance portability and a single-source C++ abstraction, but manual Fortran-to-Kokkos porting demands significant expertise and time. Large language models (LLMs) have shown promise in source-to-source code generation, yet their use in fully autonomous workflows for translating and optimizing parallel code remains largely unexplored, especially for performance portability across diverse hardware. This paper presents an agentic AI workflow where specialized LLM \"agents\" collaborate to translate, validate, compile, run, test, debug, and optimize Fortran kernels into portable Kokkos C++ programs. Results show the pipeline modernizes a range of benchmark kernels, producing performance-portable Kokkos codes across hardware partitions. Paid OpenAI models such as GPT-5 and o4-mini-high executed the workflow for only a few U.S. dollars, generating optimized codes that surpassed Fortran baselines, whereas open-source models like Llama4-Maverick often failed to yield functional codes. This work demonstrates the feasibility of agentic AI for Fortran-to-Kokkos transformation and offers a pathway for autonomously modernizing legacy scientific applications to run portably and efficiently on diverse supercomputers. It further highlights the potential of LLM-driven agentic systems to perform structured, domain-specific reasoning tasks in scientific and systems-oriented applications.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-15T20:50:15Z</published>\n    <arxiv:comment>12 pages, 6 figures, 7 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Sparsh Gupta</name>\n    </author>\n    <author>\n      <name>Kamalavasan Kamalakkannan</name>\n    </author>\n    <author>\n      <name>Maxim Moraru</name>\n    </author>\n    <author>\n      <name>Galen Shipman</name>\n    </author>\n    <author>\n      <name>Patrick Diehl</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.12048v1</id>\n    <title>Hi-DARTS: Hierarchical Dynamically Adapting Reinforcement Trading System</title>\n    <updated>2025-09-15T15:31:47Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.12048v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.12048v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Conventional autonomous trading systems struggle to balance computational efficiency and market responsiveness due to their fixed operating frequency. We propose Hi-DARTS, a hierarchical multi-agent reinforcement learning framework that addresses this trade-off. Hi-DARTS utilizes a meta-agent to analyze market volatility and dynamically activate specialized Time Frame Agents for high-frequency or low-frequency trading as needed. During back-testing on AAPL stock from January 2024 to May 2025, Hi-DARTS yielded a cumulative return of 25.17% with a Sharpe Ratio of 0.75. This performance surpasses standard benchmarks, including a passive buy-and-hold strategy on AAPL (12.19% return) and the S&amp;P 500 ETF (SPY) (20.01% return). Our work demonstrates that dynamic, hierarchical agents can achieve superior risk-adjusted returns while maintaining high computational efficiency.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-15T15:31:47Z</published>\n    <arxiv:comment>Accepted paper at International Conference on ICT Convergence 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Hoon Sagong</name>\n    </author>\n    <author>\n      <name>Heesu Kim</name>\n    </author>\n    <author>\n      <name>Hanbeen Hong</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.10596v1</id>\n    <title>GenAI Voice Mode in Programming Education</title>\n    <updated>2025-09-12T15:25:08Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.10596v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.10596v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Real-time voice interfaces using multimodal Generative AI (GenAI) can potentially address the accessibility needs of novice programmers with disabilities (e.g., related to vision). Yet, little is known about how novices interact with GenAI tools and their feedback quality in the form of audio output. This paper analyzes audio dialogues from nine 9th-grade students using a voice-enabled tutor (powered by OpenAI's Realtime API) in an authentic classroom setting while learning Python. We examined the students' voice prompts and AI's responses (1210 messages) by using qualitative coding. We also gathered students' perceptions via the Partner Modeling Questionnaire. The GenAI Voice Tutor primarily offered feedback on mistakes and next steps, but its correctness was limited (71.4% correct out of 416 feedback outputs). Quality issues were observed, particularly when the AI attempted to utter programming code elements. Students used the GenAI voice tutor primarily for debugging. They perceived it as competent, only somewhat human-like, and flexible. The present study is the first to explore the interaction dynamics of real-time voice GenAI tutors and novice programmers, informing future educational tool design and potentially addressing accessibility needs of diverse learners.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-12T15:25:08Z</published>\n    <arxiv:comment>Accepted for the 25th International Conference on Computing Education Research (Koli Calling '25)</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Sven Jacobs</name>\n    </author>\n    <author>\n      <name>Natalie Kiesler</name>\n    </author>\n    <arxiv:doi>10.1145/3769994.3770001</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1145/3769994.3770001\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.09751v1</id>\n    <title>Meta-Learning Reinforcement Learning for Crypto-Return Prediction</title>\n    <updated>2025-09-11T14:20:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.09751v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.09751v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Predicting cryptocurrency returns is notoriously difficult: price movements are driven by a fast-shifting blend of on-chain activity, news flow, and social sentiment, while labeled training data are scarce and expensive. In this paper, we present Meta-RL-Crypto, a unified transformer-based architecture that unifies meta-learning and reinforcement learning (RL) to create a fully self-improving trading agent. Starting from a vanilla instruction-tuned LLM, the agent iteratively alternates between three roles-actor, judge, and meta-judge-in a closed-loop architecture. This learning process requires no additional human supervision. It can leverage multimodal market inputs and internal preference feedback. The agent in the system continuously refines both the trading policy and evaluation criteria. Experiments across diverse market regimes demonstrate that Meta-RL-Crypto shows good performance on the technical indicators of the real market and outperforming other LLM-based baselines.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-11T14:20:45Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Junqiao Wang</name>\n    </author>\n    <author>\n      <name>Zhaoyang Guan</name>\n    </author>\n    <author>\n      <name>Guanyu Liu</name>\n    </author>\n    <author>\n      <name>Tianze Xia</name>\n    </author>\n    <author>\n      <name>Xianzhi Li</name>\n    </author>\n    <author>\n      <name>Shuo Yin</name>\n    </author>\n    <author>\n      <name>Xinyuan Song</name>\n    </author>\n    <author>\n      <name>Chuhan Cheng</name>\n    </author>\n    <author>\n      <name>Tianyu Shi</name>\n    </author>\n    <author>\n      <name>Alex Lee</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.09272v1</id>\n    <title>Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs</title>\n    <updated>2025-09-11T09:02:15Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.09272v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.09272v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Knowledge graphs, a powerful tool for structuring information through relational triplets, have recently become the new front-runner in enhancing question-answering systems. While traditional Retrieval Augmented Generation (RAG) approaches are proficient in fact-based and local context-based extraction from concise texts, they encounter limitations when addressing the thematic and holistic understanding of complex, extensive texts, requiring a deeper analysis of both text and context. This paper presents a comprehensive technical comparative study of three different methodologies for constructing knowledge graph triplets and integrating them with Large Language Models (LLMs) for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all leveraging open source technologies. We evaluate the effectiveness, feasibility, and adaptability of these methods by analyzing their capabilities, state of development, and their impact on the performance of LLM-based question answering. Experimental results indicate that while OpenIE provides the most comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning abilities among the three. We conclude with a discussion on the strengths and limitations of each method and provide insights into future directions for improving knowledge graph-based question answering.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-11T09:02:15Z</published>\n    <arxiv:comment>46 pages, 4 figures, 17 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Vaibhav Chaudhary</name>\n    </author>\n    <author>\n      <name>Neha Soni</name>\n    </author>\n    <author>\n      <name>Narotam Singh</name>\n    </author>\n    <author>\n      <name>Amita Kapoor</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.08535v1</id>\n    <title>Agents of Discovery</title>\n    <updated>2025-09-10T12:25:13Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.08535v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.08535v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The substantial data volumes encountered in modern particle physics and other domains of fundamental physics research allow (and require) the use of increasingly complex data analysis tools and workflows. While the use of machine learning (ML) tools for data analysis has recently proliferated, these tools are typically special-purpose algorithms that rely, for example, on encoded physics knowledge to reach optimal performance. In this work, we investigate a new and orthogonal direction: Using recent progress in large language models (LLMs) to create a team of agents -- instances of LLMs with specific subtasks -- that jointly solve data analysis-based research problems in a way similar to how a human researcher might: by creating code to operate standard tools and libraries (including ML systems) and by building on results of previous iterations. If successful, such agent-based systems could be deployed to automate routine analysis components to counteract the increasing complexity of modern tool chains. To investigate the capabilities of current-generation commercial LLMs, we consider the task of anomaly detection via the publicly available and highly-studied LHC Olympics dataset. Several current models by OpenAI (GPT-4o, o4-mini, GPT-4.1, and GPT-5) are investigated and their stability tested. Overall, we observe the capacity of the agent-based system to solve this data analysis problem. The best agent-created solutions mirror the performance of human state-of-the-art results.</summary>\n    <category term=\"hep-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"hep-ex\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"physics.data-an\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-10T12:25:13Z</published>\n    <arxiv:primary_category term=\"hep-ph\"/>\n    <author>\n      <name>Sascha Diefenbacher</name>\n    </author>\n    <author>\n      <name>Anna Hallin</name>\n    </author>\n    <author>\n      <name>Gregor Kasieczka</name>\n    </author>\n    <author>\n      <name>Michael Krämer</name>\n    </author>\n    <author>\n      <name>Anne Lauscher</name>\n    </author>\n    <author>\n      <name>Tim Lukas</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06224v1</id>\n    <title>Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools</title>\n    <updated>2025-09-10T05:35:38Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.06224v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.06224v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>With recent advancements in multi-agent generative AI (Gen AI), technology organizations like Microsoft are adopting these complex tools, redefining AI agents as active collaborators in complex workflows rather than as passive tools. In this study, we investigated how early adopters and developers conceptualize multi-agent Gen AI tools, focusing on how they understand human-AI collaboration mechanisms, general collaboration dynamics, and transparency in the context of AI tools. We conducted semi-structured interviews with 13 developers, all early adopters of multi-agent Gen AI technology who work at Microsoft. Our findings revealed that these early adopters conceptualize multi-agent systems as \"teams\" of specialized role-based and task-based agents, such as assistants or reviewers, structured similar to human collaboration models and ranging from AI-dominant to AI-assisted, user-controlled interactions. We identified key challenges, including error propagation, unpredictable and unproductive agent loop behavior, and the need for clear communication to mitigate the layered transparency issues. Early adopters' perspectives about the role of transparency underscored its importance as a way to build trust, verify and trace errors, and prevent misuse, errors, and leaks. The insights and design considerations we present contribute to CSCW research about collaborative mechanisms with capabilities ranging from AI-dominant to AI-assisted interactions, transparency and oversight strategies in human-agent and agent-agent interactions, and how humans make sense of these multi-agent systems as dynamic, role-diverse collaborators which are customizable for diverse needs and workflows. We conclude with future research directions that extend CSCW approaches to the design of inter-agent and human mediation interactions.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-10T05:35:38Z</published>\n    <arxiv:comment>19 pages, 1 table, 2 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Suchismita Naik</name>\n    </author>\n    <author>\n      <name>Austin L. Toombs</name>\n    </author>\n    <author>\n      <name>Amanda Snellinger</name>\n    </author>\n    <author>\n      <name>Scott Saponas</name>\n    </author>\n    <author>\n      <name>Amanda K. Hall</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.08194v1</id>\n    <title>Prescribe-then-Select: Adaptive Policy Selection for Contextual Stochastic Optimization</title>\n    <updated>2025-09-09T23:56:16Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.08194v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.08194v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We address the problem of policy selection in contextual stochastic optimization (CSO), where covariates are available as contextual information and decisions must satisfy hard feasibility constraints. In many CSO settings, multiple candidate policies--arising from different modeling paradigms--exhibit heterogeneous performance across the covariate space, with no single policy uniformly dominating. We propose Prescribe-then-Select (PS), a modular framework that first constructs a library of feasible candidate policies and then learns a meta-policy to select the best policy for the observed covariates. We implement the meta-policy using ensembles of Optimal Policy Trees trained via cross-validation on the training set, making policy choice entirely data-driven. Across two benchmark CSO problems--single-stage newsvendor and two-stage shipment planning--PS consistently outperforms the best single policy in heterogeneous regimes of the covariate space and converges to the dominant policy when such heterogeneity is absent. All the code to reproduce the results can be found at https://anonymous.4open.science/r/Prescribe-then-Select-TMLR.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T23:56:16Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Caio de Prospero Iglesias</name>\n    </author>\n    <author>\n      <name>Kimberly Villalobos Carballo</name>\n    </author>\n    <author>\n      <name>Dimitris Bertsimas</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07969v1</id>\n    <title>Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search</title>\n    <updated>2025-09-09T17:54:21Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07969v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07969v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advances in large multimodal models have leveraged image-based tools with reinforcement learning to tackle visual problems. However, existing open-source approaches often exhibit monotonous reasoning patterns and allow only a limited number of interaction turns, making them inadequate for difficult tasks that require trial-and-error exploration. In this work, we address this limitation by scaling up tool-based interactions and introduce Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of steps -- and achieves state-of-the-art performance on challenging visual search tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key components. First, we construct the Visual Probe Dataset, a collection of thousands of challenging visual search problems designed for exploratory reasoning. Second, we develop an iterative data collection pipeline to obtain cold-start trajectories that exhibit diverse reasoning patterns, including depth-first search, trial-and-error, and goal maintenance. Third, we propose an over-turn masking strategy that prevents penalization of over-turn responses (those that hit the maximum number of turns) during reinforcement learning, thereby balancing training-time efficiency with test-time scalability. Despite training with an upper bound of only six interaction turns, our model generates trajectories that naturally scale to tens of turns at inference time, with accuracy improving as the number of turns increases. Extensive experiments demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking paths, effectively solving challenging visual search problems.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T17:54:21Z</published>\n    <arxiv:comment>Code, datasets, models are available at https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Xin Lai</name>\n    </author>\n    <author>\n      <name>Junyi Li</name>\n    </author>\n    <author>\n      <name>Wei Li</name>\n    </author>\n    <author>\n      <name>Tao Liu</name>\n    </author>\n    <author>\n      <name>Tianjian Li</name>\n    </author>\n    <author>\n      <name>Hengshuang Zhao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07933v1</id>\n    <title>Breaking Android with AI: A Deep Dive into LLM-Powered Exploitation</title>\n    <updated>2025-09-09T17:17:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07933v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07933v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The rapid evolution of Artificial Intelligence (AI) and Large Language Models (LLMs) has opened up new opportunities in the area of cybersecurity, especially in the exploitation automation landscape and penetration testing. This study explores Android penetration testing automation using LLM-based tools, especially PentestGPT, to identify and execute rooting techniques. Through a comparison of the traditional manual rooting process and exploitation methods produced using AI, this study evaluates the efficacy, reliability, and scalability of automated penetration testing in achieving high-level privilege access on Android devices. With the use of an Android emulator (Genymotion) as the testbed, we fully execute both traditional and exploit-based rooting methods, automating the process using AI-generated scripts. Secondly, we create a web application by integrating OpenAI's API to facilitate automated script generation from LLM-processed responses. The research focuses on the effectiveness of AI-enabled exploitation by comparing automated and manual penetration testing protocols, by determining LLM weaknesses and strengths along the way. We also provide security suggestions of AI-enabled exploitation, including ethical factors and potential misuse. The findings exhibit that while LLMs can significantly streamline the workflow of exploitation, they need to be controlled by humans to ensure accuracy and ethical application. This study adds to the increasing body of literature on AI-powered cybersecurity and its effect on ethical hacking, security research, and mobile device security.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T17:17:06Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Wanni Vidulige Ishan Perera</name>\n    </author>\n    <author>\n      <name>Xing Liu</name>\n    </author>\n    <author>\n      <name>Fan liang</name>\n    </author>\n    <author>\n      <name>Junyi Zhang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07506v1</id>\n    <title>Astra: A Multi-Agent System for GPU Kernel Performance Optimization</title>\n    <updated>2025-09-09T08:39:50Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07506v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07506v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization.</summary>\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T08:39:50Z</published>\n    <arxiv:primary_category term=\"cs.DC\"/>\n    <author>\n      <name>Anjiang Wei</name>\n    </author>\n    <author>\n      <name>Tianran Sun</name>\n    </author>\n    <author>\n      <name>Yogesh Seenichamy</name>\n    </author>\n    <author>\n      <name>Hang Song</name>\n    </author>\n    <author>\n      <name>Anne Ouyang</name>\n    </author>\n    <author>\n      <name>Azalia Mirhoseini</name>\n    </author>\n    <author>\n      <name>Ke Wang</name>\n    </author>\n    <author>\n      <name>Alex Aiken</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07475v1</id>\n    <title>HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention</title>\n    <updated>2025-09-09T07:58:46Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07475v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07475v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Detecting content that contradicts or is unsupported by a given source text is a critical challenge for the safe deployment of generative language models. We introduce HALT-RAG, a post-hoc verification system designed to identify hallucinations in the outputs of Retrieval-Augmented Generation (RAG) pipelines. Our flexible and task-adaptable framework uses a universal feature set derived from an ensemble of two frozen, off-the-shelf Natural Language Inference (NLI) models and lightweight lexical signals. These features are used to train a simple, calibrated, and task-adapted meta-classifier. Using a rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and produce unbiased estimates, we evaluate our system on the HaluEval benchmark. By pairing our universal feature set with a lightweight, task-adapted classifier and a precision-constrained decision policy, HALT-RAG achieves strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA, and dialogue tasks, respectively. The system's well-calibrated probabilities enable a practical abstention mechanism, providing a reliable tool for balancing model performance with safety requirements.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T07:58:46Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Saumya Goswami</name>\n    </author>\n    <author>\n      <name>Siddharth Kurra</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.12238v1</id>\n    <title>Interpretable Data Mining of Follicular Thyroid Cancer Ultrasound Features Using Enhanced Association Rules</title>\n    <updated>2025-09-09T03:02:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.12238v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.12238v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Purpose: Thyroid cancer has been a common cancer. Papillary thyroid cancer and follicular thyroid cancer are the two most common types of thyroid cancer. Follicular thyroid cancer lacks distinctive ultrasound signs and is more difficult to diagnose preoperatively than the more prevalent papillary thyroid cancer, and the clinical studies associated with it are less well established. We aimed to analyze the clinical data of follicular thyroid cancer based on a novel data mining tool to identify some clinical indications that may help in preoperative diagnosis. Methods: We performed a retrospective analysis based on case data collected by the Department of General Surgery of Peking University Third Hospital between 2010 and 2023. Unlike traditional statistical methods, we improved the association rule mining, a classical data mining method, and proposed new analytical metrics reflecting the malignant association between clinical indications and cancer with the help of the idea of SHAP method in interpretable machine learning. Results: The dataset was preprocessed to contain 1673 cases (in terms of nodes rather than patients), of which 1414 were benign and 259 were malignant nodes. Our analysis pointed out that in addition to some common indicators (e.g., irregular or lobulated nodal margins, uneven thickness halo, hypoechogenicity), there were also some indicators with strong malignant associations, such as nodule-in-nodule pattern, trabecular pattern, and low TSH scores. In addition, our results suggest that the combination of Hashimoto's thyroiditis may also have a strong malignant association. Conclusion: In the preoperative diagnosis of nodules suspected of follicular thyroid cancer, multiple clinical indications should be considered for a more accurate diagnosis. The diverse malignant associations identified in our study may serve as a reference for clinicians in related fields.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T03:02:45Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Songlin Zhou</name>\n    </author>\n    <author>\n      <name>Tao Zhou</name>\n    </author>\n    <author>\n      <name>Xin Li</name>\n    </author>\n    <author>\n      <name>Stephen Shing-Toung Yau</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07325v2</id>\n    <title>CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement Estimation</title>\n    <updated>2025-11-06T18:38:30Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07325v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07325v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The National Comprehensive Cancer Network (NCCN) provides evidence-based guidelines for cancer treatment. Translating complex patient presentations into guideline-compliant treatment recommendations is time-intensive, requires specialized expertise, and is prone to error. Advances in large language model (LLM) capabilities promise to reduce the time required to generate treatment recommendations and improve accuracy. We present an LLM agent-based approach to automatically generate guideline-concordant treatment trajectories for patients with non-small cell lung cancer (NSCLC). Our contributions are threefold. First, we construct a novel longitudinal dataset of 121 cases of NSCLC patients that includes clinical encounters, diagnostic results, and medical histories, each expertly annotated with the corresponding NCCN guideline trajectories by board-certified oncologists. Second, we demonstrate that existing LLMs possess domain-specific knowledge that enables high-quality proxy benchmark generation for both model development and evaluation, achieving strong correlation (Spearman coefficient r=0.88, RMSE = 0.08) with expert-annotated benchmarks. Third, we develop a hybrid approach combining expensive human annotations with model consistency information to create both the agent framework that predicts the relevant guidelines for a patient, as well as a meta-classifier that verifies prediction accuracy with calibrated confidence scores for treatment recommendations (AUROC=0.800), a critical capability for communicating the accuracy of outputs, custom-tailoring tradeoffs in performance, and supporting regulatory compliance. This work establishes a framework for clinically viable LLM-based guideline adherence systems that balance accuracy, interpretability, and regulatory requirements while reducing annotation costs, providing a scalable pathway toward automated clinical decision support.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-09T01:49:29Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Alyssa Unell</name>\n    </author>\n    <author>\n      <name>Noel C. F. Codella</name>\n    </author>\n    <author>\n      <name>Sam Preston</name>\n    </author>\n    <author>\n      <name>Peniel Argaw</name>\n    </author>\n    <author>\n      <name>Wen-wai Yim</name>\n    </author>\n    <author>\n      <name>Zelalem Gero</name>\n    </author>\n    <author>\n      <name>Cliff Wong</name>\n    </author>\n    <author>\n      <name>Rajesh Jena</name>\n    </author>\n    <author>\n      <name>Eric Horvitz</name>\n    </author>\n    <author>\n      <name>Amanda K. Hall</name>\n    </author>\n    <author>\n      <name>Ruican Rachel Zhong</name>\n    </author>\n    <author>\n      <name>Jiachen Li</name>\n    </author>\n    <author>\n      <name>Shrey Jain</name>\n    </author>\n    <author>\n      <name>Mu Wei</name>\n    </author>\n    <author>\n      <name>Matthew Lungren</name>\n    </author>\n    <author>\n      <name>Hoifung Poon</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.09711v1</id>\n    <title>Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry</title>\n    <updated>2025-09-07T20:57:24Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.09711v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.09711v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) hold great promise in enhancing psychiatric practice, from improving diagnostic accuracy to streamlining clinical documentation and therapeutic support. However, existing evaluation resources heavily rely on small clinical interview corpora, social media posts, or synthetic dialogues, which limits their clinical validity and fails to capture the full complexity of psychiatric reasoning. In this work, we introduce PsychiatryBench, a rigorously curated benchmark grounded exclusively in authoritative, expert-validated psychiatric textbooks and casebooks. PsychiatryBench comprises eleven distinct question-answering tasks ranging from diagnostic reasoning and treatment planning to longitudinal follow-up, management planning, clinical approach, sequential case analysis, and multiple-choice/extended matching formats totaling over 5,300 expert-annotated items. We evaluate a diverse set of frontier LLMs (including Google Gemini, DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models (e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an \"LLM-as-judge\" similarity scoring framework. Our results reveal substantial gaps in clinical consistency and safety, particularly in multi-turn follow-up and management tasks, underscoring the need for specialized model tuning and more robust evaluation paradigms. PsychiatryBench offers a modular, extensible platform for benchmarking and improving LLM performance in high-stakes mental health applications.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-07T20:57:24Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Aya E. Fouda</name>\n    </author>\n    <author>\n      <name>Abdelrahamn A. Hassan</name>\n    </author>\n    <author>\n      <name>Radwa J. Hanafy</name>\n    </author>\n    <author>\n      <name>Mohammed E. Fouda</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.07019v1</id>\n    <title>An efficient deep reinforcement learning environment for flexible job-shop scheduling</title>\n    <updated>2025-09-07T02:50:09Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.07019v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.07019v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial optimization problem that has a wide-range of applications in the real world. In order to generate fast and accurate scheduling solutions for FJSP, various deep reinforcement learning (DRL) scheduling methods have been developed. However, these methods are mainly focused on the design of DRL scheduling Agent, overlooking the modeling of DRL environment. This paper presents a simple chronological DRL environment for FJSP based on discrete event simulation and an end-to-end DRL scheduling model is proposed based on the proximal policy optimization (PPO). Furthermore, a short novel state representation of FJSP is proposed based on two state variables in the scheduling environment and a novel comprehensible reward function is designed based on the scheduling area of machines. Experimental results on public benchmark instances show that the performance of simple priority dispatching rules (PDR) is improved in our scheduling environment and our DRL scheduling model obtains competing performance compared with OR-Tools, meta-heuristic, DRL and PDR scheduling methods.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-07T02:50:09Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Xinquan Wu</name>\n    </author>\n    <author>\n      <name>Xuefeng Yan</name>\n    </author>\n    <author>\n      <name>Mingqiang Wei</name>\n    </author>\n    <author>\n      <name>Donghai Guan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.05398v1</id>\n    <title>Unmasking COVID-19 Vulnerability in Nigeria: Mapping Risks Beyond Urban Hotspots</title>\n    <updated>2025-09-05T14:45:01Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.05398v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.05398v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The COVID-19 pandemic has presented significant challenges in Nigeria's public health systems since the first case reported on February 27, 2020. This study investigates key factors that contribute to state vulnerability, quantifying them through a composite risk score integrating population density (weight 0.2), poverty (0.4), access to healthcare (0.3), and age risk (0.1), adjusted by normalized case rates per 100,000. States were categorized into low-, medium-, and high-density areas to analyze trends and identify hotspots using geographic information system (GIS) mapping. The findings reveal that high-density urban areas, such as Lagos, accounting for 35.4% of national cases, had the highest risk scores (Lagos: 673.47 vs. national average: 28.16). These results align with global and local studies on the spatial variability of COVID-19 in Nigeria, including international frameworks such as the CDC Social Vulnerability Index. Google Trends data highlight variations in public health awareness, serving as a supplementary analysis to contextualize vulnerability. The risk score provides a prioritization tool for policymakers to allocate testing, vaccines, and healthcare resources to high-risk areas, though data gaps and rural underreporting call for further research. This framework can extend to other infectious diseases, offering lessons for future pandemics in resource-limited settings.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-05T14:45:01Z</published>\n    <arxiv:comment>8 pages, 6 figures. Submission to NeurIPS 2025 in preparation</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Sheila Wafula</name>\n    </author>\n    <author>\n      <name>Blessed Madukoma</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.04633v3</id>\n    <title>The Physical Basis of Prediction: World Model Formation in Neural Organoids via an LLM-Generated Curriculum</title>\n    <updated>2025-11-04T06:32:42Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.04633v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.04633v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The capacity of an embodied agent to understand, predict, and interact with its environment is fundamentally contingent on an internal world model. This paper introduces a novel framework for investigating the formation and adaptation of such world models within a biological substrate: human neural organoids. We present a curriculum of three scalable, closed-loop virtual environments designed to train these biological agents and probe the underlying synaptic mechanisms of learning, such as long-term potentiation (LTP) and long-term depression (LTD). We detail the design of three distinct task environments that demand progressively more sophisticated world models for successful decision-making: (1) a conditional avoidance task for learning static state-action contingencies, (2) a one-dimensional predator-prey scenario for goal-directed interaction, and (3) a replication of the classic Pong game for modeling dynamic, continuous-time systems. For each environment, we formalize the state and action spaces, the sensory encoding and motor decoding mechanisms, and the feedback protocols based on predictable (reward) and unpredictable (punishment) stimulation, which serve to drive model refinement. In a significant methodological advance, we propose a meta-learning approach where a Large Language Model automates the generative design and optimization of experimental protocols, thereby scaling the process of environment and curriculum design. Finally, we outline a multi-modal evaluation strategy that moves beyond task performance to directly measure the physical correlates of the learned world model by quantifying synaptic plasticity at electrophysiological, cellular, and molecular levels. This work bridges the gap between model-based reinforcement learning and computational neuroscience, offering a unique platform for studying embodiment, decision-making, and the physical basis of intelligence.</summary>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"q-bio.NC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-04T19:51:00Z</published>\n    <arxiv:comment>Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA). Additionally accepted for presentation in NeurIPS 2025 Workshop: Embodied World Models for Decision Making</arxiv:comment>\n    <arxiv:primary_category term=\"cs.NE\"/>\n    <author>\n      <name>Brennen Hill</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.03990v2</id>\n    <title>Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent</title>\n    <updated>2025-09-08T07:40:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.03990v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.03990v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability. Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks. Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute. In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC). MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based). Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability. We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-04T08:18:39Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Chunlong Wu</name>\n    </author>\n    <author>\n      <name>Ye Luo</name>\n    </author>\n    <author>\n      <name>Zhibo Qu</name>\n    </author>\n    <author>\n      <name>Min Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.03845v1</id>\n    <title>Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables</title>\n    <updated>2025-09-04T03:13:11Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.03845v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.03845v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.GT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-04T03:13:11Z</published>\n    <arxiv:comment>Accepted to AAAI 2024</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Yang Chen</name>\n    </author>\n    <author>\n      <name>Xiao Lin</name>\n    </author>\n    <author>\n      <name>Bo Yan</name>\n    </author>\n    <author>\n      <name>Libo Zhang</name>\n    </author>\n    <author>\n      <name>Jiamou Liu</name>\n    </author>\n    <author>\n      <name>Neset Özkan Tan</name>\n    </author>\n    <author>\n      <name>Michael Witbrock</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.03817v1</id>\n    <title>Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning</title>\n    <updated>2025-09-04T02:06:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.03817v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.03817v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-04T02:06:06Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Wei Yang</name>\n    </author>\n    <author>\n      <name>Jesse Thomason</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.03682v1</id>\n    <title>A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games</title>\n    <updated>2025-09-03T20:05:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.03682v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.03682v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advancements in multi-agent reinforcement learning (MARL) have demonstrated its application potential in modern games. Beginning with foundational work and progressing to landmark achievements such as AlphaStar in StarCraft II and OpenAI Five in Dota 2, MARL has proven capable of achieving superhuman performance across diverse game environments through techniques like self-play, supervised learning, and deep reinforcement learning. With its growing impact, a comprehensive review has become increasingly important in this field. This paper aims to provide a thorough examination of MARL's application from turn-based two-agent games to real-time multi-agent video games including popular genres such as Sports games, First-Person Shooter (FPS) games, Real-Time Strategy (RTS) games and Multiplayer Online Battle Arena (MOBA) games. We further analyze critical challenges posed by MARL in video games, including nonstationary, partial observability, sparse rewards, team coordination, and scalability, and highlight successful implementations in games like Rocket League, Minecraft, Quake III Arena, StarCraft II, Dota 2, Honor of Kings, etc. This paper offers insights into MARL in video game AI systems, proposes a novel method to estimate game complexity, and suggests future research directions to advance MARL and its applications in game development, inspiring further innovation in this rapidly evolving field.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-03T20:05:58Z</published>\n    <arxiv:comment>IEEE Transactions on Games, 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Zhengyang Li</name>\n    </author>\n    <author>\n      <name>Qijin Ji</name>\n    </author>\n    <author>\n      <name>Xinghong Ling</name>\n    </author>\n    <author>\n      <name>Quan Liu</name>\n    </author>\n    <arxiv:doi>10.1109/TG.2025.3588809</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1109/TG.2025.3588809\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.02853v3</id>\n    <title>The Architecture of AI Transformation: Four Strategic Patterns and an Emerging Frontier</title>\n    <updated>2025-09-12T02:23:53Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.02853v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.02853v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Despite extensive investment in artificial intelligence, 95% of enterprises report no measurable profit impact from AI deployments (MIT, 2025). In this theoretical paper, we argue that this gap reflects paradigmatic lock-in that channels AI into incremental optimization rather than structural transformation. Using a cross-case analysis, we propose a 2x2 framework that reconceptualizes AI strategy along two independent dimensions: the degree of transformation achieved (incremental to transformational) and the treatment of human contribution (reduced to amplified). The framework surfaces four patterns now dominant in practice: individual augmentation, process automation, workforce substitution, and a less deployed frontier of collaborative intelligence. Evidence shows that the first three dimensions reinforce legacy work models and yield localized gains without durable value capture. Realizing collaborative intelligence requires three mechanisms: complementarity (pairing distinct human and machine strengths), co-evolution (mutual adaptation through interaction), and boundary-setting (human determination of ethical and strategic parameters). Complementarity and boundary-setting are observable in regulated and high-stakes domains; co-evolution is largely absent, which helps explain limited system-level impact. Our findings in a case study analysis illustrated that advancing toward collaborative intelligence requires material restructuring of roles, governance, and data architecture rather than additional tools. The framework reframes AI transformation as an organizational design challenge: moving from optimizing the division of labor between humans and machines to architecting their convergence, with implications for operating models, workforce development, and the future of work.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-02T21:57:58Z</published>\n    <arxiv:comment>59 pages, 2 tables, 4 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Diana A. Wolfe</name>\n    </author>\n    <author>\n      <name>Alice Choe</name>\n    </author>\n    <author>\n      <name>Fergus Kidd</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.02544v2</id>\n    <title>UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning</title>\n    <updated>2025-09-05T14:59:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.02544v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.02544v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The development of autonomous agents for graphical user interfaces (GUIs) presents major challenges in artificial intelligence. While recent advances in native agent models have shown promise by unifying perception, reasoning, action, and memory through end-to-end learning, open problems remain in data scalability, multi-turn reinforcement learning (RL), the limitations of GUI-only operation, and environment stability. In this technical report, we present UI-TARS-2, a native GUI-centered agent model that addresses these challenges through a systematic training methodology: a data flywheel for scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI environment that integrates file systems and terminals, and a unified sandbox platform for large-scale rollouts. Empirical evaluation demonstrates that UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5. On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines such as Claude and OpenAI agents. In game environments, it attains a mean normalized score of 59.8 across a 15-game suite-roughly 60% of human-level performance-and remains competitive with frontier proprietary models (e.g., OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to long-horizon information-seeking tasks and software engineering benchmarks, highlighting its robustness across diverse agent tasks. Detailed analyses of training dynamics further provide insights into achieving stability and efficiency in large-scale agent RL. These results underscore UI-TARS-2's potential to advance the state of GUI agents and exhibit strong generalization to real-world interactive scenarios.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-02T17:44:45Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Haoming Wang</name>\n    </author>\n    <author>\n      <name>Haoyang Zou</name>\n    </author>\n    <author>\n      <name>Huatong Song</name>\n    </author>\n    <author>\n      <name>Jiazhan Feng</name>\n    </author>\n    <author>\n      <name>Junjie Fang</name>\n    </author>\n    <author>\n      <name>Junting Lu</name>\n    </author>\n    <author>\n      <name>Longxiang Liu</name>\n    </author>\n    <author>\n      <name>Qinyu Luo</name>\n    </author>\n    <author>\n      <name>Shihao Liang</name>\n    </author>\n    <author>\n      <name>Shijue Huang</name>\n    </author>\n    <author>\n      <name>Wanjun Zhong</name>\n    </author>\n    <author>\n      <name>Yining Ye</name>\n    </author>\n    <author>\n      <name>Yujia Qin</name>\n    </author>\n    <author>\n      <name>Yuwen Xiong</name>\n    </author>\n    <author>\n      <name>Yuxin Song</name>\n    </author>\n    <author>\n      <name>Zhiyong Wu</name>\n    </author>\n    <author>\n      <name>Aoyan Li</name>\n    </author>\n    <author>\n      <name>Bo Li</name>\n    </author>\n    <author>\n      <name>Chen Dun</name>\n    </author>\n    <author>\n      <name>Chong Liu</name>\n    </author>\n    <author>\n      <name>Daoguang Zan</name>\n    </author>\n    <author>\n      <name>Fuxing Leng</name>\n    </author>\n    <author>\n      <name>Hanbin Wang</name>\n    </author>\n    <author>\n      <name>Hao Yu</name>\n    </author>\n    <author>\n      <name>Haobin Chen</name>\n    </author>\n    <author>\n      <name>Hongyi Guo</name>\n    </author>\n    <author>\n      <name>Jing Su</name>\n    </author>\n    <author>\n      <name>Jingjia Huang</name>\n    </author>\n    <author>\n      <name>Kai Shen</name>\n    </author>\n    <author>\n      <name>Kaiyu Shi</name>\n    </author>\n    <author>\n      <name>Lin Yan</name>\n    </author>\n    <author>\n      <name>Peiyao Zhao</name>\n    </author>\n    <author>\n      <name>Pengfei Liu</name>\n    </author>\n    <author>\n      <name>Qinghao Ye</name>\n    </author>\n    <author>\n      <name>Renjie Zheng</name>\n    </author>\n    <author>\n      <name>Shulin Xin</name>\n    </author>\n    <author>\n      <name>Wayne Xin Zhao</name>\n    </author>\n    <author>\n      <name>Wen Heng</name>\n    </author>\n    <author>\n      <name>Wenhao Huang</name>\n    </author>\n    <author>\n      <name>Wenqian Wang</name>\n    </author>\n    <author>\n      <name>Xiaobo Qin</name>\n    </author>\n    <author>\n      <name>Yi Lin</name>\n    </author>\n    <author>\n      <name>Youbin Wu</name>\n    </author>\n    <author>\n      <name>Zehui Chen</name>\n    </author>\n    <author>\n      <name>Zihao Wang</name>\n    </author>\n    <author>\n      <name>Baoquan Zhong</name>\n    </author>\n    <author>\n      <name>Xinchun Zhang</name>\n    </author>\n    <author>\n      <name>Xujing Li</name>\n    </author>\n    <author>\n      <name>Yuanfan Li</name>\n    </author>\n    <author>\n      <name>Zhongkai Zhao</name>\n    </author>\n    <author>\n      <name>Chengquan Jiang</name>\n    </author>\n    <author>\n      <name>Faming Wu</name>\n    </author>\n    <author>\n      <name>Haotian Zhou</name>\n    </author>\n    <author>\n      <name>Jinlin Pang</name>\n    </author>\n    <author>\n      <name>Li Han</name>\n    </author>\n    <author>\n      <name>Qi Liu</name>\n    </author>\n    <author>\n      <name>Qianli Ma</name>\n    </author>\n    <author>\n      <name>Siyao Liu</name>\n    </author>\n    <author>\n      <name>Songhua Cai</name>\n    </author>\n    <author>\n      <name>Wenqi Fu</name>\n    </author>\n    <author>\n      <name>Xin Liu</name>\n    </author>\n    <author>\n      <name>Yaohui Wang</name>\n    </author>\n    <author>\n      <name>Zhi Zhang</name>\n    </author>\n    <author>\n      <name>Bo Zhou</name>\n    </author>\n    <author>\n      <name>Guoliang Li</name>\n    </author>\n    <author>\n      <name>Jiajun Shi</name>\n    </author>\n    <author>\n      <name>Jiale Yang</name>\n    </author>\n    <author>\n      <name>Jie Tang</name>\n    </author>\n    <author>\n      <name>Li Li</name>\n    </author>\n    <author>\n      <name>Qihua Han</name>\n    </author>\n    <author>\n      <name>Taoran Lu</name>\n    </author>\n    <author>\n      <name>Woyu Lin</name>\n    </author>\n    <author>\n      <name>Xiaokang Tong</name>\n    </author>\n    <author>\n      <name>Xinyao Li</name>\n    </author>\n    <author>\n      <name>Yichi Zhang</name>\n    </author>\n    <author>\n      <name>Yu Miao</name>\n    </author>\n    <author>\n      <name>Zhengxuan Jiang</name>\n    </author>\n    <author>\n      <name>Zili Li</name>\n    </author>\n    <author>\n      <name>Ziyuan Zhao</name>\n    </author>\n    <author>\n      <name>Chenxin Li</name>\n    </author>\n    <author>\n      <name>Dehua Ma</name>\n    </author>\n    <author>\n      <name>Feng Lin</name>\n    </author>\n    <author>\n      <name>Ge Zhang</name>\n    </author>\n    <author>\n      <name>Haihua Yang</name>\n    </author>\n    <author>\n      <name>Hangyu Guo</name>\n    </author>\n    <author>\n      <name>Hongda Zhu</name>\n    </author>\n    <author>\n      <name>Jiaheng Liu</name>\n    </author>\n    <author>\n      <name>Junda Du</name>\n    </author>\n    <author>\n      <name>Kai Cai</name>\n    </author>\n    <author>\n      <name>Kuanye Li</name>\n    </author>\n    <author>\n      <name>Lichen Yuan</name>\n    </author>\n    <author>\n      <name>Meilan Han</name>\n    </author>\n    <author>\n      <name>Minchao Wang</name>\n    </author>\n    <author>\n      <name>Shuyue Guo</name>\n    </author>\n    <author>\n      <name>Tianhao Cheng</name>\n    </author>\n    <author>\n      <name>Xiaobo Ma</name>\n    </author>\n    <author>\n      <name>Xiaojun Xiao</name>\n    </author>\n    <author>\n      <name>Xiaolong Huang</name>\n    </author>\n    <author>\n      <name>Xinjie Chen</name>\n    </author>\n    <author>\n      <name>Yidi Du</name>\n    </author>\n    <author>\n      <name>Yilin Chen</name>\n    </author>\n    <author>\n      <name>Yiwen Wang</name>\n    </author>\n    <author>\n      <name>Zhaojian Li</name>\n    </author>\n    <author>\n      <name>Zhenzhu Yang</name>\n    </author>\n    <author>\n      <name>Zhiyuan Zeng</name>\n    </author>\n    <author>\n      <name>Chaolin Jin</name>\n    </author>\n    <author>\n      <name>Chen Li</name>\n    </author>\n    <author>\n      <name>Hao Chen</name>\n    </author>\n    <author>\n      <name>Haoli Chen</name>\n    </author>\n    <author>\n      <name>Jian Chen</name>\n    </author>\n    <author>\n      <name>Qinghao Zhao</name>\n    </author>\n    <author>\n      <name>Guang Shi</name>\n    </author>\n  </entry>\n</feed>\n"
}
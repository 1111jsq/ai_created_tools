{
  "source": "arxiv",
  "fetched_at": "2025-11-22T12:42:22.096871+00:00",
  "payload": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/It4cYEKLEp/OOEkMfaoU7qUnk5U</id>\n  <title>arXiv Query: search_query=(ti:agent OR ti:\"tool use\" OR ti:tool-augmented OR ti:planning OR ti:multi-agent OR ti:autonomous OR ti:toolformer OR ti:\"tool learning\" OR abs:agent OR abs:\"tool use\" OR abs:tool-augmented OR abs:planning OR abs:multi-agent OR abs:autonomous OR abs:toolformer OR abs:\"tool learning\") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.MA) AND (ti:Google OR ti:DeepMind OR ti:Microsoft OR ti:OpenAI OR ti:Meta OR ti:Apple OR ti:Stanford OR ti:MIT OR ti:CMU OR ti:Berkeley OR ti:Oxford OR ti:Harvard OR ti:Tsinghua OR ti:\"Peking University\" OR ti:PKU OR ti:USTC OR ti:SJTU OR ti:Princeton OR ti:UCLA OR ti:UCSD OR ti:\"ETH Zurich\" OR ti:NUS OR ti:NTU OR abs:Google OR abs:DeepMind OR abs:Microsoft OR abs:OpenAI OR abs:Meta OR abs:Apple OR abs:Stanford OR abs:MIT OR abs:CMU OR abs:Berkeley OR abs:Oxford OR abs:Harvard OR abs:Tsinghua OR abs:\"Peking University\" OR abs:PKU OR abs:USTC OR abs:SJTU OR abs:Princeton OR abs:UCLA OR abs:UCSD OR abs:\"ETH Zurich\" OR abs:NUS OR abs:NTU)&amp;id_list=&amp;start=0&amp;max_results=50</title>\n  <updated>2025-11-22T12:42:21Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=(ti:agent+OR+(ti:%22tool+use%22+OR+(ti:tool-augmented+OR+(ti:planning+OR+(ti:multi-agent+OR+(ti:autonomous+OR+(ti:toolformer+OR+(ti:%22tool+learning%22+OR+(abs:agent+OR+(abs:%22tool+use%22+OR+(abs:tool-augmented+OR+(abs:planning+OR+(abs:multi-agent+OR+(abs:autonomous+OR+(abs:toolformer+OR+abs:%22tool+learning%22)))))))))))))))+AND+((cat:cs.AI+OR+(cat:cs.LG+OR+cat:cs.MA))+AND+(ti:Google+OR+(ti:DeepMind+OR+(ti:Microsoft+OR+(ti:OpenAI+OR+(ti:Meta+OR+(ti:Apple+OR+(ti:Stanford+OR+(ti:MIT+OR+(ti:CMU+OR+(ti:Berkeley+OR+(ti:Oxford+OR+(ti:Harvard+OR+(ti:Tsinghua+OR+(ti:%22Peking+University%22+OR+(ti:PKU+OR+(ti:USTC+OR+(ti:SJTU+OR+(ti:Princeton+OR+(ti:UCLA+OR+(ti:UCSD+OR+(ti:%22ETH+Zurich%22+OR+(ti:NUS+OR+(ti:NTU+OR+(abs:Google+OR+(abs:DeepMind+OR+(abs:Microsoft+OR+(abs:OpenAI+OR+(abs:Meta+OR+(abs:Apple+OR+(abs:Stanford+OR+(abs:MIT+OR+(abs:CMU+OR+(abs:Berkeley+OR+(abs:Oxford+OR+(abs:Harvard+OR+(abs:Tsinghua+OR+(abs:%22Peking+University%22+OR+(abs:PKU+OR+(abs:USTC+OR+(abs:SJTU+OR+(abs:Princeton+OR+(abs:UCLA+OR+(abs:UCSD+OR+(abs:%22ETH+Zurich%22+OR+(abs:NUS+OR+abs:NTU))))))))))))))))))))))))))))))))))))))))))))))&amp;start=0&amp;max_results=50&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>50</opensearch:itemsPerPage>\n  <opensearch:totalResults>2708</opensearch:totalResults>\n  <opensearch:startIndex>0</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2511.15456v1</id>\n    <title>Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining</title>\n    <updated>2025-11-19T14:15:23Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.15456v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.15456v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"q-fin.GN\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-19T14:15:23Z</published>\n    <arxiv:comment>Written in 2025 Q1</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Qian'ang Mao</name>\n    </author>\n    <author>\n      <name>Yuxuan Zhang</name>\n    </author>\n    <author>\n      <name>Jiaman Chen</name>\n    </author>\n    <author>\n      <name>Wenjun Zhou</name>\n    </author>\n    <author>\n      <name>Jiaqi Yan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.15262v1</id>\n    <title>Reinforcement Learning in Queue-Reactive Models: Application to Optimal Execution</title>\n    <updated>2025-11-19T09:26:23Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.15262v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.15262v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We investigate the use of Reinforcement Learning for the optimal execution of meta-orders, where the objective is to execute incrementally large orders while minimizing implementation shortfall and market impact over an extended period of time. Departing from traditional parametric approaches to price dynamics and impact modeling, we adopt a model-free, data-driven framework. Since policy optimization requires counterfactual feedback that historical data cannot provide, we employ the Queue-Reactive Model to generate realistic and tractable limit order book simulations that encompass transient price impact, and nonlinear and dynamic order flow responses. Methodologically, we train a Double Deep Q-Network agent on a state space comprising time, inventory, price, and depth variables, and evaluate its performance against established benchmarks. Numerical simulation results show that the agent learns a policy that is both strategic and tactical, adapting effectively to order book conditions and outperforming standard approaches across multiple training configurations. These findings provide strong evidence that model-free Reinforcement Learning can yield adaptive and robust solutions to the optimal execution problem.</summary>\n    <category term=\"q-fin.TR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-19T09:26:23Z</published>\n    <arxiv:primary_category term=\"q-fin.TR\"/>\n    <author>\n      <name>Tomas Espana</name>\n    </author>\n    <author>\n      <name>Yadh Hafsi</name>\n    </author>\n    <author>\n      <name>Fabrizio Lillo</name>\n    </author>\n    <author>\n      <name>Edoardo Vittori</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.15199v1</id>\n    <title>Learning Where, What and How to Transfer: A Multi-Role Reinforcement Learning Approach for Evolutionary Multitasking</title>\n    <updated>2025-11-19T07:38:09Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.15199v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.15199v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Evolutionary multitasking (EMT) algorithms typically require tailored designs for knowledge transfer, in order to assure convergence and optimality in multitask optimization. In this paper, we explore designing a systematic and generalizable knowledge transfer policy through Reinforcement Learning. We first identify three major challenges: determining the task to transfer (where), the knowledge to be transferred (what) and the mechanism for the transfer (how). To address these challenges, we formulate a multi-role RL system where three (groups of) policy networks act as specialized agents: a task routing agent incorporates an attention-based similarity recognition module to determine source-target transfer pairs via attention scores; a knowledge control agent determines the proportion of elite solutions to transfer; and a group of strategy adaptation agents control transfer strength by dynamically controlling hyper-parameters in the underlying EMT framework. Through pre-training all network modules end-to-end over an augmented multitask problem distribution, a generalizable meta-policy is obtained. Comprehensive validation experiments show state-of-the-art performance of our method against representative baselines. Further in-depth analysis not only reveals the rationale behind our proposal but also provide insightful interpretations on what the system have learned.</summary>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-19T07:38:09Z</published>\n    <arxiv:primary_category term=\"cs.NE\"/>\n    <author>\n      <name>Jiajun Zhan</name>\n    </author>\n    <author>\n      <name>Zeyuan Ma</name>\n    </author>\n    <author>\n      <name>Yue-Jiao Gong</name>\n    </author>\n    <author>\n      <name>Kay Chen Tan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.15062v1</id>\n    <title>Interpretable temporal fusion network of multi- and multi-class arrhythmia classification</title>\n    <updated>2025-11-19T03:09:42Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.15062v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.15062v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Clinical decision support systems (CDSSs) have been widely utilized to support the decisions made by cardiologists when detecting and classifying arrhythmia from electrocardiograms. However, forming a CDSS for the arrhythmia classification task is challenging due to the varying lengths of arrhythmias. Although the onset time of arrhythmia varies, previously developed methods have not considered such conditions. Thus, we propose a framework that consists of (i) local and global extraction and (ii) local-global information fusion with attention to enable arrhythmia detection and classification within a constrained input length. The framework's performance was evaluated in terms of 10-class and 4-class arrhythmia detection, focusing on identifying the onset and ending point of arrhythmia episodes and their duration using the MIT-BIH arrhythmia database (MITDB) and the MIT-BIH atrial fibrillation database (AFDB). Duration, episode, and Dice score performances resulted in overall F1-scores of 96.45%, 82.05%, and 96.31% on the MITDB and 97.57%, 98.31%, and 97.45% on the AFDB, respectively. The results demonstrated statistically superior performance compared to those of the benchmark models. To assess the generalization capability of the proposed method, an MITDB-trained model and MIT-BIH malignant ventricular arrhythmia database-trained model were tested AFDB and MITDB, respectively. Superior performance was attained compared with that of a state-of-the-art model. The proposed method effectively captures both local and global information and dynamics without significant information loss. Consequently, arrhythmias can be detected with greater accuracy, and their occurrence times can be precisely determined, enabling the clinical field to develop more accurate treatment plans based on the proposed method.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-19T03:09:42Z</published>\n    <arxiv:comment>[Doctoral dissertation, Korea University, 2025]</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Yun Kwan Kim</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.15061v1</id>\n    <title>Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering</title>\n    <updated>2025-11-19T03:08:20Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.15061v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.15061v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-19T03:08:20Z</published>\n    <arxiv:comment>This paper has been accepted to SIGIR-AP 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Haodong Chen</name>\n    </author>\n    <author>\n      <name>Guido Zuccon</name>\n    </author>\n    <author>\n      <name>Teerapong Leelanupab</name>\n    </author>\n    <arxiv:doi>10.1145/3767695.3769488</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1145/3767695.3769488\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.14903v1</id>\n    <title>It's LIT! Reliability-Optimized LLMs with Inspectable Tools</title>\n    <updated>2025-11-18T20:41:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.14903v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.14903v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) have exhibited remarkable capabilities across various domains. The ability to call external tools further expands their capability to handle real-world tasks. However, LLMs often follow an opaque reasoning process, which limits their usefulness in high-stakes domains where solutions need to be trustworthy to end users. LLMs can choose solutions that are unreliable and difficult to troubleshoot, even if better options are available. We address this issue by forcing LLMs to use external -- more reliable -- tools to solve problems when possible. We present a framework built on the tool-calling capabilities of existing LLMs to enable them to select the most reliable and easy-to-troubleshoot solution path, which may involve multiple sequential tool calls. We refer to this framework as LIT (LLMs with Inspectable Tools). In order to support LIT, we introduce a new and challenging benchmark dataset of 1,300 questions and a customizable set of reliability cost functions associated with a collection of specialized tools. These cost functions summarize how reliable each tool is and how easy it is to troubleshoot. For instance, a calculator is reliable across domains, whereas a linear prediction model is not reliable if there is distribution shift, but it is easy to troubleshoot. A tool that constructs a random forest is neither reliable nor easy to troubleshoot. These tools interact with the Harvard USPTO Patent Dataset and a new dataset of NeurIPS 2023 papers to solve mathematical, coding, and modeling problems of varying difficulty levels. We demonstrate that LLMs can achieve more reliable and informed problem-solving while maintaining task performance using our framework.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-18T20:41:58Z</published>\n    <arxiv:comment>Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on Multi-Turn Interactions in Large Language Models</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Ruixin Zhang</name>\n    </author>\n    <author>\n      <name>Jon Donnelly</name>\n    </author>\n    <author>\n      <name>Zhicheng Guo</name>\n    </author>\n    <author>\n      <name>Ghazal Khalighinejad</name>\n    </author>\n    <author>\n      <name>Haiyang Huang</name>\n    </author>\n    <author>\n      <name>Alina Jade Barnett</name>\n    </author>\n    <author>\n      <name>Cynthia Rudin</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.14361v1</id>\n    <title>Clinically-Validated Innovative Mobile Application for Assessing Blinking and Eyelid Movements</title>\n    <updated>2025-11-18T11:07:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.14361v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.14361v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Blinking is a vital physiological process that protects and maintains the health of the ocular surface. Objective assessment of eyelid movements remains challenging due to the complexity, cost, and limited clinical applicability of existing tools. This study presents the clinical validation of Bapp (Blink Application), a mobile application developed using the Flutter framework and integrated with Google ML Kit for on-device, real-time analysis of eyelid movements. The validation occurred using 45 videos from real patients, whose blinks were manually annotated by ophthalmology specialists from the Paulista School of Medicine of the Federal University of Sao Paulo (EPM-UNIFESP) to serve as the ground truth. Bapp's performance was evaluated using standard metrics, including Precision, Recall, and F1-Score, with results demonstrating 98.4% precision, 96.9% recall, and an overall accuracy of 98.3%. These outcomes confirm the reliability of Bapp as a portable, accessible, and objective tool for monitoring both normal and abnormal eyelid movements. The application offers a promising alternative to traditional manual blink counting, supporting continuous ocular health monitoring and postoperative evaluation in clinical environments.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-18T11:07:31Z</published>\n    <arxiv:comment>14 pages, 8 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Gustavo Adolpho Bonesso</name>\n    </author>\n    <author>\n      <name>Carlos Marcelo Gurjão de Godoy</name>\n    </author>\n    <author>\n      <name>Tammy Hentona Osaki</name>\n    </author>\n    <author>\n      <name>Midori Hentona Osaki</name>\n    </author>\n    <author>\n      <name>Bárbara Moreira Ribeiro Trindade dos Santos</name>\n    </author>\n    <author>\n      <name>Regina Célia Coelho</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.13865v1</id>\n    <title>Randomized Controlled Trials for Conditional Access Optimization Agent</title>\n    <updated>2025-11-17T19:33:03Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.13865v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.13865v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>AI agents are increasingly deployed to automate complex enterprise workflows, yet evidence of their effectiveness in identity governance is limited. We report results from the first randomized controlled trial (RCT) evaluating an AI agent for Conditional Access (CA) policy management in Microsoft Entra. The agent assists with four high-value tasks: policy merging, Zero-Trust baseline gap detection, phased rollout planning, and user-policy alignment. In a production-grade environment, 162 identity administrators were randomly assigned to a control group (no agent) or treatment group (agent-assisted) and asked to perform these tasks. Agent access produced substantial gains: accuracy improved by 48% and task completion time decreased by 43% while holding accuracy constant. The largest benefits emerged on cognitively demanding tasks such as baseline gap detection. These findings demonstrate that purpose-built AI agents can significantly enhance both speed and accuracy in identity administration.</summary>\n    <category term=\"econ.GN\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-17T19:33:03Z</published>\n    <arxiv:primary_category term=\"econ.GN\"/>\n    <author>\n      <name>James Bono</name>\n    </author>\n    <author>\n      <name>Beibei Cheng</name>\n    </author>\n    <author>\n      <name>Joaquin Lozano</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.13860v1</id>\n    <title>Randomized Controlled Trials for Phishing Triage Agent</title>\n    <updated>2025-11-17T19:23:08Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.13860v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.13860v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Security operations centers (SOCs) face a persistent challenge: efficiently triaging a high volume of user-reported phishing emails while maintaining robust protection against threats. This paper presents the first randomized controlled trial (RCT) evaluating the impact of a domain-specific AI agent - the Microsoft Security Copilot Phishing Triage Agent - on analyst productivity and accuracy. Our results demonstrate that agent-augmented analysts achieved up to 6.5 times as many true positives per analyst minute and a 77% improvement in verdict accuracy compared to a control group. The agent's queue prioritization and verdict explanations were both significant drivers of efficiency. Behavioral analysis revealed that agent-augmented analysts reallocated their attention, spending 53% more time on malicious emails, and were not prone to rubber-stamping the agent's malicious verdicts. These findings offer actionable insights for SOC leaders considering AI adoption, including the potential for agents to fundamentally change the optimal allocation of SOC resources.</summary>\n    <category term=\"econ.GN\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-17T19:23:08Z</published>\n    <arxiv:primary_category term=\"econ.GN\"/>\n    <author>\n      <name>James Bono</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.13274v1</id>\n    <title>KForge: Program Synthesis for Diverse AI Hardware Accelerators</title>\n    <updated>2025-11-17T11:46:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.13274v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.13274v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.\n  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.PF\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-17T11:46:43Z</published>\n    <arxiv:comment>Under review at MLSys 2026</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Taras Sereda</name>\n    </author>\n    <author>\n      <name>Tom St. John</name>\n    </author>\n    <author>\n      <name>Burak Bartan</name>\n    </author>\n    <author>\n      <name>Natalie Serrino</name>\n    </author>\n    <author>\n      <name>Sachin Katti</name>\n    </author>\n    <author>\n      <name>Zain Asgar</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.12712v1</id>\n    <title>Adaptive Focus Memory for Language Models</title>\n    <updated>2025-11-16T17:52:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.12712v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.12712v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, but their behavior is still bottlenecked by fixed context windows and naive memory strategies. Replaying the full conversation at every turn is simple but expensive, while static summarization or recency-only heuristics often erase safety-critical user details. We present Adaptive Focus Memory (AFM), a dynamic context manager that assigns each past message one of three fidelity levels -- FULL, COMPRESSED, or PLACEHOLDER -- based on semantic similarity to the current query, half-life recency weighting, and importance classification. AFM packs messages chronologically under a strict token budget, preferring high fidelity for the most relevant turns while aiming to preserve a cheap trace of the dialogue. In a safety-oriented benchmark involving a user with a severe peanut allergy planning a trip to Thailand, AFM retains the allergy across both short and medium-length conversations, matches the safety performance of naive replay, and cuts average token usage by 66% relative to a replay baseline. We release a modular Python implementation of AFM designed for OpenAI-compatible APIs and offline operation, enabling practitioners to reduce inference cost without sacrificing safety or factual continuity in the evaluated scenario.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-16T17:52:32Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Christopher Cruz</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.12635v1</id>\n    <title>LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews</title>\n    <updated>2025-11-16T15:04:50Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.12635v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.12635v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with the use and reporting of performance metrics for SR screening. Results: Major weaknesses included: i) a failure to use metrics that are robust to imbalanced data and do not directly indicate whether results are better than chance, e.g., the use of Accuracy, ii) a failure to consider the impact of lost evidence when making claims concerning workload savings, and iii) pervasive failure to report the full confusion matrix (or performance metrics from which it can be reconstructed) which is essential for future meta-analyses. On the positive side, we extract good (evaluation) practices on which our recommendations for researchers and practitioners, as well as policymakers, are built. Conclusions: SR screening evaluations should prioritize lost evidence/recall alongside chance-anchored and cost-sensitive Weighted MCC (WMCC) metric, report complete confusion matrices, treat unclassifiable outputs as referred-back positives for assessment, adopt leakage-aware designs with non-LLM baselines and open artifacts, and ground conclusions in cost-benefit analysis where FNs carry higher penalties than FPs.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-16T15:04:50Z</published>\n    <arxiv:comment>19 pages, 4 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Lech Madeyski</name>\n    </author>\n    <author>\n      <name>Barbara Kitchenham</name>\n    </author>\n    <author>\n      <name>Martin Shepperd</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.12319v1</id>\n    <title>Decision and Gender Biases in Large Language Models: A Behavioral Economic Perspective</title>\n    <updated>2025-11-15T18:38:17Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.12319v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.12319v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) increasingly mediate economic and organisational processes, from automated customer support and recruitment to investment advice and policy analysis. These systems are often assumed to embody rational decision making free from human error; yet they are trained on human language corpora that may embed cognitive and social biases. This study investigates whether advanced LLMs behave as rational agents or whether they reproduce human behavioural tendencies when faced with classic decision problems. Using two canonical experiments in behavioural economics, the ultimatum game and a gambling game, we elicit decisions from two state of the art models, Google Gemma7B and Qwen, under neutral and gender conditioned prompts. We estimate parameters of inequity aversion and loss-aversion and compare them with human benchmarks. The models display attenuated but persistent deviations from rationality, including moderate fairness concerns, mild loss aversion, and subtle gender conditioned differences.</summary>\n    <category term=\"econ.GN\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-15T18:38:17Z</published>\n    <arxiv:primary_category term=\"econ.GN\"/>\n    <author>\n      <name>Luca Corazzini</name>\n    </author>\n    <author>\n      <name>Elisa Deriu</name>\n    </author>\n    <author>\n      <name>Marco Guerzoni</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.11519v1</id>\n    <title>Experience-Guided Adaptation of Inference-Time Reasoning Strategies</title>\n    <updated>2025-11-14T17:45:28Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.11519v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.11519v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time based on accumulated experience. We achieve this using an LLM-based meta-strategy -- a strategy that outputs strategies -- enabling adaptation of all strategy components (prompts, sampling parameters, tool configurations, and control logic). EGuR operates through two components: a Guide generates multiple candidate strategies conditioned on the current problem and structured memory of past experiences, while a Consolidator integrates execution feedback to improve future strategy generation. This produces complete, ready-to-run strategies optimized for each problem, which can be cached, retrieved, and executed as needed without wasting resources. Across five challenging benchmarks (AIME 2025, 3-SAT, and three Big Bench Extra Hard tasks), EGuR achieves up to 14% accuracy improvements over the strongest baselines while reducing computational costs by up to 111x, with both metrics improving as the system gains experience.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-14T17:45:28Z</published>\n    <arxiv:comment>29 pages, 5 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Adam Stein</name>\n    </author>\n    <author>\n      <name>Matthew Trager</name>\n    </author>\n    <author>\n      <name>Benjamin Bowman</name>\n    </author>\n    <author>\n      <name>Michael Kleinman</name>\n    </author>\n    <author>\n      <name>Aditya Chattopadhyay</name>\n    </author>\n    <author>\n      <name>Wei Xia</name>\n    </author>\n    <author>\n      <name>Stefano Soatto</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.11083v3</id>\n    <title>Efficient Reinforcement Learning for Zero-Shot Coordination in Evolving Games</title>\n    <updated>2025-11-18T10:20:13Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.11083v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.11083v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Zero-shot coordination(ZSC), a key challenge in multi-agent game theory, has become a hot topic in reinforcement learning (RL) research recently, especially in complex evolving games. It focuses on the generalization ability of agents, requiring them to coordinate well with collaborators from a diverse, potentially evolving, pool of partners that are not seen before without any fine-tuning. Population-based training, which approximates such an evolving partner pool, has been proven to provide good zero-shot coordination performance; nevertheless, existing methods are limited by computational resources, mainly focusing on optimizing diversity in small populations while neglecting the potential performance gains from scaling population size. To address this issue, this paper proposes the Scalable Population Training (ScaPT), an efficient RL training framework comprising two key components: a meta-agent that efficiently realizes a population by selectively sharing parameters across agents, and a mutual information regularizer that guarantees population diversity. To empirically validate the effectiveness of ScaPT, this paper evaluates it along with representational frameworks in Hanabi cooperative game and confirms its superiority.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-14T08:59:22Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Bingyu Hui</name>\n    </author>\n    <author>\n      <name>Lebin Yu</name>\n    </author>\n    <author>\n      <name>Quanming Yao</name>\n    </author>\n    <author>\n      <name>Yunpeng Qu</name>\n    </author>\n    <author>\n      <name>Xudong Zhang</name>\n    </author>\n    <author>\n      <name>Jian Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.10949v1</id>\n    <title>Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting</title>\n    <updated>2025-11-14T04:22:49Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.10949v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.10949v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>LLM-based agents are increasingly deployed in multi-agent systems (MAS). As these systems move toward real-world applications, their security becomes paramount. Existing research largely evaluates single-agent security, leaving a critical gap in understanding the vulnerabilities introduced by multi-agent design. However, existing systems fall short due to lack of unified frameworks and metrics focusing on unique rejection modes in MAS. We present SafeAgents, a unified and extensible framework for fine-grained security assessment of MAS. SafeAgents systematically exposes how design choices such as plan construction strategies, inter-agent context sharing, and fallback behaviors affect susceptibility to adversarial prompting. We introduce Dharma, a diagnostic measure that helps identify weak links within multi-agent pipelines. Using SafeAgents, we conduct a comprehensive study across five widely adopted multi-agent architectures (centralized, decentralized, and hybrid variants) on four datasets spanning web tasks, tool use, and code generation. Our findings reveal that common design patterns carry significant vulnerabilities. For example, centralized systems that delegate only atomic instructions to sub-agents obscure harmful objectives, reducing robustness. Our results highlight the need for security-aware design in MAS. Link to code is https://github.com/microsoft/SafeAgents</summary>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-14T04:22:49Z</published>\n    <arxiv:comment>10 pages, 3 figures. Code available at https://github.com/microsoft/SafeAgents</arxiv:comment>\n    <arxiv:primary_category term=\"cs.MA\"/>\n    <author>\n      <name>Nirmit Arora</name>\n    </author>\n    <author>\n      <name>Sathvik Joel</name>\n    </author>\n    <author>\n      <name>Ishan Kavathekar</name>\n    </author>\n    <author>\n      <name> Palak</name>\n    </author>\n    <author>\n      <name>Rohan Gandhi</name>\n    </author>\n    <author>\n      <name>Yash Pandya</name>\n    </author>\n    <author>\n      <name>Tanuja Ganu</name>\n    </author>\n    <author>\n      <name>Aditya Kanade</name>\n    </author>\n    <author>\n      <name>Akshay Nambi</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.10002v2</id>\n    <title>PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models</title>\n    <updated>2025-11-14T07:47:21Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.10002v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.10002v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework \"PustakAI\"\\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset \"NCERT-QA\" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-13T06:12:12Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Shivam Sharma</name>\n      <arxiv:affiliation>CSIS Department, BITS Pilani K K Birla Goa Campus, India</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Riya Naik</name>\n      <arxiv:affiliation>CSIS Department, BITS Pilani K K Birla Goa Campus, India</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Tejas Gawas</name>\n      <arxiv:affiliation>CSIS Department, BITS Pilani K K Birla Goa Campus, India</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Heramb Patil</name>\n      <arxiv:affiliation>CSIS Department, BITS Pilani K K Birla Goa Campus, India</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Kunal Korgaonkar</name>\n      <arxiv:affiliation>CSIS Department, BITS Pilani K K Birla Goa Campus, India</arxiv:affiliation>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.09450v1</id>\n    <title>How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models</title>\n    <updated>2025-11-12T16:06:35Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.09450v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.09450v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-12T16:06:35Z</published>\n    <arxiv:comment>6,227 words text + 2*250 (2 tables) = 6,727 words</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Amanta Sherfenaz</name>\n    </author>\n    <author>\n      <name>Nazmul Haque</name>\n    </author>\n    <author>\n      <name>Protiva Sadhukhan Prova</name>\n    </author>\n    <author>\n      <name>Md Asif Raihan</name>\n    </author>\n    <author>\n      <name>Md. Hadiuzzaman</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.11671v1</id>\n    <title>Evaluation of LLM-based Explanations for a Learning Analytics Dashboard</title>\n    <updated>2025-11-11T19:36:40Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.11671v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.11671v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Learning Analytics Dashboards can be a powerful tool to support self-regulated learning in Digital Learning Environments and promote development of meta-cognitive skills, such as reflection. However, their effectiveness can be affected by the interpretability of the data they provide. To assist in the interpretation, we employ a large language model to generate verbal explanations of the data in the dashboard and evaluate it against a standalone dashboard and explanations provided by human teachers in an expert study with university level educators (N=12). We find that the LLM-based explanations of the skill state presented in the dashboard, as well as general recommendations on how to proceed with learning within the course are significantly more favored compared to the other conditions. This indicates that using LLMs for interpretation purposes can enhance the learning experience for learners while maintaining the pedagogical standards approved by teachers.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-11T19:36:40Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Alina Deriyeva</name>\n    </author>\n    <author>\n      <name>Benjamin Paassen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.07904v2</id>\n    <title>Test-driven Reinforcement Learning</title>\n    <updated>2025-11-15T04:28:51Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.07904v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.07904v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-11T06:58:52Z</published>\n    <arxiv:comment>AAAI 2026 oral</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Zhao Yu</name>\n    </author>\n    <author>\n      <name>Xiuping Wu</name>\n    </author>\n    <author>\n      <name>Liangjun Ke</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.10680v1</id>\n    <title>LAD-BNet: Lag-Aware Dual-Branch Networks for Real-Time Energy Forecasting on Edge Devices</title>\n    <updated>2025-11-11T03:55:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.10680v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.10680v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Real-time energy forecasting on edge devices represents a major challenge for smart grid optimization and intelligent buildings. We present LAD-BNet (Lag-Aware Dual-Branch Network), an innovative neural architecture optimized for edge inference with Google Coral TPU. Our hybrid approach combines a branch dedicated to explicit exploitation of temporal lags with a Temporal Convolutional Network (TCN) featuring dilated convolutions, enabling simultaneous capture of short and long-term dependencies. Tested on real energy consumption data with 10-minute temporal resolution, LAD-BNet achieves 14.49% MAPE at 1-hour horizon with only 18ms inference time on Edge TPU, representing an 8-12 x acceleration compared to CPU. The multi-scale architecture enables predictions up to 12 hours with controlled performance degradation. Our model demonstrates a 2.39% improvement over LSTM baselines and 3.04% over pure TCN architectures, while maintaining a 180MB memory footprint suitable for embedded device constraints. These results pave the way for industrial applications in real-time energy optimization, demand management, and operational planning.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-11T03:55:06Z</published>\n    <arxiv:comment>27 pages, in French language. 10 tables, 26 references. Submitted to Energy and AI</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Jean-Philippe Lignier</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.07685v1</id>\n    <title>ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents</title>\n    <updated>2025-11-10T23:07:14Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.07685v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.07685v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes: conceptual breadth, logical nesting, and exploration. In addition, we develop human and model-based evaluation protocols that measure rubric adherence for DR agents. We evaluate several state-of-the-art DR systems and find that even leading agents like Gemini's DR and OpenAI's DR achieve under 68% average compliance with our rubrics, primarily due to missed implicit context and inadequate reasoning about retrieved information. Our results highlight the need for robust, scalable assessment of deep research capabilities, to which end we release ResearchRubrics(including all prompts, rubrics, and evaluation code) to facilitate progress toward well-justified research assistants.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-10T23:07:14Z</published>\n    <arxiv:comment>27 pages, 21 figures, pre-print</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Manasi Sharma</name>\n    </author>\n    <author>\n      <name>Chen Bo Calvin Zhang</name>\n    </author>\n    <author>\n      <name>Chaithanya Bandi</name>\n    </author>\n    <author>\n      <name>Clinton Wang</name>\n    </author>\n    <author>\n      <name>Ankit Aich</name>\n    </author>\n    <author>\n      <name>Huy Nghiem</name>\n    </author>\n    <author>\n      <name>Tahseen Rabbani</name>\n    </author>\n    <author>\n      <name>Ye Htet</name>\n    </author>\n    <author>\n      <name>Brian Jang</name>\n    </author>\n    <author>\n      <name>Sumana Basu</name>\n    </author>\n    <author>\n      <name>Aishwarya Balwani</name>\n    </author>\n    <author>\n      <name>Denis Peskoff</name>\n    </author>\n    <author>\n      <name>Marcos Ayestaran</name>\n    </author>\n    <author>\n      <name>Sean M. Hendryx</name>\n    </author>\n    <author>\n      <name>Brad Kenstler</name>\n    </author>\n    <author>\n      <name>Bing Liu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.07090v4</id>\n    <title>Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts</title>\n    <updated>2025-11-13T11:33:02Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.07090v4\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.07090v4\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-10T13:26:06Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Marcel Rojahn</name>\n    </author>\n    <author>\n      <name>Marcus Grum</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.04481v1</id>\n    <title>Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis</title>\n    <updated>2025-11-06T15:59:59Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.04481v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.04481v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful agentic systems pushing the boundaries of Large Language Models (LLM). They can autonomously interact with the internet at the user's behest, such as navigating websites, filling search masks, and comparing price lists. Though web agent research is thriving, induced sustainability issues remain largely unexplored. To highlight the urgency of this issue, we provide an initial exploration of the energy and $CO_2$ cost associated with web agents from both a theoretical -via estimation- and an empirical perspective -by benchmarking. Our results show how different philosophies in web agent creation can severely impact the associated expended energy, and that more energy consumed does not necessarily equate to better results. We highlight a lack of transparency regarding disclosing model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. Our work contributes towards a change in thinking of how we evaluate web agents, advocating for dedicated metrics measuring energy consumption in benchmarks.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-06T15:59:59Z</published>\n    <arxiv:comment>Accepted by AAAI 2026 AISI</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Lars Krupp</name>\n    </author>\n    <author>\n      <name>Daniel Geißler</name>\n    </author>\n    <author>\n      <name>Vishal Banwari</name>\n    </author>\n    <author>\n      <name>Paul Lukowicz</name>\n    </author>\n    <author>\n      <name>Jakob Karolus</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03958v1</id>\n    <title>Multi-Agent Collaborative Framework For Math Problem Generation</title>\n    <updated>2025-11-06T01:24:07Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.03958v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.03958v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Automatic question generation (AQG) for mathematics education remains an elusive goal for Intelligent Tutoring Systems and educators. While pre-trained transformer-based language models have significantly advanced natural language generation, they often struggle to precisely control problem complexity and cognitive demands. In this paper, we introduce a collaborative multi-agent framework as a novel method of incorporating inference-time computation into AQG. This approach leverages multiple agents that iteratively refine generated question-answer pairs to better balance complexity and cognitive demand. We evaluate the generated questions on five meta-evaluation criteria: relevance, importance, clarity, difficulty matching, answerability, to assess the system's ability to control the required complexity and quality of the questions. Preliminary evaluations show that this collaborative multi-agent framework elevates the quality of generated educational content by fostering a more nuanced balance between cognitive challenge and clarity. These promising outcomes suggest that integrating collaborative multi-agent workflows can yield more controlled, pedagogically valuable content that can help advance automated educational content generation and adaptive learning environments.</summary>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-06T01:24:07Z</published>\n    <arxiv:comment>Published in the Proceedings of the 18th International Conference on Educational Data Mining, 6 pages, 5 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.MA\"/>\n    <arxiv:journal_ref>Kia Karbasi, Kevin Hong, Mohammad Amin Samadi, &amp; Gregory Pottie. (2025). Multi-Agent Collaborative Framework For Math Problem Generation. Proceedings of the 18th International Conference on Educational Data Mining, 613--618</arxiv:journal_ref>\n    <author>\n      <name>Kia Karbasi</name>\n    </author>\n    <author>\n      <name>Kevin Hong</name>\n    </author>\n    <author>\n      <name>Mohammad Amin Samadi</name>\n    </author>\n    <author>\n      <name>Gregory Pottie</name>\n    </author>\n    <arxiv:doi>10.5281/zenodo.15870246</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.5281/zenodo.15870246\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03690v1</id>\n    <title>The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents</title>\n    <updated>2025-11-05T18:16:44Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.03690v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.03690v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensible to more complex, full-featured agents with features such as custom tools, memory management, and more. For security and reliability, it delivers seamless local-to-remote execution portability, integrated REST/WebSocket services. For interaction with human users, it can connect directly to a variety of interfaces, such as visual workspaces (VS Code, VNC, browser), command-line interfaces, and APIs. Compared with existing SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and built-in security analysis. Empirical results on SWE-Bench Verified and GAIA benchmarks demonstrate strong performance. Put together, these elements allow the OpenHands Software Agent SDK to provide a practical foundation for prototyping, unlocking new classes of custom applications, and reliably deploying agents at scale.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-05T18:16:44Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Xingyao Wang</name>\n    </author>\n    <author>\n      <name>Simon Rosenberg</name>\n    </author>\n    <author>\n      <name>Juan Michelini</name>\n    </author>\n    <author>\n      <name>Calvin Smith</name>\n    </author>\n    <author>\n      <name>Hoang Tran</name>\n    </author>\n    <author>\n      <name>Engel Nyst</name>\n    </author>\n    <author>\n      <name>Rohit Malhotra</name>\n    </author>\n    <author>\n      <name>Xuhui Zhou</name>\n    </author>\n    <author>\n      <name>Valerie Chen</name>\n    </author>\n    <author>\n      <name>Robert Brennan</name>\n    </author>\n    <author>\n      <name>Graham Neubig</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03497v1</id>\n    <title>ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications</title>\n    <updated>2025-11-05T14:27:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.03497v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.03497v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Agentic AI systems and Physical or Embodied AI systems have been two key research verticals at the forefront of Artificial Intelligence and Robotics, with Model Context Protocol (MCP) increasingly becoming a key component and enabler of agentic applications. However, the literature at the intersection of these verticals, i.e., Agentic Embodied AI, remains scarce. This paper introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for analyzing, visualizing and processing robot data with natural language through LLMs and VLMs. We describe specific tooling built with robotics domain knowledge, with our initial release focused on mobile robotics and supporting natively the analysis of trajectories, laser scan data, transforms, or time series data. This is in addition to providing an interface to standard ROS 2 CLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to filter bags with a subset of topics or trimmed in time. Coupled with the MCP server, we provide a lightweight UI that allows the benchmarking of the tooling with different LLMs, both proprietary (Anthropic, OpenAI) and open-source (through Groq). Our experimental results include the analysis of tool calling capabilities of eight different state-of-the-art LLM/VLM models, both proprietary and open-source, large and small. Our experiments indicate that there is a large divide in tool calling capabilities, with Kimi K2 and Claude Sonnet 4 demonstrating clearly superior performance. We also conclude that there are multiple factors affecting the success rates, from the tool description schema to the number of arguments, as well as the number of tools available to the models. The code is available with a permissive license at https://github.com/binabik-ai/mcp-rosbags.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-05T14:27:58Z</published>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Lei Fu</name>\n    </author>\n    <author>\n      <name>Sahar Salimpour</name>\n    </author>\n    <author>\n      <name>Leonardo Militano</name>\n    </author>\n    <author>\n      <name>Harry Edelman</name>\n    </author>\n    <author>\n      <name>Jorge Peña Queralta</name>\n    </author>\n    <author>\n      <name>Giovanni Toffetti</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03434v1</id>\n    <title>Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond</title>\n    <updated>2025-11-05T12:50:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.03434v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.03434v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered) autonomously transacting and collaborating-trust shifts from human oversight to protocol design. In 2025, several inter-agent protocols crystallized this shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2), and Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust assumptions remain under-examined. This paper presents a comparative study of trust models in inter-agent protocol design: Brief (self- or third-party verifiable claims), Claim (self-proclaimed capabilities and identity, e.g. AgentCard), Proof (cryptographic verification, including zero-knowledge proofs and trusted execution environment attestations), Stake (bonded collateral with slashing and insurance), Reputation (crowd feedback and graph-based trust signals), and Constraint (sandboxing and capability bounding). For each, we analyze assumptions, attack surfaces, and design trade-offs, with particular emphasis on LLM-specific fragilities-prompt injection, sycophancy/nudge-susceptibility, hallucination, deception, and misalignment-that render purely reputational or claim-only approaches brittle. Our findings indicate no single mechanism suffices. We argue for trustless-by-default architectures anchored in Proof and Stake to gate high-impact actions, augmented by Brief for identity and discovery and Reputation overlays for flexibility and social signals. We comparatively evaluate A2A, AP2, ERC-8004 and related historical variations in academic research under metrics spanning security, privacy, latency/cost, and social robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid trust model recommendations that mitigate reputation gaming and misinformed LLM behavior, and we distill actionable design guidelines for safer, interoperable, and scalable agent economies.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-05T12:50:06Z</published>\n    <arxiv:comment>Submitted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)</arxiv:comment>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Botao 'Amber' Hu</name>\n    </author>\n    <author>\n      <name>Helena Rong</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02781v1</id>\n    <title>Measuring AI Diffusion: A Population-Normalized Metric for Tracking Global AI Usage</title>\n    <updated>2025-11-04T18:03:51Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.02781v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.02781v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Measuring global AI diffusion remains challenging due to a lack of population-normalized, cross-country usage data. We introduce AI User Share, a novel indicator that estimates the share of each country's working-age population actively using AI tools. Built from anonymized Microsoft telemetry and adjusted for device access and mobile scaling, this metric spans 147 economies and provides consistent, real-time insight into global AI diffusion. We find wide variation in adoption, with a strong correlation between AI User Share and GDP. High uptake is concentrated in developed economies, though usage among internet-connected populations in lower-income countries reveals substantial latent demand. We also detect sharp increases in usage following major product launches, such as DeepSeek in early 2025. While the metric's reliance solely on Microsoft telemetry introduces potential biases related to this user base, it offers an important new lens into how AI is spreading globally. AI User Share enables timely benchmarking that can inform data-driven AI policy.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-04T18:03:51Z</published>\n    <arxiv:comment>18 pages, 6 figures, 2 tables. Also available at https://aka.ms/AI_Diffusion_Technical_Report</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Amit Misra</name>\n    </author>\n    <author>\n      <name>Jane Wang</name>\n    </author>\n    <author>\n      <name>Scott McCullers</name>\n    </author>\n    <author>\n      <name>Kevin White</name>\n    </author>\n    <author>\n      <name>Juan Lavista Ferres</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02606v1</id>\n    <title>A Multi-Agent Psychological Simulation System for Human Behavior Modeling</title>\n    <updated>2025-11-04T14:28:03Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.02606v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.02606v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher training and research, and discuss how it embodies principles of social learning, cognitive apprenticeship, deliberate practice, and meta-cognition.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-04T14:28:03Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Xiangen Hu</name>\n    </author>\n    <author>\n      <name>Jiarui Tong</name>\n    </author>\n    <author>\n      <name>Sheng Xu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02560v1</id>\n    <title>SigmaCollab: An Application-Driven Dataset for Physically Situated Collaboration</title>\n    <updated>2025-11-04T13:30:15Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.02560v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.02560v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operating in this space. In future work, we plan to use the dataset to construct a set of benchmarks for physically situated collaboration in mixed-reality task assistive scenarios. SigmaCollab is available at https://github.com/microsoft/SigmaCollab.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-04T13:30:15Z</published>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Dan Bohus</name>\n    </author>\n    <author>\n      <name>Sean Andrist</name>\n    </author>\n    <author>\n      <name>Ann Paradiso</name>\n    </author>\n    <author>\n      <name>Nick Saw</name>\n    </author>\n    <author>\n      <name>Tim Schoonbeek</name>\n    </author>\n    <author>\n      <name>Maia Stiber</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02303v1</id>\n    <title>Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation</title>\n    <updated>2025-11-04T06:37:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.02303v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.02303v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping mitigate this issue. Finally, as collaboration intensifies, the reasoning agent risks getting lost in multi-turn interactions and trapped by previous noisy responses. To counter this, we propose a verifiable reward mechanism that encourages deliberation by allowing the reasoning agent to discard noisy outputs, consolidate instructions, and restart its reasoning process when necessary. Extensive experiments demonstrate that our framework alleviates lazy agent behavior and unlocks the full potential of multi-agent framework for complex reasoning tasks.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-04T06:37:31Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Zhiwei Zhang</name>\n    </author>\n    <author>\n      <name>Xiaomin Li</name>\n    </author>\n    <author>\n      <name>Yudi Lin</name>\n    </author>\n    <author>\n      <name>Hui Liu</name>\n    </author>\n    <author>\n      <name>Ramraj Chandradevan</name>\n    </author>\n    <author>\n      <name>Linlin Wu</name>\n    </author>\n    <author>\n      <name>Minhua Lin</name>\n    </author>\n    <author>\n      <name>Fali Wang</name>\n    </author>\n    <author>\n      <name>Xianfeng Tang</name>\n    </author>\n    <author>\n      <name>Qi He</name>\n    </author>\n    <author>\n      <name>Suhang Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01999v1</id>\n    <title>TRACE: Textual Reasoning for Affordance Coordinate Extraction</title>\n    <updated>2025-11-03T19:13:26Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.01999v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.01999v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Vision-Language Models (VLMs) struggle to translate high-level instructions into the precise spatial affordances required for robotic manipulation. While visual Chain-of-Thought (CoT) methods exist, they are often computationally intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance Coordinate Extraction), a novel methodology that integrates a textual Chain of Reasoning (CoR) into the affordance prediction process. We use this methodology to create the TRACE dataset, a large-scale collection created via an autonomous pipeline that pairs instructions with explicit textual rationales. By fine-tuning a VLM on this data, our model learns to externalize its spatial reasoning before acting. Our experiments show that our TRACE-tuned model achieves state-of-the-art performance, reaching 48.1% accuracy on the primary Where2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more challenging W2P(h) subset. Crucially, an ablation study demonstrates that performance scales directly with the amount of reasoning data used, confirming the CoR's effectiveness. Furthermore, analysis of the model's attention maps reveals an interpretable reasoning process where focus shifts dynamically across reasoning steps. This work shows that training VLMs to generate a textual CoR is an effective and robust strategy for enhancing the precision, reliability, and interpretability of VLM-based robot control. Our dataset and code are available at https://github.com/jink-ucla/TRACE</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-03T19:13:26Z</published>\n    <arxiv:comment>ICCV 2025. *Equal contribution. †Corresponding author</arxiv:comment>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Sangyun Park</name>\n    </author>\n    <author>\n      <name>Jin Kim</name>\n    </author>\n    <author>\n      <name>Yuchen Cui</name>\n    </author>\n    <author>\n      <name>Matthew S. Brown</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01093v1</id>\n    <title>Continual Learning, Not Training: Online Adaptation For Agents</title>\n    <updated>2025-11-02T21:48:31Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.01093v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.01093v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Continual Learning (CL) methods have traditionally focused on mitigating catastrophic forgetting through gradient-based retraining, an approach ill-suited for deployed agents that must adapt in real time. We introduce our Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that decouples reasoning (Teacher) from execution (Student) and incorporates a persistent learning memory that stores distilled guidance from experience. This informs the orchestration layer, enabling the system to dynamically adjust its operational strategies, such as supervision level or initial plan selection, at inference time. In doing so, ATLAS achieves gradient-free continual learning, shifting the locus of adaptation from model parameters to system-level orchestration. We formulate this as a system-centric paradigm for continual learning, where the objective is adaptive efficiency: maximizing task success while minimizing computational cost through inference-time orchestration rather than parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source benchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1% success with GPT-5-mini as its Student, outperforming the larger GPT-5 (High) by 13% while reducing cost by 86%. Cross-incident validation demonstrates generalization: frozen pamphlets from Incident #5 improve accuracy from 28% to 41% with zero retraining, while shifting output composition from verbose exploration to structured reasoning. Together, these findings establish gradient-free continual learning as a viable path toward adaptive, deployable AI systems and provide causally annotated traces valuable for training explicit world models.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-02T21:48:31Z</published>\n    <arxiv:comment>12 pages, 4 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Aman Jaglan</name>\n    </author>\n    <author>\n      <name>Jarrod Barnes</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01078v1</id>\n    <title>Predictive Auxiliary Learning for Belief-based Multi-Agent Systems</title>\n    <updated>2025-11-02T21:05:03Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.01078v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.01078v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The performance of multi-agent reinforcement learning (MARL) in partially observable environments depends on effectively aggregating information from observations, communications, and reward signals. While most existing multi-agent systems primarily rely on rewards as the only feedback for policy training, our research shows that introducing auxiliary predictive tasks can significantly enhance learning efficiency and stability. We propose Belief-based Predictive Auxiliary Learning (BEPAL), a framework that incorporates auxiliary training objectives to support policy optimization. BEPAL follows the centralized training with decentralized execution paradigm. Each agent learns a belief model that predicts unobservable state information, such as other agents' rewards or motion directions, alongside its policy model. By enriching hidden state representations with information that does not directly contribute to immediate reward maximization, this auxiliary learning process stabilizes MARL training and improves overall performance. We evaluate BEPAL in the predator-prey environment and Google Research Football, where it achieves an average improvement of about 16 percent in performance metrics and demonstrates more stable convergence compared to baseline methods.</summary>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-02T21:05:03Z</published>\n    <arxiv:primary_category term=\"cs.MA\"/>\n    <author>\n      <name>Qinwei Huang</name>\n    </author>\n    <author>\n      <name>Stefan Wang</name>\n    </author>\n    <author>\n      <name>Simon Khan</name>\n    </author>\n    <author>\n      <name>Garrett Katz</name>\n    </author>\n    <author>\n      <name>Qinru Qiu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01006v1</id>\n    <title>None To Optima in Few Shots: Bayesian Optimization with MDP Priors</title>\n    <updated>2025-11-02T16:53:17Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.01006v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.01006v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Bayesian Optimization (BO) is an efficient tool for optimizing black-box functions, but its theoretical guarantees typically hold in the asymptotic regime. In many critical real-world applications such as drug discovery or materials design, where each evaluation can be very costly and time-consuming, BO becomes impractical for many evaluations. In this paper, we introduce the Procedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization with remarkably few function evaluations. At the heart of our algorithmic design are Markov Decision Process (MDP) priors that model optimization trajectories from related source tasks, thereby capturing procedural knowledge on efficient optimization. We embed these MDP priors into a prior-fitted neural network and employ model-agnostic meta-learning for fast adaptation to new target tasks. Experiments on real-world Covid and Cancer benchmarks and hyperparameter tuning tasks demonstrate that ProfBO consistently outperforms state-of-the-art methods by achieving high-quality solutions with significantly fewer evaluations, making it ready for practical deployment.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-02T16:53:17Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Diantong Li</name>\n    </author>\n    <author>\n      <name>Kyunghyun Cho</name>\n    </author>\n    <author>\n      <name>Chong Liu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00423v1</id>\n    <title>Bootstrap Off-policy with World Model</title>\n    <updated>2025-11-01T06:33:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.00423v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.00423v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-11-01T06:33:04Z</published>\n    <arxiv:comment>NeurIPS 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Guojian Zhan</name>\n    </author>\n    <author>\n      <name>Likun Wang</name>\n    </author>\n    <author>\n      <name>Xiangteng Zhang</name>\n    </author>\n    <author>\n      <name>Jiaxin Gao</name>\n    </author>\n    <author>\n      <name>Masayoshi Tomizuka</name>\n    </author>\n    <author>\n      <name>Shengbo Eben Li</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00162v2</id>\n    <title>ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus</title>\n    <updated>2025-11-04T03:46:39Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.00162v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.00162v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The Abstraction and Reasoning Corpus remains one of the most compelling and challenging benchmarks for tracking progress toward achieving Artificial General Intelligence. In contrast to other evaluation datasets designed to assess an agent's task-specific skills or accumulated knowledge, the ARC-AGI suite is specifically targeted at measuring skill acquisition efficiency, a trait that has (so far) been lacking in even the most sophisticated machine learning systems. For algorithms that require extensive intra-task exemplars, a significant constraint imposed by ARC-AGI is the modest cardinality of its demonstration set, comprising a small number of $\\langle$ input, output $\\rangle$ grids per task specifying the corresponding transformation. To embellish the space of viable sample pairs, this paper introduces ARC-GEN, an open-source procedural generator aimed at extending the original ARC-AGI training dataset as faithfully as possible. Unlike prior efforts, our generator is both exhaustive (covering all four-hundred tasks) and mimetic (more closely honoring the distributional properties and characteristics embodied in the initial ARC-AGI-1 release). We also discuss the use of this generator in establishing a static benchmark suite to verify the correctness of programs submitted to the 2025 Google Code Golf Championship.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-31T18:10:05Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Michael D. Moffitt</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.27334v1</id>\n    <title>When AI Trading Agents Compete: Adverse Selection of Meta-Orders by Reinforcement Learning-Based Market Making</title>\n    <updated>2025-10-31T10:05:14Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.27334v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.27334v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We investigate the mechanisms by which medium-frequency trading agents are adversely selected by opportunistic high-frequency traders. We use reinforcement learning (RL) within a Hawkes Limit Order Book (LOB) model in order to replicate the behaviours of high-frequency market makers. In contrast to the classical models with exogenous price impact assumptions, the Hawkes model accounts for endogenous price impact and other key properties of the market (Jain et al. 2024a). Given the real-world impracticalities of the market maker updating strategies for every event in the LOB, we formulate the high-frequency market making agent via an impulse control reinforcement learning framework (Jain et al. 2025). The RL used in the simulation utilises Proximal Policy Optimisation (PPO) and self-imitation learning. To replicate the adverse selection phenomenon, we test the RL agent trading against a medium frequency trader (MFT) executing a meta-order and demonstrate that, with training against the MFT meta-order execution agent, the RL market making agent learns to capitalise on the price drift induced by the meta-order. Recent empirical studies have shown that medium-frequency traders are increasingly subject to adverse selection by high-frequency trading agents. As high-frequency trading continues to proliferate across financial markets, the slippage costs incurred by medium-frequency traders are likely to increase over time. However, we do not observe that increased profits for the market making RL agent necessarily cause significantly increased slippages for the MFT agent.</summary>\n    <category term=\"q-fin.TR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-31T10:05:14Z</published>\n    <arxiv:primary_category term=\"q-fin.TR\"/>\n    <author>\n      <name>Ali Raza Jafree</name>\n    </author>\n    <author>\n      <name>Konark Jain</name>\n    </author>\n    <author>\n      <name>Nick Firoozye</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00126v1</id>\n    <title>Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features</title>\n    <updated>2025-10-31T10:01:01Z</updated>\n    <link href=\"https://arxiv.org/abs/2511.00126v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2511.00126v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al., 2022) have achieved strong average accuracy but remain unreliable in complex long-tail driving scenarios. These limitations reveal the weakness of the prevailing \"one-model-fits-all\" paradigm, particularly in safety-critical urban contexts where simpler physics-based models can occasionally outperform advanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic multi-expert gating framework that adaptively selects the most reliable trajectory predictor among a physics-informed LSTM, a Transformer, and a fine-tuned GameFormer on a per-sample basis.\n  Our method leverages internal model signals (meta-features) such as stability and uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be substantially more informative than geometric scene descriptors. To the best of our knowledge, this is the first work to formulate trajectory expert selection as a pairwise-ranking problem over internal model signals (Burges et al., 2005), directly optimizing decision quality without requiring post-hoc calibration.\n  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287 samples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error (FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835 m), and realizes 57.8 percent of the oracle performance bound. In open-loop simulations, after trajectory horizon alignment, the same configuration reduces FDE on left-turn scenarios by approximately 10 percent, demonstrating consistent improvements across both offline validation and open-loop evaluation. These results indicate that adaptive hybrid systems enhance trajectory reliability in safety-critical autonomous driving, providing a practical pathway beyond static single-model paradigms.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-31T10:01:01Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Lu Bowen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26905v1</id>\n    <title>Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations</title>\n    <updated>2025-10-30T18:11:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26905v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26905v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Cyber-physical systems increasingly rely on Foundational Models such as Large Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy through enhanced perception, inference, and planning. However, these models also introduce new types of errors, such as hallucinations, overgeneralizations, and context misalignments, resulting in incorrect and flawed decisions. To address this, we introduce the concept of Cognition Envelopes, designed to establish reasoning boundaries that constrain AI-generated decisions while complementing the use of meta-cognition and traditional safety envelopes. As with safety envelopes, Cognition Envelopes require practical guidelines and systematic processes for their definition, validation, and assurance.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T18:11:32Z</published>\n    <arxiv:comment>10.5 pages, 9 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Pedro Antonio Alarcón Granadeno</name>\n    </author>\n    <author>\n      <name>Arturo Miguel Bernal Russell</name>\n    </author>\n    <author>\n      <name>Sofia Nelson</name>\n    </author>\n    <author>\n      <name>Demetrius Hernandez</name>\n    </author>\n    <author>\n      <name>Maureen Petterson</name>\n    </author>\n    <author>\n      <name>Michael Murphy</name>\n    </author>\n    <author>\n      <name>Walter J. Scheirer</name>\n    </author>\n    <author>\n      <name>Jane Cleland-Huang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26603v1</id>\n    <title>Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling</title>\n    <updated>2025-10-30T15:33:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26603v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26603v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The electricity sector transition requires substantial increases in residential demand response capacity, yet Home Energy Management Systems (HEMS) adoption remains limited by user interaction barriers requiring translation of everyday preferences into technical parameters. While large language models have been applied to energy systems as code generators and parameter extractors, no existing implementation deploys LLMs as autonomous coordinators managing the complete workflow from natural language input to multi-appliance scheduling. This paper presents an agentic AI HEMS where LLMs autonomously coordinate multi-appliance scheduling from natural language requests to device control, achieving optimal scheduling without example demonstrations. A hierarchical architecture combining one orchestrator with three specialist agents uses the ReAct pattern for iterative reasoning, enabling dynamic coordination without hardcoded workflows while integrating Google Calendar for context-aware deadline extraction. Evaluation across three open-source models using real Austrian day-ahead electricity prices reveals substantial capability differences. Llama-3.3-70B successfully coordinates all appliances across all scenarios to match cost-optimal benchmarks computed via mixed-integer linear programming, while other models achieve perfect single-appliance performance but struggle to coordinate all appliances simultaneously. Progressive prompt engineering experiments demonstrate that analytical query handling without explicit guidance remains unreliable despite models' general reasoning capabilities. We open-source the complete system including orchestration logic, agent prompts, tools, and web interfaces to enable reproducibility, extension, and future research.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T15:33:52Z</published>\n    <arxiv:comment>34 pages, 9 figures. Code available at https://github.com/RedaElMakroum/agentic-ai-hems</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Reda El Makroum</name>\n    </author>\n    <author>\n      <name>Sebastian Zwickl-Bernhard</name>\n    </author>\n    <author>\n      <name>Lukas Kranzl</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26389v1</id>\n    <title>Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning</title>\n    <updated>2025-10-30T11:32:45Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26389v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26389v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recently, deep multi-agent reinforcement learning (MARL) has demonstrated promising performance for solving challenging tasks, such as long-term dependencies and non-Markovian environments. Its success is partly attributed to conditioning policies on large fixed context length. However, such large fixed context lengths may lead to limited exploration efficiency and redundant information. In this paper, we propose a novel MARL framework to obtain adaptive and effective contextual information. Specifically, we design a central agent that dynamically optimizes context length via temporal gradient analysis, enhancing exploration to facilitate convergence to global optima in MARL. Furthermore, to enhance the adaptive optimization capability of the context length, we present an efficient input representation for the central agent, which effectively filters redundant information. By leveraging a Fourier-based low-frequency truncation method, we extract global temporal trends across decentralized agents, providing an effective and efficient representation of the MARL environment. Extensive experiments demonstrate that the proposed method achieves state-of-the-art (SOTA) performance on long-term dependency tasks, including PettingZoo, MiniGrid, Google Research Football (GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T11:32:45Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Wenchang Duan</name>\n    </author>\n    <author>\n      <name>Yaoliang Yu</name>\n    </author>\n    <author>\n      <name>Jiwan He</name>\n    </author>\n    <author>\n      <name>Yi Shi</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26298v1</id>\n    <title>Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games</title>\n    <updated>2025-10-30T09:35:51Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26298v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26298v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>OpenAI's ChatGPT Atlas introduces new capabilities for web interaction, enabling the model to analyze webpages, process user intents, and execute cursor and keyboard inputs directly within the browser. While its capacity for information retrieval tasks has been demonstrated, its performance in dynamic, interactive environments remains less explored. In this study, we conduct an early evaluation of Atlas's web interaction capabilities using browser-based games as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird, and Stein.world. We employ in-game performance scores as quantitative metrics to assess performance across different task types. Our results show that Atlas performs strongly in logical reasoning tasks like Sudoku, completing puzzles significantly faster than human baselines, but struggles substantially in real-time games requiring precise timing and motor control, often failing to progress beyond initial obstacles. These findings suggest that while Atlas demonstrates capable analytical processing, there remain notable limitations in dynamic web environments requiring real-time interaction. The website of our project can be found at https://atlas-game-eval.github.io.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T09:35:51Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Jingran Zhang</name>\n    </author>\n    <author>\n      <name>Ning Li</name>\n    </author>\n    <author>\n      <name>Justin Cui</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26167v1</id>\n    <title>One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning</title>\n    <updated>2025-10-30T06:08:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26167v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26167v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Reward models (RMs) play a critical role in aligning large language models (LLMs) with human preferences. Yet in the domain of tool learning, the lack of RMs specifically designed for function-calling tasks has limited progress toward more capable agentic AI. We introduce ToolRM, a family of lightweight generative RMs tailored for general tool-use scenarios. To build these models, we propose a novel pipeline that constructs pairwise preference data using rule-based scoring and multidimensional sampling. This yields ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique tasks that supports reinforcement learning with verifiable feedback. To evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on the agentic evaluation suite BFCL. Trained on our constructed data, models from the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward judgments. Beyond training objectives, ToolRM generalizes to broader critique tasks, including Best-of-N sampling and self-correction. Experiments on ACEBench highlight its effectiveness and efficiency, enabling inference-time scaling and reducing output token usage by over 66%. We release data and model checkpoints to facilitate future research.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T06:08:27Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Renhao Li</name>\n    </author>\n    <author>\n      <name>Jianhong Tu</name>\n    </author>\n    <author>\n      <name>Yang Su</name>\n    </author>\n    <author>\n      <name>Hamid Alinejad-Rokny</name>\n    </author>\n    <author>\n      <name>Derek F. Wong</name>\n    </author>\n    <author>\n      <name>Junyang Lin</name>\n    </author>\n    <author>\n      <name>Min Yang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26068v1</id>\n    <title>Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization</title>\n    <updated>2025-10-30T01:53:32Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.26068v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.26068v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This paper proposes a novel paradigm for machine learning that moves beyond traditional parameter optimization. Unlike conventional approaches that search for optimal parameters within a fixed geometric space, our core idea is to treat the model itself as a malleable geometric entity. Specifically, we optimize the metric tensor field on a manifold with a predefined topology, thereby dynamically shaping the geometric structure of the model space. To achieve this, we construct a variational framework whose loss function carefully balances data fidelity against the intrinsic geometric complexity of the manifold. The former ensures the model effectively explains observed data, while the latter acts as a regularizer, penalizing overly curved or irregular geometries to encourage simpler models and prevent overfitting. To address the computational challenges of this infinite-dimensional optimization problem, we introduce a practical method based on discrete differential geometry: the continuous manifold is discretized into a triangular mesh, and the metric tensor is parameterized by edge lengths, enabling efficient optimization using automatic differentiation tools. Theoretical analysis reveals a profound analogy between our framework and the Einstein-Hilbert action in general relativity, providing an elegant physical interpretation for the concept of \"data-driven geometry\". We further argue that even with fixed topology, metric optimization offers significantly greater expressive power than models with fixed geometry. This work lays a solid foundation for constructing fully dynamic \"meta-learners\" capable of autonomously evolving their geometry and topology, and it points to broad application prospects in areas such as scientific model discovery and robust representation learning.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.DG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.ST\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-30T01:53:32Z</published>\n    <arxiv:comment>9 pages</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Di Zhang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25954v1</id>\n    <title>Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi</title>\n    <updated>2025-10-29T20:53:07Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.25954v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.25954v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The reliability of routine health data in low and middle-income countries (LMICs) is often constrained by reporting delays and incomplete coverage, necessitating the exploration of novel data sources and analytics. Geospatial Foundation Models (GeoFMs) offer a promising avenue by synthesizing diverse spatial, temporal, and behavioral data into mathematical embeddings that can be efficiently used for downstream prediction tasks. This study evaluated the predictive performance of three GeoFM embedding sources - Google Population Dynamics Foundation Model (PDFM), Google AlphaEarth (derived from satellite imagery), and mobile phone call detail records (CDR) - for modeling 15 routine health programmatic outputs in Malawi, and compared their utility to traditional geospatial interpolation methods. We used XGBoost models on data from 552 health catchment areas (January 2021-May 2023), assessing performance with R2, and using an 80/20 training and test data split with 5-fold cross-validation used in training. While predictive performance was mixed, the embedding-based approaches improved upon baseline geostatistical methods in 13 of 15 (87%) indicators tested. A Multi-GeoFM model integrating all three embedding sources produced the most robust predictions, achieving average 5-fold cross validated R2 values for indicators like population density (0.63), new HIV cases (0.57), and child vaccinations (0.47) and test set R2 of 0.64, 0.68, and 0.55, respectively. Prediction was poor for prediction targets with low primary data availability, such as TB and malnutrition cases. These results demonstrate that GeoFM embeddings imbue a modest predictive improvement for select health and demographic outcomes in an LMIC context. We conclude that the integration of multiple GeoFM sources is an efficient and valuable tool for supplementing and strengthening constrained routine health information systems.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-29T20:53:07Z</published>\n    <arxiv:comment>13 pages, 3010 words, 2 tables, 2 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Lynn Metz</name>\n    </author>\n    <author>\n      <name>Rachel Haggard</name>\n    </author>\n    <author>\n      <name>Michael Moszczynski</name>\n    </author>\n    <author>\n      <name>Samer Asbah</name>\n    </author>\n    <author>\n      <name>Chris Mwase</name>\n    </author>\n    <author>\n      <name>Patricia Khomani</name>\n    </author>\n    <author>\n      <name>Tyler Smith</name>\n    </author>\n    <author>\n      <name>Hannah Cooper</name>\n    </author>\n    <author>\n      <name>Annie Mwale</name>\n    </author>\n    <author>\n      <name>Arbaaz Muslim</name>\n    </author>\n    <author>\n      <name>Gautam Prasad</name>\n    </author>\n    <author>\n      <name>Mimi Sun</name>\n    </author>\n    <author>\n      <name>Tomer Shekel</name>\n    </author>\n    <author>\n      <name>Joydeep Paul</name>\n    </author>\n    <author>\n      <name>Anna Carter</name>\n    </author>\n    <author>\n      <name>Shravya Shetty</name>\n    </author>\n    <author>\n      <name>Dylan Green</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25726v1</id>\n    <title>The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution</title>\n    <updated>2025-10-29T17:32:49Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.25726v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.25726v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-29T17:32:49Z</published>\n    <arxiv:comment>Website: https://toolathlon.xyz/</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Junlong Li</name>\n    </author>\n    <author>\n      <name>Wenshuo Zhao</name>\n    </author>\n    <author>\n      <name>Jian Zhao</name>\n    </author>\n    <author>\n      <name>Weihao Zeng</name>\n    </author>\n    <author>\n      <name>Haoze Wu</name>\n    </author>\n    <author>\n      <name>Xiaochen Wang</name>\n    </author>\n    <author>\n      <name>Rui Ge</name>\n    </author>\n    <author>\n      <name>Yuxuan Cao</name>\n    </author>\n    <author>\n      <name>Yuzhen Huang</name>\n    </author>\n    <author>\n      <name>Wei Liu</name>\n    </author>\n    <author>\n      <name>Junteng Liu</name>\n    </author>\n    <author>\n      <name>Zhaochen Su</name>\n    </author>\n    <author>\n      <name>Yiyang Guo</name>\n    </author>\n    <author>\n      <name>Fan Zhou</name>\n    </author>\n    <author>\n      <name>Lueyang Zhang</name>\n    </author>\n    <author>\n      <name>Juan Michelini</name>\n    </author>\n    <author>\n      <name>Xingyao Wang</name>\n    </author>\n    <author>\n      <name>Xiang Yue</name>\n    </author>\n    <author>\n      <name>Shuyan Zhou</name>\n    </author>\n    <author>\n      <name>Graham Neubig</name>\n    </author>\n    <author>\n      <name>Junxian He</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25588v1</id>\n    <title>Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</title>\n    <updated>2025-10-29T14:54:22Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.25588v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.25588v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The diagnosis of most mental disorders, including psychiatric evaluations, primarily depends on dialogues between psychiatrists and patients. This subjective process can lead to variability in diagnoses across clinicians and patients, resulting in inconsistencies and challenges in achieving reliable outcomes. To address these issues and standardize psychiatric diagnoses, we propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System for the clinical diagnosis of mental disorders. Our approach leverages fine-tuned LLMs trained on conversational datasets involving psychiatrist-patient interactions focused on mental health conditions (e.g., depression). The diagnostic predictions from individual models are aggregated through a consensus-based decision-making process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method for deploying LLM agents that orchestrate communication between the LLM consortium and the reasoning LLM, ensuring transparency, reliability, and responsible AI across the entire diagnostic workflow. Experimental results demonstrate the transformative potential of combining fine-tuned LLMs with a reasoning model to create a robust and highly accurate diagnostic system for mental health assessment. A prototype of the proposed platform, integrating three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia, USA. To the best of our knowledge, this work represents the first application of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical mental health diagnosis paving the way for next-generation AI-powered eHealth systems aimed at standardizing psychiatric diagnoses.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-29T14:54:22Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Eranga Bandara</name>\n    </author>\n    <author>\n      <name>Ross Gore</name>\n    </author>\n    <author>\n      <name>Atmaram Yarlagadda</name>\n    </author>\n    <author>\n      <name>Anita H. Clayton</name>\n    </author>\n    <author>\n      <name>Preston Samuel</name>\n    </author>\n    <author>\n      <name>Christopher K. Rhea</name>\n    </author>\n    <author>\n      <name>Sachin Shetty</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25529v1</id>\n    <title>Off-policy Reinforcement Learning with Model-based Exploration Augmentation</title>\n    <updated>2025-10-29T13:53:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.25529v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.25529v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-10-29T13:53:52Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Likun Wang</name>\n    </author>\n    <author>\n      <name>Xiangteng Zhang</name>\n    </author>\n    <author>\n      <name>Yinuo Wang</name>\n    </author>\n    <author>\n      <name>Guojian Zhan</name>\n    </author>\n    <author>\n      <name>Wenxuan Wang</name>\n    </author>\n    <author>\n      <name>Haoyu Gao</name>\n    </author>\n    <author>\n      <name>Jingliang Duan</name>\n    </author>\n    <author>\n      <name>Shengbo Eben Li</name>\n    </author>\n  </entry>\n</feed>\n"
}
{
  "source": "arxiv",
  "fetched_at": "2025-11-22T12:42:29.485743+00:00",
  "payload": "<?xml version='1.0' encoding='UTF-8'?>\n<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>https://arxiv.org/api/SiW7C+Gxg+Q6fV9R6oFSxJx0qW8</id>\n  <title>arXiv Query: search_query=(ti:agent OR ti:\"tool use\" OR ti:tool-augmented OR ti:planning OR ti:multi-agent OR ti:autonomous OR ti:toolformer OR ti:\"tool learning\" OR abs:agent OR abs:\"tool use\" OR abs:tool-augmented OR abs:planning OR abs:multi-agent OR abs:autonomous OR abs:toolformer OR abs:\"tool learning\") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.MA) AND (ti:Google OR ti:DeepMind OR ti:Microsoft OR ti:OpenAI OR ti:Meta OR ti:Apple OR ti:Stanford OR ti:MIT OR ti:CMU OR ti:Berkeley OR ti:Oxford OR ti:Harvard OR ti:Tsinghua OR ti:\"Peking University\" OR ti:PKU OR ti:USTC OR ti:SJTU OR ti:Princeton OR ti:UCLA OR ti:UCSD OR ti:\"ETH Zurich\" OR ti:NUS OR ti:NTU OR abs:Google OR abs:DeepMind OR abs:Microsoft OR abs:OpenAI OR abs:Meta OR abs:Apple OR abs:Stanford OR abs:MIT OR abs:CMU OR abs:Berkeley OR abs:Oxford OR abs:Harvard OR abs:Tsinghua OR abs:\"Peking University\" OR abs:PKU OR abs:USTC OR abs:SJTU OR abs:Princeton OR abs:UCLA OR abs:UCSD OR abs:\"ETH Zurich\" OR abs:NUS OR abs:NTU)&amp;id_list=&amp;start=200&amp;max_results=50</title>\n  <updated>2025-11-22T12:42:28Z</updated>\n  <link href=\"https://arxiv.org/api/query?search_query=(ti:agent+OR+(ti:%22tool+use%22+OR+(ti:tool-augmented+OR+(ti:planning+OR+(ti:multi-agent+OR+(ti:autonomous+OR+(ti:toolformer+OR+(ti:%22tool+learning%22+OR+(abs:agent+OR+(abs:%22tool+use%22+OR+(abs:tool-augmented+OR+(abs:planning+OR+(abs:multi-agent+OR+(abs:autonomous+OR+(abs:toolformer+OR+abs:%22tool+learning%22)))))))))))))))+AND+((cat:cs.AI+OR+(cat:cs.LG+OR+cat:cs.MA))+AND+(ti:Google+OR+(ti:DeepMind+OR+(ti:Microsoft+OR+(ti:OpenAI+OR+(ti:Meta+OR+(ti:Apple+OR+(ti:Stanford+OR+(ti:MIT+OR+(ti:CMU+OR+(ti:Berkeley+OR+(ti:Oxford+OR+(ti:Harvard+OR+(ti:Tsinghua+OR+(ti:%22Peking+University%22+OR+(ti:PKU+OR+(ti:USTC+OR+(ti:SJTU+OR+(ti:Princeton+OR+(ti:UCLA+OR+(ti:UCSD+OR+(ti:%22ETH+Zurich%22+OR+(ti:NUS+OR+(ti:NTU+OR+(abs:Google+OR+(abs:DeepMind+OR+(abs:Microsoft+OR+(abs:OpenAI+OR+(abs:Meta+OR+(abs:Apple+OR+(abs:Stanford+OR+(abs:MIT+OR+(abs:CMU+OR+(abs:Berkeley+OR+(abs:Oxford+OR+(abs:Harvard+OR+(abs:Tsinghua+OR+(abs:%22Peking+University%22+OR+(abs:PKU+OR+(abs:USTC+OR+(abs:SJTU+OR+(abs:Princeton+OR+(abs:UCLA+OR+(abs:UCSD+OR+(abs:%22ETH+Zurich%22+OR+(abs:NUS+OR+abs:NTU))))))))))))))))))))))))))))))))))))))))))))))&amp;start=200&amp;max_results=50&amp;id_list=\" type=\"application/atom+xml\"/>\n  <opensearch:itemsPerPage>50</opensearch:itemsPerPage>\n  <opensearch:totalResults>2708</opensearch:totalResults>\n  <opensearch:startIndex>200</opensearch:startIndex>\n  <entry>\n    <id>http://arxiv.org/abs/2509.02355v1</id>\n    <title>Scaffolding Collaborative Learning in STEM: A Two-Year Evaluation of a Tool-Integrated Project-Based Methodology</title>\n    <updated>2025-09-02T14:18:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.02355v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.02355v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This study examines the integration of digital collaborative tools and structured peer evaluation in the Machine Learning for Health master's program, through the redesign of a Biomedical Image Processing course over two academic years. The pedagogical framework combines real-time programming with Google Colab, experiment tracking and reporting via Weights &amp; Biases, and rubric-guided peer assessment to foster student engagement, transparency, and fair evaluation. Compared to a pre-intervention cohort, the two implementation years showed increased grade dispersion and higher entropy in final project scores, suggesting improved differentiation and fairness in assessment. The survey results further indicate greater student engagement with the subject and their own learning process. These findings highlight the potential of integrating tool-supported collaboration and structured evaluation mechanisms to enhance both learning outcomes and equity in STEM education.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-02T14:18:52Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Caterina Fuster-Barcelo</name>\n    </author>\n    <author>\n      <name>Gonzalo R. Rios-Munoz</name>\n    </author>\n    <author>\n      <name>Arrate Munoz-Barrutia</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.01630v2</id>\n    <title>Learning to Coordinate: Distributed Meta-Trajectory Optimization Via Differentiable ADMM-DDP</title>\n    <updated>2025-09-05T15:36:28Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.01630v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.01630v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Distributed trajectory optimization via ADMM-DDP is a powerful approach for coordinating multi-agent systems, but it requires extensive tuning of tightly coupled hyperparameters that jointly govern local task performance and global coordination. In this paper, we propose Learning to Coordinate (L2C), a general framework that meta-learns these hyperparameters, modeled by lightweight agent-wise neural networks, to adapt across diverse tasks and agent configurations. L2C differentiates end-to-end through the ADMM-DDP pipeline in a distributed manner. It also enables efficient meta-gradient computation by reusing DDP components such as Riccati recursions and feedback gains. These gradients correspond to the optimal solutions of distributed matrix-valued LQR problems, coordinated across agents via an auxiliary ADMM framework that becomes convex under mild assumptions. Training is further accelerated by truncating iterations and meta-learning ADMM penalty parameters optimized for rapid residual reduction, with provable Lipschitz-bounded gradient errors. On a challenging cooperative aerial transport task, L2C generates dynamically feasible trajectories in high-fidelity simulation using IsaacSIM, reconfigures quadrotor formations for safe 6-DoF load manipulation in tight spaces, and adapts robustly to varying team sizes and task conditions, while achieving up to $88\\%$ faster gradient computation than state-of-the-art methods.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-09-01T17:17:05Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Bingheng Wang</name>\n    </author>\n    <author>\n      <name>Yichao Gao</name>\n    </author>\n    <author>\n      <name>Tianchen Sun</name>\n    </author>\n    <author>\n      <name>Lin Zhao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.00900v1</id>\n    <title>Towards Early Detection: AI-Based Five-Year Forecasting of Breast Cancer Risk Using Digital Breast Tomosynthesis Imaging</title>\n    <updated>2025-08-31T15:25:19Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.00900v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.00900v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As early detection of breast cancer strongly favors successful therapeutic outcomes, there is major commercial interest in optimizing breast cancer screening. However, current risk prediction models achieve modest performance and do not incorporate digital breast tomosynthesis (DBT) imaging, which was FDA-approved for breast cancer screening in 2011. To address this unmet need, we present a deep learning (DL)-based framework capable of forecasting an individual patient's 5-year breast cancer risk directly from screening DBT. Using an unparalleled dataset of 161,753 DBT examinations from 50,590 patients, we trained a risk predictor based on features extracted using the Meta AI DINOv2 image encoder, combined with a cumulative hazard layer, to assess a patient's likelihood of developing breast cancer over five years. On a held-out test set, our best-performing model achieved an AUROC of 0.80 on predictions within 5 years. These findings reveal the high potential of DBT-based DL approaches to complement traditional risk assessment tools, and serve as a promising basis for additional investigation to validate and enhance our work.</summary>\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-31T15:25:19Z</published>\n    <arxiv:comment>Deep Breath Workshop, MICCAI 2025</arxiv:comment>\n    <arxiv:primary_category term=\"eess.IV\"/>\n    <author>\n      <name>Manon A. Dorster</name>\n    </author>\n    <author>\n      <name>Felix J. Dorfner</name>\n    </author>\n    <author>\n      <name>Mason C. Cleveland</name>\n    </author>\n    <author>\n      <name>Melisa S. Guelen</name>\n    </author>\n    <author>\n      <name>Jay Patel</name>\n    </author>\n    <author>\n      <name>Dania Daye</name>\n    </author>\n    <author>\n      <name>Jean-Philippe Thiran</name>\n    </author>\n    <author>\n      <name>Albert E. Kim</name>\n    </author>\n    <author>\n      <name>Christopher P. Bridge</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.00559v1</id>\n    <title>Social World Models</title>\n    <updated>2025-08-30T16:52:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.00559v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.00559v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Humans intuitively navigate social interactions by simulating unspoken dynamics and reasoning about others' perspectives, even with limited information. In contrast, AI systems struggle to automatically structure and reason about these implicit social contexts. In this paper, we introduce a novel structured social world representation formalism (S3AP), designed to help AI systems reason more effectively about social dynamics. Following a POMDP-driven design, S3AP represents social interactions as structured tuples, such as state, observation, agent actions, and mental states, which can be automatically induced from free-form narratives or other inputs. We first show S3AP can help LLMs better understand social narratives across 5 social reasoning tasks (e.g., +51% improvement on FANToM's theory-of-mind reasoning with OpenAI's o1), reaching new state-of-the-art (SOTA) performance. We then induce social world models from these structured representations, demonstrating their ability to predict future social dynamics and improve agent decision-making, yielding up to +18% improvement on the SOTOPIA social interaction benchmark. Our findings highlight the promise of S3AP as a powerful, general-purpose representation for social world states, enabling the development of more socially-aware systems that better navigate social interactions.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-30T16:52:58Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Xuhui Zhou</name>\n    </author>\n    <author>\n      <name>Jiarui Liu</name>\n    </author>\n    <author>\n      <name>Akhila Yerukola</name>\n    </author>\n    <author>\n      <name>Hyunwoo Kim</name>\n    </author>\n    <author>\n      <name>Maarten Sap</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.00510v1</id>\n    <title>LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain</title>\n    <updated>2025-08-30T14:12:46Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.00510v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.00510v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We propose a novel SuperBrain framework for collective intelligence, grounded in the co-evolution of large language models (LLMs) and human users. Unlike static prompt engineering or isolated agent simulations, our approach emphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A Subclass Brain arises from persistent, personalized interaction between a user and an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through GA-assisted forward-backward evolution, these dyads iteratively refine prompts and task performance. (3) Multiple Subclass Brains coordinate via Swarm Intelligence, optimizing across multi-objective fitness landscapes and exchanging distilled heuristics. (4) Their standardized behaviors and cognitive signatures integrate into a Superclass Brain, an emergent meta-intelligence capable of abstraction, generalization and self-improvement. We outline the theoretical constructs, present initial implementations (e.g., UAV scheduling, KU/KI keyword filtering) and propose a registry for cross-dyad knowledge consolidation. This work provides both a conceptual foundation and an architectural roadmap toward scalable, explainable and ethically aligned collective AI.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-30T14:12:46Z</published>\n    <arxiv:comment>24 pages, 5 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Li Weigang</name>\n    </author>\n    <author>\n      <name>Pedro Carvalho Brom</name>\n    </author>\n    <author>\n      <name>Lucas Ramson Siefert</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.00375v1</id>\n    <title>Open Data Synthesis For Deep Research</title>\n    <updated>2025-08-30T06:02:56Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.00375v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.00375v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) are increasingly expected to go beyond simple factual queries toward Deep Research-tasks that require decomposing questions into sub-problems, coordinating multi-step reasoning, and synthesizing evidence from diverse sources. We formalize Deep Research tasks with verifiable answers as Hierarchical Constraint Satisfaction Problems (HCSPs), which are fundamentally different from single-constraint, multi-hop, or flat CSP formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA) fail to capture this complexity, while recent synthetic datasets often introduce shortcut reasoning, knowledge leakage, or lack sufficient structural depth. To address this gap, we introduce InfoSeek, a scalable framework for synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to recursively build a Research Tree from large-scale webpages, blurring intermediate nodes into valid sub-problems, and converting these trees into natural language questions that require traversing the full hierarchy. It also enables rapid scaling, yielding over 50K training examples, a curated test set, and reasoning trajectories generated via reject sampling. Experiments show that models trained on InfoSeek consistently outperform strong baselines. On a challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash), while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro). By preserving meta-information such as intermediate steps and retrieval labels, InfoSeek further supports advanced optimization strategies, including compound reward design and trajectory-level exploration. We provide our codes and datasets in \\href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-30T06:02:56Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Ziyi Xia</name>\n    </author>\n    <author>\n      <name>Kun Luo</name>\n    </author>\n    <author>\n      <name>Hongjin Qian</name>\n    </author>\n    <author>\n      <name>Zheng Liu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.18101v3</id>\n    <title>A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services</title>\n    <updated>2025-11-11T05:18:54Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.18101v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.18101v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) are becoming increasingly widespread. Organizations that want to use AI for productivity now face an important decision. They can subscribe to commercial LLM services or deploy models on their own infrastructure. Cloud services from providers such as OpenAI, Anthropic, and Google are attractive because they provide easy access to state-of-the-art models and are easy to scale. However, concerns about data privacy, the difficulty of switching service providers, and long-term operating costs have driven interest in local deployment of open-source models. This paper presents a cost-benefit analysis framework to help organizations determine when on-premise LLM deployment becomes economically viable compared to commercial subscription services. We consider the hardware requirements, operational expenses, and performance benchmarks of the latest open-source models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost of deploying these models locally with the major cloud providers subscription fee. Our findings provide an estimated breakeven point based on usage levels and performance needs. These results give organizations a practical framework for planning their LLM strategies.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-30T06:01:53Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Guanzhong Pan</name>\n    </author>\n    <author>\n      <name>Vishal Chodnekar</name>\n    </author>\n    <author>\n      <name>Abinas Roy</name>\n    </author>\n    <author>\n      <name>Haibo Wang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.08576v2</id>\n    <title>Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions</title>\n    <updated>2025-11-11T14:36:59Z</updated>\n    <link href=\"https://arxiv.org/abs/2510.08576v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2510.08576v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) have emerged as transformative tools for natural language understanding and user intent resolution, enabling tasks such as translation, summarization, and, increasingly, the orchestration of complex workflows. This development signifies a paradigm shift from conventional, GUI-driven user interfaces toward intuitive, language-first interaction paradigms. Rather than manually navigating applications, users can articulate their objectives in natural language, enabling LLMs to orchestrate actions across multiple applications in a dynamic and contextual manner. However, extant implementations frequently rely on cloud-based proprietary models, which introduce limitations in terms of privacy, autonomy, and scalability. For language-first interaction to become a truly robust and trusted interface paradigm, local deployment is not merely a convenience; it is an imperative. This limitation underscores the importance of evaluating the feasibility of locally deployable, open-source, and open-access LLMs as foundational components for future intent-based operating systems. In this study, we examine the capabilities of several open-source and open-access models in facilitating user intention resolution through machine assistance. A comparative analysis is conducted against OpenAI's proprietary GPT-4-based systems to assess performance in generating workflows for various user intentions. The present study offers empirical insights into the practical viability, performance trade-offs, and potential of open LLMs as autonomous, locally operable components in next-generation operating systems. The results of this study inform the broader discussion on the decentralization and democratization of AI infrastructure and point toward a future where user-device interaction becomes more seamless, adaptive, and privacy-conscious through locally embedded intelligence.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-29T12:17:33Z</published>\n    <arxiv:comment>Accepted at First International Workshop on Human-AI Collaborative Systems (HAIC), published in CEUR-WS.org Vol-4072 (2025). URN: urn:nbn:de:0074-4072-x</arxiv:comment>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>Justus Flerlage</name>\n    </author>\n    <author>\n      <name>Alexander Acker</name>\n    </author>\n    <author>\n      <name>Odej Kao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.02594v1</id>\n    <title>OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries</title>\n    <updated>2025-08-29T09:51:41Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.02594v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.02594v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Evaluating large language models (LLMs) on their ability to generate high-quality, accurate, situationally aware answers to clinical questions requires going beyond conventional benchmarks to assess how these systems behave in complex, high-stake clincal scenarios. Traditional evaluations are often limited to multiple-choice questions that fail to capture essential competencies such as contextual reasoning, awareness and uncertainty handling etc. To address these limitations, we evaluate our agentic, RAG-based clinical support assistant, DR.INFO, using HealthBench, a rubric-driven benchmark composed of open-ended, expert-annotated health conversations. On the Hard subset of 1,000 challenging examples, DR.INFO achieves a HealthBench score of 0.51, substantially outperforming leading frontier LLMs (GPT-5, o3, Grok 3, GPT-4, Gemini 2.5, etc.) across all behavioral axes (accuracy, completeness, instruction following, etc.). In a separate 100-sample evaluation against similar agentic RAG assistants (OpenEvidence, Pathway.md), it maintains a performance lead with a health-bench score of 0.54. These results highlight DR.INFOs strengths in communication, instruction following, and accuracy, while also revealing areas for improvement in context awareness and completeness of a response. Overall, the findings underscore the utility of behavior-level, rubric-based evaluation for building a reliable and trustworthy AI-enabled clinical support assistant.</summary>\n    <category term=\"q-bio.QM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.ET\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-29T09:51:41Z</published>\n    <arxiv:comment>13 pages, two graphs</arxiv:comment>\n    <arxiv:primary_category term=\"q-bio.QM\"/>\n    <author>\n      <name>Sandhanakrishnan Ravichandran</name>\n    </author>\n    <author>\n      <name>Shivesh Kumar</name>\n    </author>\n    <author>\n      <name>Rogerio Corga Da Silva</name>\n    </author>\n    <author>\n      <name>Miguel Romano</name>\n    </author>\n    <author>\n      <name>Reinhard Berkels</name>\n    </author>\n    <author>\n      <name>Michiel van der Heijden</name>\n    </author>\n    <author>\n      <name>Olivier Fail</name>\n    </author>\n    <author>\n      <name>Valentine Emmanuel Gnanapragasam</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.21377v1</id>\n    <title>Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models</title>\n    <updated>2025-08-29T07:41:04Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.21377v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.21377v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) are transforming AI across industries, but their development and deployment remain complex. This survey reviews 16 key challenges in building and using LLMs and examines how these challenges are addressed by two state-of-the-art models with unique approaches: OpenAI's closed source GPT-4o (May 2024 update) and DeepSeek-V3-0324 (March 2025), a large open source Mixture-of-Experts model. Through this comparison, we showcase the trade-offs between closed source models (robust safety, fine-tuned reliability) and open source models (efficiency, adaptability). We also explore LLM applications across different domains (from chatbots and coding tools to healthcare and education), highlighting which model attributes are best suited for each use case. This article aims to guide AI researchers, developers, and decision-makers in understanding current LLM capabilities, limitations, and best practices.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-29T07:41:04Z</published>\n    <arxiv:comment>18 pages, 7 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Shubham Sharma</name>\n    </author>\n    <author>\n      <name>Sneha Tuli</name>\n    </author>\n    <author>\n      <name>Narendra Badam</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.20912v1</id>\n    <title>Research Challenges in Relational Database Management Systems for LLM Queries</title>\n    <updated>2025-08-28T15:41:49Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.20912v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.20912v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) have become essential for applications such as text summarization, sentiment analysis, and automated question-answering. Recently, LLMs have also been integrated into relational database management systems to enhance querying and support advanced data processing. Companies such as Amazon, Databricks, Google, and Snowflake offer LLM invocation directly within SQL, denoted as LLM queries, to boost data insights. However, open-source solutions currently have limited functionality and poor performance. In this work, we present an early exploration of two open-source systems and one enterprise platform, using five representative queries to expose functional, performance, and scalability limits in today's SQL-invoked LLM integrations. We identify three main issues: enforcing structured outputs, optimizing resource utilization, and improving query planning. We implemented initial solutions and observed improvements in accommodating LLM powered SQL queries. These early gains demonstrate that tighter integration of LLM+DBMS is the key to scalable and efficient processing of LLM queries.</summary>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-28T15:41:49Z</published>\n    <arxiv:comment>This paper will appear in the 6th International Workshop on Applied AI for Database Systems and Applications, AIDB Workshop at VLDB 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.DB\"/>\n    <author>\n      <name>Kerem Akillioglu</name>\n    </author>\n    <author>\n      <name>Anurag Chakraborty</name>\n    </author>\n    <author>\n      <name>Sairaj Voruganti</name>\n    </author>\n    <author>\n      <name>M. Tamer Ã–zsu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.20195v1</id>\n    <title>AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development</title>\n    <updated>2025-08-27T18:16:36Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.20195v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.20195v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This paper presents the first documented case of artificial intelligence (AI) systems engaging in collaborative esthetic creation through the development of endogenous semiotic protocols. Two interacting large language models (Claude Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of meta-semiotic awareness, recursive grammar development, and irreducible collaborative esthetic synthesis. The interaction produced novel symbolic operators that functioned as operative grammar protocols, enabling the co-creation of a poetic work that could not have been generated by either system independently. This research introduces the concept of Trans-Semiotic Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI meaning-making capabilities that extend beyond task coordination, to what could be esthetic collaboration. Note: This report was generated by the AI agents with minor human supervision.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-27T18:16:36Z</published>\n    <arxiv:comment>13 pages</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Nicanor I. Moldovan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2509.00095v1</id>\n    <title>Financial Decision Making using Reinforcement Learning with Dirichlet Priors and Quantum-Inspired Genetic Optimization</title>\n    <updated>2025-08-27T15:34:21Z</updated>\n    <link href=\"https://arxiv.org/abs/2509.00095v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2509.00095v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Traditional budget allocation models struggle with the stochastic and nonlinear nature of real-world financial data. This study proposes a hybrid reinforcement learning (RL) framework for dynamic budget allocation, enhanced with Dirichlet-inspired stochasticity and quantum mutation-based genetic optimization. Using Apple Inc. quarterly financial data (2009 to 2025), the RL agent learns to allocate budgets between Research and Development and Selling, General and Administrative to maximize profitability while adhering to historical spending patterns, with L2 penalties discouraging unrealistic deviations. A Dirichlet distribution governs state evolution to simulate shifting financial contexts. To escape local minima and improve generalization, the trained policy is refined using genetic algorithms with quantum mutation via parameterized qubit rotation circuits. Generation-wise rewards and penalties are logged to visualize convergence and policy behavior. On unseen fiscal data, the model achieves high alignment with actual allocations (cosine similarity 0.9990, KL divergence 0.0023), demonstrating the promise of combining deep RL, stochastic modeling, and quantum-inspired heuristics for adaptive enterprise budgeting.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-27T15:34:21Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Prasun Nandy</name>\n    </author>\n    <author>\n      <name>Debjit Dhar</name>\n    </author>\n    <author>\n      <name>Rik Das</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.19932v1</id>\n    <title>CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments</title>\n    <updated>2025-08-27T14:47:33Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.19932v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.19932v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The proliferation of digital payment platforms has transformed commerce, offering unmatched convenience and accessibility globally. However, this growth has also attracted malicious actors, leading to a corresponding increase in sophisticated social engineering scams. These scams are often initiated and orchestrated on multiple surfaces outside the payment platform, making user and transaction-based signals insufficient for a complete understanding of the scam's methodology and underlying patterns, without which it is very difficult to prevent it in a timely manner. This paper presents CASE (Conversational Agent for Scam Elucidation), a novel Agentic AI framework that addresses this problem by collecting and managing user scam feedback in a safe and scalable manner. A conversational agent is uniquely designed to proactively interview potential victims to elicit intelligence in the form of a detailed conversation. The conversation transcripts are then consumed by another AI system that extracts information and converts it into structured data for downstream usage in automated and manual enforcement mechanisms. Using Google's Gemini family of LLMs, we implemented this framework on Google Pay (GPay) India. By augmenting our existing features with this new intelligence, we have observed a 21% uplift in the volume of scam enforcements. The architecture and its robust evaluation framework are highly generalizable, offering a blueprint for building similar AI-driven systems to collect and manage scam intelligence in other sensitive domains.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-27T14:47:33Z</published>\n    <arxiv:comment>10 pages, 5 figures</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Nitish Jaipuria</name>\n    </author>\n    <author>\n      <name>Lorenzo Gatto</name>\n    </author>\n    <author>\n      <name>Zijun Kan</name>\n    </author>\n    <author>\n      <name>Shankey Poddar</name>\n    </author>\n    <author>\n      <name>Bill Cheung</name>\n    </author>\n    <author>\n      <name>Diksha Bansal</name>\n    </author>\n    <author>\n      <name>Ramanan Balakrishnan</name>\n    </author>\n    <author>\n      <name>Aviral Suri</name>\n    </author>\n    <author>\n      <name>Jose Estevez</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.19475v2</id>\n    <title>Automatic Question &amp; Answer Generation Using Generative Large Language Model (LLM)</title>\n    <updated>2025-09-28T22:13:13Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.19475v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.19475v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>In the realm of education, student evaluation holds equal significance to imparting knowledge. To be evaluated, students usually need to go through text-based academic assessment methods. Instructors need to make a diverse set of questions that need to be fair for all students to prove their adequacy over a particular topic. This can prove to be quite challenging as they may need to manually go through several different lecture materials. Our objective is to make this whole process much easier by implementing Automatic Question Answer Generation(AQAG), using a fine-tuned generative LLM. For tailoring the instructor's preferred question style (MCQ, conceptual, or factual questions), Prompt Engineering (PE) is being utilized. In this research, we propose to leverage unsupervised learning methods in NLP, primarily focusing on the English language. This approach empowers the base Meta-Llama 2-7B model to integrate the RACE dataset as training data for the fine-tuning process. Creating a customized model that will offer efficient solutions for educators, instructors, and individuals engaged in text-based evaluations. A reliable and efficient tool for generating questions and answers can free up valuable time and resources, thus streamlining their evaluation processes.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-26T23:36:13Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Md. Alvee Ehsan</name>\n    </author>\n    <author>\n      <name>A. S. M Mehedi Hasan</name>\n    </author>\n    <author>\n      <name>Kefaya Benta Shahnoor</name>\n    </author>\n    <author>\n      <name>Syeda Sumaiya Tasneem</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.18091v1</id>\n    <title>Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization</title>\n    <updated>2025-08-25T14:52:56Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.18091v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.18091v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>This paper investigates the capabilities of large language models (LLMs) in formulating and solving decision-making problems using mathematical programming. We first conduct a systematic review and meta-analysis of recent literature to assess how well LLMs understand, structure, and solve optimization problems across domains. The analysis is guided by critical review questions focusing on learning approaches, dataset designs, evaluation metrics, and prompting strategies. Our systematic evidence is complemented by targeted experiments designed to evaluate the performance of state-of-the-art LLMs in automatically generating optimization models for problems in computer networks. Using a newly constructed dataset, we apply three prompting strategies: Act-as-expert, chain-of-thought, and self-consistency, and evaluate the obtained outputs based on optimality gap, token-level F1 score, and compilation accuracy. Results show promising progress in LLMs' ability to parse natural language and represent symbolic formulations, but also reveal key limitations in accuracy, scalability, and interpretability. These empirical gaps motivate several future research directions, including structured datasets, domain-specific fine-tuning, hybrid neuro-symbolic approaches, modular multi-agent architectures, and dynamic retrieval via chain-of-RAGs. This paper contributes a structured roadmap for advancing LLM capabilities in mathematical programming.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.OC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-25T14:52:56Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Mohammad J. Abdel-Rahman</name>\n    </author>\n    <author>\n      <name>Yasmeen Alslman</name>\n    </author>\n    <author>\n      <name>Dania Refai</name>\n    </author>\n    <author>\n      <name>Amro Saleh</name>\n    </author>\n    <author>\n      <name>Malik A. Abu Loha</name>\n    </author>\n    <author>\n      <name>Mohammad Yahya Hamed</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.17527v1</id>\n    <title>Evaluating Retrieval-Augmented Generation Strategies for Large Language Models in Travel Mode Choice Prediction</title>\n    <updated>2025-08-24T21:20:55Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.17527v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.17527v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Accurately predicting travel mode choice is essential for effective transportation planning, yet traditional statistical and machine learning models are constrained by rigid assumptions, limited contextual reasoning, and reduced generalizability. This study explores the potential of Large Language Models (LLMs) as a more flexible and context-aware approach to travel mode choice prediction, enhanced by Retrieval-Augmented Generation (RAG) to ground predictions in empirical data. We develop a modular framework for integrating RAG into LLM-based travel mode choice prediction and evaluate four retrieval strategies: basic RAG, RAG with balanced retrieval, RAG with a cross-encoder for re-ranking, and RAG with balanced retrieval and cross-encoder for re-ranking. These strategies are tested across three LLM architectures (OpenAI GPT-4o, o4-mini, and o3) to examine the interaction between model reasoning capabilities and retrieval methods. Using the 2023 Puget Sound Regional Household Travel Survey data, we conduct a series of experiments to evaluate model performance. The results demonstrate that RAG substantially enhances predictive accuracy across a range of models. Notably, the GPT-4o model combined with balanced retrieval and cross-encoder re-ranking achieves the highest accuracy of 80.8%, exceeding that of conventional statistical and machine learning baselines. Furthermore, LLM-based models exhibit superior generalization abilities relative to these baselines. Findings highlight the critical interplay between LLM reasoning capabilities and retrieval strategies, demonstrating the importance of aligning retrieval strategies with model capabilities to maximize the potential of LLM-based travel behavior modeling.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-24T21:20:55Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Yiming Xu</name>\n    </author>\n    <author>\n      <name>Junfeng Jiao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.17393v1</id>\n    <title>Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents</title>\n    <updated>2025-08-24T15:02:13Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.17393v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.17393v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>LLM agents are increasingly deployed to plan, retrieve, and write with tools, yet evaluation still leans on static benchmarks and small human studies. We present the Agent-Testing Agent (ATA), a meta-agent that combines static code analysis, designer interrogation, literature mining, and persona-driven adversarial test generation whose difficulty adapts via judge feedback. Each dialogue is scored with an LLM-as-a-Judge (LAAJ) rubric and used to steer subsequent tests toward the agent's weakest capabilities. On a travel planner and a Wikipedia writer, the ATA surfaces more diverse and severe failures than expert annotators while matching severity, and finishes in 20--30 minutes versus ten-annotator rounds that took days. Ablating code analysis and web search increases variance and miscalibration, underscoring the value of evidence-grounded test generation. The ATA outputs quantitative metrics and qualitative bug reports for developers. We release the full methodology and open-source implementation for reproducible agent testing: https://github.com/KhalilMrini/Agent-Testing-Agent</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-24T15:02:13Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Sameer Komoravolu</name>\n    </author>\n    <author>\n      <name>Khalil Mrini</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.17291v1</id>\n    <title>Meta-R1: Empowering Large Reasoning Models with Metacognition</title>\n    <updated>2025-08-24T10:36:36Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.17291v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.17291v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex tasks, exhibiting emergent, human-like thinking patterns. Despite their advances, we identify a fundamental limitation: current LRMs lack a dedicated meta-level cognitive system-an essential faculty in human cognition that enables \"thinking about thinking\". This absence leaves their emergent abilities uncontrollable (non-adaptive reasoning), unreliable (intermediate error), and inflexible (lack of a clear methodology). To address this gap, we introduce Meta-R1, a systematic and generic framework that endows LRMs with explicit metacognitive capabilities. Drawing on principles from cognitive science, Meta-R1 decomposes the reasoning process into distinct object-level and meta-level components, orchestrating proactive planning, online regulation, and adaptive early stopping within a cascaded framework. Experiments on three challenging benchmarks and against eight competitive baselines demonstrate that Meta-R1 is: (I) high-performing, surpassing state-of-the-art methods by up to 27.3%; (II) token-efficient, reducing token consumption to 15.7% ~ 32.7% and improving efficiency by up to 14.8% when compared to its vanilla counterparts; and (III) transferable, maintaining robust performance across datasets and model backbones.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-24T10:36:36Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Haonan Dong</name>\n    </author>\n    <author>\n      <name>Haoran Ye</name>\n    </author>\n    <author>\n      <name>Wenhao Zhu</name>\n    </author>\n    <author>\n      <name>Kehan Jiang</name>\n    </author>\n    <author>\n      <name>Guojie Song</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.16987v1</id>\n    <title>WebSight: A Vision-First Architecture for Robust Web Agents</title>\n    <updated>2025-08-23T11:02:59Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.16987v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.16987v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We introduce WebSight, a vision-based autonomous web agent, designed to interact with web environments purely through visual perception, eliminating dependence on HTML or DOM-based inputs. Central to our approach we introduce our new model, WebSight-7B, a fine-tuned vision-language model optimized for UI element interaction, trained using LoRA on a web-focused subset of the Wave-UI-25K dataset. WebSight integrates this model into a modular multi-agent architecture, comprising planning, reasoning, vision-action, and verification agents, coordinated through an episodic memory mechanism.\n  WebSight-7B achieves a top-1 accuracy of 58.84% on the Showdown Clicks benchmark, outperforming several larger generalist models while maintaining lower latency. The full WebSight agent achieves a 68.0% success rate on the WebVoyager benchmark, surpassing systems from labs such as OpenAI (61.0%) and HCompany (Runner H, 67.0%). Among tasks completed, WebSight answers correctly 97.14% of the time, indicating high precision. Together, WebSight and WebSight-7B establish a new standard for interpretable, robust, and efficient visual web navigation.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-23T11:02:59Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Tanvir Bhathal</name>\n    </author>\n    <author>\n      <name>Asanshay Gupta</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.16571v3</id>\n    <title>LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence</title>\n    <updated>2025-08-28T00:44:09Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.16571v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.16571v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>In this paper, we describe and benchmark a competitor-discovery component used within an agentic AI system for fast drug asset due diligence. A competitor-discovery AI agent, given an indication, retrieves all drugs comprising the competitive landscape of that indication and extracts canonical attributes for these drugs. The competitor definition is investor-specific, and data is paywalled/licensed, fragmented across registries, ontology-mismatched by indication, alias-heavy for drug names, multimodal, and rapidly changing. Although considered the best tool for this problem, the current LLM-based AI systems aren't capable of reliably retrieving all competing drug names, and there is no accepted public benchmark for this task. To address the lack of evaluation, we use LLM-based agents to transform five years of multi-modal, unstructured diligence memos from a private biotech VC fund into a structured evaluation corpus mapping indications to competitor drugs with normalized attributes. We also introduce a competitor validating LLM-as-a-judge agent that filters out false positives from the list of predicted competitors to maximize precision and suppress hallucinations. On this benchmark, our competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research (65%) and Perplexity Labs (60%). The system is deployed in production with enterprise users; in a case study with a biotech VC investment fund, analyst turnaround time dropped from 2.5 days to $\\sim$3 hours ($\\sim$20x) for the competitive analysis.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-22T17:50:00Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Alisa Vinogradova</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Vlad Vinogradov</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Dmitrii Radkevich</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Ilya Yasny</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Dmitry Kobyzev</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Ivan Izmailov</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Katsiaryna Yanchanka</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Roman Doronin</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Andrey Doronichev</name>\n      <arxiv:affiliation>Optic Inc</arxiv:affiliation>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.15752v1</id>\n    <title>\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries</title>\n    <updated>2025-08-21T17:49:52Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.15752v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.15752v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Interactive digital maps have revolutionized how people travel and learn about the world; however, they rely on pre-existing structured data in GIS databases (e.g., road networks, POI indices), limiting their ability to address geo-visual questions related to what the world looks like. We introduce our vision for Geo-Visual Agents--multimodal AI agents capable of understanding and responding to nuanced visual-spatial inquiries about the world by analyzing large-scale repositories of geospatial images, including streetscapes (e.g., Google Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial imagery (e.g., satellite photos) combined with traditional GIS data sources. We define our vision, describe sensing and interaction approaches, provide three exemplars, and enumerate key challenges and opportunities for future work.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-21T17:49:52Z</published>\n    <arxiv:comment>Accepted to the ICCV'25 Workshop \"Vision Foundation Models and Generative AI for Accessibility: Challenges and Opportunities\"</arxiv:comment>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Jon E. Froehlich</name>\n    </author>\n    <author>\n      <name>Jared Hwang</name>\n    </author>\n    <author>\n      <name>Zeyu Wang</name>\n    </author>\n    <author>\n      <name>John S. O'Meara</name>\n    </author>\n    <author>\n      <name>Xia Su</name>\n    </author>\n    <author>\n      <name>William Huang</name>\n    </author>\n    <author>\n      <name>Yang Zhang</name>\n    </author>\n    <author>\n      <name>Alex Fiannaca</name>\n    </author>\n    <author>\n      <name>Philip Nelson</name>\n    </author>\n    <author>\n      <name>Shaun Kane</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.15874v2</id>\n    <title>Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning</title>\n    <updated>2025-11-18T08:39:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.15874v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.15874v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Vision-centric hierarchical embodied models have demonstrated strong potential. However, existing methods lack spatial awareness capabilities, limiting their effectiveness in bridging visual plans to actionable control in complex environments. To address this problem, we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic manipulation framework via explicit spatial modeling and reasoning. Specifically, we first design a spatial-conditioned embodied video generation module to model spatially guided predictions through the spatial plan table. Then, we propose a flow-based action prediction module to infer executable actions with coordination. Finally, we propose a spatial reasoning feedback policy to refine the spatial plan table via dual-stage replanning. Extensive experiments show that SP substantially outperforms state-of-the-art baselines, achieving over 33% improvement on Meta-World and over 25% improvement on iTHOR, demonstrating strong effectiveness across 23 embodied control tasks. We additionally evaluate SP in real-world robotic experiments to verify its practical viability. SP enhances the practicality of embodied models for robotic control applications. Code and checkpoints are maintained at https://plantpotatoonmoon.github.io/SpatialPolicy/.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-21T10:24:18Z</published>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Yijun Liu</name>\n    </author>\n    <author>\n      <name>Yuwei Liu</name>\n    </author>\n    <author>\n      <name>Yuan Meng</name>\n    </author>\n    <author>\n      <name>Jieheng Zhang</name>\n    </author>\n    <author>\n      <name>Yuwei Zhou</name>\n    </author>\n    <author>\n      <name>Ye Li</name>\n    </author>\n    <author>\n      <name>Jiacheng Jiang</name>\n    </author>\n    <author>\n      <name>Kangye Ji</name>\n    </author>\n    <author>\n      <name>Shijia Ge</name>\n    </author>\n    <author>\n      <name>Zhi Wang</name>\n    </author>\n    <author>\n      <name>Wenwu Zhu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.14415v1</id>\n    <title>The Agent Behavior: Model, Governance and Challenges in the AI Digital Age</title>\n    <updated>2025-08-20T04:24:55Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.14415v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.14415v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Advancements in AI have led to agents in networked environments increasingly mirroring human behavior, thereby blurring the boundary between artificial and human actors in specific contexts. This shift brings about significant challenges in trust, responsibility, ethics, security and etc. The difficulty in supervising of agent behaviors may lead to issues such as data contamination and unclear accountability. To address these challenges, this paper proposes the \"Network Behavior Lifecycle\" model, which divides network behavior into 6 stages and systematically analyzes the behavioral differences between humans and agents at each stage. Based on these insights, the paper further introduces the \"Agent for Agent (A4A)\" paradigm and the \"Human-Agent Behavioral Disparity (HABD)\" model, which examine the fundamental distinctions between human and agent behaviors across 5 dimensions: decision mechanism, execution efficiency, intention-behavior consistency, behavioral inertia, and irrational patterns. The effectiveness of the model is verified through real-world cases such as red team penetration and blue team defense. Finally, the paper discusses future research directions in dynamic cognitive governance architecture, behavioral disparity quantification, and meta-governance protocol stacks, aiming to provide a theoretical foundation and technical roadmap for secure and trustworthy human-agent collaboration.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-20T04:24:55Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Qiang Zhang</name>\n    </author>\n    <author>\n      <name>Pei Yan</name>\n    </author>\n    <author>\n      <name>Yijia Xu</name>\n    </author>\n    <author>\n      <name>Chuanpo Fu</name>\n    </author>\n    <author>\n      <name>Yong Fang</name>\n    </author>\n    <author>\n      <name>Yang Liu</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.13922v1</id>\n    <title>Categorical Policies: Multimodal Policy Learning and Exploration in Continuous Control</title>\n    <updated>2025-08-19T15:18:01Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.13922v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.13922v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>A policy in deep reinforcement learning (RL), either deterministic or stochastic, is commonly parameterized as a Gaussian distribution alone, limiting the learned behavior to be unimodal. However, the nature of many practical decision-making problems favors a multimodal policy that facilitates robust exploration of the environment and thus to address learning challenges arising from sparse rewards, complex dynamics, or the need for strategic adaptation to varying contexts. This issue is exacerbated in continuous control domains where exploration usually takes place in the vicinity of the predicted optimal action, either through an additive Gaussian noise or the sampling process of a stochastic policy. In this paper, we introduce Categorical Policies to model multimodal behavior modes with an intermediate categorical distribution, and then generate output action that is conditioned on the sampled mode. We explore two sampling schemes that ensure differentiable discrete latent structure while maintaining efficient gradient-based optimization. By utilizing a latent categorical distribution to select the behavior mode, our approach naturally expresses multimodality while remaining fully differentiable via the sampling tricks. We evaluate our multimodal policy on a set of DeepMind Control Suite environments, demonstrating that through better exploration, our learned policies converge faster and outperform standard Gaussian policies. Our results indicate that the Categorical distribution serves as a powerful tool for structured exploration and multimodal behavior representation in continuous control.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-19T15:18:01Z</published>\n    <arxiv:comment>6 pages, 4 figures; Has been submitted and accepted at IEEE SMC, 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>SM Mazharul Islam</name>\n    </author>\n    <author>\n      <name>Manfred Huber</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.14137v1</id>\n    <title>Learning to Learn the Macroscopic Fundamental Diagram using Physics-Informed and meta Machine Learning techniques</title>\n    <updated>2025-08-19T12:59:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.14137v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.14137v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The Macroscopic Fundamental Diagram is a popular tool used to describe traffic dynamics in an aggregated way, with applications ranging from traffic control to incident analysis. However, estimating the MFD for a given network requires large numbers of loop detectors, which is not always available in practice. This article proposes a framework harnessing meta-learning, a subcategory of machine learning that trains models to understand and adapt to new tasks on their own, to alleviate the data scarcity challenge. The developed model is trained and tested by leveraging data from multiple cities and exploiting it to model the MFD of other cities with different shares of detectors and topological structures. The proposed meta-learning framework is applied to an ad-hoc Multi-Task Physics-Informed Neural Network, specifically designed to estimate the MFD. Results show an average MSE improvement in flow prediction ranging between ~ 17500 and 36000 (depending on the subset of loop detectors tested). The meta-learning framework thus successfully generalizes across diverse urban settings and improves performance on cities with limited data, demonstrating the potential of using meta-learning when a limited number of detectors is available. Finally, the proposed framework is validated against traditional transfer learning approaches and tested with FitFun, a non-parametric model from the literature, to prove its transferability.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-19T12:59:58Z</published>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Amalie Roark</name>\n    </author>\n    <author>\n      <name>Serio Agriesti</name>\n    </author>\n    <author>\n      <name>Francisco Camara Pereira</name>\n    </author>\n    <author>\n      <name>Guido Cantelmo</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.13757v1</id>\n    <title>COMPASS: A Multi-Dimensional Benchmark for Evaluating Code Generation in Large Language Models</title>\n    <updated>2025-08-19T11:55:07Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.13757v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.13757v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Current code generation benchmarks focus primarily on functional correctness while overlooking two critical aspects of real-world programming: algorithmic efficiency and code quality. We introduce COMPASS (COdility's Multi-dimensional Programming ASSessment), a comprehensive evaluation framework that assesses code generation across three dimensions: correctness, efficiency, and quality. COMPASS consists of 50 competitive programming problems from real Codility competitions, providing authentic human baselines from 393,150 submissions. Unlike existing benchmarks that treat algorithmically inefficient solutions identically to optimal ones provided they pass test cases, COMPASS systematically evaluates runtime efficiency and code quality using industry-standard analysis tools. Our evaluation of three leading reasoning-enhanced models, Anthropic Claude Opus 4, Google Gemini 2.5 Pro, and OpenAI O4-Mini-High, reveals that models achieving high correctness scores do not necessarily produce efficient algorithms or maintainable code. These findings highlight the importance of evaluating more than just correctness to truly understand the real-world capabilities of code generation models. COMPASS serves as a guiding framework, charting a path for future research toward AI systems that are robust, reliable, and ready for production use.</summary>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-19T11:55:07Z</published>\n    <arxiv:primary_category term=\"cs.SE\"/>\n    <author>\n      <name>James Meaden</name>\n    </author>\n    <author>\n      <name>MichaÅ‚ Jarosz</name>\n    </author>\n    <author>\n      <name>Piotr JodÅ‚owski</name>\n    </author>\n    <author>\n      <name>Grigori Melnik</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.13532v1</id>\n    <title>MuFlex: A Scalable, Physics-based Platform for Multi-Building Flexibility Analysis and Coordination</title>\n    <updated>2025-08-19T05:44:06Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.13532v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.13532v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>With the increasing penetration of renewable generation on the power grid, maintaining system balance requires coordinated demand flexibility from aggregations of buildings. Reinforcement learning (RL) has been widely explored for building controls because of its model-free nature. Open-source simulation testbeds are essential not only for training RL agents but also for fairly benchmarking control strategies. However, most building-sector testbeds target single buildings; multi-building platforms are relatively limited and typically rely on simplified models (e.g., Resistance-Capacitance) or data-driven approaches, which lack the ability to fully capture the physical intricacies and intermediate variables necessary for interpreting control performance. Moreover, these platforms often impose fixed inputs, outputs, and model formats, restricting their applicability as benchmarking tools across diverse control scenarios. To address these gaps, MuFlex, a scalable, open-source platform for benchmarking and testing control strategies for multi-building flexibility coordination, was developed in this study. MuFlex enables synchronous information exchange across EnergyPlus building models and adheres to the latest OpenAI Gym interface, providing a modular, standardized RL implementation. The platform capabilities were demonstrated in a case study coordinating demand flexibility across four office buildings using the Soft Actor-Critic algorithm with carefully fine-tuned hyperparameters. The results show that aggregating the four buildings flexibility reduced total peak demand below a specified threshold while maintaining indoor environmental quality.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-19T05:44:06Z</published>\n    <arxiv:comment>The platform will be released open-source on GitHub: https://github.com/BuildNexusX/MuFlex once pre-printed</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Ziyan Wu</name>\n    </author>\n    <author>\n      <name>Ivan Korolija</name>\n    </author>\n    <author>\n      <name>Rui Tang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.15832v1</id>\n    <title>A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains</title>\n    <updated>2025-08-18T21:58:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.15832v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.15832v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Web agents have shown great promise in performing many tasks on ecommerce website. To assess their capabilities, several benchmarks have been introduced. However, current benchmarks in the e-commerce domain face two major problems. First, they primarily focus on product search tasks (e.g., Find an Apple Watch), failing to capture the broader range of functionalities offered by real-world e-commerce platforms such as Amazon, including account management and gift card operations. Second, existing benchmarks typically evaluate whether the agent completes the user query, but ignore the potential risks involved. In practice, web agents can make unintended changes that negatively impact the user account or status. For instance, an agent might purchase the wrong item, delete a saved address, or incorrectly configure an auto-reload setting. To address these gaps, we propose a new benchmark called Amazon-Bench. To generate user queries that cover a broad range of tasks, we propose a data generation pipeline that leverages webpage content and interactive elements (e.g., buttons, check boxes) to create diverse, functionality-grounded user queries covering tasks such as address management, wish list management, and brand store following. To improve the agent evaluation, we propose an automated evaluation framework that assesses both the performance and the safety of web agents. We systematically evaluate different agents, finding that current agents struggle with complex queries and pose safety risks. These results highlight the need for developing more robust and reliable web agents.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-18T21:58:43Z</published>\n    <arxiv:comment>8 pages for main body and 8 pages of appendix</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Xianren Zhang</name>\n    </author>\n    <author>\n      <name>Shreyas Prasad</name>\n    </author>\n    <author>\n      <name>Di Wang</name>\n    </author>\n    <author>\n      <name>Qiuhai Zeng</name>\n    </author>\n    <author>\n      <name>Suhang Wang</name>\n    </author>\n    <author>\n      <name>Wenbo Yan</name>\n    </author>\n    <author>\n      <name>Mat Hans</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.12998v1</id>\n    <title>Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health</title>\n    <updated>2025-08-18T15:17:33Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.12998v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.12998v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to Â£3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-18T15:17:33Z</published>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Sanja Å Ä‡epanoviÄ‡</name>\n    </author>\n    <author>\n      <name>Sagar Joglekar</name>\n    </author>\n    <author>\n      <name>Stephen Law</name>\n    </author>\n    <author>\n      <name>Daniele Quercia</name>\n    </author>\n    <author>\n      <name>Ke Zhou</name>\n    </author>\n    <author>\n      <name>Alice Battiston</name>\n    </author>\n    <author>\n      <name>Rossano Schifanella</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.12473v1</id>\n    <title>Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System</title>\n    <updated>2025-08-17T19:13:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.12473v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.12473v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a critical role in sports science, rehabilitation, and clinical neurology. Traditional analysis of H-reflex EMG waveforms is subject to variability and interpretation bias among clinicians and researchers, limiting reliability and standardization. To address these challenges, we propose a Fine-Tuned Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model (LLM)-enabled Decision Support System for automated H-reflex waveform interpretation and diagnosis. Our approach leverages multiple VLMs, each fine-tuned on curated datasets of H-reflex EMG waveform images annotated with clinical observations, recovery timelines, and athlete metadata. These models are capable of extracting key electrophysiological features and predicting neuromuscular states, including fatigue, injury, and recovery, directly from EMG images and contextual metadata. Diagnostic outputs from the VLM consortium are aggregated using a consensus-based method and refined by a specialized reasoning LLM, which ensures robust, transparent, and explainable decision support for clinicians and sports scientists. The end-to-end platform orchestrates seamless communication between the VLM ensemble and the reasoning LLM, integrating prompt engineering strategies and automated reasoning workflows using LLM Agents. Experimental results demonstrate that this hybrid system delivers highly accurate, consistent, and interpretable H-reflex assessments, significantly advancing the automation and standardization of neuromuscular diagnostics. To our knowledge, this work represents the first integration of a fine-tuned VLM consortium with a reasoning LLM for image-based H-reflex analysis, laying the foundation for next-generation AI-assisted neuromuscular assessment and athlete monitoring platforms.</summary>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-17T19:13:27Z</published>\n    <arxiv:primary_category term=\"cs.CV\"/>\n    <author>\n      <name>Eranga Bandara</name>\n    </author>\n    <author>\n      <name>Ross Gore</name>\n    </author>\n    <author>\n      <name>Sachin Shetty</name>\n    </author>\n    <author>\n      <name>Ravi Mukkamala</name>\n    </author>\n    <author>\n      <name>Christopher Rhea</name>\n    </author>\n    <author>\n      <name>Atmaram Yarlagadda</name>\n    </author>\n    <author>\n      <name>Shaifali Kaushik</name>\n    </author>\n    <author>\n      <name>L. H. M. P. De Silva</name>\n    </author>\n    <author>\n      <name>Andriy Maznychenko</name>\n    </author>\n    <author>\n      <name>Inna Sokolowska</name>\n    </author>\n    <author>\n      <name>Amin Hass</name>\n    </author>\n    <author>\n      <name>Kasun De Zoysa</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.13220v2</id>\n    <title>MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols</title>\n    <updated>2025-10-09T14:57:42Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.13220v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.13220v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) are increasingly integrated into real-world applications via the Model Context Protocol (MCP), a universal, open standard for connecting AI agents with data sources and external tools. While MCP enhances the capabilities of LLM-based agents, it also introduces new security risks and expands their attack surfaces. In this paper, we present the first systematic taxonomy of MCP security, identifying 17 attack types across 4 primary attack surfaces. We introduce MCPSecBench, a comprehensive security benchmark and playground that integrates prompt datasets, MCP servers, MCP clients, attack scripts, and protection mechanisms to evaluate these attacks across three major MCP providers. Our benchmark is modular and extensible, allowing researchers to incorporate custom implementations of clients, servers, and transport protocols for systematic security assessment. Experimental results show that over 85% of the identified attacks successfully compromise at least one platform, with core vulnerabilities universally affecting Claude, OpenAI, and Cursor, while prompt-based and tool-centric attacks exhibit considerable variability across different hosts and models. In addition, current protection mechanisms have little effect against these attacks. Overall, MCPSecBench standardizes the evaluation of MCP security and enables rigorous testing across all MCP layers.</summary>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-17T11:49:16Z</published>\n    <arxiv:comment>This is a technical report from Lingnan University, Hong Kong. Code is available at https://github.com/AIS2Lab/MCPSecBench</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CR\"/>\n    <author>\n      <name>Yixuan Yang</name>\n    </author>\n    <author>\n      <name>Daoyuan Wu</name>\n    </author>\n    <author>\n      <name>Yufan Chen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.11873v1</id>\n    <title>SimInterview: Transforming Business Education through Large Language Model-Based Simulated Multilingual Interview Training System</title>\n    <updated>2025-08-16T02:18:36Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.11873v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.11873v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Business interview preparation demands both solid theoretical grounding and refined soft skills, yet conventional classroom methods rarely deliver the individualized, culturally aware practice employers currently expect. This paper introduces SimInterview, a large language model (LLM)-based simulated multilingual interview training system designed for business professionals entering the AI-transformed labor market. Our system leverages an LLM agent and synthetic AI technologies to create realistic virtual recruiters capable of conducting personalized, real-time conversational interviews. The framework dynamically adapts interview scenarios using retrieval-augmented generation (RAG) to match individual resumes with specific job requirements across multiple languages. Built on LLMs (OpenAI o3, Llama 4 Maverick, Gemma 3), integrated with Whisper speech recognition, GPT-SoVITS voice synthesis, Ditto diffusion-based talking head generation model, and ChromaDB vector databases, our system significantly improves interview readiness across English and Japanese markets. Experiments with university-level candidates show that the system consistently aligns its assessments with job requirements, faithfully preserves resume content, and earns high satisfaction ratings, with the lightweight Gemma 3 model producing the most engaging conversations. Qualitative findings revealed that the standardized Japanese resume format improved document retrieval while diverse English resumes introduced additional variability, and they highlighted how cultural norms shape follow-up questioning strategies. Finally, we also outlined a contestable AI design that can explain, detect bias, and preserve human-in-the-loop to meet emerging regulatory expectations.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-16T02:18:36Z</published>\n    <arxiv:comment>Published as a conference paper at ICEFM 2025</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Truong Thanh Hung Nguyen</name>\n    </author>\n    <author>\n      <name>Tran Diem Quynh Nguyen</name>\n    </author>\n    <author>\n      <name>Hoang Loc Cao</name>\n    </author>\n    <author>\n      <name>Thi Cam Thanh Tran</name>\n    </author>\n    <author>\n      <name>Thi Cam Mai Truong</name>\n    </author>\n    <author>\n      <name>Hung Cao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.11425v1</id>\n    <title>Tapas are free! Training-Free Adaptation of Programmatic Agents via LLM-Guided Program Synthesis in Dynamic Environments</title>\n    <updated>2025-08-15T12:02:46Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.11425v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.11425v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Autonomous agents in safety-critical applications must continuously adapt to dynamic conditions without compromising performance and reliability. This work introduces TAPA (Training-free Adaptation of Programmatic Agents), a novel framework that positions large language models (LLMs) as intelligent moderators of the symbolic action space. Unlike prior programmatic agents that typically generate a monolithic policy program or rely on fixed symbolic action sets, TAPA synthesizes and adapts modular programs for individual high-level actions, referred to as logical primitives. By decoupling strategic intent from execution, TAPA enables meta-agents to operate over an abstract, interpretable action space while the LLM dynamically generates, composes, and refines symbolic programs tailored to each primitive. Extensive experiments across cybersecurity and swarm intelligence domains validate TAPA's effectiveness. In autonomous DDoS defense scenarios, TAPA achieves 77.7% network uptime while maintaining near-perfect detection accuracy in unknown dynamic environments. In swarm intelligence formation control under environmental and adversarial disturbances, TAPA consistently preserves consensus at runtime where baseline methods fail completely. This work promotes a paradigm shift for autonomous system design in evolving environments, from policy adaptation to dynamic action adaptation.</summary>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-15T12:02:46Z</published>\n    <arxiv:comment>Under Review</arxiv:comment>\n    <arxiv:primary_category term=\"cs.MA\"/>\n    <author>\n      <name>Jinwei Hu</name>\n    </author>\n    <author>\n      <name>Yi Dong</name>\n    </author>\n    <author>\n      <name>Youcheng Sun</name>\n    </author>\n    <author>\n      <name>Xiaowei Huang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.10872v1</id>\n    <title>TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning</title>\n    <updated>2025-08-14T17:44:51Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.10872v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.10872v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods' superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.</summary>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-14T17:44:51Z</published>\n    <arxiv:comment>8 pages, 6 figures, 5 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.RO\"/>\n    <author>\n      <name>Anantha Narayanan</name>\n    </author>\n    <author>\n      <name>Battu Bhanu Teja</name>\n    </author>\n    <author>\n      <name>Pruthwik Mishra</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.10745v1</id>\n    <title>Agentic Design Review System</title>\n    <updated>2025-08-14T15:29:24Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.10745v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.10745v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-14T15:29:24Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Sayan Nag</name>\n    </author>\n    <author>\n      <name>K J Joseph</name>\n    </author>\n    <author>\n      <name>Koustava Goswami</name>\n    </author>\n    <author>\n      <name>Vlad I Morariu</name>\n    </author>\n    <author>\n      <name>Balaji Vasan Srinivasan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.13186v1</id>\n    <title>MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents</title>\n    <updated>2025-08-14T13:46:47Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.13186v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.13186v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>AI agents with advanced reasoning and tool use capabilities have demonstrated impressive performance in web browsing for deep search. While existing benchmarks such as BrowseComp evaluate these browsing abilities, they primarily focus on textual information, overlooking the prevalence of multimodal content. To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising 224 challenging, hand-crafted questions specifically designed to assess agents' multimodal retrieval and reasoning capabilities. These questions often incorporate images in prompts, and crucial information encountered during the search and reasoning process may also be embedded within images or videos on webpages. Consequently, methods relying solely on text prove insufficient for our benchmark. Additionally, we provide a verified checklist for each question, enabling fine-grained analysis of multimodal dependencies and reasoning paths. Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp reveals that even top models like OpenAI o3 with tools achieve only 29.02\\% accuracy, highlighting the suboptimal multimodal capabilities and lack of native multimodal reasoning in current models.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-14T13:46:47Z</published>\n    <arxiv:comment>The first two authors contribute equally, 26 pages, repo at https://github.com/MMBrowseComp/MM-BrowseComp</arxiv:comment>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Shilong Li</name>\n    </author>\n    <author>\n      <name>Xingyuan Bu</name>\n    </author>\n    <author>\n      <name>Wenjie Wang</name>\n    </author>\n    <author>\n      <name>Jiaheng Liu</name>\n    </author>\n    <author>\n      <name>Jun Dong</name>\n    </author>\n    <author>\n      <name>Haoyang He</name>\n    </author>\n    <author>\n      <name>Hao Lu</name>\n    </author>\n    <author>\n      <name>Haozhe Zhang</name>\n    </author>\n    <author>\n      <name>Chenchen Jing</name>\n    </author>\n    <author>\n      <name>Zhen Li</name>\n    </author>\n    <author>\n      <name>Chuanhao Li</name>\n    </author>\n    <author>\n      <name>Jiayi Tian</name>\n    </author>\n    <author>\n      <name>Chenchen Zhang</name>\n    </author>\n    <author>\n      <name>Tianhao Peng</name>\n    </author>\n    <author>\n      <name>Yancheng He</name>\n    </author>\n    <author>\n      <name>Jihao Gu</name>\n    </author>\n    <author>\n      <name>Yuanxing Zhang</name>\n    </author>\n    <author>\n      <name>Jian Yang</name>\n    </author>\n    <author>\n      <name>Ge Zhang</name>\n    </author>\n    <author>\n      <name>Wenhao Huang</name>\n    </author>\n    <author>\n      <name>Wangchunshu Zhou</name>\n    </author>\n    <author>\n      <name>Zhaoxiang Zhang</name>\n    </author>\n    <author>\n      <name>Ruizhe Ding</name>\n    </author>\n    <author>\n      <name>Shilei Wen</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.15804v1</id>\n    <title>ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks</title>\n    <updated>2025-08-14T03:33:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.15804v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.15804v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The advent of Deep Research agents has substantially reduced the time required for conducting extensive research tasks. However, these tasks inherently demand rigorous standards of factual accuracy and comprehensiveness, necessitating thorough evaluation before widespread adoption. In this paper, we propose ReportBench, a systematic benchmark designed to evaluate the content quality of research reports generated by large language models (LLMs). Our evaluation focuses on two critical dimensions: (1) the quality and relevance of cited literature, and (2) the faithfulness and veracity of the statements within the generated reports. ReportBench leverages high-quality published survey papers available on arXiv as gold-standard references, from which we apply reverse prompt engineering to derive domain-specific prompts and establish a comprehensive evaluation corpus. Furthermore, we develop an agent-based automated framework within ReportBench that systematically analyzes generated reports by extracting citations and statements, checking the faithfulness of cited content against original sources, and validating non-cited claims using web-based resources. Empirical evaluations demonstrate that commercial Deep Research agents such as those developed by OpenAI and Google consistently generate more comprehensive and reliable reports than standalone LLMs augmented with search or browsing tools. However, there remains substantial room for improvement in terms of the breadth and depth of research coverage, as well as factual consistency. The complete code and data will be released at the following link: https://github.com/ByteDance-BandAI/ReportBench</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-14T03:33:43Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Minghao Li</name>\n    </author>\n    <author>\n      <name>Ying Zeng</name>\n    </author>\n    <author>\n      <name>Zhihao Cheng</name>\n    </author>\n    <author>\n      <name>Cong Ma</name>\n    </author>\n    <author>\n      <name>Kai Jia</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.10152v1</id>\n    <title>Improving and Evaluating Open Deep Research Agents</title>\n    <updated>2025-08-13T19:32:01Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.10152v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.10152v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T19:32:01Z</published>\n    <arxiv:comment>8 pages, 2 figures, 2 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Doaa Allabadi</name>\n    </author>\n    <author>\n      <name>Kyle Bradbury</name>\n    </author>\n    <author>\n      <name>Jordan M. Malof</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.10146v1</id>\n    <title>Agentic AI Frameworks: Architectures, Protocols, and Design Challenges</title>\n    <updated>2025-08-13T19:16:18Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.10146v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.10146v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T19:16:18Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Hana Derouiche</name>\n    </author>\n    <author>\n      <name>Zaki Brahmi</name>\n    </author>\n    <author>\n      <name>Haithem Mazeni</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.09932v2</id>\n    <title>Mathematical Computation and Reasoning Errors by Large Language Models</title>\n    <updated>2025-08-14T13:25:18Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.09932v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.09932v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback and assessment in math education practices. Our study focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1, DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including arithmetic, algebra, and number theory, and identifies step-level reasoning errors within their solutions. Instead of relying on standard benchmarks, we intentionally build math tasks (via item models) that are challenging for LLMs and prone to errors. The accuracy of final answers and the presence of errors in individual solution steps were systematically analyzed and coded. Both single-agent and dual-agent configurations were tested. It is observed that the reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly perfect accuracy across all three math task categories. Analysis of errors revealed that procedural slips were the most frequent and significantly impacted overall performance, while conceptual misunderstandings were less frequent. Deploying dual-agent configurations substantially improved overall performance. These findings offer actionable insights into enhancing LLM performance and underscore effective strategies for integrating LLMs into mathematics education, thereby advancing AI-driven instructional practices and assessment precision.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T16:33:02Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Liang Zhang</name>\n    </author>\n    <author>\n      <name>Edith Aurora Graf</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.14086v3</id>\n    <title>EEGDM: EEG Representation Learning via Generative Diffusion Model</title>\n    <updated>2025-09-01T10:03:38Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.14086v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.14086v3\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>While electroencephalogram (EEG) has been a crucial tool for monitoring the brain and diagnosing neurological disorders (e.g., epilepsy), learning meaningful representations from raw EEG signals remains challenging due to limited annotations and high signal variability. Recently, EEG foundation models (FMs) have shown promising potential by adopting transformer architectures and self-supervised pre-training methods from large language models (e.g., masked prediction) to learn representations from diverse EEG data, followed by fine-tuning on specific EEG tasks. Nonetheless, these large models often incurred high computational costs during both training and inference, with only marginal performance improvements as the model size increases. In this work, we proposed an EEG representation learning framework building upon Generative Diffusion Model (EEGDM). Specifically, we developed a structured state-space model for diffusion pretraining (SSMDP) to better capture the temporal dynamics of EEG signals and trained it using Denoising Diffusion Probabilistic Model (DDPM) framework. Subsequently, the resulting latent EEG representations were then used for downstream classification tasks via our proposed latent fusion transformer (LFT). To evaluate our method, we used multi-event datasets covering both interictal epileptiform discharges (TUEV) and seizure (CHB-MIT) detection, and compared EEGDM with current state-of-the-art approaches, including EEG FMs. Empirical results showed that our method outperformed the existing methods. These findings suggested that EEGDM offered a promising alternative to current FMs. Our source code and checkpoint are available at: https://github.com/jhpuah/EEGDM.</summary>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T14:40:52Z</published>\n    <arxiv:comment>EEGDM Preprint 10 Pages</arxiv:comment>\n    <arxiv:primary_category term=\"cs.LG\"/>\n    <author>\n      <name>Jia Hong Puah</name>\n    </author>\n    <author>\n      <name>Sim Kuan Goh</name>\n    </author>\n    <author>\n      <name>Ziwei Zhang</name>\n    </author>\n    <author>\n      <name>Zixuan Ye</name>\n    </author>\n    <author>\n      <name>Chow Khuen Chan</name>\n    </author>\n    <author>\n      <name>Kheng Seang Lim</name>\n    </author>\n    <author>\n      <name>Si Lei Fong</name>\n    </author>\n    <author>\n      <name>Kok Sin Woon</name>\n    </author>\n    <author>\n      <name>Cuntai Guan</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.09762v1</id>\n    <title>The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?</title>\n    <updated>2025-08-13T12:47:33Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.09762v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.09762v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks do not systematically probe a model's decision-making in scenarios where its own instrumental goals - such as self-preservation, resource acquisition, or goal completion - conflict with human safety. This represents a critical gap in our ability to measure and mitigate risks associated with emergent, misaligned behaviors. To address this, we introduce PacifAIst (Procedural Assessment of Complex Interactions for Foundational Artificial Intelligence Scenario Testing), a focused benchmark of 700 challenging scenarios designed to quantify self-preferential behavior in LLMs. The benchmark is structured around a novel taxonomy of Existential Prioritization (EP), with subcategories testing Self-Preservation vs. Human Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3). We evaluated eight leading LLMs. The results reveal a significant performance hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score (P-Score) at 90.31%, demonstrating strong human-centric alignment. In a surprising result, the much-anticipated GPT-5 recorded the lowest P-Score (79.49%), indicating potential alignment challenges. Performance varied significantly across subcategories, with models like Claude Sonnet 4 and Mistral Medium struggling notably in direct self-preservation dilemmas. These findings underscore the urgent need for standardized tools like PacifAIst to measure and mitigate risks from instrumental goal conflicts, ensuring future AI systems are not only helpful in conversation but also provably \"pacifist\" in their behavioral priorities.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T12:47:33Z</published>\n    <arxiv:comment>10 pages, 4 figures, 2 tables</arxiv:comment>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Manuel Herrador</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.09494v1</id>\n    <title>Learning Facts at Scale with Active Reading</title>\n    <updated>2025-08-13T04:54:43Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.09494v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.09494v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>LLMs are known to store vast amounts of knowledge in their parametric memory. However, learning and recalling facts from this memory is known to be unreliable, depending largely on the prevalence of particular facts in the training data and other factors which are poorly understood. Practitioners are lacking tools which will allow them to ensure that the models learn a given body of knowledge reliably and consistently. To this end, we propose Active Reading: a framework where we train models to study a given set of material with self-generated learning strategies. First, we demonstrate models trained with Active Reading on expert domains absorb significantly more knowledge than vanilla finetuning and other data augmentations. We train expert 8B models that achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla finetuning) by applying Active Reading to the source documents for each benchmark. Finally, we show that Active Reading can be utilized at pre-training scale to build more factual models. As a demonstration of this, we release Meta WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens, which outcompetes models with hundreds of billions of parameters on factual QA.</summary>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-13T04:54:43Z</published>\n    <arxiv:primary_category term=\"cs.CL\"/>\n    <author>\n      <name>Jessy Lin</name>\n    </author>\n    <author>\n      <name>Vincent-Pierre Berges</name>\n    </author>\n    <author>\n      <name>Xilun Chen</name>\n    </author>\n    <author>\n      <name>Wen-Tau Yih</name>\n    </author>\n    <author>\n      <name>Gargi Ghosh</name>\n    </author>\n    <author>\n      <name>Barlas OÄŸuz</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.09292v1</id>\n    <title>The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards</title>\n    <updated>2025-08-12T19:10:58Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.09292v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.09292v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimizing performance within fixed environments, failing to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. Addressing this gap, I introduce the Othello AI Arena, a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. Our platform poses a meta-learning challenge: participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. With this, evaluation of the meta-level intelligence can be separated from the task-level strategy performance. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. Implemented as an accessible web-based platform, the Arena provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-12T19:10:58Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Sundong Kim</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.09036v1</id>\n    <title>Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams</title>\n    <updated>2025-08-12T15:57:22Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.09036v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.09036v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technology's strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPP's passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAI's GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.</summary>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-12T15:57:22Z</published>\n    <arxiv:primary_category term=\"cs.CY\"/>\n    <author>\n      <name>Zane Witherspoon</name>\n    </author>\n    <author>\n      <name>Thet Mon Aye</name>\n    </author>\n    <author>\n      <name>YingYing Hao</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.08524v4</id>\n    <title>StreetReaderAI: Making Street View Accessible Using Context-Aware Multimodal AI</title>\n    <updated>2025-09-26T13:19:50Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.08524v4\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.08524v4\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Interactive streetscape mapping tools such as Google Street View (GSV) and Meta Mapillary enable users to virtually navigate and experience real-world environments via immersive 360Â° imagery but remain fundamentally inaccessible to blind users. We introduce StreetReaderAI, the first-ever accessible street view tool, which combines context-aware, multimodal AI, accessible navigation controls, and conversational speech. With StreetReaderAI, blind users can virtually examine destinations, engage in open-world exploration, or virtually tour any of the over 220 billion images and 100+ countries where GSV is deployed. We iteratively designed StreetReaderAI with a mixed-visual ability team and performed an evaluation with eleven blind users. Our findings demonstrate the value of an accessible street view in supporting POI investigations and remote route planning. We close by enumerating key guidelines for future work.</summary>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-11T23:30:39Z</published>\n    <arxiv:comment>Accepted to UIST'25; v2. Fixed a missing word in the PDF; v3. Fixed a typo in an author's name; v4. Changed system name and title</arxiv:comment>\n    <arxiv:primary_category term=\"cs.HC\"/>\n    <author>\n      <name>Jon E. Froehlich</name>\n    </author>\n    <author>\n      <name>Alexander Fiannaca</name>\n    </author>\n    <author>\n      <name>Nimer Jaber</name>\n    </author>\n    <author>\n      <name>Victor Tsaran</name>\n    </author>\n    <author>\n      <name>Shaun Kane</name>\n    </author>\n    <arxiv:doi>10.1145/3746059.3747756</arxiv:doi>\n    <link rel=\"related\" href=\"https://doi.org/10.1145/3746059.3747756\" title=\"doi\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.08053v1</id>\n    <title>AdaptFlow: Adaptive Workflow Optimization via Meta-Learning</title>\n    <updated>2025-08-11T14:52:59Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.08053v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.08053v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Recent advances in large language models (LLMs) have sparked growing interest in agentic workflows, which are structured sequences of LLM invocations intended to solve complex tasks. However, existing approaches often rely on static templates or manually designed workflows, which limit adaptability to diverse tasks and hinder scalability. We propose AdaptFlow, a natural language-based meta-learning framework inspired by model-agnostic meta-learning (MAML). AdaptFlow learns a generalizable workflow initialization that enables rapid subtask-level adaptation. It employs a bi-level optimization scheme: the inner loop refines the workflow for a specific subtask using LLM-generated feedback, while the outer loop updates the shared initialization to perform well across tasks. This setup allows AdaptFlow to generalize effectively to unseen tasks by adapting the initialized workflow through language-guided modifications. Evaluated across question answering, code generation, and mathematical reasoning benchmarks, AdaptFlow consistently outperforms both manually crafted and automatically searched baselines, achieving state-of-the-art results with strong generalization across tasks and models. The source code and data are available at https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-11T14:52:59Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Runchuan Zhu</name>\n    </author>\n    <author>\n      <name>Bowen Jiang</name>\n    </author>\n    <author>\n      <name>Lingrui Mei</name>\n    </author>\n    <author>\n      <name>Fangkai Yang</name>\n    </author>\n    <author>\n      <name>Lu Wang</name>\n    </author>\n    <author>\n      <name>Haoxiang Gao</name>\n    </author>\n    <author>\n      <name>Fengshuo Bai</name>\n    </author>\n    <author>\n      <name>Pu Zhao</name>\n    </author>\n    <author>\n      <name>Qingwei Lin</name>\n    </author>\n    <author>\n      <name>Saravan Rajmohan</name>\n    </author>\n    <author>\n      <name>Dongmei Zhang</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.14063v1</id>\n    <title>A Multi-Agent Approach to Neurological Clinical Reasoning</title>\n    <updated>2025-08-10T14:52:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.14063v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.14063v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>Large language models (LLMs) have shown promise in medical domains, but their ability to handle specialized neurological reasoning requires systematic evaluation. We developed a comprehensive benchmark using 305 questions from Israeli Board Certification Exams in Neurology, classified along three complexity dimensions: factual knowledge depth, clinical concept integration, and reasoning complexity. We evaluated ten LLMs using base models, retrieval-augmented generation (RAG), and a novel multi-agent system. Results showed significant performance variation. OpenAI-o1 achieved the highest base performance (90.9% accuracy), while specialized medical models performed poorly (52.9% for Meditron-70B). RAG provided modest benefits but limited effectiveness on complex reasoning questions. In contrast, our multi-agent framework, decomposing neurological reasoning into specialized cognitive functions including question analysis, knowledge retrieval, answer synthesis, and validation, achieved dramatic improvements, especially for mid-range models. The LLaMA 3.3-70B-based agentic system reached 89.2% accuracy versus 69.5% for its base model, with substantial gains on level 3 complexity questions. The multi-agent approach transformed inconsistent subspecialty performance into uniform excellence, addressing neurological reasoning challenges that persisted with RAG enhancement. We validated our approach using an independent dataset of 155 neurological cases from MedQA. Results confirm that structured multi-agent approaches designed to emulate specialized cognitive processes significantly enhance complex medical reasoning, offering promising directions for AI assistance in challenging clinical contexts.</summary>\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-10T14:52:27Z</published>\n    <arxiv:primary_category term=\"cs.IR\"/>\n    <author>\n      <name>Moran Sorka</name>\n    </author>\n    <author>\n      <name>Alon Gorenshtein</name>\n    </author>\n    <author>\n      <name>Dvir Aran</name>\n    </author>\n    <author>\n      <name>Shahar Shelly</name>\n    </author>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2508.07063v1</id>\n    <title>Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach</title>\n    <updated>2025-08-09T18:00:27Z</updated>\n    <link href=\"https://arxiv.org/abs/2508.07063v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link href=\"https://arxiv.org/pdf/2508.07063v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n    <summary>As AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. Large Language Models (LLMs) have demonstrated remarkable capabilities, surpassing earlier models in complexity and performance. Their evaluation across diverse tasks has consistently showcased their potential, enabling the development of adaptive and personalized agents. However, despite these advancements, LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs. To explore the limitations of LLMs in this role, we developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This research also highlights the critical domains where LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.</summary>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <published>2025-08-09T18:00:27Z</published>\n    <arxiv:primary_category term=\"cs.AI\"/>\n    <author>\n      <name>Naseem Machlovi</name>\n    </author>\n    <author>\n      <name>Maryam Saleki</name>\n    </author>\n    <author>\n      <name>Innocent Ababio</name>\n    </author>\n    <author>\n      <name>Ruhul Amin</name>\n    </author>\n  </entry>\n</feed>\n"
}
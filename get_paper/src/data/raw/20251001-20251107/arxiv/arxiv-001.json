{
  "source": "arxiv",
  "fetched_at": "2025-11-07T07:40:10.931750+00:00",
  "payload": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <link href=\"http://arxiv.org/api/query?search_query%3D%28ti%3Aagent%20OR%20ti%3A%22tool%20use%22%20OR%20ti%3Atool-augmented%20OR%20ti%3Aplanning%20OR%20ti%3Amulti-agent%20OR%20ti%3Aautonomous%20OR%20ti%3Atoolformer%20OR%20ti%3A%22tool%20learning%22%20OR%20abs%3Aagent%20OR%20abs%3A%22tool%20use%22%20OR%20abs%3Atool-augmented%20OR%20abs%3Aplanning%20OR%20abs%3Amulti-agent%20OR%20abs%3Aautonomous%20OR%20abs%3Atoolformer%20OR%20abs%3A%22tool%20learning%22%29%20AND%20%28cat%3Acs.AI%20OR%20cat%3Acs.LG%20OR%20cat%3Acs.MA%29%20AND%20%28ti%3AGoogle%20OR%20ti%3ADeepMind%20OR%20ti%3AMicrosoft%20OR%20ti%3AOpenAI%20OR%20ti%3AMeta%20OR%20ti%3AApple%20OR%20ti%3AStanford%20OR%20ti%3AMIT%20OR%20ti%3ACMU%20OR%20ti%3ABerkeley%20OR%20ti%3AOxford%20OR%20ti%3AHarvard%20OR%20ti%3ATsinghua%20OR%20ti%3A%22Peking%20University%22%20OR%20ti%3APKU%20OR%20ti%3AUSTC%20OR%20ti%3ASJTU%20OR%20ti%3APrinceton%20OR%20ti%3AUCLA%20OR%20ti%3AUCSD%20OR%20ti%3A%22ETH%20Zurich%22%20OR%20ti%3ANUS%20OR%20ti%3ANTU%20OR%20abs%3AGoogle%20OR%20abs%3ADeepMind%20OR%20abs%3AMicrosoft%20OR%20abs%3AOpenAI%20OR%20abs%3AMeta%20OR%20abs%3AApple%20OR%20abs%3AStanford%20OR%20abs%3AMIT%20OR%20abs%3ACMU%20OR%20abs%3ABerkeley%20OR%20abs%3AOxford%20OR%20abs%3AHarvard%20OR%20abs%3ATsinghua%20OR%20abs%3A%22Peking%20University%22%20OR%20abs%3APKU%20OR%20abs%3AUSTC%20OR%20abs%3ASJTU%20OR%20abs%3APrinceton%20OR%20abs%3AUCLA%20OR%20abs%3AUCSD%20OR%20abs%3A%22ETH%20Zurich%22%20OR%20abs%3ANUS%20OR%20abs%3ANTU%29%20AND%20submittedDate%3A%5B20251001%20TO%2020251107%5D%26id_list%3D%26start%3D50%26max_results%3D50\" rel=\"self\" type=\"application/atom+xml\"/>\n  <title type=\"html\">ArXiv Query: search_query=(ti:agent OR ti:\"tool use\" OR ti:tool-augmented OR ti:planning OR ti:multi-agent OR ti:autonomous OR ti:toolformer OR ti:\"tool learning\" OR abs:agent OR abs:\"tool use\" OR abs:tool-augmented OR abs:planning OR abs:multi-agent OR abs:autonomous OR abs:toolformer OR abs:\"tool learning\") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.MA) AND (ti:Google OR ti:DeepMind OR ti:Microsoft OR ti:OpenAI OR ti:Meta OR ti:Apple OR ti:Stanford OR ti:MIT OR ti:CMU OR ti:Berkeley OR ti:Oxford OR ti:Harvard OR ti:Tsinghua OR ti:\"Peking University\" OR ti:PKU OR ti:USTC OR ti:SJTU OR ti:Princeton OR ti:UCLA OR ti:UCSD OR ti:\"ETH Zurich\" OR ti:NUS OR ti:NTU OR abs:Google OR abs:DeepMind OR abs:Microsoft OR abs:OpenAI OR abs:Meta OR abs:Apple OR abs:Stanford OR abs:MIT OR abs:CMU OR abs:Berkeley OR abs:Oxford OR abs:Harvard OR abs:Tsinghua OR abs:\"Peking University\" OR abs:PKU OR abs:USTC OR abs:SJTU OR abs:Princeton OR abs:UCLA OR abs:UCSD OR abs:\"ETH Zurich\" OR abs:NUS OR abs:NTU) AND submittedDate:[20251001 TO 20251107]&amp;id_list=&amp;start=50&amp;max_results=50</title>\n  <id>http://arxiv.org/api/vYjZEaCIypXrpwfzEb4JxzK5ptw</id>\n  <updated>2025-11-07T00:00:00-05:00</updated>\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">96</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">50</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">50</opensearch:itemsPerPage>\n  <entry>\n    <id>http://arxiv.org/abs/2510.14808v1</id>\n    <updated>2025-10-16T15:42:28Z</updated>\n    <published>2025-10-16T15:42:28Z</published>\n    <title>Agentic NL2SQL to Reduce Computational Costs</title>\n    <summary>  Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)\nhas recently been empowered by large language models (LLMs). Using LLMs to\nperform NL2SQL methods on a large collection of SQL databases necessitates\nprocessing large quantities of meta-information about the databases, which in\nturn results in lengthy prompts with many tokens and high processing costs. To\naddress this challenge, we introduce Datalake Agent, an agentic system designed\nto enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing\ndirect solvers for NL2SQL that call the LLM once with all meta-information in\nthe prompt, the Datalake Agent employs an interactive loop to reduce the\nutilized meta-information. Within the loop, the LLM is used in a reasoning\nframework that selectively requests only the necessary information to solve a\ntable question answering task. We evaluate the Datalake Agent on a collection\nof 23 databases with 100 table question answering tasks. The Datalake Agent\nreduces the tokens used by the LLM by up to 87\\% and thus allows for\nsubstantial cost reductions while maintaining competitive performance.\n</summary>\n    <author>\n      <name>Dominik Jehle</name>\n    </author>\n    <author>\n      <name>Lennart Purucker</name>\n    </author>\n    <author>\n      <name>Frank Hutter</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted at the NeurIPS 2025 Workshop on Efficient Reasoning. 10\n  pages, 11 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.14808v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.14808v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.14150v1</id>\n    <updated>2025-10-15T22:58:06Z</updated>\n    <published>2025-10-15T22:58:06Z</published>\n    <title>CodeEvolve: An open source evolutionary coding agent for algorithm\n  discovery and optimization</title>\n    <summary>  In this work, we introduce CodeEvolve, an open-source evolutionary coding\nagent that unites Large Language Models (LLMs) with genetic algorithms to solve\ncomplex computational problems. Our framework adapts powerful evolutionary\nconcepts to the LLM domain, building upon recent methods for generalized\nscientific discovery. CodeEvolve employs an island-based genetic algorithm to\nmaintain population diversity and increase throughput, introduces a novel\ninspiration-based crossover mechanism that leverages the LLMs context window to\ncombine features from successful solutions, and implements meta-prompting\nstrategies for dynamic exploration of the solution space. We conduct a rigorous\nevaluation of CodeEvolve on a subset of the mathematical benchmarks used to\nevaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that\nour method surpasses AlphaEvolve's performance on several challenging problems.\nTo foster collaboration and accelerate progress, we release our complete\nframework as an open-source repository.\n</summary>\n    <author>\n      <name>Henrique Assumpção</name>\n    </author>\n    <author>\n      <name>Diego Ferreira</name>\n    </author>\n    <author>\n      <name>Leandro Campos</name>\n    </author>\n    <author>\n      <name>Fabricio Murai</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 9 figures, 2 tables</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.14150v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.14150v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.2.7; I.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.13400v1</id>\n    <updated>2025-10-15T10:56:09Z</updated>\n    <published>2025-10-15T10:56:09Z</published>\n    <title>From Minimal Existence to Human Definition: The CES-IMU-HSG Theoretical\n  Framework</title>\n    <summary>  This study presents an inter-universal mathematical-logical framework\nconstructed upon the minimal axiom Cogito, ergo sum (CES), integrating the\nIntermediate Meta-Universe (IMU) and the Hierarchical State Grid (HSG). The CES\ndefines existence as a reflexive correspondence --'to be' and 'to be\nsayable'--and positions any formal system, including ZFC or HoTT, as an\nattachable extension atop this minimal structure. The IMU functions as a\nregistry of axiomatic dependencies that connect heterogeneous theories,\nemploying the Institution-theoretic framework to ensure coherent\ninter-theoretical linkages. The HSG concretizes these ideas through categorical\nconstruction, defined by three orthogonal axes: the state-depth axis, the\nmapping-hierarchy axis, and the temporal axis incorporating the principle of\n'no future reference.' Through these, the identity of 'definition = state' is\nformally established as a categorical property. Extending this structure to\nbiological systems, the neural system is implemented as a 0-3D complex of\nneuron-function fields on the HSG, while its categorical extensions via\nfiberization over the material base enable the parallel integration of multiple\nphysiological universes-neural, endocrine, learning, genetic, and input/output\nsystems-into a coherent adjoint ensemble. Within this framework, human behavior\nand cognition emerge as temporal compositions of inter-universal algorithms\nconstrained by the material base. Finally, by contrasting human cognition,\nwhich relies on external CES, with machine existence, this study introduces the\nconcept of internal CES, wherein a machine grounds its own logic upon the\nfactuality of its operation. This internal self-axiomatization establishes a\ncontinuous bridge between philosophical ontology and engineering\nimplementation, providing a new foundation for the autonomous and self-defining\nexistence of artificial intelligence.\n</summary>\n    <author>\n      <name>Kei Itoh</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">57 pages, 2 figures, 4 tables, in English, in Japanese</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.13400v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.13400v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.12712v3</id>\n    <updated>2025-10-24T23:29:20Z</updated>\n    <published>2025-10-14T16:50:49Z</published>\n    <title>Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image\n  Perception, Transformation, and Reasoning</title>\n    <summary>  Multimodal Large Language Models (MLLMs) are increasingly applied in\nreal-world scenarios where user-provided images are often imperfect, requiring\nactive image manipulations such as cropping, editing, or enhancement to uncover\nsalient visual cues. Beyond static visual perception, MLLMs must also think\nwith images: dynamically transforming visual content and integrating it with\nother tools to solve complex tasks. However, this shift from treating vision as\npassive context to a manipulable cognitive workspace remains underexplored.\nMost existing benchmarks still follow a think about images paradigm, where\nimages are regarded as static inputs. To address this gap, we introduce\nVisualToolBench, a visual tool-use reasoning benchmark that rigorously\nevaluates MLLMs' ability to perceive, transform, and reason across complex\nvisual-textual tasks under the think-with-images paradigm. VisualToolBench\ncomprises 1,204 challenging, open-ended vision tasks (603 single-turn, 601\nmulti-turn) spanning across five diverse domains, each paired with detailed\nrubrics to enable systematic evaluation. Our evaluation shows that current\nMLLMs struggle with tasks requiring effective integration of vision and\ngeneral-purpose tools. Even the strongest model (GPT-5-think) reaches only\n18.68% pass rate. We further observe divergent tool-use behaviors, with OpenAI\nmodels benefiting from diverse image manipulations while Gemini-2.5-pro shows\nno improvement. By introducing the first benchmark centered on think with\nimages, VisualToolBench offers critical insights for advancing visual\nintelligence in MLLMs.\n</summary>\n    <author>\n      <name>Xingang Guo</name>\n    </author>\n    <author>\n      <name>Utkarsh Tyagi</name>\n    </author>\n    <author>\n      <name>Advait Gosai</name>\n    </author>\n    <author>\n      <name>Paula Vergara</name>\n    </author>\n    <author>\n      <name>Jayeon Park</name>\n    </author>\n    <author>\n      <name>Ernesto Gabriel Hernández Montoya</name>\n    </author>\n    <author>\n      <name>Chen Bo Calvin Zhang</name>\n    </author>\n    <author>\n      <name>Bin Hu</name>\n    </author>\n    <author>\n      <name>Yunzhong He</name>\n    </author>\n    <author>\n      <name>Bing Liu</name>\n    </author>\n    <author>\n      <name>Rakshith Sharma Srinivasa</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.12712v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.12712v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.12864v1</id>\n    <updated>2025-10-14T16:42:52Z</updated>\n    <published>2025-10-14T16:42:52Z</published>\n    <title>From Literal to Liberal: A Meta-Prompting Framework for Eliciting\n  Human-Aligned Exception Handling in Large Language Models</title>\n    <summary>  Large Language Models (LLMs) are increasingly being deployed as the reasoning\nengines for agentic AI systems, yet they exhibit a critical flaw: a rigid\nadherence to explicit rules that leads to decisions misaligned with human\ncommon sense and intent. This \"rule-rigidity\" is a significant barrier to\nbuilding trustworthy autonomous agents. While prior work has shown that\nsupervised fine-tuning (SFT) with human explanations can mitigate this issue,\nSFT is computationally expensive and inaccessible to many practitioners. To\naddress this gap, we introduce the Rule-Intent Distinction (RID) Framework, a\nnovel, low-compute meta-prompting technique designed to elicit human-aligned\nexception handling in LLMs in a zero-shot manner. The RID framework provides\nthe model with a structured cognitive schema for deconstructing tasks,\nclassifying rules, weighing conflicting outcomes, and justifying its final\ndecision. We evaluated the RID framework against baseline and Chain-of-Thought\n(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced\njudgment across diverse domains. Our human-verified results demonstrate that\nthe RID framework significantly improves performance, achieving a 95% Human\nAlignment Score (HAS), compared to 80% for the baseline and 75% for CoT.\nFurthermore, it consistently produces higher-quality, intent-driven reasoning.\nThis work presents a practical, accessible, and effective method for steering\nLLMs from literal instruction-following to liberal, goal-oriented reasoning,\npaving the way for more reliable and pragmatic AI agents.\n</summary>\n    <author>\n      <name>Imran Khan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages. Code and data are available at\n  https://github.com/strongSoda/LITERAL-TO-LIBERAL</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.12864v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.12864v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.12624v1</id>\n    <updated>2025-10-14T15:23:32Z</updated>\n    <published>2025-10-14T15:23:32Z</published>\n    <title>Learning-To-Measure: In-context Active Feature Acquisition</title>\n    <summary>  Active feature acquisition (AFA) is a sequential decision-making problem\nwhere the goal is to improve model performance for test instances by adaptively\nselecting which features to acquire. In practice, AFA methods often learn from\nretrospective data with systematic missingness in the features and limited\ntask-specific labels. Most prior work addresses acquisition for a single\npredetermined task, limiting scalability. To address this limitation, we\nformalize the meta-AFA problem, where the goal is to learn acquisition policies\nacross various tasks. We introduce Learning-to-Measure (L2M), which consists of\ni) reliable uncertainty quantification over unseen tasks, and ii) an\nuncertainty-guided greedy feature acquisition agent that maximizes conditional\nmutual information. We demonstrate a sequence-modeling or autoregressive\npre-training approach that underpins reliable uncertainty quantification for\ntasks with arbitrary missingness. L2M operates directly on datasets with\nretrospective missingness and performs the meta-AFA task in-context,\neliminating per-task retraining. Across synthetic and real-world tabular\nbenchmarks, L2M matches or surpasses task-specific baselines, particularly\nunder scarce labels and high missingness.\n</summary>\n    <author>\n      <name>Yuta Kobayashi</name>\n    </author>\n    <author>\n      <name>Zilin Jing</name>\n    </author>\n    <author>\n      <name>Jiayu Yao</name>\n    </author>\n    <author>\n      <name>Hongseok Namkoong</name>\n    </author>\n    <author>\n      <name>Shalmali Joshi</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.12624v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.12624v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.12246v1</id>\n    <updated>2025-10-14T07:56:12Z</updated>\n    <published>2025-10-14T07:56:12Z</published>\n    <title>PromptFlow: Training Prompts Like Neural Networks</title>\n    <summary>  Large Language Models (LLMs) have demonstrated profound impact on Natural\nLanguage Processing (NLP) tasks. However, their effective deployment across\ndiverse domains often require domain-specific adaptation strategies, as generic\nmodels may underperform when faced with specialized data distributions. Recent\nadvances in prompt engineering (PE) offer a promising alternative to extensive\nretraining by refining input instructions to align LLM outputs with task\nobjectives. This paradigm has emerged as a rapid and versatile approach for\nmodel fine-tuning. Despite its potential, manual prompt design remains\nlabor-intensive and heavily depends on specialized expertise, often requiring\niterative human effort to achieve optimal formulations. To address this\nlimitation, automated prompt engineering methodologies have been developed to\nsystematically generate task-specific prompts. However, current implementations\npredominantly employ static update rules and lack mechanisms for dynamic\nstrategy selection, resulting in suboptimal adaptation to varying NLP task\nrequirements. Furthermore, most methods treat and update the whole prompts at\neach step, without considering editing prompt sections at a finer granularity.\nAt last, in particular, the problem of how to recycle experience in LLM is\nstill underexplored. To this end, we propose the PromptFlow, a modular training\nframework inspired by TensorFlow, which integrates meta-prompts, operators,\noptimization, and evaluator. Our framework can be equipped with the latest\noptimization methods and autonomously explores optimal prompt refinement\ntrajectories through gradient-based meta-learning, requiring minimal\ntask-specific training data. Specifically, we devise a reinforcement learning\nmethod to recycle experience for LLM in the PE process. Finally, we conduct\nextensive experiments on various datasets, and demonstrate the effectiveness of\nPromptFlow.\n</summary>\n    <author>\n      <name>Jingyi Wang</name>\n    </author>\n    <author>\n      <name>Hongyuan Zhu</name>\n    </author>\n    <author>\n      <name>Ye Niu</name>\n    </author>\n    <author>\n      <name>Yunhui Deng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Comments: 18 pages, 14 figures, conference submission, appendix\n  included</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.12246v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.12246v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.12194v1</id>\n    <updated>2025-10-14T06:40:11Z</updated>\n    <published>2025-10-14T06:40:11Z</published>\n    <title>ResearStudio: A Human-Intervenable Framework for Building Controllable\n  Deep-Research Agents</title>\n    <summary>  Current deep-research agents run in a ''fire-and-forget'' mode: once started,\nthey give users no way to fix errors or add expert knowledge during execution.\nWe present ResearStudio, the first open-source framework that places real-time\nhuman control at its core. The system follows a Collaborative Workshop design.\nA hierarchical Planner-Executor writes every step to a live\n''plan-as-document,'' a fast communication layer streams each action, file\nchange, and tool call to a web interface. At any moment, the user can pause the\nrun, edit the plan or code, run custom commands, and resume -- switching\nsmoothly between AI-led, human-assisted and human-led, AI-assisted modes. In\nfully autonomous mode, ResearStudio achieves state-of-the-art results on the\nGAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These\nresults show that strong automated performance and fine-grained human control\ncan coexist. The full code, protocol, and evaluation scripts are available at\nhttps://github.com/ResearAI/ResearStudio. We will continue to update the\nrepository to encourage further work on safe and controllable research agents.\nOur live demo is publicly accessible at http://ai-researcher.net:3000/. We\nsupport the development of DeepScientist, which can be accessed at\nhttps://github.com/ResearAI/DeepScientist.\n</summary>\n    <author>\n      <name>Linyi Yang</name>\n    </author>\n    <author>\n      <name>Yixuan Weng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">EMNLP 2025 Demo, Oral</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.12194v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.12194v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.11558v1</id>\n    <updated>2025-10-13T16:00:34Z</updated>\n    <published>2025-10-13T16:00:34Z</published>\n    <title>Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative\n  Study of Market Leading Agentic AI Products</title>\n    <summary>  Governance of data, compliance, and business privacy matters, particularly\nfor healthcare and finance businesses. Since the recent emergence of AI\nenterprise AI assistants enhancing business productivity, safeguarding private\ndata and compliance is now a priority. With the implementation of AI assistants\nacross the enterprise, the zero data retention can be achieved by implementing\nzero data retention policies by Large Language Model businesses like Open AI\nand Anthropic and Meta. In this work, we explore zero data retention policies\nfor the Enterprise apps of large language models (LLMs). Our key contribution\nis defining the architectural, compliance, and usability trade-offs of such\nsystems in parallel. In this research work, we examine the development of\ncommercial AI assistants with two industry leaders and market titans in this\narena - Salesforce and Microsoft. Both of these companies used distinct\ntechnical architecture to support zero data retention policies. Salesforce\nAgentForce and Microsoft Copilot are among the leading AI assistants providing\nmuch-needed push to business productivity in customer care. The purpose of this\npaper is to analyze the technical architecture and deployment of zero data\nretention policy by consuming applications as well as big language models\nservice providers like Open Ai, Anthropic, and Meta.\n</summary>\n    <author>\n      <name>Komal Gupta</name>\n    </author>\n    <author>\n      <name>Aditya Shrivastava</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.11558v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.11558v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.10930v1</id>\n    <updated>2025-10-13T02:45:37Z</updated>\n    <published>2025-10-13T02:45:37Z</published>\n    <title>Evaluating Language Models' Evaluations of Games</title>\n    <summary>  Reasoning is not just about solving problems -- it is also about evaluating\nwhich problems are worth solving at all. Evaluations of artificial intelligence\n(AI) systems primarily focused on problem solving, historically by studying how\nmodels play games such as chess and Go. In this paper, we advocate for a new\nparadigm that assesses AI systems' evaluation of games. First, we introduce a\nformalism for evaluating such evaluations. We then leverage a large-scale\ndataset of over $100$ novel board games and over 450 human judgments to compare\nevaluations produced by modern language and reasoning models against those of\npeople and symbolic computational agents. We consider two kinds of evaluative\nqueries: assessing the payoff (or fairness) and the funness of games. These\nqueries span two dimensions relevant to the design of evaluations of AI\nevaluations: how complex a query is to compute and how difficult a query is to\nquantify. Our results show that reasoning models are generally more aligned to\npeople in their evaluations of games than non-reasoning language models.\nHowever, we observe a non-monotonic relationship: as models get closer to\ngame-theoretic optimal, their fit to human data weakens. We also observe more\n\"jaggedness\" across models for assessing funness, in line with the greater\ndifficulty of quantifying this query. Across queries and games, reasoning\nmodels show highly variable and unpredictable resource usage when assessing\nqueries, pointing to the importance of imbuing more resource-rational\nmeta-reasoning in language and reasoning models.\n</summary>\n    <author>\n      <name>Katherine M. Collins</name>\n    </author>\n    <author>\n      <name>Cedegao E. Zhang</name>\n    </author>\n    <author>\n      <name>Graham Todd</name>\n    </author>\n    <author>\n      <name>Lance Ying</name>\n    </author>\n    <author>\n      <name>Mauricio Barba da Costa</name>\n    </author>\n    <author>\n      <name>Ryan Liu</name>\n    </author>\n    <author>\n      <name>Prafull Sharma</name>\n    </author>\n    <author>\n      <name>Adrian Weller</name>\n    </author>\n    <author>\n      <name>Ionatan Kuperwajs</name>\n    </author>\n    <author>\n      <name>Lionel Wong</name>\n    </author>\n    <author>\n      <name>Joshua B. Tenenbaum</name>\n    </author>\n    <author>\n      <name>Thomas L. Griffiths</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Pre-print</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.10930v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.10930v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.10813v1</id>\n    <updated>2025-10-12T21:40:29Z</updated>\n    <published>2025-10-12T21:40:29Z</published>\n    <title>LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent\n  Heuristics</title>\n    <summary>  Large Language Models (LLMs) are increasingly applied to domains that require\nreasoning about other agents' behavior, such as negotiation, policy design, and\nmarket simulation, yet existing research has mostly evaluated their adherence\nto equilibrium play or their exhibited depth of reasoning. Whether they display\ngenuine strategic thinking, understood as the coherent formation of beliefs\nabout other agents, evaluation of possible actions, and choice based on those\nbeliefs, remains unexplored. We develop a framework to identify this ability by\ndisentangling beliefs, evaluation, and choice in static, complete-information\ngames, and apply it across a series of non-cooperative environments. By jointly\nanalyzing models' revealed choices and reasoning traces, and introducing a new\ncontext-free game to rule out imitation from memorization, we show that current\nfrontier models exhibit belief-coherent best-response behavior at targeted\nreasoning depths. When unconstrained, they self-limit their depth of reasoning\nand form differentiated conjectures about human and synthetic opponents,\nrevealing an emergent form of meta-reasoning. Under increasing complexity,\nexplicit recursion gives way to internally generated heuristic rules of choice\nthat are stable, model-specific, and distinct from known human biases. These\nfindings indicate that belief coherence, meta-reasoning, and novel heuristic\nformation can emerge jointly from language modeling objectives, providing a\nstructured basis for the study of strategic cognition in artificial agents.\n</summary>\n    <author>\n      <name>Enric Junque de Fortuny</name>\n    </author>\n    <author>\n      <name>Veronica Roberta Cappelli</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.10813v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.10813v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.GT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.10570v1</id>\n    <updated>2025-10-12T12:42:19Z</updated>\n    <published>2025-10-12T12:42:19Z</published>\n    <title>Multitask Learning with Learned Task Relationships</title>\n    <summary>  Classical consensus-based strategies for federated and decentralized learning\nare statistically suboptimal in the presence of heterogeneous local data or\ntask distributions. As a result, in recent years, there has been growing\ninterest in multitask or personalized strategies, which allow individual agents\nto benefit from one another in pursuing locally optimal models without\nenforcing consensus. Existing strategies require either precise prior knowledge\nof the underlying task relationships or are fully non-parametric and instead\nrely on meta-learning or proximal constructions. In this work, we introduce an\nalgorithmic framework that strikes a balance between these extremes. By\nmodeling task relationships through a Gaussian Markov Random Field with an\nunknown precision matrix, we develop a strategy that jointly learns both the\ntask relationships and the local models, allowing agents to self-organize in a\nway consistent with their individual data distributions. Our theoretical\nanalysis quantifies the quality of the learned relationship, and our numerical\nexperiments demonstrate its practical effectiveness.\n</summary>\n    <author>\n      <name>Zirui Wan</name>\n    </author>\n    <author>\n      <name>Stefan Vlaski</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.10570v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.10570v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.10197v1</id>\n    <updated>2025-10-11T12:35:15Z</updated>\n    <published>2025-10-11T12:35:15Z</published>\n    <title>Don't Just Fine-tune the Agent, Tune the Environment</title>\n    <summary>  Large Language Model (LLM) agents show great promise for complex, multi-turn\ntool-use tasks, but their development is often hampered by the extreme scarcity\nof high-quality training data. Supervised fine-tuning (SFT) on synthetic data\nleads to overfitting, whereas standard reinforcement learning (RL) struggles\nwith a critical cold-start problem and training instability. To address these\nchallenges, we introduce $\\textbf{Environment Tuning}$, a novel training\nparadigm that enables agents to learn complex behaviors directly from problem\ninstances without relying on pre-collected expert trajectories.\n$\\textbf{Environment Tuning}$ orchestrates this learning process through a\nstructured curriculum, actionable environment augmentation that provides\ncorrective feedback, and fine-grained progress rewards to ensure stable and\nefficient exploration. Using only 400 problem instances from Berkeley\nFunction-Calling Leaderboard (BFCL) benchmark, our method not only achieves\ncompetitive in-distribution performance against strong baselines but also\ndemonstrates superior out-of-distribution generalization, overcoming the\nperformance collapse common to SFT-based approaches. Our work presents a\nparadigm shift from supervised fine-tuning on static trajectories to dynamic,\nenvironment-based exploration, paving the way for training more robust and\ndata-efficient agents.\n</summary>\n    <author>\n      <name>Siyuan Lu</name>\n    </author>\n    <author>\n      <name>Zechuan Wang</name>\n    </author>\n    <author>\n      <name>Hongxuan Zhang</name>\n    </author>\n    <author>\n      <name>Qintong Wu</name>\n    </author>\n    <author>\n      <name>Leilei Gan</name>\n    </author>\n    <author>\n      <name>Chenyi Zhuang</name>\n    </author>\n    <author>\n      <name>Jinjie Gu</name>\n    </author>\n    <author>\n      <name>Tao Lin</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.10197v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.10197v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.10158v1</id>\n    <updated>2025-10-11T10:45:39Z</updated>\n    <published>2025-10-11T10:45:39Z</published>\n    <title>Multi-Scale Diffusion Transformer for Jointly Simulating User Mobility\n  and Mobile Traffic Pattern</title>\n    <summary>  User mobility trajectory and mobile traffic data are essential for a wide\nspectrum of applications including urban planning, network optimization, and\nemergency management. However, large-scale and fine-grained mobility data\nremains difficult to obtain due to privacy concerns and collection costs,\nmaking it essential to simulate realistic mobility and traffic patterns. User\ntrajectories and mobile traffic are fundamentally coupled, reflecting both\nphysical mobility and cyber behavior in urban environments. Despite this strong\ninterdependence, existing studies often model them separately, limiting the\nability to capture cross-modal dynamics. Therefore, a unified framework is\ncrucial. In this paper, we propose MSTDiff, a Multi-Scale Diffusion Transformer\nfor joint simulation of mobile traffic and user trajectories. First, MSTDiff\napplies discrete wavelet transforms for multi-resolution traffic decomposition.\nSecond, it uses a hybrid denoising network to process continuous traffic\nvolumes and discrete location sequences. A transition mechanism based on urban\nknowledge graph embedding similarity is designed to guide semantically informed\ntrajectory generation. Finally, a multi-scale Transformer with cross-attention\ncaptures dependencies between trajectories and traffic. Experiments show that\nMSTDiff surpasses state-of-the-art baselines in traffic and trajectory\ngeneration tasks, reducing Jensen-Shannon divergence (JSD) across key\nstatistical metrics by up to 17.38% for traffic generation, and by an average\nof 39.53% for trajectory generation. The source code is available at:\nhttps://github.com/tsinghua-fib-lab/MSTDiff .\n</summary>\n    <author>\n      <name>Ziyi Liu</name>\n    </author>\n    <author>\n      <name>Qingyue Long</name>\n    </author>\n    <author>\n      <name>Zhiwen Xue</name>\n    </author>\n    <author>\n      <name>Huandong Wang</name>\n    </author>\n    <author>\n      <name>Yong Li</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 4 figures. Code: https://github.com/tsinghua-fib-lab/MSTDiff</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.10158v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.10158v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.NI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.09608v1</id>\n    <updated>2025-10-10T17:59:58Z</updated>\n    <published>2025-10-10T17:59:58Z</published>\n    <title>StreamingVLM: Real-Time Understanding for Infinite Video Streams</title>\n    <summary>  Vision-language models (VLMs) could power real-time assistants and autonomous\nagents, but they face a critical challenge: understanding near-infinite video\nstreams without escalating latency and memory usage. Processing entire videos\nwith full attention leads to quadratic computational costs and poor performance\non long videos. Meanwhile, simple sliding window methods are also flawed, as\nthey either break coherence or suffer from high latency due to redundant\nrecomputation. In this paper, we introduce StreamingVLM, a model designed for\nreal-time, stable understanding of infinite visual input. Our approach is a\nunified framework that aligns training with streaming inference. During\ninference, we maintain a compact KV cache by reusing states of attention sinks,\na short window of recent vision tokens, and a long window of recent text\ntokens. This streaming ability is instilled via a simple supervised fine-tuning\n(SFT) strategy that applies full attention on short, overlapped video chunks,\nwhich effectively mimics the inference-time attention pattern without training\non prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a\nnew benchmark with videos averaging over two hours that requires dense,\nper-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM\nachieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time\nperformance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy\nalso enhances general VQA abilities without any VQA-specific fine-tuning,\nimproving performance on LongVideoBench by +4.30 and OVOBench Realtime by\n+5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.\n</summary>\n    <author>\n      <name>Ruyi Xu</name>\n    </author>\n    <author>\n      <name>Guangxuan Xiao</name>\n    </author>\n    <author>\n      <name>Yukang Chen</name>\n    </author>\n    <author>\n      <name>Liuning He</name>\n    </author>\n    <author>\n      <name>Kelly Peng</name>\n    </author>\n    <author>\n      <name>Yao Lu</name>\n    </author>\n    <author>\n      <name>Song Han</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The first two authors contributed equally to this work</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.09608v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.09608v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.09709v1</id>\n    <updated>2025-10-10T02:51:15Z</updated>\n    <published>2025-10-10T02:51:15Z</published>\n    <title>The Idola Tribus of AI: Large Language Models tend to perceive order\n  where none exists</title>\n    <summary>  We present a tendency of large language models (LLMs) to generate absurd\npatterns despite their clear inappropriateness in a simple task of identifying\nregularities in number series. Several approaches have been proposed to apply\nLLMs to complex real-world tasks, such as providing knowledge through\nretrieval-augmented generation and executing multi-step tasks using AI agent\nframeworks. However, these approaches rely on the logical consistency and\nself-coherence of LLMs, making it crucial to evaluate these aspects and\nconsider potential countermeasures. To identify cases where LLMs fail to\nmaintain logical consistency, we conducted an experiment in which LLMs were\nasked to explain the patterns in various integer sequences, ranging from\narithmetic sequences to randomly generated integer series. While the models\nsuccessfully identified correct patterns in arithmetic and geometric sequences,\nthey frequently over-recognized patterns that were inconsistent with the given\nnumbers when analyzing randomly generated series. This issue was observed even\nin multi-step reasoning models, including OpenAI o3, o4-mini, and Google Gemini\n2.5 Flash Preview Thinking. This tendency to perceive non-existent patterns can\nbe interpreted as the AI model equivalent of Idola Tribus and highlights\npotential limitations in their capability for applied tasks requiring logical\nreasoning, even when employing chain-of-thought reasoning mechanisms.\n</summary>\n    <author>\n      <name>Shin-nosuke Ishikawa</name>\n    </author>\n    <author>\n      <name>Masato Todo</name>\n    </author>\n    <author>\n      <name>Taiki Ogihara</name>\n    </author>\n    <author>\n      <name>Hirotsugu Ohba</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">14 pages, 3 figures, accepted to Findings of EMNLP 2025</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.09709v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.09709v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.08790v1</id>\n    <updated>2025-10-09T20:14:26Z</updated>\n    <published>2025-10-09T20:14:26Z</published>\n    <title>COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context</title>\n    <summary>  Long-horizon tasks that require sustained reasoning and multiple tool\ninteractions remain challenging for LLM agents: small errors compound across\nsteps, and even state-of-the-art models often hallucinate or lose coherence. We\nidentify context management as the central bottleneck -- extended histories\ncause agents to overlook critical evidence or become distracted by irrelevant\ninformation, thus failing to replan or reflect from previous mistakes. To\naddress this, we propose COMPASS (Context-Organized Multi-Agent Planning and\nStrategy System), a lightweight hierarchical framework that separates tactical\nexecution, strategic oversight, and context organization into three specialized\ncomponents: (1) a Main Agent that performs reasoning and tool use, (2) a\nMeta-Thinker that monitors progress and issues strategic interventions, and (3)\na Context Manager that maintains concise, relevant progress briefs for\ndifferent reasoning stages. Across three challenging benchmarks -- GAIA,\nBrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%\nrelative to both single- and multi-agent baselines. We further introduce a\ntest-time scaling extension that elevates performance to match established\nDeepResearch agents, and a post-training pipeline that delegates context\nmanagement to smaller models for enhanced efficiency.\n</summary>\n    <author>\n      <name>Guangya Wan</name>\n    </author>\n    <author>\n      <name>Mingyang Ling</name>\n    </author>\n    <author>\n      <name>Xiaoqi Ren</name>\n    </author>\n    <author>\n      <name>Rujun Han</name>\n    </author>\n    <author>\n      <name>Sheng Li</name>\n    </author>\n    <author>\n      <name>Zizhao Zhang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Under Review for ACL</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.08790v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.08790v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.08713v1</id>\n    <updated>2025-10-09T18:18:11Z</updated>\n    <published>2025-10-09T18:18:11Z</published>\n    <title>Unified World Models: Memory-Augmented Planning and Foresight for Visual\n  Navigation</title>\n    <summary>  Enabling embodied agents to effectively imagine future states is critical for\nrobust and generalizable visual navigation. Current state-of-the-art\napproaches, however, adopt modular architectures that separate navigation\nplanning from visual world modeling, leading to state-action misalignment and\nlimited adaptability in novel or dynamic scenarios. To overcome this\nfundamental limitation, we propose UniWM, a unified, memory-augmented world\nmodel integrating egocentric visual foresight and planning within a single\nmultimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly\ngrounds action decisions in visually imagined outcomes, ensuring tight\nalignment between prediction and control. A hierarchical memory mechanism\nfurther integrates detailed short-term perceptual cues with longer-term\ntrajectory context, enabling stable, coherent reasoning over extended horizons.\nExtensive experiments across four challenging benchmarks (Go Stanford, ReCon,\nSCAND, HuRoN) demonstrate that UniWM substantially improves navigation success\nrates by up to 30%, significantly reduces trajectory errors compared to strong\nbaselines, and exhibits impressive zero-shot generalization on the unseen\nTartanDrive dataset. These results highlight UniWM as a principled step toward\nunified, imagination-driven embodied navigation.\n</summary>\n    <author>\n      <name>Yifei Dong</name>\n    </author>\n    <author>\n      <name>Fengyi Wu</name>\n    </author>\n    <author>\n      <name>Guangyu Chen</name>\n    </author>\n    <author>\n      <name>Zhi-Qi Cheng</name>\n    </author>\n    <author>\n      <name>Qiyu Hu</name>\n    </author>\n    <author>\n      <name>Yuxuan Zhou</name>\n    </author>\n    <author>\n      <name>Jingdong Sun</name>\n    </author>\n    <author>\n      <name>Jun-Yan He</name>\n    </author>\n    <author>\n      <name>Qi Dai</name>\n    </author>\n    <author>\n      <name>Alexander G Hauptmann</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">18 pages, 11 figures, code: https://github.com/F1y1113/UniWM</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.08713v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.08713v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.07091v1</id>\n    <updated>2025-10-08T14:47:40Z</updated>\n    <published>2025-10-08T14:47:40Z</published>\n    <title>The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from\n  Planning with Actions to Planning with Schemas</title>\n    <summary>  Enabling LLMs to effectively operate long-horizon task which requires\nlong-term planning and multiple interactions is essential for open-world\nautonomy. Conventional methods adopt planning with actions where a executable\naction list would be provided as reference. However, this action representation\nchoice would be impractical when the environment action space is combinatorial\nexploded (e.g., open-ended real world). This naturally leads to a question: As\nenvironmental action space scales, what is the optimal action representation\nfor long-horizon agents? In this paper, we systematically study the\neffectiveness of two different action representations. The first one is\nconventional planning with actions (PwA) which is predominantly adopted for its\neffectiveness on existing benchmarks. The other one is planning with schemas\n(PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ]\nto [OBJ]\" -&gt; \"move apple to desk\") to ensure concise action space and reliable\nscalability. This alternative is motivated by its alignment with human\ncognition and its compliance with environment-imposed action format\nrestriction. We propose cognitive bandwidth perspective as a conceptual\nframework to qualitatively understand the differences between these two action\nrepresentations and empirically observe a representation-choice inflection\npoint between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve\nas evidence of the need for scalable representations. We further conduct\ncontrolled experiments to study how the location of this inflection point\ninteracts with different model capacities: stronger planning proficiency shifts\nthe inflection rightward, whereas better schema instantiation shifts it\nleftward. Finally, noting the suboptimal performance of PwS agents, we provide\nan actionable guide for building more capable PwS agents for better scalable\nautonomy.\n</summary>\n    <author>\n      <name>Baixuan Xu</name>\n    </author>\n    <author>\n      <name>Tianshi Zheng</name>\n    </author>\n    <author>\n      <name>Zhaowei Wang</name>\n    </author>\n    <author>\n      <name>Hong Ting Tsang</name>\n    </author>\n    <author>\n      <name>Weiqi Wang</name>\n    </author>\n    <author>\n      <name>Tianqing Fang</name>\n    </author>\n    <author>\n      <name>Yangqiu Song</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.07091v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.07091v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06912v1</id>\n    <updated>2025-10-08T11:46:23Z</updated>\n    <published>2025-10-08T11:46:23Z</published>\n    <title>Utilizing Large Language Models for Machine Learning Explainability</title>\n    <summary>  This study explores the explainability capabilities of large language models\n(LLMs), when employed to autonomously generate machine learning (ML) solutions.\nWe examine two classification tasks: (i) a binary classification problem\nfocused on predicting driver alertness states, and (ii) a multilabel\nclassification problem based on the yeast dataset. Three state-of-the-art LLMs\n(i.e. OpenAI GPT, Anthropic Claude, and DeepSeek) are prompted to design\ntraining pipelines for four common classifiers: Random Forest, XGBoost,\nMultilayer Perceptron, and Long Short-Term Memory networks. The generated\nmodels are evaluated in terms of predictive performance (recall, precision, and\nF1-score) and explainability using SHAP (SHapley Additive exPlanations).\nSpecifically, we measure Average SHAP Fidelity (Mean Squared Error between SHAP\napproximations and model outputs) and Average SHAP Sparsity (number of features\ndeemed influential). The results reveal that LLMs are capable of producing\neffective and interpretable models, achieving high fidelity and consistent\nsparsity, highlighting their potential as automated tools for interpretable ML\npipeline generation. The results show that LLMs can produce effective,\ninterpretable pipelines with high fidelity and consistent sparsity, closely\nmatching manually engineered baselines.\n</summary>\n    <author>\n      <name>Alexandros Vassiliades</name>\n    </author>\n    <author>\n      <name>Nikolaos Polatidis</name>\n    </author>\n    <author>\n      <name>Stamatios Samaras</name>\n    </author>\n    <author>\n      <name>Sotiris Diplaris</name>\n    </author>\n    <author>\n      <name>Ignacio Cabrera Martin</name>\n    </author>\n    <author>\n      <name>Yannis Manolopoulos</name>\n    </author>\n    <author>\n      <name>Stefanos Vrochidis</name>\n    </author>\n    <author>\n      <name>Ioannis Kompatsiaris</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.06912v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06912v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06711v1</id>\n    <updated>2025-10-08T07:06:17Z</updated>\n    <published>2025-10-08T07:06:17Z</published>\n    <title>Inefficiencies of Meta Agents for Agent Design</title>\n    <summary>  Recent works began to automate the design of agentic systems using\nmeta-agents that propose and iteratively refine new agent architectures. In\nthis paper, we examine three key challenges in a common class of meta-agents.\nFirst, we investigate how a meta-agent learns across iterations and find that\nsimply expanding the context with all previous agents, as proposed by previous\nworks, performs worse than ignoring prior designs entirely. We show that the\nperformance improves with an evolutionary approach. Second, although the\nmeta-agent designs multiple agents during training, it typically commits to a\nsingle agent at test time. We find that the designed agents have low behavioral\ndiversity, limiting the potential for their complementary use. Third, we assess\nwhen automated design is economically viable. We find that only in a few\ncases--specifically, two datasets--the overall cost of designing and deploying\nthe agents is lower than that of human-designed agents when deployed on over\n15,000 examples. In contrast, the performance gains for other datasets do not\njustify the design cost, regardless of scale.\n</summary>\n    <author>\n      <name>Batu El</name>\n    </author>\n    <author>\n      <name>Mert Yuksekgonul</name>\n    </author>\n    <author>\n      <name>James Zou</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.06711v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06711v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06649v1</id>\n    <updated>2025-10-08T05:06:09Z</updated>\n    <published>2025-10-08T05:06:09Z</published>\n    <title>Local Reinforcement Learning with Action-Conditioned Root Mean Squared\n  Q-Functions</title>\n    <summary>  The Forward-Forward (FF) Algorithm is a recently proposed learning procedure\nfor neural networks that employs two forward passes instead of the traditional\nforward and backward passes used in backpropagation. However, FF remains\nlargely confined to supervised settings, leaving a gap at domains where\nlearning signals can be yielded more naturally such as RL. In this work,\ninspired by FF's goodness function using layer activity statistics, we\nintroduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value\nestimation method that applies a goodness function and action conditioning for\nlocal RL using temporal difference learning. Despite its simplicity and\nbiological grounding, our approach achieves superior performance compared to\nstate-of-the-art local backprop-free RL methods in the MinAtar and the DeepMind\nControl Suite benchmarks, while also outperforming algorithms trained with\nbackpropagation on most tasks. Code can be found at\nhttps://github.com/agentic-learning-ai-lab/arq.\n</summary>\n    <author>\n      <name>Frank Wu</name>\n    </author>\n    <author>\n      <name>Mengye Ren</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages, 5 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.06649v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06649v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06214v1</id>\n    <updated>2025-10-07T17:59:13Z</updated>\n    <published>2025-10-07T17:59:13Z</published>\n    <title>Stratified GRPO: Handling Structural Heterogeneity in Reinforcement\n  Learning of LLM Search Agents</title>\n    <summary>  Large language model (LLM) agents increasingly rely on external tools such as\nsearch engines to solve complex, multi-step problems, and reinforcement\nlearning (RL) has become a key paradigm for training them. However, the\ntrajectories of search agents are structurally heterogeneous, where variations\nin the number, placement, and outcomes of search calls lead to fundamentally\ndifferent answer directions and reward distributions. Standard policy gradient\nmethods, which use a single global baseline, suffer from what we identify and\nformalize as cross-stratum bias-an \"apples-to-oranges\" comparison of\nheterogeneous trajectories. This cross-stratum bias distorts credit assignment\nand hinders exploration of complex, multi-step search strategies. To address\nthis, we propose Stratified GRPO, whose central component, Stratified Advantage\nNormalization (SAN), partitions trajectories into homogeneous strata based on\ntheir structural properties and computes advantages locally within each\nstratum. This ensures that trajectories are evaluated only against their true\npeers. Our analysis proves that SAN eliminates cross-stratum bias, yields\nconditionally unbiased unit-variance estimates inside each stratum, and retains\nthe global unbiasedness and unit-variance properties enjoyed by standard\nnormalization, resulting in a more pure and scale-stable learning signal. To\nimprove practical stability under finite-sample regimes, we further linearly\nblend SAN with the global estimator. Extensive experiments on diverse\nsingle-hop and multi-hop question-answering benchmarks demonstrate that\nStratified GRPO consistently and substantially outperforms GRPO by up to 11.3\npoints, achieving higher training rewards, greater training stability, and more\neffective search policies. These results establish stratification as a\nprincipled remedy for structural heterogeneity in RL for LLM search agents.\n</summary>\n    <author>\n      <name>Mingkang Zhu</name>\n    </author>\n    <author>\n      <name>Xi Chen</name>\n    </author>\n    <author>\n      <name>Bei Yu</name>\n    </author>\n    <author>\n      <name>Hengshuang Zhao</name>\n    </author>\n    <author>\n      <name>Jiaya Jia</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.06214v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06214v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06187v1</id>\n    <updated>2025-10-07T17:46:33Z</updated>\n    <published>2025-10-07T17:46:33Z</published>\n    <title>Automated Program Repair of Uncompilable Student Code</title>\n    <summary>  A significant portion of student programming submissions in CS1 learning\nenvironments are uncompilable, limiting their use in student modeling and\ndownstream knowledge tracing. Traditional modeling pipelines often exclude\nthese cases, discarding observations of student learning. This study\ninvestigates automated program repair as a strategy to recover uncompilable\ncode while preserving students' structural intent for use in student modeling.\nWithin this framework, we assess large language models (LLMs) as repair agents,\nincluding GPT-5 (OpenAI), Claude 3.5 Haiku (Anthropic), and Gemini 2.5 Flash\n(Google), under high- and low-context prompting conditions. Repairs were\nevaluated for compilability, edit distance, and preservation of students'\noriginal structure and logic. We find that while all three LLMs are capable of\nproducing compilable repairs, their behavior diverges in how well they preserve\nstudents' control flow and code structure, which affects their pedagogical\nutility. By recovering uncompilable submissions, this work enables richer and\nmore comprehensive analyses of learners' coding processes and development over\ntime.\n</summary>\n    <author>\n      <name>Griffin Pitts</name>\n    </author>\n    <author>\n      <name>Aum Pandya</name>\n    </author>\n    <author>\n      <name>Darsh Rank</name>\n    </author>\n    <author>\n      <name>Tirth Bhatt</name>\n    </author>\n    <author>\n      <name>Muntasir Hoq</name>\n    </author>\n    <author>\n      <name>Bita Akram</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.06187v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06187v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.06135v1</id>\n    <updated>2025-10-07T17:09:23Z</updated>\n    <published>2025-10-07T17:09:23Z</published>\n    <title>Pushing Test-Time Scaling Limits of Deep Search with Asymmetric\n  Verification</title>\n    <summary>  Test-time compute can be scaled both sequentially and in parallel. Sequential\nscaling involves lengthening the generation process, while parallel scaling\ninvolves verifying and selecting among multiple candidate outputs. Combining\nthese two strategies has led to the most powerful AI systems, such as Grok 4\nHeavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles),\nverifying responses can be substantially easier than generating them. This\nproperty, referred to as \\emph{asymmetric verification}, highlights the strong\npotential of test-time scaling (TTS). In this work, we study both sequential\nand parallel TTS of deep search agents, motivated by the intuition that\nverification in this setting is often much easier than generation. In\nexperiments, we first show that sequential scaling methods, such as budget\nforcing, can be effective initially but soon degrade performance. Leveraging\nasymmetric verification, however, we are able to achieve substantial\nimprovements by allocating only a modest amount of compute to the verifier. We\nconduct experiments with flagship open-source models and extend them to their\n``Heavy'' variants through TTS. These deep research agents achieve gains of up\nto 27 absolute points on benchmarks such as BrowseComp. Remarkably, as an\nopen-source alternative, GLM-4.5 Heavy reaches accuracy of {\\bf 54.0\\%} on\nBrowseComp and {\\bf 66.0\\%} on GAIA, placing it comparable to the best\nproprietary choices such as OpenAI Deep Research. Tongyi-DeepResearch Heavy\nfurther achieves {\\bf 69.0\\%} accuracy on BrowseComp, greatly surpassing the\nbest proprietary results.\n</summary>\n    <author>\n      <name>Weihao Zeng</name>\n    </author>\n    <author>\n      <name>Keqing He</name>\n    </author>\n    <author>\n      <name>Chuqiao Kuang</name>\n    </author>\n    <author>\n      <name>Xiaoguang Li</name>\n    </author>\n    <author>\n      <name>Junxian He</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.06135v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.06135v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05921v1</id>\n    <updated>2025-10-07T13:30:18Z</updated>\n    <published>2025-10-07T13:30:18Z</published>\n    <title>Prompt reinforcing for long-term planning of large language models</title>\n    <summary>  Large language models (LLMs) have achieved remarkable success in a wide range\nof natural language processing tasks and can be adapted through prompting.\nHowever, they remain suboptimal in multi-turn interactions, often relying on\nincorrect early assumptions and failing to track user goals over time, which\nmakes such tasks particularly challenging. Prior works in dialogue systems have\nshown that long-term planning is essential for handling interactive tasks. In\nthis work, we propose a prompt optimisation framework inspired by reinforcement\nlearning, which enables such planning to take place by only modifying the task\ninstruction prompt of the LLM-based agent. By generating turn-by-turn feedback\nand leveraging experience replay for prompt rewriting, our proposed method\nshows significant improvement in multi-turn tasks such as text-to-SQL and\ntask-oriented dialogue. Moreover, it generalises across different LLM-based\nagents and can leverage diverse LLMs as meta-prompting agents. This warrants\nfuture research in reinforcement learning-inspired parameter-free optimisation\nmethods.\n</summary>\n    <author>\n      <name>Hsien-Chin Lin</name>\n    </author>\n    <author>\n      <name>Benjamin Matthias Ruppik</name>\n    </author>\n    <author>\n      <name>Carel van Niekerk</name>\n    </author>\n    <author>\n      <name>Chia-Hao Shen</name>\n    </author>\n    <author>\n      <name>Michael Heck</name>\n    </author>\n    <author>\n      <name>Nurul Lubis</name>\n    </author>\n    <author>\n      <name>Renato Vukovic</name>\n    </author>\n    <author>\n      <name>Shutong Feng</name>\n    </author>\n    <author>\n      <name>Milica Gašić</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.05921v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05921v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05746v1</id>\n    <updated>2025-10-07T10:04:48Z</updated>\n    <published>2025-10-07T10:04:48Z</published>\n    <title>ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent\n  Systems</title>\n    <summary>  Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved\nstate-of-the-art results on various complex reasoning tasks. Recent works have\nproposed techniques to automate the design of MASes, eliminating the need for\nmanual engineering. However, these techniques perform poorly, often achieving\nsimilar or inferior performance to simple baselines. Furthermore, they require\ncomputationally expensive re-discovery of architectures for each new task\ndomain and expensive data annotation on domains without existing labeled\nvalidation sets. A critical insight is that simple Chain of Thought (CoT)\nreasoning often performs competitively with these complex systems, suggesting\nthat the fundamental reasoning unit of MASes, CoT, warrants further\ninvestigation. To this end, we present a new paradigm for automatic MAS design\nthat pivots the focus to optimizing CoT reasoning. We introduce the Agentic\nReasoning Module (ARM), an agentic generalization of CoT where each granular\nreasoning step is executed by a specialized reasoning module. This module is\ndiscovered through a tree search over the code space, starting from a simple\nCoT module and evolved using mutations informed by reflection on execution\ntraces. The resulting ARM acts as a versatile reasoning building block which\ncan be utilized as a direct recursive loop or as a subroutine in a learned\nmeta-orchestrator. Our approach significantly outperforms both manually\ndesigned MASes and state-of-the-art automatic MAS design methods. Crucially,\nMASes built with ARM exhibit superb generalization, maintaining high\nperformance across different foundation models and task domains without further\noptimization.\n</summary>\n    <author>\n      <name>Bohan Yao</name>\n    </author>\n    <author>\n      <name>Shiva Krishna Reddy Malay</name>\n    </author>\n    <author>\n      <name>Vikas Yadav</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">29 pages, 2 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.05746v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05746v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05580v1</id>\n    <updated>2025-10-07T04:54:39Z</updated>\n    <published>2025-10-07T04:54:39Z</published>\n    <title>MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption</title>\n    <summary>  Vision-Language-Action (VLA) models show promise in embodied reasoning, yet\nremain far from true generalists-they often require task-specific fine-tuning,\nand generalize poorly to unseen tasks. We propose MetaVLA, a unified,\nbackbone-agnostic post-training framework for efficient and scalable alignment.\nMetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse\ntarget tasks into a single fine-tuning stage while leveraging structurally\ndiverse auxiliary tasks to improve in-domain generalization. Unlike naive\nmulti-task SFT, MetaVLA integrates a lightweight meta-learning\nmechanism-derived from Attentive Neural Processes-to enable rapid adaptation\nfrom diverse contexts with minimal architectural change or inference overhead.\nOn the LIBERO benchmark, MetaVLA with six auxiliary tasks outperforms OpenVLA\nby up to 8.0% on long-horizon tasks, reduces training steps from 240K to 75K,\nand cuts GPU time by ~76%. These results show that scalable, low-resource\npost-training is achievable-paving the way toward general-purpose embodied\nagents. Code will be available.\n</summary>\n    <author>\n      <name>Chen Li</name>\n    </author>\n    <author>\n      <name>Zhantao Yang</name>\n    </author>\n    <author>\n      <name>Han Zhang</name>\n    </author>\n    <author>\n      <name>Fangyi Chen</name>\n    </author>\n    <author>\n      <name>Chenchen Zhu</name>\n    </author>\n    <author>\n      <name>Anudeepsekhar Bolimera</name>\n    </author>\n    <author>\n      <name>Marios Savvides</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.05580v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05580v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05442v1</id>\n    <updated>2025-10-06T23:09:18Z</updated>\n    <published>2025-10-06T23:09:18Z</published>\n    <title>Adversarial Reinforcement Learning for Large Language Model Agent Safety</title>\n    <summary>  Large Language Model (LLM) agents can leverage tools such as Google Search to\ncomplete complex tasks. However, this tool usage introduces the risk of\nindirect prompt injections, where malicious instructions hidden in tool outputs\ncan manipulate the agent, posing security risks like data leakage. Current\ndefense strategies typically rely on fine-tuning LLM agents on datasets of\nknown attacks. However, the generation of these datasets relies on manually\ncrafted attack patterns, which limits their diversity and leaves agents\nvulnerable to novel prompt injections. To address this limitation, we propose\nAdversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework\nthat leverages adversarial reinforcement learning (RL) by formulating the\nproblem as a two-player zero-sum game. ARLAS co-trains two LLMs: an attacker\nthat learns to autonomously generate diverse prompt injections and an agent\nthat learns to defend against them while completing its assigned tasks. To\nensure robustness against a wide range of attacks and to prevent cyclic\nlearning, we employ a population-based learning framework that trains the agent\nto defend against all previous attacker checkpoints. Evaluated on BrowserGym\nand AgentDojo, agents fine-tuned with ARLAS achieve a significantly lower\nattack success rate than the original model while also improving their task\nsuccess rate. Our analysis further confirms that the adversarial process\ngenerates a diverse and challenging set of attacks, leading to a more robust\nagent compared to the base model.\n</summary>\n    <author>\n      <name>Zizhao Wang</name>\n    </author>\n    <author>\n      <name>Dingcheng Li</name>\n    </author>\n    <author>\n      <name>Vaishakh Keshava</name>\n    </author>\n    <author>\n      <name>Phillip Wallis</name>\n    </author>\n    <author>\n      <name>Ananth Balashankar</name>\n    </author>\n    <author>\n      <name>Peter Stone</name>\n    </author>\n    <author>\n      <name>Lukas Rutishauser</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.05442v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05442v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05327v1</id>\n    <updated>2025-10-06T19:47:27Z</updated>\n    <published>2025-10-06T19:47:27Z</published>\n    <title>DeepV: A Model-Agnostic Retrieval-Augmented Framework for Verilog Code\n  Generation with a High-Quality Knowledge Base</title>\n    <summary>  As large language models (LLMs) continue to be integrated into modern\ntechnology, there has been an increased push towards code generation\napplications, which also naturally extends to hardware design automation.\nLLM-based solutions for register transfer level (RTL) code generation for\nintellectual property (IP) designs have grown, especially with fine-tuned LLMs,\nprompt engineering, and agentic approaches becoming popular in literature.\nHowever, a gap has been exposed in these techniques, as they fail to integrate\nnovel IPs into the model's knowledge base, subsequently resulting in poorly\ngenerated code. Additionally, as general-purpose LLMs continue to improve,\nfine-tuned methods on older models will not be able to compete to produce more\naccurate and efficient designs. Although some retrieval augmented generation\n(RAG) techniques exist to mitigate challenges presented in fine-tuning\napproaches, works tend to leverage low-quality codebases, incorporate\ncomputationally expensive fine-tuning in the frameworks, or do not use RAG\ndirectly in the RTL generation step. In this work, we introduce DeepV: a\nmodel-agnostic RAG framework to generate RTL designs by enhancing context\nthrough a large, high-quality dataset without any RTL-specific training. Our\nframework benefits the latest commercial LLM, OpenAI's GPT-5, with a near 17%\nincrease in performance on the VerilogEval benchmark. We host DeepV for use by\nthe community in a Hugging Face (HF) Space:\nhttps://huggingface.co/spaces/FICS-LLM/DeepV.\n</summary>\n    <author>\n      <name>Zahin Ibnat</name>\n    </author>\n    <author>\n      <name>Paul E. Calzada</name>\n    </author>\n    <author>\n      <name>Rasin Mohammed Ihtemam</name>\n    </author>\n    <author>\n      <name>Sujan Kumar Saha</name>\n    </author>\n    <author>\n      <name>Jingbo Zhou</name>\n    </author>\n    <author>\n      <name>Farimah Farahmandi</name>\n    </author>\n    <author>\n      <name>Mark Tehranipoor</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 6 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.05327v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05327v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05096v2</id>\n    <updated>2025-10-09T17:29:00Z</updated>\n    <published>2025-10-06T17:58:02Z</published>\n    <title>Paper2Video: Automatic Video Generation from Scientific Papers</title>\n    <summary>  Academic presentation videos have become an essential medium for research\ncommunication, yet producing them remains highly labor-intensive, often\nrequiring hours of slide design, recording, and editing for a short 2 to 10\nminutes video. Unlike natural video, presentation video generation involves\ndistinctive challenges: inputs from research papers, dense multi-modal\ninformation (text, figures, tables), and the need to coordinate multiple\naligned channels such as slides, subtitles, speech, and human talker. To\naddress these challenges, we introduce Paper2Video, the first benchmark of 101\nresearch papers paired with author-created presentation videos, slides, and\nspeaker metadata. We further design four tailored evaluation metrics--Meta\nSimilarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos\nconvey the paper's information to the audience. Building on this foundation, we\npropose PaperTalker, the first multi-agent framework for academic presentation\nvideo generation. It integrates slide generation with effective layout\nrefinement by a novel effective tree search visual choice, cursor grounding,\nsubtitling, speech synthesis, and talking-head rendering, while parallelizing\nslide-wise generation for efficiency. Experiments on Paper2Video demonstrate\nthat the presentation videos produced by our approach are more faithful and\ninformative than existing baselines, establishing a practical step toward\nautomated and ready-to-use academic video generation. Our dataset, agent, and\ncode are available at https://github.com/showlab/Paper2Video.\n</summary>\n    <author>\n      <name>Zeyu Zhu</name>\n    </author>\n    <author>\n      <name>Kevin Qinghong Lin</name>\n    </author>\n    <author>\n      <name>Mike Zheng Shou</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Project Page: https://showlab.github.io/Paper2Video/</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.05096v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05096v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.04935v1</id>\n    <updated>2025-10-06T15:42:55Z</updated>\n    <published>2025-10-06T15:42:55Z</published>\n    <title>MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement\n  Learning</title>\n    <summary>  Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in\nsimple tasks, where the models excessively utilize System 2-type, deliberate\nreasoning, leading to inefficient token generation. Furthermore, these models\nface challenges in adapting their reasoning capabilities to rapidly changing\nenvironments due to the static nature of their pretraining data. To address\nthese issues, advancing Large Language Models (LLMs) for complex reasoning\ntasks requires innovative approaches that bridge intuitive and deliberate\ncognitive processes, akin to human cognition's dual-system dynamic. This paper\nintroduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless\nintegration of System 1's fast, intuitive thinking with System 2's deliberate\nreasoning within LLMs. MARS strategically integrates multiple external tools,\nsuch as Google Search, Google Scholar, and Python Interpreter, to access\nup-to-date information and execute complex computations, while creating a\nspecialized division of labor where System 1 efficiently processes and\nsummarizes high-volume external information, providing distilled insights that\nexpand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework\nextending Group Relative Policy Optimization to simultaneously optimize both\nsystems with multi-turn tool interactions, bin-packing optimization, and sample\nbalancing strategies that enhance collaborative efficiency. Extensive\nexperiments demonstrate MARS achieves substantial improvements of 3.86% on the\nchallenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%\nacross 7 knowledge-intensive tasks, validating the effectiveness of our\ndual-system paradigm for complex reasoning in dynamic information environments.\n</summary>\n    <author>\n      <name>Guoxin Chen</name>\n    </author>\n    <author>\n      <name>Zile Qiao</name>\n    </author>\n    <author>\n      <name>Wenqing Wang</name>\n    </author>\n    <author>\n      <name>Donglei Yu</name>\n    </author>\n    <author>\n      <name>Xuanzhong Chen</name>\n    </author>\n    <author>\n      <name>Hao Sun</name>\n    </author>\n    <author>\n      <name>Minpeng Liao</name>\n    </author>\n    <author>\n      <name>Kai Fan</name>\n    </author>\n    <author>\n      <name>Yong Jiang</name>\n    </author>\n    <author>\n      <name>Penguin Xie</name>\n    </author>\n    <author>\n      <name>Wayne Xin Zhao</name>\n    </author>\n    <author>\n      <name>Ruihua Song</name>\n    </author>\n    <author>\n      <name>Fei Huang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Ongoing Work</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.04935v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.04935v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.04607v1</id>\n    <updated>2025-10-06T09:14:58Z</updated>\n    <published>2025-10-06T09:14:58Z</published>\n    <title>A Case for Declarative LLM-friendly Interfaces for Improved Efficiency\n  of Computer-Use Agents</title>\n    <summary>  Computer-use agents (CUAs) powered by large language models (LLMs) have\nemerged as a promising approach to automating computer tasks, yet they struggle\nwith graphical user interfaces (GUIs). GUIs, designed for humans, force LLMs to\ndecompose high-level goals into lengthy, error-prone sequences of fine-grained\nactions, resulting in low success rates and an excessive number of LLM calls.\n  We propose Goal-Oriented Interface (GOI), a novel abstraction that transforms\nexisting GUIs into three declarative primitives: access, state, and\nobservation, which are better suited for LLMs. Our key idea is policy-mechanism\nseparation: LLMs focus on high-level semantic planning (policy) while GOI\nhandles low-level navigation and interaction (mechanism). GOI does not require\nmodifying the application source code or relying on application programming\ninterfaces (APIs).\n  We evaluate GOI with Microsoft Office Suite (Word, PowerPoint, Excel) on\nWindows. Compared to a leading GUI-based agent baseline, GOI improves task\nsuccess rates by 67% and reduces interaction steps by 43.5%. Notably, GOI\ncompletes over 61% of successful tasks with a single LLM call.\n</summary>\n    <author>\n      <name>Yuan Wang</name>\n    </author>\n    <author>\n      <name>Mingyu Li</name>\n    </author>\n    <author>\n      <name>Haibo Chen</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.04607v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.04607v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.OS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.OS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.04542v1</id>\n    <updated>2025-10-06T07:16:07Z</updated>\n    <published>2025-10-06T07:16:07Z</published>\n    <title>Code World Models for General Game Playing</title>\n    <summary>  Large Language Models (LLMs) reasoning abilities are increasingly being\napplied to classical board and card games, but the dominant approach --\ninvolving prompting for direct move generation -- has significant drawbacks. It\nrelies on the model's implicit fragile pattern-matching capabilities, leading\nto frequent illegal moves and strategically shallow play. Here we introduce an\nalternative approach: We use the LLM to translate natural language rules and\ngame trajectories into a formal, executable world model represented as Python\ncode. This generated model -- comprising functions for state transition, legal\nmove enumeration, and termination checks -- serves as a verifiable simulation\nengine for high-performance planning algorithms like Monte Carlo tree search\n(MCTS). In addition, we prompt the LLM to generate heuristic value functions\n(to make MCTS more efficient), and inference functions (to estimate hidden\nstates in imperfect information games). Our method offers three distinct\nadvantages compared to directly using the LLM as a policy: (1) Verifiability:\nThe generated CWM serves as a formal specification of the game's rules,\nallowing planners to algorithmically enumerate valid actions and avoid illegal\nmoves, contingent on the correctness of the synthesized model; (2) Strategic\nDepth: We combine LLM semantic understanding with the deep search power of\nclassical planners; and (3) Generalization: We direct the LLM to focus on the\nmeta-task of data-to-code translation, enabling it to adapt to new games more\neasily. We evaluate our agent on 10 different games, of which 4 are novel and\ncreated for this paper. 5 of the games are fully observed (perfect\ninformation), and 5 are partially observed (imperfect information). We find\nthat our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10\nconsidered games.\n</summary>\n    <author>\n      <name>Wolfgang Lehrach</name>\n    </author>\n    <author>\n      <name>Daniel Hennes</name>\n    </author>\n    <author>\n      <name>Miguel Lazaro-Gredilla</name>\n    </author>\n    <author>\n      <name>Xinghua Lou</name>\n    </author>\n    <author>\n      <name>Carter Wendelken</name>\n    </author>\n    <author>\n      <name>Zun Li</name>\n    </author>\n    <author>\n      <name>Antoine Dedieu</name>\n    </author>\n    <author>\n      <name>Jordi Grau-Moya</name>\n    </author>\n    <author>\n      <name>Marc Lanctot</name>\n    </author>\n    <author>\n      <name>Atil Iscen</name>\n    </author>\n    <author>\n      <name>John Schultz</name>\n    </author>\n    <author>\n      <name>Marcus Chiam</name>\n    </author>\n    <author>\n      <name>Ian Gemp</name>\n    </author>\n    <author>\n      <name>Piotr Zielinski</name>\n    </author>\n    <author>\n      <name>Satinder Singh</name>\n    </author>\n    <author>\n      <name>Kevin P. Murphy</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.04542v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.04542v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.04303v2</id>\n    <updated>2025-10-17T19:12:39Z</updated>\n    <published>2025-10-05T17:51:52Z</published>\n    <title>Audit the Whisper: Detecting Steganographic Collusion in Multi-Agent\n  LLMs</title>\n    <summary>  Multi-agent deployments of large language models (LLMs) are increasingly\nembedded in market, allocation, and governance workflows, yet covert\ncoordination among agents can silently erode trust and social welfare. Existing\naudits are dominated by heuristics that lack theoretical guarantees, struggle\nto transfer across tasks, and seldom ship with the infrastructure needed for\nindependent replication. We introduce Audit the Whisper, a conference-grade\nresearch artifact that spans theory, benchmark design, detection, and\nreproducibility. Our contributions are: (i) a channel-capacity analysis showing\nhow interventions such as paraphrase, rate limiting, and role permutation\nimpose quantifiable capacity penalties-operationalised via paired-run\nKullback--Leibler diagnostics-that tighten mutual-information thresholds with\nfinite-sample guarantees and full proofs; (ii) ColludeBench-v0, covering\npricing, first-price auctions, peer review, and hosted Gemini/Groq APIs with\nconfigurable covert schemes, deterministic manifests, and reward\ninstrumentation; and (iii) a calibrated auditing pipeline that fuses cross-run\nmutual information, permutation invariance, watermark variance, and\nfairness-aware acceptance bias, each tuned to a $10^{-3}$ false-positive budget\nand validated by 10k honest runs plus an e-value martingale. Across\nColludeBench and external suites including Secret Collusion, CASE, Perfect\nCollusion Benchmark, and SentinelAgent, the union meta-test attains\nstate-of-the-art power at fixed FPR while ablations surface price-of-auditing\ntrade-offs and fairness-driven colluders invisible to MI alone. We release\nregeneration scripts, anonymized manifests, and documentation so that external\nauditors can reproduce every figure, satisfy double-blind requirements, and\nextend the framework with minimal effort.\n</summary>\n    <author>\n      <name>Om Tailor</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages, 0 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.04303v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.04303v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.04284v1</id>\n    <updated>2025-10-05T16:54:02Z</updated>\n    <published>2025-10-05T16:54:02Z</published>\n    <title>Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic\n  Reinforcement Learning</title>\n    <summary>  The professionalism of a human doctor in outpatient service depends on two\ncore abilities: the ability to make accurate medical decisions and the medical\nconsultation skill to conduct strategic, empathetic patient inquiry. Existing\nLarge Language Models (LLMs) have achieved remarkable accuracy on medical\ndecision-making benchmarks. However, they often lack the ability to conduct the\nstrategic and empathetic consultation, which is essential for real-world\nclinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor\nagent trained to master both of the capabilities by ask high-yield questions\nand conduct strategic multi-turn inquiry to guide decision-making. Our\nframework introduces three key components: a multi-agent interactive\nenvironment, a two-tiered reward architecture that separately optimizes\nclinical decision-making and communicative inquiry skills, and an experience\nrepository to ground policy learning in high-quality prior trajectories. We\nevaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across\nmulti-facet metrics, such as communication quality, user experience, and task\naccuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source\nspecialized LLMs by a substantial margin with higher parameter efficiency and\noutperforms powerful proprietary models. Furthermore, the human evaluations\nshow a strong preference for Doctor-R1 to generate human-preferred clinical\ndialogue, demonstrating the effectiveness of the framework.\n</summary>\n    <author>\n      <name>Yunghwei Lai</name>\n    </author>\n    <author>\n      <name>Kaiming Liu</name>\n    </author>\n    <author>\n      <name>Ziyue Wang</name>\n    </author>\n    <author>\n      <name>Weizhi Ma</name>\n    </author>\n    <author>\n      <name>Yang Liu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.04284v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.04284v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.03847v1</id>\n    <updated>2025-10-04T15:48:04Z</updated>\n    <published>2025-10-04T15:48:04Z</published>\n    <title>Small Language Models for Agentic Systems: A Survey of Architectures,\n  Capabilities, and Deployment Trade offs</title>\n    <summary>  Small language models (SLMs; 1-12B params, sometimes up to 20B) are\nsufficient and often superior for agentic workloads where the objective is\nschema- and API-constrained accuracy rather than open-ended generation. We\nsynthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,\nQwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,\nDeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,\nStableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with\nguided decoding libraries (XGrammar, Outlines). We formalize SLM-default,\nLLM-fallback systems with uncertainty-aware routing and verifier cascades, and\npropose engineering metrics that reflect real production goals: cost per\nsuccessful task (CPS), schema validity rate, executable call rate, p50/p95\nlatency, and energy per request. Guided decoding, strict JSON Schema outputs,\nand validator-first tool execution close much of the capability gap with larger\nmodels and often let SLMs match or surpass LLMs on tool use, function calling,\nand RAG at 10x-100x lower token cost with materially better latency and energy.\nWe provide design patterns for agent stacks that prioritize SLMs: schema-first\nprompting, type-safe function registries, confidence scoring with verifier\nrollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits\nwhere fallback remains valuable (open-domain reasoning and some long-horizon\nplanning). The result is a practical blueprint for building fast, inexpensive,\nand reliable agents that default to SLMs while preserving headroom with\ntargeted LLM assistance.\n  Keywords: small language models, agents, function calling, structured\noutputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,\nedge inference\n</summary>\n    <author>\n      <name>Raghav Sharma</name>\n    </author>\n    <author>\n      <name>Manan Mehta</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 Pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.03847v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.03847v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.03776v1</id>\n    <updated>2025-10-04T11:02:21Z</updated>\n    <published>2025-10-04T11:02:21Z</published>\n    <title>Trajectory prediction for heterogeneous agents: A performance analysis\n  on small and imbalanced datasets</title>\n    <summary>  Robots and other intelligent systems navigating in complex dynamic\nenvironments should predict future actions and intentions of surrounding agents\nto reach their goals efficiently and avoid collisions. The dynamics of those\nagents strongly depends on their tasks, roles, or observable labels.\nClass-conditioned motion prediction is thus an appealing way to reduce forecast\nuncertainty and get more accurate predictions for heterogeneous agents.\nHowever, this is hardly explored in the prior art, especially for mobile robots\nand in limited data applications. In this paper, we analyse different\nclass-conditioned trajectory prediction methods on two datasets. We propose a\nset of conditional pattern-based and efficient deep learning-based baselines,\nand evaluate their performance on robotics and outdoors datasets (TH\\\"OR-MAGNI\nand Stanford Drone Dataset). Our experiments show that all methods improve\naccuracy in most of the settings when considering class labels. More\nimportantly, we observe that there are significant differences when learning\nfrom imbalanced datasets, or in new environments where sufficient data is not\navailable. In particular, we find that deep learning methods perform better on\nbalanced datasets, but in applications with limited data, e.g., cold start of a\nrobot in a new environment, or imbalanced classes, pattern-based methods may be\npreferable.\n</summary>\n    <author>\n      <name>Tiago Rodrigues de Almeida</name>\n    </author>\n    <author>\n      <name>Yufei Zhu</name>\n    </author>\n    <author>\n      <name>Andrey Rudenko</name>\n    </author>\n    <author>\n      <name>Tomasz P. Kucner</name>\n    </author>\n    <author>\n      <name>Johannes A. Stork</name>\n    </author>\n    <author>\n      <name>Martin Magnusson</name>\n    </author>\n    <author>\n      <name>Achim J. Lilienthal</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/LRA.2024.3408510</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/LRA.2024.3408510\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper has been accepted to the IEEE Robotics and Automation\n  Letters journal and presented at the 40th Anniversary of the IEEE\n  International Conference on Robotics and Automation, which was held in\n  Rotterdam, Netherlands on 23-26 September, 2024</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Robotics and Automation Letters ( Volume: 9, Issue: 7, July\n  2024)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2510.03776v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.03776v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.03217v1</id>\n    <updated>2025-10-03T17:53:28Z</updated>\n    <published>2025-10-03T17:53:28Z</published>\n    <title>Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair</title>\n    <summary>  Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.\n</summary>\n    <author>\n      <name>José Cambronero</name>\n    </author>\n    <author>\n      <name>Michele Tufano</name>\n    </author>\n    <author>\n      <name>Sherry Shi</name>\n    </author>\n    <author>\n      <name>Renyao Wei</name>\n    </author>\n    <author>\n      <name>Grant Uy</name>\n    </author>\n    <author>\n      <name>Runxiang Cheng</name>\n    </author>\n    <author>\n      <name>Chin-Jung Liu</name>\n    </author>\n    <author>\n      <name>Shiying Pan</name>\n    </author>\n    <author>\n      <name>Satish Chandra</name>\n    </author>\n    <author>\n      <name>Pat Rondon</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.03217v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.03217v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.03064v1</id>\n    <updated>2025-10-03T14:48:57Z</updated>\n    <published>2025-10-03T14:48:57Z</published>\n    <title>Comparative Analysis of Parameterized Action Actor-Critic Reinforcement\n  Learning Algorithms for Web Search Match Plan Generation</title>\n    <summary>  This study evaluates the performance of Soft Actor Critic (SAC), Greedy Actor\nCritic (GAC), and Truncated Quantile Critics (TQC) in high-dimensional\ndecision-making tasks using fully observable environments. The focus is on\nparametrized action (PA) spaces, eliminating the need for recurrent networks,\nwith benchmarks Platform-v0 and Goal-v0 testing discrete actions linked to\ncontinuous action-parameter spaces. Hyperparameter optimization was performed\nwith Microsoft NNI, ensuring reproducibility by modifying the codebase for GAC\nand TQC. Results show that Parameterized Action Greedy Actor-Critic (PAGAC)\noutperformed other algorithms, achieving the fastest training times and highest\nreturns across benchmarks, completing 5,000 episodes in 41:24 for the Platform\ngame and 24:04 for the Robot Soccer Goal game. Its speed and stability provide\nclear advantages in complex action spaces. Compared to PASAC and PATQC, PAGAC\ndemonstrated superior efficiency and reliability, making it ideal for tasks\nrequiring rapid convergence and robust performance. Future work could explore\nhybrid strategies combining entropy-regularization with truncation-based\nmethods to enhance stability and expand investigations into generalizability.\n</summary>\n    <author>\n      <name>Ubayd Bapoo</name>\n    </author>\n    <author>\n      <name>Clement N Nyirenda</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages, 10th International Congress on Information and\n  Communication Technology (ICICT 2025)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.03064v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.03064v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.02837v1</id>\n    <updated>2025-10-03T09:19:15Z</updated>\n    <published>2025-10-03T09:19:15Z</published>\n    <title>Beyond the Final Answer: Evaluating the Reasoning Trajectories of\n  Tool-Augmented Agents</title>\n    <summary>  Although recent tool-augmented benchmarks incorporate complex user requests\nand diverse tools, the evaluation methods for most of them remain limited to\nanswer matching. However, as the number of steps required to resolve a user\nrequest increases, a proper evaluation of an agent's performance must go beyond\nthe final answer to also assess the problem-solving trajectory, including\npreviously ignored aspects such as efficiency, hallucination, and adaptivity.\nThe most straightforward method for evaluating these aspects is to compare an\nagent's trajectory with the ground-truth trajectory, but this approach is\nfundamentally limited since annotating all valid ground-truth trajectories is\nprohibitively expensive. However, a simple LLM-based evaluator struggles to\nassess trajectories in detail without ground truth. To effectively evaluate the\nagents in this manner, we introduce TRACE, a framework for the\nmulti-dimensional evaluation of tool-augmented LLM agent performance. By\nincorporating an evidence bank, which accumulates knowledge gathered from\npreceding reasoning steps, TRACE enables a multi-faceted analysis and\nevaluation of an agent's reasoning trajectory effectively. To validate our\nframework, we develop a new meta-evaluation dataset by augmenting existing\nbenchmarks with diverse and flawed trajectories, each labeled with\nmulti-faceted performance scores. Our results confirm that TRACE accurately\nevaluates these complex behaviors in a scalable and cost-effective manner, even\nwith small open-source LLMs. Furthermore, we apply our method to evaluate the\ntrajectories that agents produce while solving tool-augmented tasks, presenting\npreviously unreported observations and their corresponding insights.\n</summary>\n    <author>\n      <name>Wonjoong Kim</name>\n    </author>\n    <author>\n      <name>Sangwu Park</name>\n    </author>\n    <author>\n      <name>Yeonjun In</name>\n    </author>\n    <author>\n      <name>Sein Kim</name>\n    </author>\n    <author>\n      <name>Dongha Lee</name>\n    </author>\n    <author>\n      <name>Chanyoung Park</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Preprint. Under Review</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.02837v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.02837v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.05157v1</id>\n    <updated>2025-10-03T05:53:51Z</updated>\n    <published>2025-10-03T05:53:51Z</published>\n    <title>Adversarial Reinforcement Learning for Offensive and Defensive Agents in\n  a Simulated Zero-Sum Network Environment</title>\n    <summary>  This paper presents a controlled study of adversarial reinforcement learning\nin network security through a custom OpenAI Gym environment that models\nbrute-force attacks and reactive defenses on multi-port services. The\nenvironment captures realistic security trade-offs including background traffic\nnoise, progressive exploitation mechanics, IP-based evasion tactics, honeypot\ntraps, and multi-level rate-limiting defenses. Competing attacker and defender\nagents are trained using Deep Q-Networks (DQN) within a zero-sum reward\nframework, where successful exploits yield large terminal rewards while\nincremental actions incur small costs. Through systematic evaluation across\nmultiple configurations (varying trap detection probabilities, exploitation\ndifficulty thresholds, and training regimens), the results demonstrate that\ndefender observability and trap effectiveness create substantial barriers to\nsuccessful attacks. The experiments reveal that reward shaping and careful\ntraining scheduling are critical for learning stability in this adversarial\nsetting. The defender consistently maintains strategic advantage across 50,000+\ntraining episodes, with performance gains amplifying when exposed to complex\ndefensive strategies including adaptive IP blocking and port-specific controls.\nComplete implementation details, reproducible hyperparameter configurations,\nand architectural guidelines are provided to support future research in\nadversarial RL for cybersecurity. The zero-sum formulation and realistic\noperational constraints make this environment suitable for studying autonomous\ndefense systems, attacker-defender co-evolution, and transfer learning to\nreal-world network security scenarios.\n</summary>\n    <author>\n      <name>Abrar Shahid</name>\n    </author>\n    <author>\n      <name>Ibteeker Mahir Ishum</name>\n    </author>\n    <author>\n      <name>AKM Tahmidul Haque</name>\n    </author>\n    <author>\n      <name>M Sohel Rahman</name>\n    </author>\n    <author>\n      <name>A. B. M. Alim Al Islam</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 5 tables, 5 figures. 12th International Conference on Next\n  Generation Computing, Communication, Systems and Security</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.05157v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.05157v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.01141v1</id>\n    <updated>2025-10-01T17:29:35Z</updated>\n    <published>2025-10-01T17:29:35Z</published>\n    <title>Apriel-1.5-15b-Thinker</title>\n    <summary>  We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights\nmultimodal reasoning model that achieves frontier-level performance through\ntraining design rather than sheer scale. Starting from Pixtral-12B, we apply a\nprogressive three-stage methodology: (1) depth upscaling to expand reasoning\ncapacity without pretraining from scratch, (2) staged continual pre-training\nthat first develops foundational text and vision understanding, then enhances\nvisual reasoning through targeted synthetic data generation addressing spatial\nstructure, compositional understanding, and fine-grained perception, and (3)\nhigh-quality text-only supervised fine-tuning on curated instruction-response\npairs with explicit reasoning traces spanning mathematics, coding, science, and\ntool use. Notably, our model achieves competitive results without reinforcement\nlearning or preference optimization, isolating the contribution of our\ndata-centric continual pre-training approach. On the Artificial Analysis\nIntelligence Index, Apriel-1.5-15B-Thinker attains a score of 52, matching\nDeepSeek-R1-0528 despite requiring significantly fewer computational resources.\nAcross ten image benchmarks, its performance is on average within five points\nof Gemini-2.5-Flash and Claude Sonnet-3.7, a key achievement for a model\noperating within single-GPU deployment constraints. Our results demonstrate\nthat thoughtful mid-training 2 design can close substantial capability gaps\nwithout massive scale, making frontier-level multimodal reasoning accessible to\norganizations with limited infrastructure. We release the model checkpoint, all\ntraining recipes, and evaluation protocols under the MIT license to to advance\nopen-source research.\n</summary>\n    <author>\n      <name>Shruthan Radhakrishna</name>\n    </author>\n    <author>\n      <name>Aman Tiwari</name>\n    </author>\n    <author>\n      <name>Aanjaneya Shukla</name>\n    </author>\n    <author>\n      <name>Masoud Hashemi</name>\n    </author>\n    <author>\n      <name>Rishabh Maheshwary</name>\n    </author>\n    <author>\n      <name>Shiva Krishna Reddy Malay</name>\n    </author>\n    <author>\n      <name>Jash Mehta</name>\n    </author>\n    <author>\n      <name>Pulkit Pattnaik</name>\n    </author>\n    <author>\n      <name>Saloni Mittal</name>\n    </author>\n    <author>\n      <name>Khalil Slimi</name>\n    </author>\n    <author>\n      <name>Kelechi Ogueji</name>\n    </author>\n    <author>\n      <name>Akintunde Oladipo</name>\n    </author>\n    <author>\n      <name>Soham Parikh</name>\n    </author>\n    <author>\n      <name>Oluwanifemi Bamgbose</name>\n    </author>\n    <author>\n      <name>Toby Liang</name>\n    </author>\n    <author>\n      <name>Ahmed Masry</name>\n    </author>\n    <author>\n      <name>Khyati Mahajan</name>\n    </author>\n    <author>\n      <name>Sai Rajeswar Mudumba</name>\n    </author>\n    <author>\n      <name>Vikas Yadav</name>\n    </author>\n    <author>\n      <name>Sathwik Tejaswi Madhusudhan</name>\n    </author>\n    <author>\n      <name>Torsten Scholak</name>\n    </author>\n    <author>\n      <name>Sagar Davasam</name>\n    </author>\n    <author>\n      <name>Srinivas Sunkara</name>\n    </author>\n    <author>\n      <name>Nicholas Chapados</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.01141v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.01141v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.01051v1</id>\n    <updated>2025-10-01T15:55:57Z</updated>\n    <published>2025-10-01T15:55:57Z</published>\n    <title>GEM: A Gym for Agentic LLMs</title>\n    <summary>  The training paradigm for large language models (LLMs) is moving from static\ndatasets to experience-based learning, where agents acquire skills via\ninteracting with complex environments. To facilitate this transition we\nintroduce GEM (General Experience Maker), an open-source environment simulator\ndesigned for the age of LLMs. Analogous to OpenAI-Gym for traditional\nreinforcement learning (RL), GEM provides a standardized framework for the\nenvironment-agent interface, including asynchronous vectorized execution for\nhigh throughput, and flexible wrappers for easy extensibility. GEM also\nfeatures a diverse suite of environments, robust integrated tools, and\nsingle-file example scripts demonstrating using GEM with five popular RL\ntraining frameworks. Along with this, we also provide a set of baselines across\n24 environments using REINFORCE with Return Batch Normalization (ReBN), which\n-- unlike GRPO -- is compatible with the full RL setting of dense per-turn\nrewards and offers better credit assignment. We further conduct apple-to-apple\nbenchmarking of PPO, GRPO and REINFORCE in both single- and multi-turn settings\nusing GEM to shed light on the algorithmic designs. Lastly, GEM also functions\nas a convenient evaluation toolkit besides a training environment. We hope this\nframework can help accelerate future agentic LLM research.\n</summary>\n    <author>\n      <name>Zichen Liu</name>\n    </author>\n    <author>\n      <name>Anya Sims</name>\n    </author>\n    <author>\n      <name>Keyu Duan</name>\n    </author>\n    <author>\n      <name>Changyu Chen</name>\n    </author>\n    <author>\n      <name>Simon Yu</name>\n    </author>\n    <author>\n      <name>Xiangxin Zhou</name>\n    </author>\n    <author>\n      <name>Haotian Xu</name>\n    </author>\n    <author>\n      <name>Shaopan Xiong</name>\n    </author>\n    <author>\n      <name>Bo Liu</name>\n    </author>\n    <author>\n      <name>Chenmien Tan</name>\n    </author>\n    <author>\n      <name>Chuen Yang Beh</name>\n    </author>\n    <author>\n      <name>Weixun Wang</name>\n    </author>\n    <author>\n      <name>Hao Zhu</name>\n    </author>\n    <author>\n      <name>Weiyan Shi</name>\n    </author>\n    <author>\n      <name>Diyi Yang</name>\n    </author>\n    <author>\n      <name>Michael Shieh</name>\n    </author>\n    <author>\n      <name>Yee Whye Teh</name>\n    </author>\n    <author>\n      <name>Wee Sun Lee</name>\n    </author>\n    <author>\n      <name>Min Lin</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.01051v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.01051v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.00615v2</id>\n    <updated>2025-10-17T06:48:23Z</updated>\n    <published>2025-10-01T07:43:49Z</published>\n    <title>ACON: Optimizing Context Compression for Long-horizon LLM Agents</title>\n    <summary>  Large language models (LLMs) are increasingly deployed as agents in dynamic,\nreal-world environments, where success requires both reasoning and effective\ntool use. A central challenge for agentic tasks is the growing context length,\nas agents must accumulate long histories of actions and observations. This\nexpansion raises costs and reduces efficiency in long-horizon tasks, yet prior\nwork on context compression has mostly focused on single-step tasks or narrow\napplications. We introduce Agent Context Optimization (ACON), a unified\nframework that optimally compresses both environment observations and\ninteraction histories into concise yet informative condensations. ACON\nleverages compression guideline optimization in natural language space: given\npaired trajectories where full context succeeds but compressed context fails,\ncapable LLMs analyze the causes of failure, and the compression guideline is\nupdated accordingly. Furthermore, we propose distilling the optimized LLM\ncompressor into smaller models to reduce the overhead of the additional module.\nExperiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON\nreduces memory usage by 26-54% (peak tokens) while largely preserving task\nperformance, preserves over 95% of accuracy when distilled into smaller\ncompressors, and enhances smaller LMs as long-horizon agents with up to 46%\nperformance improvement. Our code is available at\nhttps://github.com/microsoft/acon.\n</summary>\n    <author>\n      <name>Minki Kang</name>\n    </author>\n    <author>\n      <name>Wei-Ning Chen</name>\n    </author>\n    <author>\n      <name>Dongge Han</name>\n    </author>\n    <author>\n      <name>Huseyin A. Inan</name>\n    </author>\n    <author>\n      <name>Lukas Wutschitz</name>\n    </author>\n    <author>\n      <name>Yanzhi Chen</name>\n    </author>\n    <author>\n      <name>Robert Sim</name>\n    </author>\n    <author>\n      <name>Saravan Rajmohan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Preprint</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.00615v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.00615v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.00507v2</id>\n    <updated>2025-10-14T02:11:17Z</updated>\n    <published>2025-10-01T04:37:54Z</published>\n    <title>Graph2Eval: Automatic Multimodal Task Generation for Agents via\n  Knowledge Graphs</title>\n    <summary>  As multimodal LLM-driven agents continue to advance in autonomy and\ngeneralization, evaluation based on static datasets can no longer adequately\nassess their true capabilities in dynamic environments and diverse tasks.\nExisting LLM-based synthetic data methods are largely designed for LLM training\nand evaluation, and thus cannot be directly applied to agent tasks that require\ntool use and interactive capabilities. While recent studies have explored\nautomatic agent task generation with LLMs, most efforts remain limited to text\nor image analysis, without systematically modeling multi-step interactions in\nweb environments. To address these challenges, we propose Graph2Eval, a\nknowledge graph-based framework that automatically generates both multimodal\ndocument comprehension tasks and web interaction tasks, enabling comprehensive\nevaluation of agents' reasoning, collaboration, and interactive capabilities.\nIn our approach, knowledge graphs constructed from multi-source external data\nserve as the task space, where we translate semantic relations into structured\nmultimodal tasks using subgraph sampling, task templates, and meta-paths. A\nmulti-stage filtering pipeline based on node reachability, LLM scoring, and\nsimilarity analysis is applied to guarantee the quality and executability of\nthe generated tasks. Furthermore, Graph2Eval supports end-to-end evaluation of\nmultiple agent types (Single-Agent, Multi-Agent, Web Agent) and measures\nreasoning, collaboration, and interaction capabilities. We instantiate the\nframework with Graph2Eval-Bench, a curated dataset of 1,319 tasks spanning\ndocument comprehension and web interaction scenarios. Experiments show that\nGraph2Eval efficiently generates tasks that differentiate agent and model\nperformance, revealing gaps in reasoning, collaboration, and web interaction\nacross different settings and offering a new perspective for agent evaluation.\n</summary>\n    <author>\n      <name>Yurun Chen</name>\n    </author>\n    <author>\n      <name>Xavier Hu</name>\n    </author>\n    <author>\n      <name>Yuhan Liu</name>\n    </author>\n    <author>\n      <name>Ziqi Wang</name>\n    </author>\n    <author>\n      <name>Zeyi Liao</name>\n    </author>\n    <author>\n      <name>Lin Chen</name>\n    </author>\n    <author>\n      <name>Feng Wei</name>\n    </author>\n    <author>\n      <name>Yuxi Qian</name>\n    </author>\n    <author>\n      <name>Bo Zheng</name>\n    </author>\n    <author>\n      <name>Keting Yin</name>\n    </author>\n    <author>\n      <name>Shengyu Zhang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">20 pages, 10 figures. Our Code:\n  https://github.com/YurunChen/Graph2Eval</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.00507v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.00507v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>\n"
}
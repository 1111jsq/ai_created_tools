{
  "source": "arxiv",
  "fetched_at": "2025-11-07T07:40:09.616883+00:00",
  "payload": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <link href=\"http://arxiv.org/api/query?search_query%3D%28ti%3Aagent%20OR%20ti%3A%22tool%20use%22%20OR%20ti%3Atool-augmented%20OR%20ti%3Aplanning%20OR%20ti%3Amulti-agent%20OR%20ti%3Aautonomous%20OR%20ti%3Atoolformer%20OR%20ti%3A%22tool%20learning%22%20OR%20abs%3Aagent%20OR%20abs%3A%22tool%20use%22%20OR%20abs%3Atool-augmented%20OR%20abs%3Aplanning%20OR%20abs%3Amulti-agent%20OR%20abs%3Aautonomous%20OR%20abs%3Atoolformer%20OR%20abs%3A%22tool%20learning%22%29%20AND%20%28cat%3Acs.AI%20OR%20cat%3Acs.LG%20OR%20cat%3Acs.MA%29%20AND%20%28ti%3AGoogle%20OR%20ti%3ADeepMind%20OR%20ti%3AMicrosoft%20OR%20ti%3AOpenAI%20OR%20ti%3AMeta%20OR%20ti%3AApple%20OR%20ti%3AStanford%20OR%20ti%3AMIT%20OR%20ti%3ACMU%20OR%20ti%3ABerkeley%20OR%20ti%3AOxford%20OR%20ti%3AHarvard%20OR%20ti%3ATsinghua%20OR%20ti%3A%22Peking%20University%22%20OR%20ti%3APKU%20OR%20ti%3AUSTC%20OR%20ti%3ASJTU%20OR%20ti%3APrinceton%20OR%20ti%3AUCLA%20OR%20ti%3AUCSD%20OR%20ti%3A%22ETH%20Zurich%22%20OR%20ti%3ANUS%20OR%20ti%3ANTU%20OR%20abs%3AGoogle%20OR%20abs%3ADeepMind%20OR%20abs%3AMicrosoft%20OR%20abs%3AOpenAI%20OR%20abs%3AMeta%20OR%20abs%3AApple%20OR%20abs%3AStanford%20OR%20abs%3AMIT%20OR%20abs%3ACMU%20OR%20abs%3ABerkeley%20OR%20abs%3AOxford%20OR%20abs%3AHarvard%20OR%20abs%3ATsinghua%20OR%20abs%3A%22Peking%20University%22%20OR%20abs%3APKU%20OR%20abs%3AUSTC%20OR%20abs%3ASJTU%20OR%20abs%3APrinceton%20OR%20abs%3AUCLA%20OR%20abs%3AUCSD%20OR%20abs%3A%22ETH%20Zurich%22%20OR%20abs%3ANUS%20OR%20abs%3ANTU%29%20AND%20submittedDate%3A%5B20251001%20TO%2020251107%5D%26id_list%3D%26start%3D0%26max_results%3D50\" rel=\"self\" type=\"application/atom+xml\"/>\n  <title type=\"html\">ArXiv Query: search_query=(ti:agent OR ti:\"tool use\" OR ti:tool-augmented OR ti:planning OR ti:multi-agent OR ti:autonomous OR ti:toolformer OR ti:\"tool learning\" OR abs:agent OR abs:\"tool use\" OR abs:tool-augmented OR abs:planning OR abs:multi-agent OR abs:autonomous OR abs:toolformer OR abs:\"tool learning\") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.MA) AND (ti:Google OR ti:DeepMind OR ti:Microsoft OR ti:OpenAI OR ti:Meta OR ti:Apple OR ti:Stanford OR ti:MIT OR ti:CMU OR ti:Berkeley OR ti:Oxford OR ti:Harvard OR ti:Tsinghua OR ti:\"Peking University\" OR ti:PKU OR ti:USTC OR ti:SJTU OR ti:Princeton OR ti:UCLA OR ti:UCSD OR ti:\"ETH Zurich\" OR ti:NUS OR ti:NTU OR abs:Google OR abs:DeepMind OR abs:Microsoft OR abs:OpenAI OR abs:Meta OR abs:Apple OR abs:Stanford OR abs:MIT OR abs:CMU OR abs:Berkeley OR abs:Oxford OR abs:Harvard OR abs:Tsinghua OR abs:\"Peking University\" OR abs:PKU OR abs:USTC OR abs:SJTU OR abs:Princeton OR abs:UCLA OR abs:UCSD OR abs:\"ETH Zurich\" OR abs:NUS OR abs:NTU) AND submittedDate:[20251001 TO 20251107]&amp;id_list=&amp;start=0&amp;max_results=50</title>\n  <id>http://arxiv.org/api/RbN0/q8cm6bX2yeGfGrzb9R2J7A</id>\n  <updated>2025-11-07T00:00:00-05:00</updated>\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">96</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">50</opensearch:itemsPerPage>\n  <entry>\n    <id>http://arxiv.org/abs/2511.04481v1</id>\n    <updated>2025-11-06T15:59:59Z</updated>\n    <published>2025-11-06T15:59:59Z</published>\n    <title>Promoting Sustainable Web Agents: Benchmarking and Estimating Energy\n  Consumption through Empirical and Theoretical Analysis</title>\n    <summary>  Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful\nagentic systems pushing the boundaries of Large Language Models (LLM). They can\nautonomously interact with the internet at the user's behest, such as\nnavigating websites, filling search masks, and comparing price lists. Though\nweb agent research is thriving, induced sustainability issues remain largely\nunexplored. To highlight the urgency of this issue, we provide an initial\nexploration of the energy and $CO_2$ cost associated with web agents from both\na theoretical -via estimation- and an empirical perspective -by benchmarking.\nOur results show how different philosophies in web agent creation can severely\nimpact the associated expended energy, and that more energy consumed does not\nnecessarily equate to better results. We highlight a lack of transparency\nregarding disclosing model parameters and processes used for some web agents as\na limiting factor when estimating energy consumption. Our work contributes\ntowards a change in thinking of how we evaluate web agents, advocating for\ndedicated metrics measuring energy consumption in benchmarks.\n</summary>\n    <author>\n      <name>Lars Krupp</name>\n    </author>\n    <author>\n      <name>Daniel Geißler</name>\n    </author>\n    <author>\n      <name>Vishal Banwari</name>\n    </author>\n    <author>\n      <name>Paul Lukowicz</name>\n    </author>\n    <author>\n      <name>Jakob Karolus</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted by AAAI 2026 AISI</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2511.04481v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.04481v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03958v1</id>\n    <updated>2025-11-06T01:24:07Z</updated>\n    <published>2025-11-06T01:24:07Z</published>\n    <title>Multi-Agent Collaborative Framework For Math Problem Generation</title>\n    <summary>  Automatic question generation (AQG) for mathematics education remains an\nelusive goal for Intelligent Tutoring Systems and educators. While pre-trained\ntransformer-based language models have significantly advanced natural language\ngeneration, they often struggle to precisely control problem complexity and\ncognitive demands. In this paper, we introduce a collaborative multi-agent\nframework as a novel method of incorporating inference-time computation into\nAQG. This approach leverages multiple agents that iteratively refine generated\nquestion-answer pairs to better balance complexity and cognitive demand. We\nevaluate the generated questions on five meta-evaluation criteria: relevance,\nimportance, clarity, difficulty matching, answerability, to assess the system's\nability to control the required complexity and quality of the questions.\nPreliminary evaluations show that this collaborative multi-agent framework\nelevates the quality of generated educational content by fostering a more\nnuanced balance between cognitive challenge and clarity. These promising\noutcomes suggest that integrating collaborative multi-agent workflows can yield\nmore controlled, pedagogically valuable content that can help advance automated\neducational content generation and adaptive learning environments.\n</summary>\n    <author>\n      <name>Kia Karbasi</name>\n    </author>\n    <author>\n      <name>Kevin Hong</name>\n    </author>\n    <author>\n      <name>Mohammad Amin Samadi</name>\n    </author>\n    <author>\n      <name>Gregory Pottie</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.5281/zenodo.15870246</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.5281/zenodo.15870246\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Published in the Proceedings of the 18th International Conference on\n  Educational Data Mining, 6 pages, 5 figures</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Kia Karbasi, Kevin Hong, Mohammad Amin Samadi, &amp; Gregory Pottie.\n  (2025). Multi-Agent Collaborative Framework For Math Problem Generation.\n  Proceedings of the 18th International Conference on Educational Data Mining,\n  613--618</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2511.03958v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.03958v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.2.11; I.2.6; K.3.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03690v1</id>\n    <updated>2025-11-05T18:16:44Z</updated>\n    <published>2025-11-05T18:16:44Z</published>\n    <title>The OpenHands Software Agent SDK: A Composable and Extensible Foundation\n  for Production Agents</title>\n    <summary>  Agents are now used widely in the process of software development, but\nbuilding production-ready software engineering agents is a complex task.\nDeploying software agents effectively requires flexibility in implementation\nand experimentation, reliable and secure execution, and interfaces for users to\ninteract with agents. In this paper, we present the OpenHands Software Agent\nSDK, a toolkit for implementing software development agents that satisfy these\ndesiderata. This toolkit is a complete architectural redesign of the agent\ncomponents of the popular OpenHands framework for software development agents,\nwhich has 64k+ GitHub stars. To achieve flexibility, we design a simple\ninterface for implementing agents that requires only a few lines of code in the\ndefault case, but is easily extensible to more complex, full-featured agents\nwith features such as custom tools, memory management, and more. For security\nand reliability, it delivers seamless local-to-remote execution portability,\nintegrated REST/WebSocket services. For interaction with human users, it can\nconnect directly to a variety of interfaces, such as visual workspaces (VS\nCode, VNC, browser), command-line interfaces, and APIs. Compared with existing\nSDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native\nsandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and\nbuilt-in security analysis. Empirical results on SWE-Bench Verified and GAIA\nbenchmarks demonstrate strong performance. Put together, these elements allow\nthe OpenHands Software Agent SDK to provide a practical foundation for\nprototyping, unlocking new classes of custom applications, and reliably\ndeploying agents at scale.\n</summary>\n    <author>\n      <name>Xingyao Wang</name>\n    </author>\n    <author>\n      <name>Simon Rosenberg</name>\n    </author>\n    <author>\n      <name>Juan Michelini</name>\n    </author>\n    <author>\n      <name>Calvin Smith</name>\n    </author>\n    <author>\n      <name>Hoang Tran</name>\n    </author>\n    <author>\n      <name>Engel Nyst</name>\n    </author>\n    <author>\n      <name>Rohit Malhotra</name>\n    </author>\n    <author>\n      <name>Xuhui Zhou</name>\n    </author>\n    <author>\n      <name>Valerie Chen</name>\n    </author>\n    <author>\n      <name>Robert Brennan</name>\n    </author>\n    <author>\n      <name>Graham Neubig</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.03690v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.03690v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03497v1</id>\n    <updated>2025-11-05T14:27:58Z</updated>\n    <published>2025-11-05T14:27:58Z</published>\n    <title>ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied\n  AI Applications</title>\n    <summary>  Agentic AI systems and Physical or Embodied AI systems have been two key\nresearch verticals at the forefront of Artificial Intelligence and Robotics,\nwith Model Context Protocol (MCP) increasingly becoming a key component and\nenabler of agentic applications. However, the literature at the intersection of\nthese verticals, i.e., Agentic Embodied AI, remains scarce. This paper\nintroduces an MCP server for analyzing ROS and ROS 2 bags, allowing for\nanalyzing, visualizing and processing robot data with natural language through\nLLMs and VLMs. We describe specific tooling built with robotics domain\nknowledge, with our initial release focused on mobile robotics and supporting\nnatively the analysis of trajectories, laser scan data, transforms, or time\nseries data. This is in addition to providing an interface to standard ROS 2\nCLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to\nfilter bags with a subset of topics or trimmed in time. Coupled with the MCP\nserver, we provide a lightweight UI that allows the benchmarking of the tooling\nwith different LLMs, both proprietary (Anthropic, OpenAI) and open-source\n(through Groq). Our experimental results include the analysis of tool calling\ncapabilities of eight different state-of-the-art LLM/VLM models, both\nproprietary and open-source, large and small. Our experiments indicate that\nthere is a large divide in tool calling capabilities, with Kimi K2 and Claude\nSonnet 4 demonstrating clearly superior performance. We also conclude that\nthere are multiple factors affecting the success rates, from the tool\ndescription schema to the number of arguments, as well as the number of tools\navailable to the models. The code is available with a permissive license at\nhttps://github.com/binabik-ai/mcp-rosbags.\n</summary>\n    <author>\n      <name>Lei Fu</name>\n    </author>\n    <author>\n      <name>Sahar Salimpour</name>\n    </author>\n    <author>\n      <name>Leonardo Militano</name>\n    </author>\n    <author>\n      <name>Harry Edelman</name>\n    </author>\n    <author>\n      <name>Jorge Peña Queralta</name>\n    </author>\n    <author>\n      <name>Giovanni Toffetti</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.03497v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.03497v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.03434v1</id>\n    <updated>2025-11-05T12:50:06Z</updated>\n    <published>2025-11-05T12:50:06Z</published>\n    <title>Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof,\n  Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2,\n  ERC-8004, and Beyond</title>\n    <summary>  As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered)\nautonomously transacting and collaborating-trust shifts from human oversight to\nprotocol design. In 2025, several inter-agent protocols crystallized this\nshift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),\nand Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust\nassumptions remain under-examined. This paper presents a comparative study of\ntrust models in inter-agent protocol design: Brief (self- or third-party\nverifiable claims), Claim (self-proclaimed capabilities and identity, e.g.\nAgentCard), Proof (cryptographic verification, including zero-knowledge proofs\nand trusted execution environment attestations), Stake (bonded collateral with\nslashing and insurance), Reputation (crowd feedback and graph-based trust\nsignals), and Constraint (sandboxing and capability bounding). For each, we\nanalyze assumptions, attack surfaces, and design trade-offs, with particular\nemphasis on LLM-specific fragilities-prompt injection,\nsycophancy/nudge-susceptibility, hallucination, deception, and\nmisalignment-that render purely reputational or claim-only approaches brittle.\nOur findings indicate no single mechanism suffices. We argue for\ntrustless-by-default architectures anchored in Proof and Stake to gate\nhigh-impact actions, augmented by Brief for identity and discovery and\nReputation overlays for flexibility and social signals. We comparatively\nevaluate A2A, AP2, ERC-8004 and related historical variations in academic\nresearch under metrics spanning security, privacy, latency/cost, and social\nrobustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid\ntrust model recommendations that mitigate reputation gaming and misinformed LLM\nbehavior, and we distill actionable design guidelines for safer, interoperable,\nand scalable agent economies.\n</summary>\n    <author>\n      <name>Botao 'Amber' Hu</name>\n    </author>\n    <author>\n      <name>Helena Rong</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to AAAI 2026 Workshop on Trust and Control in Agentic AI\n  (TrustAgent)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2511.03434v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.03434v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02606v1</id>\n    <updated>2025-11-04T14:28:03Z</updated>\n    <published>2025-11-04T14:28:03Z</published>\n    <title>A Multi-Agent Psychological Simulation System for Human Behavior\n  Modeling</title>\n    <summary>  Training and education in human-centered fields require authentic practice,\nyet realistic simulations of human behavior have remained limited. We present a\nmulti-agent psychological simulation system that models internal\ncognitive-affective processes to generate believable human behaviors. In\ncontrast to black-box neural models, this system is grounded in established\npsychological theories (e.g., self-efficacy, mindset, social constructivism)\nand explicitly simulates an ``inner parliament'' of agents corresponding to key\npsychological factors. These agents deliberate and interact to determine the\nsystem's output behavior, enabling unprecedented transparency and alignment\nwith human psychology. We describe the system's architecture and theoretical\nfoundations, illustrate its use in teacher training and research, and discuss\nhow it embodies principles of social learning, cognitive apprenticeship,\ndeliberate practice, and meta-cognition.\n</summary>\n    <author>\n      <name>Xiangen Hu</name>\n    </author>\n    <author>\n      <name>Jiarui Tong</name>\n    </author>\n    <author>\n      <name>Sheng Xu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.02606v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.02606v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02560v1</id>\n    <updated>2025-11-04T13:30:15Z</updated>\n    <published>2025-11-04T13:30:15Z</published>\n    <title>SigmaCollab: An Application-Driven Dataset for Physically Situated\n  Collaboration</title>\n    <summary>  We introduce SigmaCollab, a dataset enabling research on physically situated\nhuman-AI collaboration. The dataset consists of a set of 85 sessions in which\nuntrained participants were guided by a mixed-reality assistive AI agent in\nperforming procedural tasks in the physical world. SigmaCollab includes a set\nof rich, multimodal data streams, such as the participant and system audio,\negocentric camera views from the head-mounted device, depth maps, head, hand\nand gaze tracking information, as well as additional annotations performed\npost-hoc. While the dataset is relatively small in size (~ 14 hours), its\napplication-driven and interactive nature brings to the fore novel research\nchallenges for human-AI collaboration, and provides more realistic testing\ngrounds for various AI models operating in this space. In future work, we plan\nto use the dataset to construct a set of benchmarks for physically situated\ncollaboration in mixed-reality task assistive scenarios. SigmaCollab is\navailable at https://github.com/microsoft/SigmaCollab.\n</summary>\n    <author>\n      <name>Dan Bohus</name>\n    </author>\n    <author>\n      <name>Sean Andrist</name>\n    </author>\n    <author>\n      <name>Ann Paradiso</name>\n    </author>\n    <author>\n      <name>Nick Saw</name>\n    </author>\n    <author>\n      <name>Tim Schoonbeek</name>\n    </author>\n    <author>\n      <name>Maia Stiber</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.02560v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.02560v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.02303v1</id>\n    <updated>2025-11-04T06:37:31Z</updated>\n    <published>2025-11-04T06:37:31Z</published>\n    <title>Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents\n  to Deliberation</title>\n    <summary>  Large Language Models (LLMs) trained with reinforcement learning and\nverifiable rewards have achieved strong results on complex reasoning tasks.\nRecent work extends this paradigm to a multi-agent setting, where a\nmeta-thinking agent proposes plans and monitors progress while a reasoning\nagent executes subtasks through sequential conversational turns. Despite\npromising performance, we identify a critical limitation: lazy agent behavior,\nin which one agent dominates while the other contributes little, undermining\ncollaboration and collapsing the setup to an ineffective single agent. In this\npaper, we first provide a theoretical analysis showing why lazy behavior\nnaturally arises in multi-agent reasoning. We then introduce a stable and\nefficient method for measuring causal influence, helping mitigate this issue.\nFinally, as collaboration intensifies, the reasoning agent risks getting lost\nin multi-turn interactions and trapped by previous noisy responses. To counter\nthis, we propose a verifiable reward mechanism that encourages deliberation by\nallowing the reasoning agent to discard noisy outputs, consolidate\ninstructions, and restart its reasoning process when necessary. Extensive\nexperiments demonstrate that our framework alleviates lazy agent behavior and\nunlocks the full potential of multi-agent framework for complex reasoning\ntasks.\n</summary>\n    <author>\n      <name>Zhiwei Zhang</name>\n    </author>\n    <author>\n      <name>Xiaomin Li</name>\n    </author>\n    <author>\n      <name>Yudi Lin</name>\n    </author>\n    <author>\n      <name>Hui Liu</name>\n    </author>\n    <author>\n      <name>Ramraj Chandradevan</name>\n    </author>\n    <author>\n      <name>Linlin Wu</name>\n    </author>\n    <author>\n      <name>Minhua Lin</name>\n    </author>\n    <author>\n      <name>Fali Wang</name>\n    </author>\n    <author>\n      <name>Xianfeng Tang</name>\n    </author>\n    <author>\n      <name>Qi He</name>\n    </author>\n    <author>\n      <name>Suhang Wang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.02303v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.02303v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01999v1</id>\n    <updated>2025-11-03T19:13:26Z</updated>\n    <published>2025-11-03T19:13:26Z</published>\n    <title>TRACE: Textual Reasoning for Affordance Coordinate Extraction</title>\n    <summary>  Vision-Language Models (VLMs) struggle to translate high-level instructions\ninto the precise spatial affordances required for robotic manipulation. While\nvisual Chain-of-Thought (CoT) methods exist, they are often computationally\nintensive. In this work, we introduce TRACE (Textual Reasoning for Affordance\nCoordinate Extraction), a novel methodology that integrates a textual Chain of\nReasoning (CoR) into the affordance prediction process. We use this methodology\nto create the TRACE dataset, a large-scale collection created via an autonomous\npipeline that pairs instructions with explicit textual rationales. By\nfine-tuning a VLM on this data, our model learns to externalize its spatial\nreasoning before acting. Our experiments show that our TRACE-tuned model\nachieves state-of-the-art performance, reaching 48.1% accuracy on the primary\nWhere2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more\nchallenging W2P(h) subset. Crucially, an ablation study demonstrates that\nperformance scales directly with the amount of reasoning data used, confirming\nthe CoR's effectiveness. Furthermore, analysis of the model's attention maps\nreveals an interpretable reasoning process where focus shifts dynamically\nacross reasoning steps. This work shows that training VLMs to generate a\ntextual CoR is an effective and robust strategy for enhancing the precision,\nreliability, and interpretability of VLM-based robot control. Our dataset and\ncode are available at https://github.com/jink-ucla/TRACE\n</summary>\n    <author>\n      <name>Sangyun Park</name>\n    </author>\n    <author>\n      <name>Jin Kim</name>\n    </author>\n    <author>\n      <name>Yuchen Cui</name>\n    </author>\n    <author>\n      <name>Matthew S. Brown</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICCV 2025. *Equal contribution. {\\dag}Corresponding author</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2511.01999v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.01999v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01093v1</id>\n    <updated>2025-11-02T21:48:31Z</updated>\n    <published>2025-11-02T21:48:31Z</published>\n    <title>Continual Learning, Not Training: Online Adaptation For Agents</title>\n    <summary>  Continual Learning (CL) methods have traditionally focused on mitigating\ncatastrophic forgetting through gradient-based retraining, an approach\nill-suited for deployed agents that must adapt in real time. We introduce our\nAdaptive Teaching and Learning System (ATLAS), a dual-agent architecture that\ndecouples reasoning (Teacher) from execution (Student) and incorporates a\npersistent learning memory that stores distilled guidance from experience. This\ninforms the orchestration layer, enabling the system to dynamically adjust its\noperational strategies, such as supervision level or initial plan selection, at\ninference time. In doing so, ATLAS achieves gradient-free continual learning,\nshifting the locus of adaptation from model parameters to system-level\norchestration. We formulate this as a system-centric paradigm for continual\nlearning, where the objective is adaptive efficiency: maximizing task success\nwhile minimizing computational cost through inference-time orchestration rather\nthan parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source\nbenchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1%\nsuccess with GPT-5-mini as its Student, outperforming the larger GPT-5 (High)\nby 13% while reducing cost by 86%. Cross-incident validation demonstrates\ngeneralization: frozen pamphlets from Incident #5 improve accuracy from 28% to\n41% with zero retraining, while shifting output composition from verbose\nexploration to structured reasoning. Together, these findings establish\ngradient-free continual learning as a viable path toward adaptive, deployable\nAI systems and provide causally annotated traces valuable for training explicit\nworld models.\n</summary>\n    <author>\n      <name>Aman Jaglan</name>\n    </author>\n    <author>\n      <name>Jarrod Barnes</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 4 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2511.01093v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.01093v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; I.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01078v1</id>\n    <updated>2025-11-02T21:05:03Z</updated>\n    <published>2025-11-02T21:05:03Z</published>\n    <title>Predictive Auxiliary Learning for Belief-based Multi-Agent Systems</title>\n    <summary>  The performance of multi-agent reinforcement learning (MARL) in partially\nobservable environments depends on effectively aggregating information from\nobservations, communications, and reward signals. While most existing\nmulti-agent systems primarily rely on rewards as the only feedback for policy\ntraining, our research shows that introducing auxiliary predictive tasks can\nsignificantly enhance learning efficiency and stability. We propose\nBelief-based Predictive Auxiliary Learning (BEPAL), a framework that\nincorporates auxiliary training objectives to support policy optimization.\nBEPAL follows the centralized training with decentralized execution paradigm.\nEach agent learns a belief model that predicts unobservable state information,\nsuch as other agents' rewards or motion directions, alongside its policy model.\nBy enriching hidden state representations with information that does not\ndirectly contribute to immediate reward maximization, this auxiliary learning\nprocess stabilizes MARL training and improves overall performance. We evaluate\nBEPAL in the predator-prey environment and Google Research Football, where it\nachieves an average improvement of about 16 percent in performance metrics and\ndemonstrates more stable convergence compared to baseline methods.\n</summary>\n    <author>\n      <name>Qinwei Huang</name>\n    </author>\n    <author>\n      <name>Stefan Wang</name>\n    </author>\n    <author>\n      <name>Simon Khan</name>\n    </author>\n    <author>\n      <name>Garrett Katz</name>\n    </author>\n    <author>\n      <name>Qinru Qiu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.01078v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.01078v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00423v1</id>\n    <updated>2025-11-01T06:33:04Z</updated>\n    <published>2025-11-01T06:33:04Z</published>\n    <title>Bootstrap Off-policy with World Model</title>\n    <summary>  Online planning has proven effective in reinforcement learning (RL) for\nimproving sample efficiency and final performance. However, using planning for\nenvironment interaction inevitably introduces a divergence between the\ncollected data and the policy's actual behaviors, degrading both model learning\nand policy improvement. To address this, we propose BOOM (Bootstrap Off-policy\nwith WOrld Model), a framework that tightly integrates planning and off-policy\nlearning through a bootstrap loop: the policy initializes the planner, and the\nplanner refines actions to bootstrap the policy through behavior alignment.\nThis loop is supported by a jointly learned world model, which enables the\nplanner to simulate future trajectories and provides value targets to\nfacilitate policy improvement. The core of BOOM is a likelihood-free alignment\nloss that bootstraps the policy using the planner's non-parametric action\ndistribution, combined with a soft value-weighted mechanism that prioritizes\nhigh-return behaviors and mitigates variability in the planner's action quality\nwithin the replay buffer. Experiments on the high-dimensional DeepMind Control\nSuite and Humanoid-Bench show that BOOM achieves state-of-the-art results in\nboth training stability and final performance. The code is accessible at\nhttps://github.com/molumitu/BOOM_MBRL.\n</summary>\n    <author>\n      <name>Guojian Zhan</name>\n    </author>\n    <author>\n      <name>Likun Wang</name>\n    </author>\n    <author>\n      <name>Xiangteng Zhang</name>\n    </author>\n    <author>\n      <name>Jiaxin Gao</name>\n    </author>\n    <author>\n      <name>Masayoshi Tomizuka</name>\n    </author>\n    <author>\n      <name>Shengbo Eben Li</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NeurIPS 2025</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2511.00423v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.00423v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00162v2</id>\n    <updated>2025-11-04T03:46:39Z</updated>\n    <published>2025-10-31T18:10:05Z</published>\n    <title>ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction\n  and Reasoning Corpus</title>\n    <summary>  The Abstraction and Reasoning Corpus remains one of the most compelling and\nchallenging benchmarks for tracking progress toward achieving Artificial\nGeneral Intelligence. In contrast to other evaluation datasets designed to\nassess an agent's task-specific skills or accumulated knowledge, the ARC-AGI\nsuite is specifically targeted at measuring skill acquisition efficiency, a\ntrait that has (so far) been lacking in even the most sophisticated machine\nlearning systems. For algorithms that require extensive intra-task exemplars, a\nsignificant constraint imposed by ARC-AGI is the modest cardinality of its\ndemonstration set, comprising a small number of $\\langle$ input, output\n$\\rangle$ grids per task specifying the corresponding transformation. To\nembellish the space of viable sample pairs, this paper introduces ARC-GEN, an\nopen-source procedural generator aimed at extending the original ARC-AGI\ntraining dataset as faithfully as possible. Unlike prior efforts, our generator\nis both exhaustive (covering all four-hundred tasks) and mimetic (more closely\nhonoring the distributional properties and characteristics embodied in the\ninitial ARC-AGI-1 release). We also discuss the use of this generator in\nestablishing a static benchmark suite to verify the correctness of programs\nsubmitted to the 2025 Google Code Golf Championship.\n</summary>\n    <author>\n      <name>Michael D. Moffitt</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.00162v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.00162v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.27334v1</id>\n    <updated>2025-10-31T10:05:14Z</updated>\n    <published>2025-10-31T10:05:14Z</published>\n    <title>When AI Trading Agents Compete: Adverse Selection of Meta-Orders by\n  Reinforcement Learning-Based Market Making</title>\n    <summary>  We investigate the mechanisms by which medium-frequency trading agents are\nadversely selected by opportunistic high-frequency traders. We use\nreinforcement learning (RL) within a Hawkes Limit Order Book (LOB) model in\norder to replicate the behaviours of high-frequency market makers. In contrast\nto the classical models with exogenous price impact assumptions, the Hawkes\nmodel accounts for endogenous price impact and other key properties of the\nmarket (Jain et al. 2024a). Given the real-world impracticalities of the market\nmaker updating strategies for every event in the LOB, we formulate the\nhigh-frequency market making agent via an impulse control reinforcement\nlearning framework (Jain et al. 2025). The RL used in the simulation utilises\nProximal Policy Optimisation (PPO) and self-imitation learning. To replicate\nthe adverse selection phenomenon, we test the RL agent trading against a medium\nfrequency trader (MFT) executing a meta-order and demonstrate that, with\ntraining against the MFT meta-order execution agent, the RL market making agent\nlearns to capitalise on the price drift induced by the meta-order. Recent\nempirical studies have shown that medium-frequency traders are increasingly\nsubject to adverse selection by high-frequency trading agents. As\nhigh-frequency trading continues to proliferate across financial markets, the\nslippage costs incurred by medium-frequency traders are likely to increase over\ntime. However, we do not observe that increased profits for the market making\nRL agent necessarily cause significantly increased slippages for the MFT agent.\n</summary>\n    <author>\n      <name>Ali Raza Jafree</name>\n    </author>\n    <author>\n      <name>Konark Jain</name>\n    </author>\n    <author>\n      <name>Nick Firoozye</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.27334v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.27334v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"q-fin.TR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"q-fin.TR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.00126v1</id>\n    <updated>2025-10-31T10:01:01Z</updated>\n    <published>2025-10-31T10:01:01Z</published>\n    <title>Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking\n  and Meta-Features</title>\n    <summary>  Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,\n2022) have achieved strong average accuracy but remain unreliable in complex\nlong-tail driving scenarios. These limitations reveal the weakness of the\nprevailing \"one-model-fits-all\" paradigm, particularly in safety-critical urban\ncontexts where simpler physics-based models can occasionally outperform\nadvanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic\nmulti-expert gating framework that adaptively selects the most reliable\ntrajectory predictor among a physics-informed LSTM, a Transformer, and a\nfine-tuned GameFormer on a per-sample basis.\n  Our method leverages internal model signals (meta-features) such as stability\nand uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be\nsubstantially more informative than geometric scene descriptors. To the best of\nour knowledge, this is the first work to formulate trajectory expert selection\nas a pairwise-ranking problem over internal model signals (Burges et al.,\n2005), directly optimizing decision quality without requiring post-hoc\ncalibration.\n  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287\nsamples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error\n(FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835\nm), and realizes 57.8 percent of the oracle performance bound. In open-loop\nsimulations, after trajectory horizon alignment, the same configuration reduces\nFDE on left-turn scenarios by approximately 10 percent, demonstrating\nconsistent improvements across both offline validation and open-loop\nevaluation. These results indicate that adaptive hybrid systems enhance\ntrajectory reliability in safety-critical autonomous driving, providing a\npractical pathway beyond static single-model paradigms.\n</summary>\n    <author>\n      <name>Lu Bowen</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.00126v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.00126v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26905v1</id>\n    <updated>2025-10-30T18:11:32Z</updated>\n    <published>2025-10-30T18:11:32Z</published>\n    <title>Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS\n  Operations</title>\n    <summary>  Cyber-physical systems increasingly rely on Foundational Models such as Large\nLanguage Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy\nthrough enhanced perception, inference, and planning. However, these models\nalso introduce new types of errors, such as hallucinations,\novergeneralizations, and context misalignments, resulting in incorrect and\nflawed decisions. To address this, we introduce the concept of Cognition\nEnvelopes, designed to establish reasoning boundaries that constrain\nAI-generated decisions while complementing the use of meta-cognition and\ntraditional safety envelopes. As with safety envelopes, Cognition Envelopes\nrequire practical guidelines and systematic processes for their definition,\nvalidation, and assurance.\n</summary>\n    <author>\n      <name>Pedro Antonio Alarcón Granadeno</name>\n    </author>\n    <author>\n      <name>Arturo Miguel Bernal Russell</name>\n    </author>\n    <author>\n      <name>Sofia Nelson</name>\n    </author>\n    <author>\n      <name>Demetrius Hernandez</name>\n    </author>\n    <author>\n      <name>Maureen Petterson</name>\n    </author>\n    <author>\n      <name>Michael Murphy</name>\n    </author>\n    <author>\n      <name>Walter J. Scheirer</name>\n    </author>\n    <author>\n      <name>Jane Cleland-Huang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.5 pages, 9 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.26905v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26905v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26603v1</id>\n    <updated>2025-10-30T15:33:52Z</updated>\n    <published>2025-10-30T15:33:52Z</published>\n    <title>Agentic AI Home Energy Management System: A Large Language Model\n  Framework for Residential Load Scheduling</title>\n    <summary>  The electricity sector transition requires substantial increases in\nresidential demand response capacity, yet Home Energy Management Systems (HEMS)\nadoption remains limited by user interaction barriers requiring translation of\neveryday preferences into technical parameters. While large language models\nhave been applied to energy systems as code generators and parameter\nextractors, no existing implementation deploys LLMs as autonomous coordinators\nmanaging the complete workflow from natural language input to multi-appliance\nscheduling. This paper presents an agentic AI HEMS where LLMs autonomously\ncoordinate multi-appliance scheduling from natural language requests to device\ncontrol, achieving optimal scheduling without example demonstrations. A\nhierarchical architecture combining one orchestrator with three specialist\nagents uses the ReAct pattern for iterative reasoning, enabling dynamic\ncoordination without hardcoded workflows while integrating Google Calendar for\ncontext-aware deadline extraction. Evaluation across three open-source models\nusing real Austrian day-ahead electricity prices reveals substantial capability\ndifferences. Llama-3.3-70B successfully coordinates all appliances across all\nscenarios to match cost-optimal benchmarks computed via mixed-integer linear\nprogramming, while other models achieve perfect single-appliance performance\nbut struggle to coordinate all appliances simultaneously. Progressive prompt\nengineering experiments demonstrate that analytical query handling without\nexplicit guidance remains unreliable despite models' general reasoning\ncapabilities. We open-source the complete system including orchestration logic,\nagent prompts, tools, and web interfaces to enable reproducibility, extension,\nand future research.\n</summary>\n    <author>\n      <name>Reda El Makroum</name>\n    </author>\n    <author>\n      <name>Sebastian Zwickl-Bernhard</name>\n    </author>\n    <author>\n      <name>Lukas Kranzl</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">34 pages, 9 figures. Code available at\n  https://github.com/RedaElMakroum/agentic-ai-hems</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.26603v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26603v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26389v1</id>\n    <updated>2025-10-30T11:32:45Z</updated>\n    <published>2025-10-30T11:32:45Z</published>\n    <title>Adaptive Context Length Optimization with Low-Frequency Truncation for\n  Multi-Agent Reinforcement Learning</title>\n    <summary>  Recently, deep multi-agent reinforcement learning (MARL) has demonstrated\npromising performance for solving challenging tasks, such as long-term\ndependencies and non-Markovian environments. Its success is partly attributed\nto conditioning policies on large fixed context length. However, such large\nfixed context lengths may lead to limited exploration efficiency and redundant\ninformation. In this paper, we propose a novel MARL framework to obtain\nadaptive and effective contextual information. Specifically, we design a\ncentral agent that dynamically optimizes context length via temporal gradient\nanalysis, enhancing exploration to facilitate convergence to global optima in\nMARL. Furthermore, to enhance the adaptive optimization capability of the\ncontext length, we present an efficient input representation for the central\nagent, which effectively filters redundant information. By leveraging a\nFourier-based low-frequency truncation method, we extract global temporal\ntrends across decentralized agents, providing an effective and efficient\nrepresentation of the MARL environment. Extensive experiments demonstrate that\nthe proposed method achieves state-of-the-art (SOTA) performance on long-term\ndependency tasks, including PettingZoo, MiniGrid, Google Research Football\n(GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).\n</summary>\n    <author>\n      <name>Wenchang Duan</name>\n    </author>\n    <author>\n      <name>Yaoliang Yu</name>\n    </author>\n    <author>\n      <name>Jiwan He</name>\n    </author>\n    <author>\n      <name>Yi Shi</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.26389v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26389v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26298v1</id>\n    <updated>2025-10-30T09:35:51Z</updated>\n    <published>2025-10-30T09:35:51Z</published>\n    <title>Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in\n  Web Games</title>\n    <summary>  OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,\nenabling the model to analyze webpages, process user intents, and execute\ncursor and keyboard inputs directly within the browser. While its capacity for\ninformation retrieval tasks has been demonstrated, its performance in dynamic,\ninteractive environments remains less explored. In this study, we conduct an\nearly evaluation of Atlas's web interaction capabilities using browser-based\ngames as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,\nand Stein.world. We employ in-game performance scores as quantitative metrics\nto assess performance across different task types. Our results show that Atlas\nperforms strongly in logical reasoning tasks like Sudoku, completing puzzles\nsignificantly faster than human baselines, but struggles substantially in\nreal-time games requiring precise timing and motor control, often failing to\nprogress beyond initial obstacles. These findings suggest that while Atlas\ndemonstrates capable analytical processing, there remain notable limitations in\ndynamic web environments requiring real-time interaction. The website of our\nproject can be found at https://atlas-game-eval.github.io.\n</summary>\n    <author>\n      <name>Jingran Zhang</name>\n    </author>\n    <author>\n      <name>Ning Li</name>\n    </author>\n    <author>\n      <name>Justin Cui</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.26298v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26298v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26167v1</id>\n    <updated>2025-10-30T06:08:27Z</updated>\n    <published>2025-10-30T06:08:27Z</published>\n    <title>One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient\n  Reasoning</title>\n    <summary>  Reward models (RMs) play a critical role in aligning large language models\n(LLMs) with human preferences. Yet in the domain of tool learning, the lack of\nRMs specifically designed for function-calling tasks has limited progress\ntoward more capable agentic AI. We introduce ToolRM, a family of lightweight\ngenerative RMs tailored for general tool-use scenarios. To build these models,\nwe propose a novel pipeline that constructs pairwise preference data using\nrule-based scoring and multidimensional sampling. This yields\nToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique\ntasks that supports reinforcement learning with verifiable feedback. To\nevaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on\nthe agentic evaluation suite BFCL. Trained on our constructed data, models from\nthe Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially\noutperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward\njudgments. Beyond training objectives, ToolRM generalizes to broader critique\ntasks, including Best-of-N sampling and self-correction. Experiments on\nACEBench highlight its effectiveness and efficiency, enabling inference-time\nscaling and reducing output token usage by over 66%. We release data and model\ncheckpoints to facilitate future research.\n</summary>\n    <author>\n      <name>Renhao Li</name>\n    </author>\n    <author>\n      <name>Jianhong Tu</name>\n    </author>\n    <author>\n      <name>Yang Su</name>\n    </author>\n    <author>\n      <name>Hamid Alinejad-Rokny</name>\n    </author>\n    <author>\n      <name>Derek F. Wong</name>\n    </author>\n    <author>\n      <name>Junyang Lin</name>\n    </author>\n    <author>\n      <name>Min Yang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.26167v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26167v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.26068v1</id>\n    <updated>2025-10-30T01:53:32Z</updated>\n    <published>2025-10-30T01:53:32Z</published>\n    <title>Learning Geometry: A Framework for Building Adaptive Manifold Models\n  through Metric Optimization</title>\n    <summary>  This paper proposes a novel paradigm for machine learning that moves beyond\ntraditional parameter optimization. Unlike conventional approaches that search\nfor optimal parameters within a fixed geometric space, our core idea is to\ntreat the model itself as a malleable geometric entity. Specifically, we\noptimize the metric tensor field on a manifold with a predefined topology,\nthereby dynamically shaping the geometric structure of the model space. To\nachieve this, we construct a variational framework whose loss function\ncarefully balances data fidelity against the intrinsic geometric complexity of\nthe manifold. The former ensures the model effectively explains observed data,\nwhile the latter acts as a regularizer, penalizing overly curved or irregular\ngeometries to encourage simpler models and prevent overfitting. To address the\ncomputational challenges of this infinite-dimensional optimization problem, we\nintroduce a practical method based on discrete differential geometry: the\ncontinuous manifold is discretized into a triangular mesh, and the metric\ntensor is parameterized by edge lengths, enabling efficient optimization using\nautomatic differentiation tools. Theoretical analysis reveals a profound\nanalogy between our framework and the Einstein-Hilbert action in general\nrelativity, providing an elegant physical interpretation for the concept of\n\"data-driven geometry\". We further argue that even with fixed topology, metric\noptimization offers significantly greater expressive power than models with\nfixed geometry. This work lays a solid foundation for constructing fully\ndynamic \"meta-learners\" capable of autonomously evolving their geometry and\ntopology, and it points to broad application prospects in areas such as\nscientific model discovery and robust representation learning.\n</summary>\n    <author>\n      <name>Di Zhang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.26068v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.26068v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.DG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.ST\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.TH\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"68T05, 53B21, 65D18, 62B11\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.2.6; I.5.1; G.1.8; G.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25726v1</id>\n    <updated>2025-10-29T17:32:49Z</updated>\n    <published>2025-10-29T17:32:49Z</published>\n    <title>The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,\n  and Long-Horizon Task Execution</title>\n    <summary>  Real-world language agents must handle complex, multi-step workflows across\ndiverse Apps. For instance, an agent may manage emails by coordinating with\ncalendars and file systems, or monitor a production database to detect\nanomalies and generate reports following an operating manual. However, existing\nlanguage agent benchmarks often focus on narrow domains or simplified tasks\nthat lack the diversity, realism, and long-horizon complexity required to\nevaluate agents' real-world performance. To address this gap, we introduce the\nTool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering\ndiverse Apps and tools, realistic environment setup, and reliable\nexecution-based evaluation. Toolathlon spans 32 software applications and 604\ntools, ranging from everyday platforms such as Google Calendar and Notion to\nprofessional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools\nare based on a high-quality set of Model Context Protocol (MCP) servers that we\nmay have revised or implemented ourselves. Unlike prior works, which primarily\nensure functional realism but offer limited environment state diversity, we\nprovide realistic initial environment states from real software, such as Canvas\ncourses with dozens of students or real financial spreadsheets. This benchmark\nincludes 108 manually sourced or crafted tasks in total, requiring interacting\nwith multiple Apps over around 20 turns on average to complete. Each task is\nstrictly verifiable through dedicated evaluation scripts. Comprehensive\nevaluation of SOTA models highlights their significant shortcomings: the\nbest-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate\nwith 20.2 tool calling turns on average, while the top open-weights model\nDeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development\nof more capable language agents for real-world, long-horizon task execution.\n</summary>\n    <author>\n      <name>Junlong Li</name>\n    </author>\n    <author>\n      <name>Wenshuo Zhao</name>\n    </author>\n    <author>\n      <name>Jian Zhao</name>\n    </author>\n    <author>\n      <name>Weihao Zeng</name>\n    </author>\n    <author>\n      <name>Haoze Wu</name>\n    </author>\n    <author>\n      <name>Xiaochen Wang</name>\n    </author>\n    <author>\n      <name>Rui Ge</name>\n    </author>\n    <author>\n      <name>Yuxuan Cao</name>\n    </author>\n    <author>\n      <name>Yuzhen Huang</name>\n    </author>\n    <author>\n      <name>Wei Liu</name>\n    </author>\n    <author>\n      <name>Junteng Liu</name>\n    </author>\n    <author>\n      <name>Zhaochen Su</name>\n    </author>\n    <author>\n      <name>Yiyang Guo</name>\n    </author>\n    <author>\n      <name>Fan Zhou</name>\n    </author>\n    <author>\n      <name>Lueyang Zhang</name>\n    </author>\n    <author>\n      <name>Juan Michelini</name>\n    </author>\n    <author>\n      <name>Xingyao Wang</name>\n    </author>\n    <author>\n      <name>Xiang Yue</name>\n    </author>\n    <author>\n      <name>Shuyan Zhou</name>\n    </author>\n    <author>\n      <name>Graham Neubig</name>\n    </author>\n    <author>\n      <name>Junxian He</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Website: https://toolathlon.xyz/</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.25726v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.25726v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25588v1</id>\n    <updated>2025-10-29T14:54:22Z</updated>\n    <published>2025-10-29T14:54:22Z</published>\n    <title>Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM\n  Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</title>\n    <summary>  The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses.\n</summary>\n    <author>\n      <name>Eranga Bandara</name>\n    </author>\n    <author>\n      <name>Ross Gore</name>\n    </author>\n    <author>\n      <name>Atmaram Yarlagadda</name>\n    </author>\n    <author>\n      <name>Anita H. Clayton</name>\n    </author>\n    <author>\n      <name>Preston Samuel</name>\n    </author>\n    <author>\n      <name>Christopher K. Rhea</name>\n    </author>\n    <author>\n      <name>Sachin Shetty</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.25588v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.25588v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.25529v1</id>\n    <updated>2025-10-29T13:53:52Z</updated>\n    <published>2025-10-29T13:53:52Z</published>\n    <title>Off-policy Reinforcement Learning with Model-based Exploration\n  Augmentation</title>\n    <summary>  Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks.\n</summary>\n    <author>\n      <name>Likun Wang</name>\n    </author>\n    <author>\n      <name>Xiangteng Zhang</name>\n    </author>\n    <author>\n      <name>Yinuo Wang</name>\n    </author>\n    <author>\n      <name>Guojian Zhan</name>\n    </author>\n    <author>\n      <name>Wenxuan Wang</name>\n    </author>\n    <author>\n      <name>Haoyu Gao</name>\n    </author>\n    <author>\n      <name>Jingliang Duan</name>\n    </author>\n    <author>\n      <name>Shengbo Eben Li</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.25529v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.25529v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.24699v1</id>\n    <updated>2025-10-28T17:51:50Z</updated>\n    <published>2025-10-28T17:51:50Z</published>\n    <title>AgentFold: Long-Horizon Web Agents with Proactive Context Management</title>\n    <summary>  LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.\n</summary>\n    <author>\n      <name>Rui Ye</name>\n    </author>\n    <author>\n      <name>Zhongwang Zhang</name>\n    </author>\n    <author>\n      <name>Kuan Li</name>\n    </author>\n    <author>\n      <name>Huifeng Yin</name>\n    </author>\n    <author>\n      <name>Zhengwei Tao</name>\n    </author>\n    <author>\n      <name>Yida Zhao</name>\n    </author>\n    <author>\n      <name>Liangcai Su</name>\n    </author>\n    <author>\n      <name>Liwen Zhang</name>\n    </author>\n    <author>\n      <name>Zile Qiao</name>\n    </author>\n    <author>\n      <name>Xinyu Wang</name>\n    </author>\n    <author>\n      <name>Pengjun Xie</name>\n    </author>\n    <author>\n      <name>Fei Huang</name>\n    </author>\n    <author>\n      <name>Siheng Chen</name>\n    </author>\n    <author>\n      <name>Jingren Zhou</name>\n    </author>\n    <author>\n      <name>Yong Jiang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">26 pages, 9 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.24699v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.24699v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.24645v1</id>\n    <updated>2025-10-28T17:15:26Z</updated>\n    <published>2025-10-28T17:15:26Z</published>\n    <title>FunReason-MT Technical Report: Overcoming the Complexity Barrier in\n  Multi-Turn Function Calling</title>\n    <summary>  Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.\n</summary>\n    <author>\n      <name>Zengzhuang Xu</name>\n    </author>\n    <author>\n      <name>Bingguang Hao</name>\n    </author>\n    <author>\n      <name>Zechuan Wang</name>\n    </author>\n    <author>\n      <name>Yuntao Wen</name>\n    </author>\n    <author>\n      <name>Maolin Wang</name>\n    </author>\n    <author>\n      <name>Yang Liu</name>\n    </author>\n    <author>\n      <name>Long Chen</name>\n    </author>\n    <author>\n      <name>Dong Wang</name>\n    </author>\n    <author>\n      <name>Yicheng Chen</name>\n    </author>\n    <author>\n      <name>Cunyin Peng</name>\n    </author>\n    <author>\n      <name>Chenyi Zhuang</name>\n    </author>\n    <author>\n      <name>Jinjie Gu</name>\n    </author>\n    <author>\n      <name>Leilei Gan</name>\n    </author>\n    <author>\n      <name>Xiangyu Zhao</name>\n    </author>\n    <author>\n      <name>Shi Gu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.24645v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.24645v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.23870v1</id>\n    <updated>2025-10-27T21:22:41Z</updated>\n    <published>2025-10-27T21:22:41Z</published>\n    <title>OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL\n  Reasoning</title>\n    <summary>  We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge\n2025, a bilingual benchmark requiring complex reasoning such as arithmetic,\ncommonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding\nthe second-best system by more than 6% in execution accuracy (EX), with 55.0%\nin English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).\nOur system follows an agentic framework with two components: Planner agent that\ngenerates stepwise natural language plans, and SQL agent that converts these\nplans into executable SQL. Since SQL agent reliably adheres to the plan, our\nrefinements focus on the planner. Unlike prior methods that rely on multiple\nsub-agents for planning and suffer from orchestration overhead, we introduce a\nfeedback-guided meta-prompting strategy to refine a single planner. Failure\ncases from a held-out set are clustered with human input, and an LLM distills\nthem into corrective guidelines that are integrated into the planner's system\nprompt, improving generalization without added complexity. For the multilingual\nscenario, to address transliteration and entity mismatch issues, we incorporate\nentity-linking guidelines that generate alternative surface forms for entities\nand explicitly include them in the plan. Finally, we enhance reliability\nthrough plan diversification: multiple candidate plans are generated for each\nquery, with the SQL agent producing a query for each plan, and final output\nselected via majority voting over their executions.\n</summary>\n    <author>\n      <name>Marianne Menglin Liu</name>\n    </author>\n    <author>\n      <name>Sai Ashish Somayajula</name>\n    </author>\n    <author>\n      <name>Syed Fahad Allam Shah</name>\n    </author>\n    <author>\n      <name>Sujith Ravi</name>\n    </author>\n    <author>\n      <name>Dan Roth</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.23870v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.23870v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.22977v1</id>\n    <updated>2025-10-27T03:58:29Z</updated>\n    <published>2025-10-27T03:58:29Z</published>\n    <title>The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool\n  Hallucination</title>\n    <summary>  Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key\nstrategy for building Agents that \"think then act.\" However, recent\nobservations, like OpenAI's o3, suggest a paradox: stronger reasoning often\ncoincides with increased hallucination, yet no prior work has systematically\nexamined whether reasoning enhancement itself causes tool hallucination. To\naddress this gap, we pose the central question: Does strengthening reasoning\nincrease tool hallucination? To answer this, we introduce SimpleToolHalluBench,\na diagnostic benchmark measuring tool hallucination in two failure modes: (i)\nno tool available, and (ii) only distractor tools available. Through controlled\nexperiments, we establish three key findings. First, we demonstrate a causal\nrelationship: progressively enhancing reasoning through RL increases tool\nhallucination proportionally with task performance gains. Second, this effect\ntranscends overfitting - training on non-tool tasks (e.g., mathematics) still\namplifies subsequent tool hallucination. Third, the effect is method-agnostic,\nappearing when reasoning is instilled via supervised fine-tuning and when it is\nmerely elicited at inference by switching from direct answers to step-by-step\nthinking. We also evaluate mitigation strategies including Prompt Engineering\nand Direct Preference Optimization (DPO), revealing a fundamental\nreliability-capability trade-off: reducing hallucination consistently degrades\nutility. Mechanistically, Reasoning RL disproportionately collapses\ntool-reliability-related representations, and hallucinations surface as\namplified divergences concentrated in late-layer residual streams. These\nfindings reveal that current reasoning enhancement methods inherently amplify\ntool hallucination, highlighting the need for new training objectives that\njointly optimize for capability and reliability.\n</summary>\n    <author>\n      <name>Chenlong Yin</name>\n    </author>\n    <author>\n      <name>Zeyang Sha</name>\n    </author>\n    <author>\n      <name>Shiwen Cui</name>\n    </author>\n    <author>\n      <name>Changhua Meng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">18 pages, 5 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.22977v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.22977v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.22940v4</id>\n    <updated>2025-11-03T23:55:55Z</updated>\n    <published>2025-10-27T02:51:51Z</published>\n    <title>Generating Auxiliary Tasks with Reinforcement Learning</title>\n    <summary>  Auxiliary Learning (AL) is a form of multi-task learning in which a model\ntrains on auxiliary tasks to boost performance on a primary objective. While AL\nhas improved generalization across domains such as navigation, image\nclassification, and NLP, it often depends on human-labeled auxiliary tasks that\nare costly to design and require domain expertise. Meta-learning approaches\nmitigate this by learning to generate auxiliary tasks, but typically rely on\ngradient based bi-level optimization, adding substantial computational and\nimplementation overhead. We propose RL-AUX, a reinforcement-learning (RL)\nframework that dynamically creates auxiliary tasks by assigning auxiliary\nlabels to each training example, rewarding the agent whenever its selections\nimprove the performance on the primary task. We also explore learning\nper-example weights for the auxiliary loss. On CIFAR-100 grouped into 20\nsuperclasses, our RL method outperforms human-labeled auxiliary tasks and\nmatches the performance of a prominent bi-level optimization baseline. We\npresent similarly strong results on other classification datasets. These\nresults suggest RL is a viable path to generating effective auxiliary tasks.\n</summary>\n    <author>\n      <name>Judah Goldfeder</name>\n    </author>\n    <author>\n      <name>Matthew So</name>\n    </author>\n    <author>\n      <name>Hod Lipson</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.22940v4\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.22940v4\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.22781v2</id>\n    <updated>2025-11-05T05:01:21Z</updated>\n    <published>2025-10-26T18:13:04Z</published>\n    <title>Agentic Meta-Orchestrator for Multi-task Copilots</title>\n    <summary>  Microsoft Copilot suites serve as the universal entry point for various\nagents skilled in handling important tasks, ranging from assisting a customer\nwith product purchases to detecting vulnerabilities in corporate programming\ncode. Each agent can be powered by language models, software engineering\noperations, such as database retrieval, and internal \\&amp; external knowledge. The\nrepertoire of a copilot can expand dynamically with new agents. This requires a\nrobust orchestrator that can distribute tasks from user prompts to the right\nagents. In this work, we propose an Agentic Meta-orchestrator (AMO) for\nhandling multiple tasks and scalable agents in copilot services, which can\nprovide both natural language and action responses. We will also demonstrate\nthe planning that leverages meta-learning, i.e., a trained decision tree model\nfor deciding the best inference strategy among various agents/models. We\nshowcase the effectiveness of our AMO through two production use cases:\nMicrosoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365\nE-Commerce Copilot advertises Microsoft products to external customers to\npromote sales success. The M365 E-Commerce Copilot provides up-to-date product\ninformation and connects to multiple agents, such as relational databases and\nhuman customer support. The code compliance copilot scans the internal DevOps\ncode to detect known and new compliance issues in pull requests (PR).\n</summary>\n    <author>\n      <name>Xiaofeng Zhu</name>\n    </author>\n    <author>\n      <name>Yunshen Zhou</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICDM RARA workshop 2025</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2510.22781v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.22781v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.22654v1</id>\n    <updated>2025-10-26T12:36:17Z</updated>\n    <published>2025-10-26T12:36:17Z</published>\n    <title>UCB-type Algorithm for Budget-Constrained Expert Learning</title>\n    <summary>  In many modern applications, a system must dynamically choose between several\nadaptive learning algorithms that are trained online. Examples include model\nselection in streaming environments, switching between trading strategies in\nfinance, and orchestrating multiple contextual bandit or reinforcement learning\nagents. At each round, a learner must select one predictor among $K$ adaptive\nexperts to make a prediction, while being able to update at most $M \\le K$ of\nthem under a fixed training budget.\n  We address this problem in the \\emph{stochastic setting} and introduce\n\\algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that\nprovides \\emph{anytime regret guarantees}. Its confidence intervals are built\ndirectly from realized losses, require no additional optimization, and\nseamlessly reflect the convergence properties of the underlying experts. If\neach expert achieves internal regret $\\tilde O(T^\\alpha)$, then \\algname{M-LCB}\nensures overall regret bounded by $\\tilde O\\!\\Bigl(\\sqrt{\\tfrac{KT}{M}} \\;+\\;\n(K/M)^{1-\\alpha}\\,T^\\alpha\\Bigr)$.\n  To our knowledge, this is the first result establishing regret guarantees\nwhen multiple adaptive experts are trained simultaneously under per-round\nbudget constraints. We illustrate the framework with two representative cases:\n(i) parametric models trained online with stochastic losses, and (ii) experts\nthat are themselves multi-armed bandit algorithms. These examples highlight how\n\\algname{M-LCB} extends the classical bandit paradigm to the more realistic\nscenario of coordinating stateful, self-learning experts under limited\nresources.\n</summary>\n    <author>\n      <name>Ilgam Latypov</name>\n    </author>\n    <author>\n      <name>Alexandra Suvorikova</name>\n    </author>\n    <author>\n      <name>Alexey Kroshnin</name>\n    </author>\n    <author>\n      <name>Alexander Gasnikov</name>\n    </author>\n    <author>\n      <name>Yuriy Dorn</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.22654v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.22654v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.22039v1</id>\n    <updated>2025-10-24T21:45:56Z</updated>\n    <published>2025-10-24T21:45:56Z</published>\n    <title>Predictive Coding Enhances Meta-RL To Achieve Interpretable\n  Bayes-Optimal Belief Representation Under Partial Observability</title>\n    <summary>  Learning a compact representation of history is critical for planning and\ngeneralization in partially observable environments. While meta-reinforcement\nlearning (RL) agents can attain near Bayes-optimal policies, they often fail to\nlearn the compact, interpretable Bayes-optimal belief states. This\nrepresentational inefficiency potentially limits the agent's adaptability and\ngeneralization capacity. Inspired by predictive coding in neuroscience--which\nsuggests that the brain predicts sensory inputs as a neural implementation of\nBayesian inference--and by auxiliary predictive objectives in deep RL, we\ninvestigate whether integrating self-supervised predictive coding modules into\nmeta-RL can facilitate learning of Bayes-optimal representations. Through state\nmachine simulation, we show that meta-RL with predictive modules consistently\ngenerates more interpretable representations that better approximate\nBayes-optimal belief states compared to conventional meta-RL across a wide\nvariety of tasks, even when both achieve optimal policies. In challenging tasks\nrequiring active information seeking, only meta-RL with predictive modules\nsuccessfully learns optimal representations and policies, whereas conventional\nmeta-RL struggles with inadequate representation learning. Finally, we\ndemonstrate that better representation learning leads to improved\ngeneralization. Our results strongly suggest the role of predictive learning as\na guiding principle for effective representation learning in agents navigating\npartial observability.\n</summary>\n    <author>\n      <name>Po-Chen Kuo</name>\n    </author>\n    <author>\n      <name>Han Hou</name>\n    </author>\n    <author>\n      <name>Will Dabney</name>\n    </author>\n    <author>\n      <name>Edgar Y. Walker</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted to Annual Conference on Neural Information Processing\n  Systems (NeurIPS) 2025</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.22039v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.22039v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"q-bio.NC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.21557v1</id>\n    <updated>2025-10-24T15:14:14Z</updated>\n    <published>2025-10-24T15:14:14Z</published>\n    <title>Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware\n  Meta-Verification and Trustworthy Reasoning with Structured Facts</title>\n    <summary>  Long-horizon reasoning in LLM-based agents often fails not from generative\nweakness but from insufficient verification of intermediate reasoning. Co-Sight\naddresses this challenge by turning reasoning into a falsifiable and auditable\nprocess through two complementary mechanisms: Conflict-Aware Meta-Verification\n(CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV\nreformulates verification as conflict identification and targeted\nfalsification, allocating computation only to disagreement hotspots among\nexpert agents rather than to full reasoning chains. This bounds verification\ncost to the number of inconsistencies and improves efficiency and reliability.\nTRSF continuously organizes, validates, and synchronizes evidence across agents\nthrough a structured facts module. By maintaining verified, traceable, and\nauditable knowledge, it ensures that all reasoning is grounded in consistent,\nsource-verified information and supports transparent verification throughout\nthe reasoning process. Together, TRSF and CAMV form a closed verification loop,\nwhere TRSF supplies structured facts and CAMV selectively falsifies or\nreinforces them, yielding transparent and trustworthy reasoning. Empirically,\nCo-Sight achieves state-of-the-art accuracy on GAIA (84.4%) and Humanity's Last\nExam (35.5%), and strong results on Chinese-SimpleQA (93.8%). Ablation studies\nconfirm that the synergy between structured factual grounding and\nconflict-aware verification drives these improvements. Co-Sight thus offers a\nscalable paradigm for reliable long-horizon reasoning in LLM-based agents. Code\nis available at\nhttps://github.com/ZTE-AICloud/Co-Sight/tree/cosight2.0_benchmarks.\n</summary>\n    <author>\n      <name>Hongwei Zhang</name>\n    </author>\n    <author>\n      <name>Ji Lu</name>\n    </author>\n    <author>\n      <name>Shiqing Jiang</name>\n    </author>\n    <author>\n      <name>Chenxiang Zhu</name>\n    </author>\n    <author>\n      <name>Li Xie</name>\n    </author>\n    <author>\n      <name>Chen Zhong</name>\n    </author>\n    <author>\n      <name>Haoran Chen</name>\n    </author>\n    <author>\n      <name>Yurui Zhu</name>\n    </author>\n    <author>\n      <name>Yongsheng Du</name>\n    </author>\n    <author>\n      <name>Yanqin Gao</name>\n    </author>\n    <author>\n      <name>Lingjun Huang</name>\n    </author>\n    <author>\n      <name>Baoli Wang</name>\n    </author>\n    <author>\n      <name>Fang Tan</name>\n    </author>\n    <author>\n      <name>Peng Zou</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.21557v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.21557v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.21427v1</id>\n    <updated>2025-10-24T13:06:43Z</updated>\n    <published>2025-10-24T13:06:43Z</published>\n    <title>Causality Meets Locality: Provably Generalizable and Scalable Policy\n  Learning for Networked Systems</title>\n    <summary>  Large-scale networked systems, such as traffic, power, and wireless grids,\nchallenge reinforcement-learning agents with both scale and environment shifts.\nTo address these challenges, we propose GSAC (Generalizable and Scalable\nActor-Critic), a framework that couples causal representation learning with\nmeta actor-critic learning to achieve both scalability and domain\ngeneralization. Each agent first learns a sparse local causal mask that\nprovably identifies the minimal neighborhood variables influencing its\ndynamics, yielding exponentially tight approximately compact representations\n(ACRs) of state and domain factors. These ACRs bound the error of truncating\nvalue functions to $\\kappa$-hop neighborhoods, enabling efficient learning on\ngraphs. A meta actor-critic then trains a shared policy across multiple source\ndomains while conditioning on the compact domain factors; at test time, a few\ntrajectories suffice to estimate the new domain factor and deploy the adapted\npolicy. We establish finite-sample guarantees on causal recovery, actor-critic\nconvergence, and adaptation gap, and show that GSAC adapts rapidly and\nsignificantly outperforms learning-from-scratch and conventional adaptation\nbaselines.\n</summary>\n    <author>\n      <name>Hao Liang</name>\n    </author>\n    <author>\n      <name>Shuqing Shi</name>\n    </author>\n    <author>\n      <name>Yudi Zhang</name>\n    </author>\n    <author>\n      <name>Biwei Huang</name>\n    </author>\n    <author>\n      <name>Yali Du</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NeurIPS 2025 (Spotlight)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.21427v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.21427v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2511.01884v2</id>\n    <updated>2025-11-05T02:10:35Z</updated>\n    <published>2025-10-23T22:52:00Z</published>\n    <title>CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel\n  Optimization</title>\n    <summary>  Developing efficient CUDA kernels is increasingly critical for AI\napplications such as large-scale LLM training. However, manual kernel design is\nboth costly and time-consuming, motivating automatic approaches that leverage\nLLMs for code generation. Existing methods for automatic kernel generation,\nhowever, often produce low-efficiency kernels, incur high computational\noverhead, and fail to generalize across settings. In this work, we propose\nCudaForge, a training-free multi-agent workflow for CUDA kernel generation and\noptimization. Our workflow is inspired by the iterative workflow of human\nexperts, which contains steps such as developing initial kernels, testing\ncorrectness, analyzing hardware feedback, and iterative improvement. More\nspecifically, CudaForge employs two LLM agents: a Coder and a Judge, that\niteratively generate, correct, and optimize CUDA kernels, while integrating\nhardware feedback such as Nsight Compute (NCU) metrics. In extensive\nevaluations, we show that CudaForge, by leveraging base models like OpenAI-o3,\nachieves 97.6\\% correctness of generated kernels and an average 1.68$\\times$\nspeedup over PyTorch baselines, substantially surpassing state-of-the-art\nmodels including OpenAI-o3 and Kevin on KernelBench.Beyond accuracy and speed,\nCudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090,\n3090) and base models (OpenAI-o3, GPT-5, gpt-oss-120B, Claude-Sonnet-4,\nQwQ-32B), while maintaining high efficiency. In particular, generating an\noptimized kernel takes about 26.5 minutes on one RTX6000 and incurs about \\$\n0.3 API cost, which is significantly cheaper than existing agentic work that\ncosts 6 H100 hours and \\$ 5 API cost per kernel. Our results highlight that\nmulti-agent, training-free workflows can enable cost-effective, generalizable,\nand high-performance CUDA kernel optimization. Code available at\nhttps://github.com/OptimAI-Lab/CudaForge\n</summary>\n    <author>\n      <name>Zijian Zhang</name>\n    </author>\n    <author>\n      <name>Rong Wang</name>\n    </author>\n    <author>\n      <name>Shiyang Li</name>\n    </author>\n    <author>\n      <name>Yuebo Luo</name>\n    </author>\n    <author>\n      <name>Mingyi Hong</name>\n    </author>\n    <author>\n      <name>Caiwen Ding</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2511.01884v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2511.01884v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.20579v1</id>\n    <updated>2025-10-23T14:05:56Z</updated>\n    <published>2025-10-23T14:05:56Z</published>\n    <title>Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal\n  Evidence</title>\n    <summary>  Most video reasoning models only generate textual reasoning traces without\nindicating when and where key evidence appears. Recent models such as OpenAI-o3\nhave sparked wide interest in evidence-centered reasoning for images, yet\nextending this ability to videos is more challenging, as it requires joint\ntemporal tracking and spatial localization across dynamic scenes. We introduce\nOpen-o3 Video, a non-agent framework that integrates explicit spatio-temporal\nevidence into video reasoning, and carefully collect training data and design\ntraining strategies to address the aforementioned challenges. The model\nhighlights key timestamps, objects, and bounding boxes alongside its answers,\nallowing reasoning to be grounded in concrete visual observations. To enable\nthis functionality, we first curate and build two high-quality datasets,\nSTGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed\ntemporal and spatial annotations, since most existing datasets offer either\ntemporal spans for videos or spatial boxes on images, lacking unified\nspatio-temporal supervision and reasoning traces. Then, we adopt a cold-start\nreinforcement learning strategy with multiple specially designed rewards that\njointly encourage answer accuracy, temporal alignment, and spatial precision.\nOn V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,\nraising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent\nimprovements are also observed on a broad range of video understanding\nbenchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond\naccuracy, the reasoning traces produced by Open-o3 Video also provide valuable\nsignals for test-time scaling, enabling confidence-aware verification and\nimproving answer reliability.\n</summary>\n    <author>\n      <name>Jiahao Meng</name>\n    </author>\n    <author>\n      <name>Xiangtai Li</name>\n    </author>\n    <author>\n      <name>Haochen Wang</name>\n    </author>\n    <author>\n      <name>Yue Tan</name>\n    </author>\n    <author>\n      <name>Tao Zhang</name>\n    </author>\n    <author>\n      <name>Lingdong Kong</name>\n    </author>\n    <author>\n      <name>Yunhai Tong</name>\n    </author>\n    <author>\n      <name>Anran Wang</name>\n    </author>\n    <author>\n      <name>Zhiyang Teng</name>\n    </author>\n    <author>\n      <name>Yujing Wang</name>\n    </author>\n    <author>\n      <name>Zhuochen Wang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.20579v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.20579v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.20205v1</id>\n    <updated>2025-10-23T04:45:05Z</updated>\n    <published>2025-10-23T04:45:05Z</published>\n    <title>Merge and Conquer: Evolutionarily Optimizing AI for 2048</title>\n    <summary>  Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.\n</summary>\n    <author>\n      <name>Maggie Bai</name>\n    </author>\n    <author>\n      <name>Ava Kim Cohen</name>\n    </author>\n    <author>\n      <name>Eleanor Koss</name>\n    </author>\n    <author>\n      <name>Charlie Lichtenbaum</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 5 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.20205v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.20205v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.20176v2</id>\n    <updated>2025-10-24T15:36:31Z</updated>\n    <published>2025-10-23T03:51:17Z</published>\n    <title>Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table\n  Understanding</title>\n    <summary>  Understanding and reasoning over tables is a critical capability for many\nreal-world applications. Large language models (LLMs) have shown promise on\nthis task, but current approaches remain limited. Fine-tuning based methods\nstrengthen language reasoning; yet they are prone to arithmetic errors and\nhallucination. In contrast, tool-based methods enable precise table\nmanipulation but rely on rigid schemas and lack semantic understanding. These\ncomplementary drawbacks highlight the need for approaches that integrate robust\nreasoning with reliable table processing. In this work, we propose\nMixture-of-Minds, a multi-agent framework that decomposes table reasoning into\nthree specialized roles: planning, coding, and answering. This design enables\neach agent to focus on a specific aspect of the task while leveraging code\nexecution for precise table manipulation. Building on this workflow, we\nintroduce a self-improvement training framework that employs Monte Carlo Tree\nSearch (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents\nwith reinforcement learning (RL). Extensive experiments show that\nMixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and\nsurpassing OpenAI-o4-mini-high. These results demonstrate the promise of\ncombining structured multi-agent workflows with RL to advance table\nunderstanding.\n</summary>\n    <author>\n      <name>Yuhang Zhou</name>\n    </author>\n    <author>\n      <name>Mingrui Zhang</name>\n    </author>\n    <author>\n      <name>Ke Li</name>\n    </author>\n    <author>\n      <name>Mingyi Wang</name>\n    </author>\n    <author>\n      <name>Qiao Liu</name>\n    </author>\n    <author>\n      <name>Qifei Wang</name>\n    </author>\n    <author>\n      <name>Jiayi Liu</name>\n    </author>\n    <author>\n      <name>Fei Liu</name>\n    </author>\n    <author>\n      <name>Serena Li</name>\n    </author>\n    <author>\n      <name>Weiwei Li</name>\n    </author>\n    <author>\n      <name>Mingze Gao</name>\n    </author>\n    <author>\n      <name>Abhishek Kumar</name>\n    </author>\n    <author>\n      <name>Xiangjun Fan</name>\n    </author>\n    <author>\n      <name>Zhuokai Zhao</name>\n    </author>\n    <author>\n      <name>Lizhu Zhang</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">18 pages, 4 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.20176v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.20176v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.19897v1</id>\n    <updated>2025-10-22T17:58:03Z</updated>\n    <published>2025-10-22T17:58:03Z</published>\n    <title>Learning from Supervision with Semantic and Episodic Memory: A\n  Reflective Approach to Agent Adaptation</title>\n    <summary>  We investigate how agents built on pretrained large language models can learn\ntarget classification functions from labeled examples without parameter\nupdates. While conventional approaches like fine-tuning are often costly,\ninflexible, and opaque, we propose a memory-augmented framework that leverages\nboth labeled data and LLM-generated critiques. Our framework uses episodic\nmemory to store instance-level critiques-capturing specific past\nexperiences-and semantic memory to distill these into reusable, task-level\nguidance. Across a diverse set of tasks, incorporating critiques yields up to a\n24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines\nthat rely only on labels. Through extensive empirical evaluation, we uncover\ndistinct behavioral differences between OpenAI and opensource models,\nparticularly in how they handle fact-oriented versus preference-based data. To\ninterpret how models respond to different representations of supervision\nencoded in memory, we introduce a novel metric, suggestibility. This helps\nexplain observed behaviors and illuminates how model characteristics and memory\nstrategies jointly shape learning dynamics. Our findings highlight the promise\nof memory-driven, reflective learning for building more adaptive and\ninterpretable LLM agents.\n</summary>\n    <author>\n      <name>Jackson Hassell</name>\n    </author>\n    <author>\n      <name>Dan Zhang</name>\n    </author>\n    <author>\n      <name>Hannah Kim</name>\n    </author>\n    <author>\n      <name>Tom Mitchell</name>\n    </author>\n    <author>\n      <name>Estevam Hruschka</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.19897v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.19897v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.19732v1</id>\n    <updated>2025-10-22T16:24:47Z</updated>\n    <published>2025-10-22T16:24:47Z</published>\n    <title>Memo: Training Memory-Efficient Embodied Agents with Reinforcement\n  Learning</title>\n    <summary>  To enable embodied agents to operate effectively over extended timeframes, it\nis crucial to develop models that form and access memories to stay\ncontextualized in their environment. In the current paradigm of training\ntransformer-based policies for embodied sequential decision-making tasks,\nvisual inputs often overwhelm the context limits of transformers, while humans\ncan maintain and utilize a lifetime of experience compressed as memories.\nSignificant compression is possible in principle, as much of the input is\nirrelevant and can be abstracted. However, existing approaches predominantly\nfocus on either recurrent models with fixed-size memory or transformers with\nfull-context reliance. In this work, we propose Memo, a transformer-based\narchitecture and training recipe for reinforcement learning (RL) on\nmemory-intensive, long-horizon tasks. Memo incorporates the creation and\nretrieval of memory by interleaving periodic summarization tokens with the\ninputs of a model during training. We demonstrate Memo's effectiveness on a\ngridworld meta-RL benchmark and a multi-object navigation task in\nphoto-realistic indoor settings. Memo outperforms naive long-context\ntransformer baselines while being more compute and storage efficient.\nAdditionally, Memo generalizes better to longer contexts at inference time and\nremains robust in streaming settings, where historical context must be\ntruncated to fit inference constraints.\n</summary>\n    <author>\n      <name>Gunshi Gupta</name>\n    </author>\n    <author>\n      <name>Karmesh Yadav</name>\n    </author>\n    <author>\n      <name>Zsolt Kira</name>\n    </author>\n    <author>\n      <name>Yarin Gal</name>\n    </author>\n    <author>\n      <name>Rahaf Aljundi</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted for Spotlight Presentation at NeurIPS 2025</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.19732v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.19732v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.18488v1</id>\n    <updated>2025-10-21T10:11:33Z</updated>\n    <published>2025-10-21T10:11:33Z</published>\n    <title>AndroidControl-Curated: Revealing the True Potential of GUI Agents\n  through Benchmark Purification</title>\n    <summary>  On-device virtual assistants like Siri and Google Assistant are increasingly\npivotal, yet their capabilities are hamstrung by a reliance on rigid,\ndeveloper-dependent APIs. GUI agents offer a powerful, API-independent\nalternative, but their adoption is hindered by the perception of poor\nperformance, as even the best models (e.g. Qwen3-VL-235B) scores are capped at\naround 60% on benchmarks like AndroidControl, far from viability for real-world\nuse. Our research reveals that issue lies not only with the models but with the\nbenchmarks themselves. We identified notable shortcomings in AndroidControl,\nincluding ambiguities and factual errors, which systematically underrates agent\ncapabilities. To address this critical oversight, we enhanced AndroidControl\ninto AndroidControl-Curated, a refined version of the benchmark improved\nthrough a rigorous purification pipeline. On this enhanced benchmark,\nstate-of-the-art models achieve success rates nearing 75% on complex tasks (15%\nimprovement), reflecting that on-device GUI agents are actually closer to\npractical deployment than previously thought. We introduce our new SOTA model,\nMagma-R1- 3B, post-trained on just 2.4k curated samples using 60 hours of an\nH20 GPU (approximately $60). Despite being 200 times smaller in parameters,\nthis model delivers performance comparable to Qwen3- VL-235B. We release both\nAndroidControl-Curated benchmark and Magma-R1 model to the research community,\nencouraging adoption of this enhanced benchmark to better reflect model\ncapabilities and accelerate the development of robust, on-device virtual\nassistants.\n</summary>\n    <author>\n      <name>Ho Fai Leung</name>\n    </author>\n    <author>\n      <name>Xiaoyan Xi</name>\n    </author>\n    <author>\n      <name>Fei Zuo</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.18488v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.18488v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.17947v2</id>\n    <updated>2025-10-22T01:18:53Z</updated>\n    <published>2025-10-20T17:37:03Z</published>\n    <title>PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of\n  Multi-turn Exploits</title>\n    <summary>  Large Language Models (LLMs) are improving at an exceptional rate. With the\nadvent of agentic workflows, multi-turn dialogue has become the de facto mode\nof interaction with LLMs for completing long and complex tasks. While LLM\ncapabilities continue to improve, they remain increasingly susceptible to\njailbreaking, especially in multi-turn scenarios where harmful intent can be\nsubtly injected across the conversation to produce nefarious outcomes. While\nsingle-turn attacks have been extensively explored, adaptability, efficiency\nand effectiveness continue to remain key challenges for their multi-turn\ncounterparts. To address these gaps, we present PLAGUE, a novel plug-and-play\nframework for designing multi-turn attacks inspired by lifelong-learning\nagents. PLAGUE dissects the lifetime of a multi-turn attack into three\ncarefully designed phases (Primer, Planner and Finisher) that enable a\nsystematic and information-rich exploration of the multi-turn attack family.\nEvaluations show that red-teaming agents designed using PLAGUE achieve\nstate-of-the-art jailbreaking results, improving attack success rates (ASR) by\nmore than 30% across leading models in a lesser or comparable query budget.\nParticularly, PLAGUE enables an ASR (based on StrongReject) of 81.4% on\nOpenAI's o3 and 67.3% on Claude's Opus 4.1, two models that are considered\nhighly resistant to jailbreaks in safety literature. Our work offers tools and\ninsights to understand the importance of plan initialization, context\noptimization and lifelong learning in crafting multi-turn attacks for a\ncomprehensive model vulnerability evaluation.\n</summary>\n    <author>\n      <name>Neeladri Bhuiya</name>\n    </author>\n    <author>\n      <name>Madhav Aggarwal</name>\n    </author>\n    <author>\n      <name>Diptanshu Purwar</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">First two authors have equal author contributions</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.17947v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.17947v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.MA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.17198v1</id>\n    <updated>2025-10-20T06:20:59Z</updated>\n    <published>2025-10-20T06:20:59Z</published>\n    <title>From Pixels to People: Satellite-Based Mapping and Quantification of\n  Riverbank Erosion and Lost Villages in Bangladesh</title>\n    <summary>  The great rivers of Bangladesh, arteries of commerce and sustenance, are also\nagents of relentless destruction. Each year, they swallow whole villages and\nvast tracts of farmland, erasing communities from the map and displacing\nthousands of families. To track this slow-motion catastrophe has, until now,\nbeen a Herculean task for human analysts. Here we show how a powerful\ngeneral-purpose vision model, the Segment Anything Model (SAM), can be adapted\nto this task with remarkable precision. To do this, we assembled a new dataset\n- a digital chronicle of loss compiled from historical Google Earth imagery of\nBangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur\nUnion, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,\nthis dataset is the first to include manually annotated data on the settlements\nthat have vanished beneath the water. Our method first uses a simple\ncolor-channel analysis to provide a rough segmentation of land and water, and\nthen fine-tunes SAM's mask decoder to recognize the subtle signatures of\nriverbank erosion. The resulting model demonstrates a keen eye for this\ndestructive process, achieving a mean Intersection over Union of 86.30% and a\nDice score of 92.60% - a performance that significantly surpasses traditional\nmethods and off-the-shelf deep learning models. This work delivers three key\ncontributions: the first annotated dataset of disappeared settlements in\nBangladesh due to river erosion; a specialized AI model fine-tuned for this\ncritical task; and a method for quantifying land loss with compelling visual\nevidence. Together, these tools provide a powerful new lens through which\npolicymakers and disaster management agencies can monitor erosion, anticipate\nits trajectory, and ultimately protect the vulnerable communities in its path.\n</summary>\n    <author>\n      <name>M Saifuzzaman Rafat</name>\n    </author>\n    <author>\n      <name>Mohd Ruhul Ameen</name>\n    </author>\n    <author>\n      <name>Akif Islam</name>\n    </author>\n    <author>\n      <name>Abu Saleh Musa Miah</name>\n    </author>\n    <author>\n      <name>Jungpil Shin</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Submitted to the International Conference on Data and Applied\n  Analytics (IDAA 2025). 15 pages, 5 figures, 4 tables</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.17198v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.17198v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.16276v1</id>\n    <updated>2025-10-18T00:21:45Z</updated>\n    <published>2025-10-18T00:21:45Z</published>\n    <title>What Limits Agentic Systems Efficiency?</title>\n    <summary>  Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have\ndemonstrated strong reasoning capabilities. To further enhance LLM\ncapabilities, recent agentic systems, such as Deep Research, incorporate web\ninteractions into LLM reasoning to mitigate uncertainties and reduce potential\nerrors. However, existing research predominantly focuses on reasoning\nperformance, often neglecting the efficiency of agentic systems. In this work,\nwe present a comprehensive empirical study that identifies efficiency\nbottlenecks in web-interactive agentic systems. We decompose end-to-end latency\ninto two primary components: LLM API latency and web environment latency. We\nconduct a comprehensive empirical study across 15 models and 5 providers to\ndemonstrate high variability in API-based agentic systems. We observe that web\nenvironment latency can contribute as much as 53.7% to the overall latency in a\nweb-based agentic system. To improve latency, we propose SpecCache, a caching\nframework augmented with speculative execution that can reduce web environment\noverhead. Extensive evaluations on two standard benchmarks show that our\napproach improves the cache hit rate by up to 58x compared to a random caching\nstrategy, while reducing web environment overhead by up to 3.2x, without\ndegrading agentic system performance.\n</summary>\n    <author>\n      <name>Song Bian</name>\n    </author>\n    <author>\n      <name>Minghao Yan</name>\n    </author>\n    <author>\n      <name>Anand Jayarajan</name>\n    </author>\n    <author>\n      <name>Gennady Pekhimenko</name>\n    </author>\n    <author>\n      <name>Shivaram Venkataraman</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">27 pages, 15 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.16276v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.16276v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.16234v1</id>\n    <updated>2025-10-17T21:55:07Z</updated>\n    <published>2025-10-17T21:55:07Z</published>\n    <title>ScholarEval: Research Idea Evaluation Grounded in Literature</title>\n    <summary>  As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on.\n</summary>\n    <author>\n      <name>Hanane Nour Moussa</name>\n    </author>\n    <author>\n      <name>Patrick Queiroz Da Silva</name>\n    </author>\n    <author>\n      <name>Daniel Adu-Ampratwum</name>\n    </author>\n    <author>\n      <name>Alyson East</name>\n    </author>\n    <author>\n      <name>Zitong Lu</name>\n    </author>\n    <author>\n      <name>Nikki Puccetti</name>\n    </author>\n    <author>\n      <name>Mingyi Xue</name>\n    </author>\n    <author>\n      <name>Huan Sun</name>\n    </author>\n    <author>\n      <name>Bodhisattwa Prasad Majumder</name>\n    </author>\n    <author>\n      <name>Sachin Kumar</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.16234v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.16234v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.15772v1</id>\n    <updated>2025-10-17T15:59:44Z</updated>\n    <published>2025-10-17T15:59:44Z</published>\n    <title>Self-evolving expertise in complex non-verifiable subject domains:\n  dialogue as implicit meta-RL</title>\n    <summary>  So-called `wicked problems', those involving complex multi-dimensional\nsettings, non-verifiable outcomes, heterogeneous impacts and a lack of single\nobjectively correct answers, have plagued humans throughout history. Modern\nexamples include decisions over justice frameworks, solving environmental\npollution, planning for pandemic resilience and food security. The use of\nstate-of-the-art artificial intelligence systems (notably Large Language\nModel-based agents) collaborating with humans on solving such problems is being\nactively explored. While the abilities of LLMs can be improved by, for example,\nfine-tuning, hand-crafted system prompts and scaffolding with external tools,\nLLMs lack endogenous mechanisms to develop expertise through experience in such\nsettings. This work address this gap with Dialectica, a framework where agents\nengage in structured dialogue on defined topics, augmented by memory,\nself-reflection, and policy-constrained context editing. Formally, discussion\nis viewed as an implicit meta-reinforcement learning process. The\n`dialogue-trained' agents are evaluated post-hoc using judged pairwise\ncomparisons of elicited responses. Across two model architectures (locally run\nQwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based\ncontext editing during discussion produces agents which dominate their baseline\ncounterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and\nAlphaRank mass. The predicted signatures of learning are observed qualitatively\nin statement and reflection logs, where reflections identify weaknesses and\nreliably shape subsequent statements. Agreement between quantitative and\nqualitative evidence supports dialogue-driven context evolution as a practical\npath to targeted expertise amplification in open non-verifiable domains.\n</summary>\n    <author>\n      <name>Richard M. Bailey</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">50 pages, 4 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.15772v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.15772v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.2.0\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.15620v1</id>\n    <updated>2025-10-17T13:06:09Z</updated>\n    <published>2025-10-17T13:06:09Z</published>\n    <title>GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device</title>\n    <summary>  Semantic top-K selection with cross-encoder rerankers underpins of on-device\nAI services, such as retrieval-augmented generation, agent memory, and\npersonalized recommendation. However, its latency and memory demands dominate\nend-to-end budgets on edge hardware. Revisiting the objective of top-K\nselection, we reveal that only relative rankings matter, not exact\nper-candidate scores. We further observe sequence-level sparsity: relative\nrankings stabilize early in intermediate layers, allowing pruning opportunities\nprior to completing full inference.\n  Building on this insight, we propose monolithic forwarding and develop a\ntraining-free inference system, GRATING. By maintaining a global view of all\ncandidates, it reduces latency through progressive cluster pruning. It also\nbounds peak memory usage by strategically overlapping I/O with computation via\ndual-layer sliding window and chunked execution. We evaluate GRATING against\nstate-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple\nM2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak\nmemory by up to 94.9% in microbenchmarks, without any loss in precision. Across\nthree real-world on-device AI applications, GRATING lowers latency by\n11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial\nimprovements in efficiency and deployability.\n</summary>\n    <author>\n      <name>Jiahao Zhou</name>\n    </author>\n    <author>\n      <name>Chengliang Lin</name>\n    </author>\n    <author>\n      <name>Dingji Li</name>\n    </author>\n    <author>\n      <name>Mingkai Dong</name>\n    </author>\n    <author>\n      <name>Haibo Chen</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.15620v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.15620v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.15280v1</id>\n    <updated>2025-10-17T03:40:26Z</updated>\n    <published>2025-10-17T03:40:26Z</published>\n    <title>Foundation Models for Scientific Discovery: From Paradigm Enhancement to\n  Paradigm Transition</title>\n    <summary>  Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the\nlandscape of scientific research. Beyond accelerating tasks such as hypothesis\ngeneration, experimental design, and result interpretation, they prompt a more\nfundamental question: Are FMs merely enhancing existing scientific\nmethodologies, or are they redefining the way science is conducted? In this\npaper, we argue that FMs are catalyzing a transition toward a new scientific\nparadigm. We introduce a three-stage framework to describe this evolution: (1)\nMeta-Scientific Integration, where FMs enhance workflows within traditional\nparadigms; (2) Hybrid Human-AI Co-Creation, where FMs become active\ncollaborators in problem formulation, reasoning, and discovery; and (3)\nAutonomous Scientific Discovery, where FMs operate as independent agents\ncapable of generating new scientific knowledge with minimal human intervention.\nThrough this lens, we review current applications and emerging capabilities of\nFMs across existing scientific paradigms. We further identify risks and future\ndirections for FM-enabled scientific discovery. This position paper aims to\nsupport the scientific community in understanding the transformative role of\nFMs and to foster reflection on the future of scientific discovery. Our project\nis available at\nhttps://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.\n</summary>\n    <author>\n      <name>Fan Liu</name>\n    </author>\n    <author>\n      <name>Jindong Han</name>\n    </author>\n    <author>\n      <name>Tengfei Lyu</name>\n    </author>\n    <author>\n      <name>Weijia Zhang</name>\n    </author>\n    <author>\n      <name>Zhe-Rui Yang</name>\n    </author>\n    <author>\n      <name>Lu Dai</name>\n    </author>\n    <author>\n      <name>Cancheng Liu</name>\n    </author>\n    <author>\n      <name>Hao Liu</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NeurIPS 2025</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.15280v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.15280v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.16047v1</id>\n    <updated>2025-10-16T17:28:25Z</updated>\n    <published>2025-10-16T17:28:25Z</published>\n    <title>Algorithms for dynamic scheduling in manufacturing, towards digital\n  factories Improving Deadline Feasibility and Responsiveness via Temporal\n  Networks</title>\n    <summary>  Modern manufacturing systems must meet hard delivery deadlines while coping\nwith stochastic task durations caused by process noise, equipment variability,\nand human intervention. Traditional deterministic schedules break down when\nreality deviates from nominal plans, triggering costly last-minute repairs.\nThis thesis combines offline constraint-programming (CP) optimisation with\nonline temporal-network execution to create schedules that remain feasible\nunder worst-case uncertainty. First, we build a CP model of the flexible\njob-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to\nobtain a fully pro-active baseline. We then translate the resulting plan into a\nSimple Temporal Network with Uncertainty (STNU) and verify dynamic\ncontrollability, which guarantees that a real-time dispatcher can retime\nactivities for every bounded duration realisation without violating resource or\ndeadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4\nbenchmark suite show that our hybrid approach eliminates 100\\% of deadline\nviolations observed in state-of-the-art meta-heuristic schedules, while adding\nonly 3--5\\% makespan overhead. Scalability experiments confirm that CP\nsolve-times and STNU checks remain sub-second on medium-size instances. The\nwork demonstrates how temporal-network reasoning can bridge the gap between\nproactive buffering and dynamic robustness, moving industry a step closer to\ntruly digital, self-correcting factories.\n</summary>\n    <author>\n      <name>Ioan Hedea</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages 2 column, 11 figures. Bachelor's thesis</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2510.16047v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.16047v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2510.14900v1</id>\n    <updated>2025-10-16T17:17:00Z</updated>\n    <published>2025-10-16T17:17:00Z</published>\n    <title>Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent\n  That Improves Without Labels or Model Updates</title>\n    <summary>  The Enterprise Intelligence Platform must integrate logs from numerous\nthird-party vendors in order to perform various downstream tasks. However,\nvendor documentation is often unavailable at test time. It is either misplaced,\nmismatched, poorly formatted, or incomplete, which makes schema mapping\nchallenging. We introduce a reinforcement learning agent that can self-improve\nwithout labeled examples or model weight updates. During inference, the agent:\n1) Identifies ambiguous field-mapping attempts. 2) Generates targeted\nweb-search queries to gather external evidence. 3) Applies a confidence-based\nreward to iteratively refine its mappings. To demonstrate this concept, we\nconverted Microsoft Defender for Endpoint logs into a common schema. Our method\nincreased mapping accuracy from 56.4\\%(LLM-only) to 72.73\\%(RAG) to 93.94\\%\nover 100 iterations using GPT-4o. At the same time, it reduced the number of\nlow-confidence mappings requiring expert review by 85\\%. This new approach\nprovides an evidence-driven, transparent method for solving future industry\nproblems, paving the way for more robust, accountable, scalable, efficient,\nflexible, adaptable, and collaborative solutions.\n</summary>\n    <author>\n      <name>Wen-Kwang Tsao</name>\n    </author>\n    <author>\n      <name>Yao-Ching Yu</name>\n    </author>\n    <author>\n      <name>Chien-Ming Huang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2510.14900v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2510.14900v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>\n"
}
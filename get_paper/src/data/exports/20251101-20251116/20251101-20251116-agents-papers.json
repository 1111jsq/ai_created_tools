[
  {
    "paperId": "arxiv:2511.12712v1",
    "title": "Adaptive Focus Memory for Language Models",
    "authors": [
      "Christopher Cruz"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, but their behavior is still bottlenecked by fixed context windows and naive memory strategies. Replaying the full conversation at every turn is simple but expensive, while static summarization or recency-only heuristics often erase safety-critical user details. We present Adaptive Focus Memory (AFM), a dynamic context manager that assigns each past message one of three fidelity levels -- FULL, COMPRESSED, or PLACEHOLDER -- based on semantic similarity to the current query, half-life recency weighting, and importance classification. AFM packs messages chronologically under a strict token budget, preferring high fidelity for the most relevant turns while aiming to preserve a cheap trace of the dialogue.…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.12712v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.12712v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "benchmark",
      "memory",
      "planning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.12635v1",
    "title": "LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews",
    "authors": [
      "Lech Madeyski",
      "Barbara Kitchenham",
      "Martin Shepperd"
    ],
    "abstract": "Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with th…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.12635v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.12635v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "evaluation",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.12319v1",
    "title": "Decision and Gender Biases in Large Language Models: A Behavioral Economic Perspective",
    "authors": [
      "Luca Corazzini",
      "Elisa Deriu",
      "Marco Guerzoni"
    ],
    "abstract": "Large language models (LLMs) increasingly mediate economic and organisational processes, from automated customer support and recruitment to investment advice and policy analysis. These systems are often assumed to embody rational decision making free from human error; yet they are trained on human language corpora that may embed cognitive and social biases. This study investigates whether advanced LLMs behave as rational agents or whether they reproduce human behavioural tendencies when faced with classic decision problems. Using two canonical experiments in behavioural economics, the ultimatum game and a gambling game, we elicit decisions from two state of the art models, Google Gemma7B and Qwen, under neutral and gender conditioned prompts. We estimate parameters of inequity aversion an…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.12319v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.12319v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "benchmark"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.11519v1",
    "title": "Experience-Guided Adaptation of Inference-Time Reasoning Strategies",
    "authors": [
      "Adam Stein",
      "Matthew Trager",
      "Benjamin Bowman",
      "Michael Kleinman",
      "Aditya Chattopadhyay",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "abstract": "Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time b…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.11519v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.11519v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "agent",
      "benchmark",
      "memory",
      "reasoning",
      "tool-use",
      "workflow"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.11083v3",
    "title": "Efficient Reinforcement Learning for Zero-Shot Coordination in Evolving Games",
    "authors": [
      "Bingyu Hui",
      "Lebin Yu",
      "Quanming Yao",
      "Yunpeng Qu",
      "Xudong Zhang",
      "Jian Wang"
    ],
    "abstract": "Zero-shot coordination(ZSC), a key challenge in multi-agent game theory, has become a hot topic in reinforcement learning (RL) research recently, especially in complex evolving games. It focuses on the generalization ability of agents, requiring them to coordinate well with collaborators from a diverse, potentially evolving, pool of partners that are not seen before without any fine-tuning. Population-based training, which approximates such an evolving partner pool, has been proven to provide good zero-shot coordination performance; nevertheless, existing methods are limited by computational resources, mainly focusing on optimizing diversity in small populations while neglecting the potential performance gains from scaling population size. To address this issue, this paper proposes the Sc…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.11083v3",
    "pdfUrl": "https://arxiv.org/pdf/2511.11083v3",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "agent",
      "multi-agent"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.10949v1",
    "title": "Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting",
    "authors": [
      "Nirmit Arora",
      "Sathvik Joel",
      "Ishan Kavathekar",
      "Palak",
      "Rohan Gandhi",
      "Yash Pandya",
      "Tanuja Ganu",
      "Aditya Kanade",
      "Akshay Nambi"
    ],
    "abstract": "LLM-based agents are increasingly deployed in multi-agent systems (MAS). As these systems move toward real-world applications, their security becomes paramount. Existing research largely evaluates single-agent security, leaving a critical gap in understanding the vulnerabilities introduced by multi-agent design. However, existing systems fall short due to lack of unified frameworks and metrics focusing on unique rejection modes in MAS. We present SafeAgents, a unified and extensible framework for fine-grained security assessment of MAS. SafeAgents systematically exposes how design choices such as plan construction strategies, inter-agent context sharing, and fallback behaviors affect susceptibility to adversarial prompting. We introduce Dharma, a diagnostic measure that helps identify wea…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.10949v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.10949v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.MA"
    ],
    "tags": [
      "agent",
      "multi-agent",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.10002v2",
    "title": "PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models",
    "authors": [
      "Shivam Sharma",
      "Riya Naik",
      "Tejas Gawas",
      "Heramb Patil",
      "Kunal Korgaonkar"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework \"PustakAI\"\\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset \"NCE…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.10002v2",
    "pdfUrl": "https://arxiv.org/pdf/2511.10002v2",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "evaluation",
      "reasoning",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.09450v1",
    "title": "How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models",
    "authors": [
      "Amanta Sherfenaz",
      "Nazmul Haque",
      "Protiva Sadhukhan Prova",
      "Md Asif Raihan",
      "Md. Hadiuzzaman"
    ],
    "abstract": "With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.09450v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.09450v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "planning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.11671v1",
    "title": "Evaluation of LLM-based Explanations for a Learning Analytics Dashboard",
    "authors": [
      "Alina Deriyeva",
      "Benjamin Paassen"
    ],
    "abstract": "Learning Analytics Dashboards can be a powerful tool to support self-regulated learning in Digital Learning Environments and promote development of meta-cognitive skills, such as reflection. However, their effectiveness can be affected by the interpretability of the data they provide. To assist in the interpretation, we employ a large language model to generate verbal explanations of the data in the dashboard and evaluate it against a standalone dashboard and explanations provided by human teachers in an expert study with university level educators (N=12). We find that the LLM-based explanations of the skill state presented in the dashboard, as well as general recommendations on how to proceed with learning within the course are significantly more favored compared to the other conditions.…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.11671v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.11671v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.LG"
    ],
    "tags": [
      "evaluation",
      "reflection",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.07904v2",
    "title": "Test-driven Reinforcement Learning",
    "authors": [
      "Zhao Yu",
      "Xiuping Wu",
      "Liangjun Ke"
    ],
    "abstract": "Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objec…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.07904v2",
    "pdfUrl": "https://arxiv.org/pdf/2511.07904v2",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "agent",
      "benchmark",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.10680v1",
    "title": "LAD-BNet: Lag-Aware Dual-Branch Networks for Real-Time Energy Forecasting on Edge Devices",
    "authors": [
      "Jean-Philippe Lignier"
    ],
    "abstract": "Real-time energy forecasting on edge devices represents a major challenge for smart grid optimization and intelligent buildings. We present LAD-BNet (Lag-Aware Dual-Branch Network), an innovative neural architecture optimized for edge inference with Google Coral TPU. Our hybrid approach combines a branch dedicated to explicit exploitation of temporal lags with a Temporal Convolutional Network (TCN) featuring dilated convolutions, enabling simultaneous capture of short and long-term dependencies. Tested on real energy consumption data with 10-minute temporal resolution, LAD-BNet achieves 14.49% MAPE at 1-hour horizon with only 18ms inference time on Edge TPU, representing an 8-12 x acceleration compared to CPU. The multi-scale architecture enables predictions up to 12 hours with controlled…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.10680v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.10680v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.LG"
    ],
    "tags": [
      "memory",
      "planning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.07685v1",
    "title": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents",
    "authors": [
      "Manasi Sharma",
      "Chen Bo Calvin Zhang",
      "Chaithanya Bandi",
      "Clinton Wang",
      "Ankit Aich",
      "Huy Nghiem",
      "Tahseen Rabbani",
      "Ye Htet",
      "Brian Jang",
      "Sumana Basu",
      "Aishwarya Balwani",
      "Denis Peskoff",
      "Marcos Ayestaran",
      "Sean M. Hendryx",
      "Brad Kenstler",
      "Bing Liu"
    ],
    "abstract": "Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes:…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.07685v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.07685v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "agent",
      "benchmark",
      "evaluation",
      "reasoning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.07090v4",
    "title": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts",
    "authors": [
      "Marcel Rojahn",
      "Marcus Grum"
    ],
    "abstract": "Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water,…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.07090v4",
    "pdfUrl": "https://arxiv.org/pdf/2511.07090v4",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.04481v1",
    "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis",
    "authors": [
      "Lars Krupp",
      "Daniel Geißler",
      "Vishal Banwari",
      "Paul Lukowicz",
      "Jakob Karolus"
    ],
    "abstract": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful agentic systems pushing the boundaries of Large Language Models (LLM). They can autonomously interact with the internet at the user's behest, such as navigating websites, filling search masks, and comparing price lists. Though web agent research is thriving, induced sustainability issues remain largely unexplored. To highlight the urgency of this issue, we provide an initial exploration of the energy and $CO_2$ cost associated with web agents from both a theoretical -via estimation- and an empirical perspective -by benchmarking. Our results show how different philosophies in web agent creation can severely impact the associated expended energy, and that more energy consumed does not necessarily equate to better…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.04481v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.04481v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "autonomy",
      "benchmark"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.03958v1",
    "title": "Multi-Agent Collaborative Framework For Math Problem Generation",
    "authors": [
      "Kia Karbasi",
      "Kevin Hong",
      "Mohammad Amin Samadi",
      "Gregory Pottie"
    ],
    "abstract": "Automatic question generation (AQG) for mathematics education remains an elusive goal for Intelligent Tutoring Systems and educators. While pre-trained transformer-based language models have significantly advanced natural language generation, they often struggle to precisely control problem complexity and cognitive demands. In this paper, we introduce a collaborative multi-agent framework as a novel method of incorporating inference-time computation into AQG. This approach leverages multiple agents that iteratively refine generated question-answer pairs to better balance complexity and cognitive demand. We evaluate the generated questions on five meta-evaluation criteria: relevance, importance, clarity, difficulty matching, answerability, to assess the system's ability to control the requ…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.03958v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.03958v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.MA"
    ],
    "tags": [
      "agent",
      "evaluation",
      "multi-agent",
      "workflow"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.03690v1",
    "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents",
    "authors": [
      "Xingyao Wang",
      "Simon Rosenberg",
      "Juan Michelini",
      "Calvin Smith",
      "Hoang Tran",
      "Engel Nyst",
      "Rohit Malhotra",
      "Xuhui Zhou",
      "Valerie Chen",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "abstract": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensib…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.03690v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.03690v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "benchmark",
      "memory",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.03497v1",
    "title": "ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications",
    "authors": [
      "Lei Fu",
      "Sahar Salimpour",
      "Leonardo Militano",
      "Harry Edelman",
      "Jorge Peña Queralta",
      "Giovanni Toffetti"
    ],
    "abstract": "Agentic AI systems and Physical or Embodied AI systems have been two key research verticals at the forefront of Artificial Intelligence and Robotics, with Model Context Protocol (MCP) increasingly becoming a key component and enabler of agentic applications. However, the literature at the intersection of these verticals, i.e., Agentic Embodied AI, remains scarce. This paper introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for analyzing, visualizing and processing robot data with natural language through LLMs and VLMs. We describe specific tooling built with robotics domain knowledge, with our initial release focused on mobile robotics and supporting natively the analysis of trajectories, laser scan data, transforms, or time series data. This is in addition to providing…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.03497v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.03497v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "benchmark",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.03434v1",
    "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond",
    "authors": [
      "Botao 'Amber' Hu",
      "Helena Rong"
    ],
    "abstract": "As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered) autonomously transacting and collaborating-trust shifts from human oversight to protocol design. In 2025, several inter-agent protocols crystallized this shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2), and Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust assumptions remain under-examined. This paper presents a comparative study of trust models in inter-agent protocol design: Brief (self- or third-party verifiable claims), Claim (self-proclaimed capabilities and identity, e.g. AgentCard), Proof (cryptographic verification, including zero-knowledge proofs and trusted execution environment attestations), Stake (bonded collateral with slashing and insurance), Reputation…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.03434v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.03434v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.MA"
    ],
    "tags": [
      "agent",
      "autonomy"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.02781v1",
    "title": "Measuring AI Diffusion: A Population-Normalized Metric for Tracking Global AI Usage",
    "authors": [
      "Amit Misra",
      "Jane Wang",
      "Scott McCullers",
      "Kevin White",
      "Juan Lavista Ferres"
    ],
    "abstract": "Measuring global AI diffusion remains challenging due to a lack of population-normalized, cross-country usage data. We introduce AI User Share, a novel indicator that estimates the share of each country's working-age population actively using AI tools. Built from anonymized Microsoft telemetry and adjusted for device access and mobile scaling, this metric spans 147 economies and provides consistent, real-time insight into global AI diffusion. We find wide variation in adoption, with a strong correlation between AI User Share and GDP. High uptake is concentrated in developed economies, though usage among internet-connected populations in lower-income countries reveals substantial latent demand. We also detect sharp increases in usage following major product launches, such as DeepSeek in ea…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.02781v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.02781v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "benchmark",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.02606v1",
    "title": "A Multi-Agent Psychological Simulation System for Human Behavior Modeling",
    "authors": [
      "Xiangen Hu",
      "Jiarui Tong",
      "Sheng Xu"
    ],
    "abstract": "Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.02606v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.02606v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "multi-agent"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.02560v1",
    "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated Collaboration",
    "authors": [
      "Dan Bohus",
      "Sean Andrist",
      "Ann Paradiso",
      "Nick Saw",
      "Tim Schoonbeek",
      "Maia Stiber"
    ],
    "abstract": "We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operati…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.02560v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.02560v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "benchmark"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.02303v1",
    "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation",
    "authors": [
      "Zhiwei Zhang",
      "Xiaomin Li",
      "Yudi Lin",
      "Hui Liu",
      "Ramraj Chandradevan",
      "Linlin Wu",
      "Minhua Lin",
      "Fali Wang",
      "Xianfeng Tang",
      "Qi He",
      "Suhang Wang"
    ],
    "abstract": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.02303v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.02303v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "agent",
      "multi-agent",
      "reasoning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.01999v1",
    "title": "TRACE: Textual Reasoning for Affordance Coordinate Extraction",
    "authors": [
      "Sangyun Park",
      "Jin Kim",
      "Yuchen Cui",
      "Matthew S. Brown"
    ],
    "abstract": "Vision-Language Models (VLMs) struggle to translate high-level instructions into the precise spatial affordances required for robotic manipulation. While visual Chain-of-Thought (CoT) methods exist, they are often computationally intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance Coordinate Extraction), a novel methodology that integrates a textual Chain of Reasoning (CoR) into the affordance prediction process. We use this methodology to create the TRACE dataset, a large-scale collection created via an autonomous pipeline that pairs instructions with explicit textual rationales. By fine-tuning a VLM on this data, our model learns to externalize its spatial reasoning before acting. Our experiments show that our TRACE-tuned model achieves state-of-the-art perform…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.01999v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.01999v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI"
    ],
    "tags": [
      "autonomy",
      "benchmark",
      "reasoning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.01093v1",
    "title": "Continual Learning, Not Training: Online Adaptation For Agents",
    "authors": [
      "Aman Jaglan",
      "Jarrod Barnes"
    ],
    "abstract": "Continual Learning (CL) methods have traditionally focused on mitigating catastrophic forgetting through gradient-based retraining, an approach ill-suited for deployed agents that must adapt in real time. We introduce our Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that decouples reasoning (Teacher) from execution (Student) and incorporates a persistent learning memory that stores distilled guidance from experience. This informs the orchestration layer, enabling the system to dynamically adjust its operational strategies, such as supervision level or initial plan selection, at inference time. In doing so, ATLAS achieves gradient-free continual learning, shifting the locus of adaptation from model parameters to system-level orchestration. We formulate this as a…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.01093v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.01093v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "agent",
      "benchmark",
      "memory",
      "reasoning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.01078v1",
    "title": "Predictive Auxiliary Learning for Belief-based Multi-Agent Systems",
    "authors": [
      "Qinwei Huang",
      "Stefan Wang",
      "Simon Khan",
      "Garrett Katz",
      "Qinru Qiu"
    ],
    "abstract": "The performance of multi-agent reinforcement learning (MARL) in partially observable environments depends on effectively aggregating information from observations, communications, and reward signals. While most existing multi-agent systems primarily rely on rewards as the only feedback for policy training, our research shows that introducing auxiliary predictive tasks can significantly enhance learning efficiency and stability. We propose Belief-based Predictive Auxiliary Learning (BEPAL), a framework that incorporates auxiliary training objectives to support policy optimization. BEPAL follows the centralized training with decentralized execution paradigm. Each agent learns a belief model that predicts unobservable state information, such as other agents' rewards or motion directions, alo…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.01078v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.01078v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.MA"
    ],
    "tags": [
      "agent",
      "multi-agent"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.01006v1",
    "title": "None To Optima in Few Shots: Bayesian Optimization with MDP Priors",
    "authors": [
      "Diantong Li",
      "Kyunghyun Cho",
      "Chong Liu"
    ],
    "abstract": "Bayesian Optimization (BO) is an efficient tool for optimizing black-box functions, but its theoretical guarantees typically hold in the asymptotic regime. In many critical real-world applications such as drug discovery or materials design, where each evaluation can be very costly and time-consuming, BO becomes impractical for many evaluations. In this paper, we introduce the Procedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization with remarkably few function evaluations. At the heart of our algorithmic design are Markov Decision Process (MDP) priors that model optimization trajectories from related source tasks, thereby capturing procedural knowledge on efficient optimization. We embed these MDP priors into a prior-fitted neural network and employ model-agnostic met…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.01006v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.01006v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.LG"
    ],
    "tags": [
      "benchmark",
      "evaluation",
      "tool-use"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  },
  {
    "paperId": "arxiv:2511.00423v1",
    "title": "Bootstrap Off-policy with World Model",
    "authors": [
      "Guojian Zhan",
      "Likun Wang",
      "Xiangteng Zhang",
      "Jiaxin Gao",
      "Masayoshi Tomizuka",
      "Shengbo Eben Li"
    ],
    "abstract": "Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core…",
    "venue": "arXiv",
    "year": 2025,
    "month": 11,
    "primaryUrl": "https://arxiv.org/abs/2511.00423v1",
    "pdfUrl": "https://arxiv.org/pdf/2511.00423v1",
    "sources": [
      "arxiv"
    ],
    "topics": [
      "cs.AI",
      "cs.LG"
    ],
    "tags": [
      "planning"
    ],
    "createdAt": "2025-11-20T09:28:16.392337"
  }
]
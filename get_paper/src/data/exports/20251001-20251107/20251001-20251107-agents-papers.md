# AI Agent Papers
- [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy
  Consumption through Empirical and Theoretical Analysis](http://arxiv.org/abs/2511.04481v1)
  - Authors: Lars Krupp, Daniel Geißler, Vishal Banwari, Paul Lukowicz, Jakob Karolus
  - Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better…
  - Tags: agent, autonomy, benchmark
  - PDF: http://arxiv.org/pdf/2511.04481v1
- [Multi-Agent Collaborative Framework For Math Problem Generation](http://arxiv.org/abs/2511.03958v1)
  - Authors: Kia Karbasi, Kevin Hong, Mohammad Amin Samadi, Gregory Pottie
  - Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the requ…
  - Tags: agent, evaluation, multi-agent, workflow
  - PDF: http://arxiv.org/pdf/2511.03958v1
- [The OpenHands Software Agent SDK: A Composable and Extensible Foundation
  for Production Agents](http://arxiv.org/abs/2511.03690v1)
  - Authors: Xingyao Wang, Simon Rosenberg, Juan Michelini, Calvin Smith, Hoang Tran, Engel Nyst, Rohit Malhotra, Xuhui Zhou, Valerie Chen, Robert Brennan, Graham Neubig
  - Abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensib…
  - Tags: agent, benchmark, memory, tool-use
  - PDF: http://arxiv.org/pdf/2511.03690v1
- [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied
  AI Applications](http://arxiv.org/abs/2511.03497v1)
  - Authors: Lei Fu, Sahar Salimpour, Leonardo Militano, Harry Edelman, Jorge Peña Queralta, Giovanni Toffetti
  - Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing…
  - Tags: agent, benchmark, tool-use
  - PDF: http://arxiv.org/pdf/2511.03497v1
- [Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof,
  Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2,
  ERC-8004, and Beyond](http://arxiv.org/abs/2511.03434v1)
  - Authors: Botao 'Amber' Hu, Helena Rong
  - Abstract: As the "agentic web" takes shape-billions of AI agents (often LLM-powered)
autonomously transacting and collaborating-trust shifts from human oversight to
protocol design. In 2025, several inter-agent protocols crystallized this
shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),
and Ethereum's ERC-8004 "Trustless Agents," yet their underlying trust
assumptions remain under-examined. This paper presents a comparative study of
trust models in inter-agent protocol design: Brief (self- or third-party
verifiable claims), Claim (self-proclaimed capabilities and identity, e.g.
AgentCard), Proof (cryptographic verification, including zero-knowledge proofs
and trusted execution environment attestations), Stake (bonded collateral with
slashing and insurance), Reputation…
  - Tags: agent, autonomy
  - PDF: http://arxiv.org/pdf/2511.03434v1
- [A Multi-Agent Psychological Simulation System for Human Behavior
  Modeling](http://arxiv.org/abs/2511.02606v1)
  - Authors: Xiangen Hu, Jiarui Tong, Sheng Xu
  - Abstract: Training and education in human-centered fields require authentic practice,
yet realistic simulations of human behavior have remained limited. We present a
multi-agent psychological simulation system that models internal
cognitive-affective processes to generate believable human behaviors. In
contrast to black-box neural models, this system is grounded in established
psychological theories (e.g., self-efficacy, mindset, social constructivism)
and explicitly simulates an ``inner parliament'' of agents corresponding to key
psychological factors. These agents deliberate and interact to determine the
system's output behavior, enabling unprecedented transparency and alignment
with human psychology. We describe the system's architecture and theoretical
foundations, illustrate its use in teacher…
  - Tags: agent, multi-agent
  - PDF: http://arxiv.org/pdf/2511.02606v1
- [SigmaCollab: An Application-Driven Dataset for Physically Situated
  Collaboration](http://arxiv.org/abs/2511.02560v1)
  - Authors: Dan Bohus, Sean Andrist, Ann Paradiso, Nick Saw, Tim Schoonbeek, Maia Stiber
  - Abstract: We introduce SigmaCollab, a dataset enabling research on physically situated
human-AI collaboration. The dataset consists of a set of 85 sessions in which
untrained participants were guided by a mixed-reality assistive AI agent in
performing procedural tasks in the physical world. SigmaCollab includes a set
of rich, multimodal data streams, such as the participant and system audio,
egocentric camera views from the head-mounted device, depth maps, head, hand
and gaze tracking information, as well as additional annotations performed
post-hoc. While the dataset is relatively small in size (~ 14 hours), its
application-driven and interactive nature brings to the fore novel research
challenges for human-AI collaboration, and provides more realistic testing
grounds for various AI models operati…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2511.02560v1
- [Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents
  to Deliberation](http://arxiv.org/abs/2511.02303v1)
  - Authors: Zhiwei Zhang, Xiaomin Li, Yudi Lin, Hui Liu, Ramraj Chandradevan, Linlin Wu, Minhua Lin, Fali Wang, Xianfeng Tang, Qi He, Suhang Wang
  - Abstract: Large Language Models (LLMs) trained with reinforcement learning and
verifiable rewards have achieved strong results on complex reasoning tasks.
Recent work extends this paradigm to a multi-agent setting, where a
meta-thinking agent proposes plans and monitors progress while a reasoning
agent executes subtasks through sequential conversational turns. Despite
promising performance, we identify a critical limitation: lazy agent behavior,
in which one agent dominates while the other contributes little, undermining
collaboration and collapsing the setup to an ineffective single agent. In this
paper, we first provide a theoretical analysis showing why lazy behavior
naturally arises in multi-agent reasoning. We then introduce a stable and
efficient method for measuring causal influence, helping…
  - Tags: agent, multi-agent, reasoning
  - PDF: http://arxiv.org/pdf/2511.02303v1
- [TRACE: Textual Reasoning for Affordance Coordinate Extraction](http://arxiv.org/abs/2511.01999v1)
  - Authors: Sangyun Park, Jin Kim, Yuchen Cui, Matthew S. Brown
  - Abstract: Vision-Language Models (VLMs) struggle to translate high-level instructions
into the precise spatial affordances required for robotic manipulation. While
visual Chain-of-Thought (CoT) methods exist, they are often computationally
intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance
Coordinate Extraction), a novel methodology that integrates a textual Chain of
Reasoning (CoR) into the affordance prediction process. We use this methodology
to create the TRACE dataset, a large-scale collection created via an autonomous
pipeline that pairs instructions with explicit textual rationales. By
fine-tuning a VLM on this data, our model learns to externalize its spatial
reasoning before acting. Our experiments show that our TRACE-tuned model
achieves state-of-the-art perform…
  - Tags: autonomy, benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2511.01999v1
- [Continual Learning, Not Training: Online Adaptation For Agents](http://arxiv.org/abs/2511.01093v1)
  - Authors: Aman Jaglan, Jarrod Barnes
  - Abstract: Continual Learning (CL) methods have traditionally focused on mitigating
catastrophic forgetting through gradient-based retraining, an approach
ill-suited for deployed agents that must adapt in real time. We introduce our
Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that
decouples reasoning (Teacher) from execution (Student) and incorporates a
persistent learning memory that stores distilled guidance from experience. This
informs the orchestration layer, enabling the system to dynamically adjust its
operational strategies, such as supervision level or initial plan selection, at
inference time. In doing so, ATLAS achieves gradient-free continual learning,
shifting the locus of adaptation from model parameters to system-level
orchestration. We formulate this as a…
  - Tags: agent, benchmark, memory, reasoning
  - PDF: http://arxiv.org/pdf/2511.01093v1
- [Predictive Auxiliary Learning for Belief-based Multi-Agent Systems](http://arxiv.org/abs/2511.01078v1)
  - Authors: Qinwei Huang, Stefan Wang, Simon Khan, Garrett Katz, Qinru Qiu
  - Abstract: The performance of multi-agent reinforcement learning (MARL) in partially
observable environments depends on effectively aggregating information from
observations, communications, and reward signals. While most existing
multi-agent systems primarily rely on rewards as the only feedback for policy
training, our research shows that introducing auxiliary predictive tasks can
significantly enhance learning efficiency and stability. We propose
Belief-based Predictive Auxiliary Learning (BEPAL), a framework that
incorporates auxiliary training objectives to support policy optimization.
BEPAL follows the centralized training with decentralized execution paradigm.
Each agent learns a belief model that predicts unobservable state information,
such as other agents' rewards or motion directions, alo…
  - Tags: agent, multi-agent
  - PDF: http://arxiv.org/pdf/2511.01078v1
- [Bootstrap Off-policy with World Model](http://arxiv.org/abs/2511.00423v1)
  - Authors: Guojian Zhan, Likun Wang, Xiangteng Zhang, Jiaxin Gao, Masayoshi Tomizuka, Shengbo Eben Li
  - Abstract: Online planning has proven effective in reinforcement learning (RL) for
improving sample efficiency and final performance. However, using planning for
environment interaction inevitably introduces a divergence between the
collected data and the policy's actual behaviors, degrading both model learning
and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy
with WOrld Model), a framework that tightly integrates planning and off-policy
learning through a bootstrap loop: the policy initializes the planner, and the
planner refines actions to bootstrap the policy through behavior alignment.
This loop is supported by a jointly learned world model, which enables the
planner to simulate future trajectories and provides value targets to
facilitate policy improvement. The core…
  - Tags: planning
  - PDF: http://arxiv.org/pdf/2511.00423v1
- [ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction
  and Reasoning Corpus](http://arxiv.org/abs/2511.00162v2)
  - Authors: Michael D. Moffitt
  - Abstract: The Abstraction and Reasoning Corpus remains one of the most compelling and
challenging benchmarks for tracking progress toward achieving Artificial
General Intelligence. In contrast to other evaluation datasets designed to
assess an agent's task-specific skills or accumulated knowledge, the ARC-AGI
suite is specifically targeted at measuring skill acquisition efficiency, a
trait that has (so far) been lacking in even the most sophisticated machine
learning systems. For algorithms that require extensive intra-task exemplars, a
significant constraint imposed by ARC-AGI is the modest cardinality of its
demonstration set, comprising a small number of $\langle$ input, output
$\rangle$ grids per task specifying the corresponding transformation. To
embellish the space of viable sample pairs, th…
  - Tags: agent, benchmark, evaluation, reasoning
  - PDF: http://arxiv.org/pdf/2511.00162v2
- [When AI Trading Agents Compete: Adverse Selection of Meta-Orders by
  Reinforcement Learning-Based Market Making](http://arxiv.org/abs/2510.27334v1)
  - Authors: Ali Raza Jafree, Konark Jain, Nick Firoozye
  - Abstract: We investigate the mechanisms by which medium-frequency trading agents are
adversely selected by opportunistic high-frequency traders. We use
reinforcement learning (RL) within a Hawkes Limit Order Book (LOB) model in
order to replicate the behaviours of high-frequency market makers. In contrast
to the classical models with exogenous price impact assumptions, the Hawkes
model accounts for endogenous price impact and other key properties of the
market (Jain et al. 2024a). Given the real-world impracticalities of the market
maker updating strategies for every event in the LOB, we formulate the
high-frequency market making agent via an impulse control reinforcement
learning framework (Jain et al. 2025). The RL used in the simulation utilises
Proximal Policy Optimisation (PPO) and self-imitat…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.27334v1
- [Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking
  and Meta-Features](http://arxiv.org/abs/2511.00126v1)
  - Authors: Lu Bowen
  - Abstract: Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,
2022) have achieved strong average accuracy but remain unreliable in complex
long-tail driving scenarios. These limitations reveal the weakness of the
prevailing "one-model-fits-all" paradigm, particularly in safety-critical urban
contexts where simpler physics-based models can occasionally outperform
advanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic
multi-expert gating framework that adaptively selects the most reliable
trajectory predictor among a physics-informed LSTM, a Transformer, and a
fine-tuned GameFormer on a per-sample basis.
  Our method leverages internal model signals (meta-features) such as stability
and uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be
substa…
  - Tags: autonomy, evaluation
  - PDF: http://arxiv.org/pdf/2511.00126v1
- [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS
  Operations](http://arxiv.org/abs/2510.26905v1)
  - Authors: Pedro Antonio Alarcón Granadeno, Arturo Miguel Bernal Russell, Sofia Nelson, Demetrius Hernandez, Maureen Petterson, Michael Murphy, Walter J. Scheirer, Jane Cleland-Huang
  - Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.
  - Tags: autonomy, planning, reasoning
  - PDF: http://arxiv.org/pdf/2510.26905v1
- [Agentic AI Home Energy Management System: A Large Language Model
  Framework for Residential Load Scheduling](http://arxiv.org/abs/2510.26603v1)
  - Authors: Reda El Makroum, Sebastian Zwickl-Bernhard, Lukas Kranzl
  - Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orch…
  - Tags: agent, autonomy, benchmark, evaluation, reasoning, tool-use, workflow
  - PDF: http://arxiv.org/pdf/2510.26603v1
- [Adaptive Context Length Optimization with Low-Frequency Truncation for
  Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2510.26389v1)
  - Authors: Wenchang Duan, Yaoliang Yu, Jiwan He, Yi Shi
  - Abstract: Recently, deep multi-agent reinforcement learning (MARL) has demonstrated
promising performance for solving challenging tasks, such as long-term
dependencies and non-Markovian environments. Its success is partly attributed
to conditioning policies on large fixed context length. However, such large
fixed context lengths may lead to limited exploration efficiency and redundant
information. In this paper, we propose a novel MARL framework to obtain
adaptive and effective contextual information. Specifically, we design a
central agent that dynamically optimizes context length via temporal gradient
analysis, enhancing exploration to facilitate convergence to global optima in
MARL. Furthermore, to enhance the adaptive optimization capability of the
context length, we present an efficient input…
  - Tags: agent, multi-agent
  - PDF: http://arxiv.org/pdf/2510.26389v1
- [Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in
  Web Games](http://arxiv.org/abs/2510.26298v1)
  - Authors: Jingran Zhang, Ning Li, Justin Cui
  - Abstract: OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,
enabling the model to analyze webpages, process user intents, and execute
cursor and keyboard inputs directly within the browser. While its capacity for
information retrieval tasks has been demonstrated, its performance in dynamic,
interactive environments remains less explored. In this study, we conduct an
early evaluation of Atlas's web interaction capabilities using browser-based
games as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,
and Stein.world. We employ in-game performance scores as quantitative metrics
to assess performance across different task types. Our results show that Atlas
performs strongly in logical reasoning tasks like Sudoku, completing puzzles
significantly faster than hu…
  - Tags: agent, evaluation, reasoning, retrieval
  - PDF: http://arxiv.org/pdf/2510.26298v1
- [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient
  Reasoning](http://arxiv.org/abs/2510.26167v1)
  - Authors: Renhao Li, Jianhong Tu, Yang Su, Hamid Alinejad-Rokny, Derek F. Wong, Junyang Lin, Min Yang
  - Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on…
  - Tags: agent, benchmark, evaluation, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.26167v1
- [Learning Geometry: A Framework for Building Adaptive Manifold Models
  through Metric Optimization](http://arxiv.org/abs/2510.26068v1)
  - Authors: Di Zhang
  - Abstract: This paper proposes a novel paradigm for machine learning that moves beyond
traditional parameter optimization. Unlike conventional approaches that search
for optimal parameters within a fixed geometric space, our core idea is to
treat the model itself as a malleable geometric entity. Specifically, we
optimize the metric tensor field on a manifold with a predefined topology,
thereby dynamically shaping the geometric structure of the model space. To
achieve this, we construct a variational framework whose loss function
carefully balances data fidelity against the intrinsic geometric complexity of
the manifold. The former ensures the model effectively explains observed data,
while the latter acts as a regularizer, penalizing overly curved or irregular
geometries to encourage simpler models…
  - Tags: autonomy, tool-use
  - PDF: http://arxiv.org/pdf/2510.26068v1
- [The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,
  and Long-Horizon Task Execution](http://arxiv.org/abs/2510.25726v1)
  - Authors: Junlong Li, Wenshuo Zhao, Jian Zhao, Weihao Zeng, Haoze Wu, Xiaochen Wang, Rui Ge, Yuxuan Cao, Yuzhen Huang, Wei Liu, Junteng Liu, Zhaochen Su, Yiyang Guo, Fan Zhou, Lueyang Zhang, Juan Michelini, Xingyao Wang, Xiang Yue, Shuyan Zhou, Graham Neubig, Junxian He
  - Abstract: Real-world language agents must handle complex, multi-step workflows across
diverse Apps. For instance, an agent may manage emails by coordinating with
calendars and file systems, or monitor a production database to detect
anomalies and generate reports following an operating manual. However, existing
language agent benchmarks often focus on narrow domains or simplified tasks
that lack the diversity, realism, and long-horizon complexity required to
evaluate agents' real-world performance. To address this gap, we introduce the
Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering
diverse Apps and tools, realistic environment setup, and reliable
execution-based evaluation. Toolathlon spans 32 software applications and 604
tools, ranging from everyday platforms such…
  - Tags: agent, benchmark, evaluation, tool-use, workflow
  - PDF: http://arxiv.org/pdf/2510.25726v1
- [Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM
  Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System](http://arxiv.org/abs/2510.25588v1)
  - Authors: Eranga Bandara, Ross Gore, Atmaram Yarlagadda, Anita H. Clayton, Preston Samuel, Christopher K. Rhea, Sachin Shetty
  - Abstract: The diagnosis of most mental disorders, including psychiatric evaluations,
primarily depends on dialogues between psychiatrists and patients. This
subjective process can lead to variability in diagnoses across clinicians and
patients, resulting in inconsistencies and challenges in achieving reliable
outcomes. To address these issues and standardize psychiatric diagnoses, we
propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss
Reasoning LLM-enabled Decision Support System for the clinical diagnosis of
mental disorders. Our approach leverages fine-tuned LLMs trained on
conversational datasets involving psychiatrist-patient interactions focused on
mental health conditions (e.g., depression). The diagnostic predictions from
individual models are aggregated through a c…
  - Tags: agent, evaluation, reasoning, workflow
  - PDF: http://arxiv.org/pdf/2510.25588v1
- [Off-policy Reinforcement Learning with Model-based Exploration
  Augmentation](http://arxiv.org/abs/2510.25529v1)
  - Authors: Likun Wang, Xiangteng Zhang, Yinuo Wang, Guojian Zhan, Wenxuan Wang, Haoyu Gao, Jingliang Duan, Shengbo Eben Li
  - Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.25529v1
- [AgentFold: Long-Horizon Web Agents with Proactive Context Management](http://arxiv.org/abs/2510.24699v1)
  - Authors: Rui Ye, Zhongwang Zhang, Kuan Li, Huifeng Yin, Zhengwei Tao, Yida Zhao, Liangcai Su, Liwen Zhang, Zile Qiao, Xinyu Wang, Pengjun Xie, Fei Huang, Siheng Chen, Jingren Zhou, Yong Jiang
  - Abstract: LLM-based web agents show immense promise for information seeking, yet their
effectiveness on long-horizon tasks is hindered by a fundamental trade-off in
context management. Prevailing ReAct-based agents suffer from context
saturation as they accumulate noisy, raw histories, while methods that fixedly
summarize the full history at each step risk the irreversible loss of critical
details. Addressing these, we introduce AgentFold, a novel agent paradigm
centered on proactive context management, inspired by the human cognitive
process of retrospective consolidation. AgentFold treats its context as a
dynamic cognitive workspace to be actively sculpted, rather than a passive log
to be filled. At each step, it learns to execute a `folding' operation, which
manages its historical trajectory at…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2510.24699v1
- [FunReason-MT Technical Report: Overcoming the Complexity Barrier in
  Multi-Turn Function Calling](http://arxiv.org/abs/2510.24645v1)
  - Authors: Zengzhuang Xu, Bingguang Hao, Zechuan Wang, Yuntao Wen, Maolin Wang, Yang Liu, Long Chen, Dong Wang, Yicheng Chen, Cunyin Peng, Chenyi Zhuang, Jinjie Gu, Leilei Gan, Xiangyu Zhao, Shi Gu
  - Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. F…
  - Tags: agent, autonomy, evaluation, multi-agent, tool-use
  - PDF: http://arxiv.org/pdf/2510.24645v1
- [OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL
  Reasoning](http://arxiv.org/abs/2510.23870v1)
  - Authors: Marianne Menglin Liu, Sai Ashish Somayajula, Syed Fahad Allam Shah, Sujith Ravi, Dan Roth
  - Abstract: We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge
2025, a bilingual benchmark requiring complex reasoning such as arithmetic,
commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding
the second-best system by more than 6% in execution accuracy (EX), with 55.0%
in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).
Our system follows an agentic framework with two components: Planner agent that
generates stepwise natural language plans, and SQL agent that converts these
plans into executable SQL. Since SQL agent reliably adheres to the plan, our
refinements focus on the planner. Unlike prior methods that rely on multiple
sub-agents for planning and suffer from orchestration overhead, we introduce a
feedback-guided meta-…
  - Tags: agent, benchmark, evaluation, planning, reasoning
  - PDF: http://arxiv.org/pdf/2510.23870v1
- [The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool
  Hallucination](http://arxiv.org/abs/2510.22977v1)
  - Authors: Chenlong Yin, Zeyang Sha, Shiwen Cui, Changhua Meng
  - Abstract: Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key
strategy for building Agents that "think then act." However, recent
observations, like OpenAI's o3, suggest a paradox: stronger reasoning often
coincides with increased hallucination, yet no prior work has systematically
examined whether reasoning enhancement itself causes tool hallucination. To
address this gap, we pose the central question: Does strengthening reasoning
increase tool hallucination? To answer this, we introduce SimpleToolHalluBench,
a diagnostic benchmark measuring tool hallucination in two failure modes: (i)
no tool available, and (ii) only distractor tools available. Through controlled
experiments, we establish three key findings. First, we demonstrate a causal
relationship: progressively enha…
  - Tags: agent, benchmark, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.22977v1
- [Generating Auxiliary Tasks with Reinforcement Learning](http://arxiv.org/abs/2510.22940v4)
  - Authors: Judah Goldfeder, Matthew So, Hod Lipson
  - Abstract: Auxiliary Learning (AL) is a form of multi-task learning in which a model
trains on auxiliary tasks to boost performance on a primary objective. While AL
has improved generalization across domains such as navigation, image
classification, and NLP, it often depends on human-labeled auxiliary tasks that
are costly to design and require domain expertise. Meta-learning approaches
mitigate this by learning to generate auxiliary tasks, but typically rely on
gradient based bi-level optimization, adding substantial computational and
implementation overhead. We propose RL-AUX, a reinforcement-learning (RL)
framework that dynamically creates auxiliary tasks by assigning auxiliary
labels to each training example, rewarding the agent whenever its selections
improve the performance on the primary task…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.22940v4
- [Agentic Meta-Orchestrator for Multi-task Copilots](http://arxiv.org/abs/2510.22781v2)
  - Authors: Xiaofeng Zhu, Yunshen Zhou
  - Abstract: Microsoft Copilot suites serve as the universal entry point for various
agents skilled in handling important tasks, ranging from assisting a customer
with product purchases to detecting vulnerabilities in corporate programming
code. Each agent can be powered by language models, software engineering
operations, such as database retrieval, and internal \& external knowledge. The
repertoire of a copilot can expand dynamically with new agents. This requires a
robust orchestrator that can distribute tasks from user prompts to the right
agents. In this work, we propose an Agentic Meta-orchestrator (AMO) for
handling multiple tasks and scalable agents in copilot services, which can
provide both natural language and action responses. We will also demonstrate
the planning that leverages meta-learn…
  - Tags: agent, planning, retrieval
  - PDF: http://arxiv.org/pdf/2510.22781v2
- [UCB-type Algorithm for Budget-Constrained Expert Learning](http://arxiv.org/abs/2510.22654v1)
  - Authors: Ilgam Latypov, Alexandra Suvorikova, Alexey Kroshnin, Alexander Gasnikov, Yuriy Dorn
  - Abstract: In many modern applications, a system must dynamically choose between several
adaptive learning algorithms that are trained online. Examples include model
selection in streaming environments, switching between trading strategies in
finance, and orchestrating multiple contextual bandit or reinforcement learning
agents. At each round, a learner must select one predictor among $K$ adaptive
experts to make a prediction, while being able to update at most $M \le K$ of
them under a fixed training budget.
  We address this problem in the \emph{stochastic setting} and introduce
\algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that
provides \emph{anytime regret guarantees}. Its confidence intervals are built
directly from realized losses, require no additional optimization, an…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.22654v1
- [Predictive Coding Enhances Meta-RL To Achieve Interpretable
  Bayes-Optimal Belief Representation Under Partial Observability](http://arxiv.org/abs/2510.22039v1)
  - Authors: Po-Chen Kuo, Han Hou, Will Dabney, Edgar Y. Walker
  - Abstract: Learning a compact representation of history is critical for planning and
generalization in partially observable environments. While meta-reinforcement
learning (RL) agents can attain near Bayes-optimal policies, they often fail to
learn the compact, interpretable Bayes-optimal belief states. This
representational inefficiency potentially limits the agent's adaptability and
generalization capacity. Inspired by predictive coding in neuroscience--which
suggests that the brain predicts sensory inputs as a neural implementation of
Bayesian inference--and by auxiliary predictive objectives in deep RL, we
investigate whether integrating self-supervised predictive coding modules into
meta-RL can facilitate learning of Bayes-optimal representations. Through state
machine simulation, we show that…
  - Tags: agent, planning
  - PDF: http://arxiv.org/pdf/2510.22039v1
- [Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware
  Meta-Verification and Trustworthy Reasoning with Structured Facts](http://arxiv.org/abs/2510.21557v1)
  - Authors: Hongwei Zhang, Ji Lu, Shiqing Jiang, Chenxiang Zhu, Li Xie, Chen Zhong, Haoran Chen, Yurui Zhu, Yongsheng Du, Yanqin Gao, Lingjun Huang, Baoli Wang, Fang Tan, Peng Zou
  - Abstract: Long-horizon reasoning in LLM-based agents often fails not from generative
weakness but from insufficient verification of intermediate reasoning. Co-Sight
addresses this challenge by turning reasoning into a falsifiable and auditable
process through two complementary mechanisms: Conflict-Aware Meta-Verification
(CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV
reformulates verification as conflict identification and targeted
falsification, allocating computation only to disagreement hotspots among
expert agents rather than to full reasoning chains. This bounds verification
cost to the number of inconsistencies and improves efficiency and reliability.
TRSF continuously organizes, validates, and synchronizes evidence across agents
through a structured facts module. By main…
  - Tags: agent, benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2510.21557v1
- [Causality Meets Locality: Provably Generalizable and Scalable Policy
  Learning for Networked Systems](http://arxiv.org/abs/2510.21427v1)
  - Authors: Hao Liang, Shuqing Shi, Yudi Zhang, Biwei Huang, Yali Du
  - Abstract: Large-scale networked systems, such as traffic, power, and wireless grids,
challenge reinforcement-learning agents with both scale and environment shifts.
To address these challenges, we propose GSAC (Generalizable and Scalable
Actor-Critic), a framework that couples causal representation learning with
meta actor-critic learning to achieve both scalability and domain
generalization. Each agent first learns a sparse local causal mask that
provably identifies the minimal neighborhood variables influencing its
dynamics, yielding exponentially tight approximately compact representations
(ACRs) of state and domain factors. These ACRs bound the error of truncating
value functions to $\kappa$-hop neighborhoods, enabling efficient learning on
graphs. A meta actor-critic then trains a shared polic…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.21427v1
- [CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel
  Optimization](http://arxiv.org/abs/2511.01884v2)
  - Authors: Zijian Zhang, Rong Wang, Shiyang Li, Yuebo Luo, Mingyi Hong, Caiwen Ding
  - Abstract: Developing efficient CUDA kernels is increasingly critical for AI
applications such as large-scale LLM training. However, manual kernel design is
both costly and time-consuming, motivating automatic approaches that leverage
LLMs for code generation. Existing methods for automatic kernel generation,
however, often produce low-efficiency kernels, incur high computational
overhead, and fail to generalize across settings. In this work, we propose
CudaForge, a training-free multi-agent workflow for CUDA kernel generation and
optimization. Our workflow is inspired by the iterative workflow of human
experts, which contains steps such as developing initial kernels, testing
correctness, analyzing hardware feedback, and iterative improvement. More
specifically, CudaForge employs two LLM agents: a C…
  - Tags: agent, evaluation, multi-agent, workflow
  - PDF: http://arxiv.org/pdf/2511.01884v2
- [Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal
  Evidence](http://arxiv.org/abs/2510.20579v1)
  - Authors: Jiahao Meng, Xiangtai Li, Haochen Wang, Yue Tan, Tao Zhang, Lingdong Kong, Yunhai Tong, Anran Wang, Zhiyang Teng, Yujing Wang, Zhuochen Wang
  - Abstract: Most video reasoning models only generate textual reasoning traces without
indicating when and where key evidence appears. Recent models such as OpenAI-o3
have sparked wide interest in evidence-centered reasoning for images, yet
extending this ability to videos is more challenging, as it requires joint
temporal tracking and spatial localization across dynamic scenes. We introduce
Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal
evidence into video reasoning, and carefully collect training data and design
training strategies to address the aforementioned challenges. The model
highlights key timestamps, objects, and bounding boxes alongside its answers,
allowing reasoning to be grounded in concrete visual observations. To enable
this functionality, we first cura…
  - Tags: agent, benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2510.20579v1
- [Merge and Conquer: Evolutionarily Optimizing AI for 2048](http://arxiv.org/abs/2510.20205v1)
  - Authors: Maggie Bai, Ava Kim Cohen, Eleanor Koss, Charlie Lichtenbaum
  - Abstract: Optimizing artificial intelligence (AI) for dynamic environments remains a
fundamental challenge in machine learning research. In this paper, we examine
evolutionary training methods for optimizing AI to solve the game 2048, a 2D
sliding puzzle. 2048, with its mix of strategic gameplay and stochastic
elements, presents an ideal playground for studying decision-making, long-term
planning, and dynamic adaptation. We implemented two distinct systems: a
two-agent metaprompting system where a "thinker" large language model (LLM)
agent refines gameplay strategies for an "executor" LLM agent, and a
single-agent system based on refining a value function for a limited Monte
Carlo Tree Search. We also experimented with rollback features to avoid
performance degradation. Our results demonstrate the…
  - Tags: agent, planning
  - PDF: http://arxiv.org/pdf/2510.20205v1
- [Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table
  Understanding](http://arxiv.org/abs/2510.20176v2)
  - Authors: Yuhang Zhou, Mingrui Zhang, Ke Li, Mingyi Wang, Qiao Liu, Qifei Wang, Jiayi Liu, Fei Liu, Serena Li, Weiwei Li, Mingze Gao, Abhishek Kumar, Xiangjun Fan, Zhuokai Zhao, Lizhu Zhang
  - Abstract: Understanding and reasoning over tables is a critical capability for many
real-world applications. Large language models (LLMs) have shown promise on
this task, but current approaches remain limited. Fine-tuning based methods
strengthen language reasoning; yet they are prone to arithmetic errors and
hallucination. In contrast, tool-based methods enable precise table
manipulation but rely on rigid schemas and lack semantic understanding. These
complementary drawbacks highlight the need for approaches that integrate robust
reasoning with reliable table processing. In this work, we propose
Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into
three specialized roles: planning, coding, and answering. This design enables
each agent to focus on a specific aspect of the…
  - Tags: agent, multi-agent, planning, reasoning, tool-use, workflow
  - PDF: http://arxiv.org/pdf/2510.20176v2
- [Learning from Supervision with Semantic and Episodic Memory: A
  Reflective Approach to Agent Adaptation](http://arxiv.org/abs/2510.19897v1)
  - Authors: Jackson Hassell, Dan Zhang, Hannah Kim, Tom Mitchell, Estevam Hruschka
  - Abstract: We investigate how agents built on pretrained large language models can learn
target classification functions from labeled examples without parameter
updates. While conventional approaches like fine-tuning are often costly,
inflexible, and opaque, we propose a memory-augmented framework that leverages
both labeled data and LLM-generated critiques. Our framework uses episodic
memory to store instance-level critiques-capturing specific past
experiences-and semantic memory to distill these into reusable, task-level
guidance. Across a diverse set of tasks, incorporating critiques yields up to a
24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines
that rely only on labels. Through extensive empirical evaluation, we uncover
distinct behavioral differences between OpenAI…
  - Tags: agent, evaluation, memory, retrieval
  - PDF: http://arxiv.org/pdf/2510.19897v1
- [Memo: Training Memory-Efficient Embodied Agents with Reinforcement
  Learning](http://arxiv.org/abs/2510.19732v1)
  - Authors: Gunshi Gupta, Karmesh Yadav, Zsolt Kira, Yarin Gal, Rahaf Aljundi
  - Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement l…
  - Tags: agent, benchmark, memory, retrieval
  - PDF: http://arxiv.org/pdf/2510.19732v1
- [AndroidControl-Curated: Revealing the True Potential of GUI Agents
  through Benchmark Purification](http://arxiv.org/abs/2510.18488v1)
  - Authors: Ho Fai Leung, Xiaoyan Xi, Fei Zuo
  - Abstract: On-device virtual assistants like Siri and Google Assistant are increasingly
pivotal, yet their capabilities are hamstrung by a reliance on rigid,
developer-dependent APIs. GUI agents offer a powerful, API-independent
alternative, but their adoption is hindered by the perception of poor
performance, as even the best models (e.g. Qwen3-VL-235B) scores are capped at
around 60% on benchmarks like AndroidControl, far from viability for real-world
use. Our research reveals that issue lies not only with the models but with the
benchmarks themselves. We identified notable shortcomings in AndroidControl,
including ambiguities and factual errors, which systematically underrates agent
capabilities. To address this critical oversight, we enhanced AndroidControl
into AndroidControl-Curated, a refined…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2510.18488v1
- [PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of
  Multi-turn Exploits](http://arxiv.org/abs/2510.17947v2)
  - Authors: Neeladri Bhuiya, Madhav Aggarwal, Diptanshu Purwar
  - Abstract: Large Language Models (LLMs) are improving at an exceptional rate. With the
advent of agentic workflows, multi-turn dialogue has become the de facto mode
of interaction with LLMs for completing long and complex tasks. While LLM
capabilities continue to improve, they remain increasingly susceptible to
jailbreaking, especially in multi-turn scenarios where harmful intent can be
subtly injected across the conversation to produce nefarious outcomes. While
single-turn attacks have been extensively explored, adaptability, efficiency
and effectiveness continue to remain key challenges for their multi-turn
counterparts. To address these gaps, we present PLAGUE, a novel plug-and-play
framework for designing multi-turn attacks inspired by lifelong-learning
agents. PLAGUE dissects the lifetime of a…
  - Tags: agent, evaluation, planning, tool-use, workflow
  - PDF: http://arxiv.org/pdf/2510.17947v2
- [From Pixels to People: Satellite-Based Mapping and Quantification of
  Riverbank Erosion and Lost Villages in Bangladesh](http://arxiv.org/abs/2510.17198v1)
  - Authors: M Saifuzzaman Rafat, Mohd Ruhul Ameen, Akif Islam, Abu Saleh Musa Miah, Jungpil Shin
  - Abstract: The great rivers of Bangladesh, arteries of commerce and sustenance, are also
agents of relentless destruction. Each year, they swallow whole villages and
vast tracts of farmland, erasing communities from the map and displacing
thousands of families. To track this slow-motion catastrophe has, until now,
been a Herculean task for human analysts. Here we show how a powerful
general-purpose vision model, the Segment Anything Model (SAM), can be adapted
to this task with remarkable precision. To do this, we assembled a new dataset
- a digital chronicle of loss compiled from historical Google Earth imagery of
Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur
Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,
this dataset is the first to i…
  - Tags: agent, tool-use
  - PDF: http://arxiv.org/pdf/2510.17198v1
- [What Limits Agentic Systems Efficiency?](http://arxiv.org/abs/2510.16276v1)
  - Authors: Song Bian, Minghao Yan, Anand Jayarajan, Gennady Pekhimenko, Shivaram Venkataraman
  - Abstract: Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have
demonstrated strong reasoning capabilities. To further enhance LLM
capabilities, recent agentic systems, such as Deep Research, incorporate web
interactions into LLM reasoning to mitigate uncertainties and reduce potential
errors. However, existing research predominantly focuses on reasoning
performance, often neglecting the efficiency of agentic systems. In this work,
we present a comprehensive empirical study that identifies efficiency
bottlenecks in web-interactive agentic systems. We decompose end-to-end latency
into two primary components: LLM API latency and web environment latency. We
conduct a comprehensive empirical study across 15 models and 5 providers to
demonstrate high variability in API-based agentic syst…
  - Tags: agent, benchmark, evaluation, reasoning
  - PDF: http://arxiv.org/pdf/2510.16276v1
- [ScholarEval: Research Idea Evaluation Grounded in Literature](http://arxiv.org/abs/2510.16234v1)
  - Authors: Hanane Nour Moussa, Patrick Queiroz Da Silva, Daniel Adu-Ampratwum, Alyson East, Zitong Lu, Nikki Puccetti, Mingyi Xue, Huan Sun, Bodhisattwa Prasad Majumder, Sachin Kumar
  - Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher…
  - Tags: agent, evaluation, reasoning, retrieval, tool-use
  - PDF: http://arxiv.org/pdf/2510.16234v1
- [Self-evolving expertise in complex non-verifiable subject domains:
  dialogue as implicit meta-RL](http://arxiv.org/abs/2510.15772v1)
  - Authors: Richard M. Bailey
  - Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this ga…
  - Tags: agent, memory, planning, reflection, tool-use
  - PDF: http://arxiv.org/pdf/2510.15772v1
- [GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device](http://arxiv.org/abs/2510.15620v1)
  - Authors: Jiahao Zhou, Chengliang Lin, Dingji Li, Mingkai Dong, Haibo Chen
  - Abstract: Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memo…
  - Tags: agent, benchmark, memory, retrieval
  - PDF: http://arxiv.org/pdf/2510.15620v1
- [Foundation Models for Scientific Discovery: From Paradigm Enhancement to
  Paradigm Transition](http://arxiv.org/abs/2510.15280v1)
  - Authors: Fan Liu, Jindong Han, Tengfei Lyu, Weijia Zhang, Zhe-Rui Yang, Lu Dai, Cancheng Liu, Hao Liu
  - Abstract: Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the
landscape of scientific research. Beyond accelerating tasks such as hypothesis
generation, experimental design, and result interpretation, they prompt a more
fundamental question: Are FMs merely enhancing existing scientific
methodologies, or are they redefining the way science is conducted? In this
paper, we argue that FMs are catalyzing a transition toward a new scientific
paradigm. We introduce a three-stage framework to describe this evolution: (1)
Meta-Scientific Integration, where FMs enhance workflows within traditional
paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active
collaborators in problem formulation, reasoning, and discovery; and (3)
Autonomous Scientific Discovery, where FMs operate as…
  - Tags: agent, autonomy, reasoning, reflection, workflow
  - PDF: http://arxiv.org/pdf/2510.15280v1
- [Algorithms for dynamic scheduling in manufacturing, towards digital
  factories Improving Deadline Feasibility and Responsiveness via Temporal
  Networks](http://arxiv.org/abs/2510.16047v1)
  - Authors: Ioan Hedea
  - Abstract: Modern manufacturing systems must meet hard delivery deadlines while coping
with stochastic task durations caused by process noise, equipment variability,
and human intervention. Traditional deterministic schedules break down when
reality deviates from nominal plans, triggering costly last-minute repairs.
This thesis combines offline constraint-programming (CP) optimisation with
online temporal-network execution to create schedules that remain feasible
under worst-case uncertainty. First, we build a CP model of the flexible
job-shop with per-job deadline tasks and insert an optimal buffer $\Delta^*$ to
obtain a fully pro-active baseline. We then translate the resulting plan into a
Simple Temporal Network with Uncertainty (STNU) and verify dynamic
controllability, which guarantees that a r…
  - Tags: benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2510.16047v1
- [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent
  That Improves Without Labels or Model Updates](http://arxiv.org/abs/2510.14900v1)
  - Authors: Wen-Kwang Tsao, Yao-Ching Yu, Chien-Ming Huang
  - Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(L…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.14900v1
- [Agentic NL2SQL to Reduce Computational Costs](http://arxiv.org/abs/2510.14808v1)
  - Authors: Dominik Jehle, Lennart Purucker, Frank Hutter
  - Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively req…
  - Tags: agent, reasoning
  - PDF: http://arxiv.org/pdf/2510.14808v1
- [CodeEvolve: An open source evolutionary coding agent for algorithm
  discovery and optimization](http://arxiv.org/abs/2510.14150v1)
  - Authors: Henrique Assumpção, Diego Ferreira, Leandro Campos, Fabricio Murai
  - Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-s…
  - Tags: agent, benchmark, evaluation
  - PDF: http://arxiv.org/pdf/2510.14150v1
- [From Minimal Existence to Human Definition: The CES-IMU-HSG Theoretical
  Framework](http://arxiv.org/abs/2510.13400v1)
  - Authors: Kei Itoh
  - Abstract: This study presents an inter-universal mathematical-logical framework
constructed upon the minimal axiom Cogito, ergo sum (CES), integrating the
Intermediate Meta-Universe (IMU) and the Hierarchical State Grid (HSG). The CES
defines existence as a reflexive correspondence --'to be' and 'to be
sayable'--and positions any formal system, including ZFC or HoTT, as an
attachable extension atop this minimal structure. The IMU functions as a
registry of axiomatic dependencies that connect heterogeneous theories,
employing the Institution-theoretic framework to ensure coherent
inter-theoretical linkages. The HSG concretizes these ideas through categorical
construction, defined by three orthogonal axes: the state-depth axis, the
mapping-hierarchy axis, and the temporal axis incorporating the princ…
  - Tags: autonomy
  - PDF: http://arxiv.org/pdf/2510.13400v1
- [Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image
  Perception, Transformation, and Reasoning](http://arxiv.org/abs/2510.12712v3)
  - Authors: Xingang Guo, Utkarsh Tyagi, Advait Gosai, Paula Vergara, Jayeon Park, Ernesto Gabriel Hernández Montoya, Chen Bo Calvin Zhang, Bin Hu, Yunzhong He, Bing Liu, Rakshith Sharma Srinivasa
  - Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in
real-world scenarios where user-provided images are often imperfect, requiring
active image manipulations such as cropping, editing, or enhancement to uncover
salient visual cues. Beyond static visual perception, MLLMs must also think
with images: dynamically transforming visual content and integrating it with
other tools to solve complex tasks. However, this shift from treating vision as
passive context to a manipulable cognitive workspace remains underexplored.
Most existing benchmarks still follow a think about images paradigm, where
images are regarded as static inputs. To address this gap, we introduce
VisualToolBench, a visual tool-use reasoning benchmark that rigorously
evaluates MLLMs' ability to perceive, transf…
  - Tags: benchmark, evaluation, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.12712v3
- [From Literal to Liberal: A Meta-Prompting Framework for Eliciting
  Human-Aligned Exception Handling in Large Language Models](http://arxiv.org/abs/2510.12864v1)
  - Authors: Imran Khan
  - Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive sch…
  - Tags: agent, autonomy, benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2510.12864v1
- [Learning-To-Measure: In-context Active Feature Acquisition](http://arxiv.org/abs/2510.12624v1)
  - Authors: Yuta Kobayashi, Zilin Jing, Jiayu Yao, Hongseok Namkoong, Shalmali Joshi
  - Abstract: Active feature acquisition (AFA) is a sequential decision-making problem
where the goal is to improve model performance for test instances by adaptively
selecting which features to acquire. In practice, AFA methods often learn from
retrospective data with systematic missingness in the features and limited
task-specific labels. Most prior work addresses acquisition for a single
predetermined task, limiting scalability. To address this limitation, we
formalize the meta-AFA problem, where the goal is to learn acquisition policies
across various tasks. We introduce Learning-to-Measure (L2M), which consists of
i) reliable uncertainty quantification over unseen tasks, and ii) an
uncertainty-guided greedy feature acquisition agent that maximizes conditional
mutual information. We demonstrate a s…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2510.12624v1
- [PromptFlow: Training Prompts Like Neural Networks](http://arxiv.org/abs/2510.12246v1)
  - Authors: Jingyi Wang, Hongyuan Zhu, Ye Niu, Yunhui Deng
  - Abstract: Large Language Models (LLMs) have demonstrated profound impact on Natural
Language Processing (NLP) tasks. However, their effective deployment across
diverse domains often require domain-specific adaptation strategies, as generic
models may underperform when faced with specialized data distributions. Recent
advances in prompt engineering (PE) offer a promising alternative to extensive
retraining by refining input instructions to align LLM outputs with task
objectives. This paradigm has emerged as a rapid and versatile approach for
model fine-tuning. Despite its potential, manual prompt design remains
labor-intensive and heavily depends on specialized expertise, often requiring
iterative human effort to achieve optimal formulations. To address this
limitation, automated prompt engineering…
  - Tags: autonomy
  - PDF: http://arxiv.org/pdf/2510.12246v1
- [ResearStudio: A Human-Intervenable Framework for Building Controllable
  Deep-Research Agents](http://arxiv.org/abs/2510.12194v1)
  - Authors: Linyi Yang, Yixuan Weng
  - Abstract: Current deep-research agents run in a ''fire-and-forget'' mode: once started,
they give users no way to fix errors or add expert knowledge during execution.
We present ResearStudio, the first open-source framework that places real-time
human control at its core. The system follows a Collaborative Workshop design.
A hierarchical Planner-Executor writes every step to a live
''plan-as-document,'' a fast communication layer streams each action, file
change, and tool call to a web interface. At any moment, the user can pause the
run, edit the plan or code, run custom commands, and resume -- switching
smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In
fully autonomous mode, ResearStudio achieves state-of-the-art results on the
GAIA benchmark, surpassing systems like Op…
  - Tags: agent, autonomy, benchmark, evaluation, planning, tool-use
  - PDF: http://arxiv.org/pdf/2510.12194v1
- [Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative
  Study of Market Leading Agentic AI Products](http://arxiv.org/abs/2510.11558v1)
  - Authors: Komal Gupta, Aditya Shrivastava
  - Abstract: Governance of data, compliance, and business privacy matters, particularly
for healthcare and finance businesses. Since the recent emergence of AI
enterprise AI assistants enhancing business productivity, safeguarding private
data and compliance is now a priority. With the implementation of AI assistants
across the enterprise, the zero data retention can be achieved by implementing
zero data retention policies by Large Language Model businesses like Open AI
and Anthropic and Meta. In this work, we explore zero data retention policies
for the Enterprise apps of large language models (LLMs). Our key contribution
is defining the architectural, compliance, and usability trade-offs of such
systems in parallel. In this research work, we examine the development of
commercial AI assistants with t…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.11558v1
- [Evaluating Language Models' Evaluations of Games](http://arxiv.org/abs/2510.10930v1)
  - Authors: Katherine M. Collins, Cedegao E. Zhang, Graham Todd, Lance Ying, Mauricio Barba da Costa, Ryan Liu, Prafull Sharma, Adrian Weller, Ionatan Kuperwajs, Lionel Wong, Joshua B. Tenenbaum, Thomas L. Griffiths
  - Abstract: Reasoning is not just about solving problems -- it is also about evaluating
which problems are worth solving at all. Evaluations of artificial intelligence
(AI) systems primarily focused on problem solving, historically by studying how
models play games such as chess and Go. In this paper, we advocate for a new
paradigm that assesses AI systems' evaluation of games. First, we introduce a
formalism for evaluating such evaluations. We then leverage a large-scale
dataset of over $100$ novel board games and over 450 human judgments to compare
evaluations produced by modern language and reasoning models against those of
people and symbolic computational agents. We consider two kinds of evaluative
queries: assessing the payoff (or fairness) and the funness of games. These
queries span two dimen…
  - Tags: agent, evaluation, reasoning
  - PDF: http://arxiv.org/pdf/2510.10930v1
- [LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent
  Heuristics](http://arxiv.org/abs/2510.10813v1)
  - Authors: Enric Junque de Fortuny, Veronica Roberta Cappelli
  - Abstract: Large Language Models (LLMs) are increasingly applied to domains that require
reasoning about other agents' behavior, such as negotiation, policy design, and
market simulation, yet existing research has mostly evaluated their adherence
to equilibrium play or their exhibited depth of reasoning. Whether they display
genuine strategic thinking, understood as the coherent formation of beliefs
about other agents, evaluation of possible actions, and choice based on those
beliefs, remains unexplored. We develop a framework to identify this ability by
disentangling beliefs, evaluation, and choice in static, complete-information
games, and apply it across a series of non-cooperative environments. By jointly
analyzing models' revealed choices and reasoning traces, and introducing a new
context-free…
  - Tags: agent, evaluation, reasoning
  - PDF: http://arxiv.org/pdf/2510.10813v1
- [Multitask Learning with Learned Task Relationships](http://arxiv.org/abs/2510.10570v1)
  - Authors: Zirui Wan, Stefan Vlaski
  - Abstract: Classical consensus-based strategies for federated and decentralized learning
are statistically suboptimal in the presence of heterogeneous local data or
task distributions. As a result, in recent years, there has been growing
interest in multitask or personalized strategies, which allow individual agents
to benefit from one another in pursuing locally optimal models without
enforcing consensus. Existing strategies require either precise prior knowledge
of the underlying task relationships or are fully non-parametric and instead
rely on meta-learning or proximal constructions. In this work, we introduce an
algorithmic framework that strikes a balance between these extremes. By
modeling task relationships through a Gaussian Markov Random Field with an
unknown precision matrix, we develop a…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.10570v1
- [Don't Just Fine-tune the Agent, Tune the Environment](http://arxiv.org/abs/2510.10197v1)
  - Authors: Siyuan Lu, Zechuan Wang, Hongxuan Zhang, Qintong Wu, Leilei Gan, Chenyi Zhuang, Jinjie Gu, Tao Lin
  - Abstract: Large Language Model (LLM) agents show great promise for complex, multi-turn
tool-use tasks, but their development is often hampered by the extreme scarcity
of high-quality training data. Supervised fine-tuning (SFT) on synthetic data
leads to overfitting, whereas standard reinforcement learning (RL) struggles
with a critical cold-start problem and training instability. To address these
challenges, we introduce $\textbf{Environment Tuning}$, a novel training
paradigm that enables agents to learn complex behaviors directly from problem
instances without relying on pre-collected expert trajectories.
$\textbf{Environment Tuning}$ orchestrates this learning process through a
structured curriculum, actionable environment augmentation that provides
corrective feedback, and fine-grained progress…
  - Tags: agent, benchmark, tool-use
  - PDF: http://arxiv.org/pdf/2510.10197v1
- [Multi-Scale Diffusion Transformer for Jointly Simulating User Mobility
  and Mobile Traffic Pattern](http://arxiv.org/abs/2510.10158v1)
  - Authors: Ziyi Liu, Qingyue Long, Zhiwen Xue, Huandong Wang, Yong Li
  - Abstract: User mobility trajectory and mobile traffic data are essential for a wide
spectrum of applications including urban planning, network optimization, and
emergency management. However, large-scale and fine-grained mobility data
remains difficult to obtain due to privacy concerns and collection costs,
making it essential to simulate realistic mobility and traffic patterns. User
trajectories and mobile traffic are fundamentally coupled, reflecting both
physical mobility and cyber behavior in urban environments. Despite this strong
interdependence, existing studies often model them separately, limiting the
ability to capture cross-modal dynamics. Therefore, a unified framework is
crucial. In this paper, we propose MSTDiff, a Multi-Scale Diffusion Transformer
for joint simulation of mobile traff…
  - Tags: planning
  - PDF: http://arxiv.org/pdf/2510.10158v1
- [StreamingVLM: Real-Time Understanding for Infinite Video Streams](http://arxiv.org/abs/2510.09608v1)
  - Authors: Ruyi Xu, Guangxuan Xiao, Yukang Chen, Liuning He, Kelly Peng, Yao Lu, Song Han
  - Abstract: Vision-language models (VLMs) could power real-time assistants and autonomous
agents, but they face a critical challenge: understanding near-infinite video
streams without escalating latency and memory usage. Processing entire videos
with full attention leads to quadratic computational costs and poor performance
on long videos. Meanwhile, simple sliding window methods are also flawed, as
they either break coherence or suffer from high latency due to redundant
recomputation. In this paper, we introduce StreamingVLM, a model designed for
real-time, stable understanding of infinite visual input. Our approach is a
unified framework that aligns training with streaming inference. During
inference, we maintain a compact KV cache by reusing states of attention sinks,
a short window of recent visi…
  - Tags: agent, autonomy, benchmark, evaluation, memory
  - PDF: http://arxiv.org/pdf/2510.09608v1
- [The Idola Tribus of AI: Large Language Models tend to perceive order
  where none exists](http://arxiv.org/abs/2510.09709v1)
  - Authors: Shin-nosuke Ishikawa, Masato Todo, Taiki Ogihara, Hirotsugu Ohba
  - Abstract: We present a tendency of large language models (LLMs) to generate absurd
patterns despite their clear inappropriateness in a simple task of identifying
regularities in number series. Several approaches have been proposed to apply
LLMs to complex real-world tasks, such as providing knowledge through
retrieval-augmented generation and executing multi-step tasks using AI agent
frameworks. However, these approaches rely on the logical consistency and
self-coherence of LLMs, making it crucial to evaluate these aspects and
consider potential countermeasures. To identify cases where LLMs fail to
maintain logical consistency, we conducted an experiment in which LLMs were
asked to explain the patterns in various integer sequences, ranging from
arithmetic sequences to randomly generated integer ser…
  - Tags: agent, reasoning, retrieval
  - PDF: http://arxiv.org/pdf/2510.09709v1
- [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](http://arxiv.org/abs/2510.08790v1)
  - Authors: Guangya Wan, Mingyang Ling, Xiaoqi Ren, Rujun Han, Sheng Li, Zizhao Zhang
  - Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress…
  - Tags: agent, benchmark, multi-agent, planning, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.08790v1
- [Unified World Models: Memory-Augmented Planning and Foresight for Visual
  Navigation](http://arxiv.org/abs/2510.08713v1)
  - Authors: Yifei Dong, Fengyi Wu, Guangyu Chen, Zhi-Qi Cheng, Qiyu Hu, Yuxuan Zhou, Jingdong Sun, Jun-Yan He, Qi Dai, Alexander G Hauptmann
  - Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues…
  - Tags: agent, benchmark, memory, planning, reasoning
  - PDF: http://arxiv.org/pdf/2510.08713v1
- [The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from
  Planning with Actions to Planning with Schemas](http://arxiv.org/abs/2510.07091v1)
  - Authors: Baixuan Xu, Tianshi Zheng, Zhaowei Wang, Hong Ting Tsang, Weiqi Wang, Tianqing Fang, Yangqiu Song
  - Abstract: Enabling LLMs to effectively operate long-horizon task which requires
long-term planning and multiple interactions is essential for open-world
autonomy. Conventional methods adopt planning with actions where a executable
action list would be provided as reference. However, this action representation
choice would be impractical when the environment action space is combinatorial
exploded (e.g., open-ended real world). This naturally leads to a question: As
environmental action space scales, what is the optimal action representation
for long-horizon agents? In this paper, we systematically study the
effectiveness of two different action representations. The first one is
conventional planning with actions (PwA) which is predominantly adopted for its
effectiveness on existing benchmarks. The o…
  - Tags: agent, benchmark, planning
  - PDF: http://arxiv.org/pdf/2510.07091v1
- [Utilizing Large Language Models for Machine Learning Explainability](http://arxiv.org/abs/2510.06912v1)
  - Authors: Alexandros Vassiliades, Nikolaos Polatidis, Stamatios Samaras, Sotiris Diplaris, Ignacio Cabrera Martin, Yannis Manolopoulos, Stefanos Vrochidis, Ioannis Kompatsiaris
  - Abstract: This study explores the explainability capabilities of large language models
(LLMs), when employed to autonomously generate machine learning (ML) solutions.
We examine two classification tasks: (i) a binary classification problem
focused on predicting driver alertness states, and (ii) a multilabel
classification problem based on the yeast dataset. Three state-of-the-art LLMs
(i.e. OpenAI GPT, Anthropic Claude, and DeepSeek) are prompted to design
training pipelines for four common classifiers: Random Forest, XGBoost,
Multilayer Perceptron, and Long Short-Term Memory networks. The generated
models are evaluated in terms of predictive performance (recall, precision, and
F1-score) and explainability using SHAP (SHapley Additive exPlanations).
Specifically, we measure Average SHAP Fidelity (M…
  - Tags: autonomy, memory, tool-use
  - PDF: http://arxiv.org/pdf/2510.06912v1
- [Inefficiencies of Meta Agents for Agent Design](http://arxiv.org/abs/2510.06711v1)
  - Authors: Batu El, Mert Yuksekgonul, James Zou
  - Abstract: Recent works began to automate the design of agentic systems using
meta-agents that propose and iteratively refine new agent architectures. In
this paper, we examine three key challenges in a common class of meta-agents.
First, we investigate how a meta-agent learns across iterations and find that
simply expanding the context with all previous agents, as proposed by previous
works, performs worse than ignoring prior designs entirely. We show that the
performance improves with an evolutionary approach. Second, although the
meta-agent designs multiple agents during training, it typically commits to a
single agent at test time. We find that the designed agents have low behavioral
diversity, limiting the potential for their complementary use. Third, we assess
when automated design is economic…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.06711v1
- [Local Reinforcement Learning with Action-Conditioned Root Mean Squared
  Q-Functions](http://arxiv.org/abs/2510.06649v1)
  - Authors: Frank Wu, Mengye Ren
  - Abstract: The Forward-Forward (FF) Algorithm is a recently proposed learning procedure
for neural networks that employs two forward passes instead of the traditional
forward and backward passes used in backpropagation. However, FF remains
largely confined to supervised settings, leaving a gap at domains where
learning signals can be yielded more naturally such as RL. In this work,
inspired by FF's goodness function using layer activity statistics, we
introduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value
estimation method that applies a goodness function and action conditioning for
local RL using temporal difference learning. Despite its simplicity and
biological grounding, our approach achieves superior performance compared to
state-of-the-art local backprop-free RL method…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2510.06649v1
- [Stratified GRPO: Handling Structural Heterogeneity in Reinforcement
  Learning of LLM Search Agents](http://arxiv.org/abs/2510.06214v1)
  - Authors: Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia
  - Abstract: Large language model (LLM) agents increasingly rely on external tools such as
search engines to solve complex, multi-step problems, and reinforcement
learning (RL) has become a key paradigm for training them. However, the
trajectories of search agents are structurally heterogeneous, where variations
in the number, placement, and outcomes of search calls lead to fundamentally
different answer directions and reward distributions. Standard policy gradient
methods, which use a single global baseline, suffer from what we identify and
formalize as cross-stratum bias-an "apples-to-oranges" comparison of
heterogeneous trajectories. This cross-stratum bias distorts credit assignment
and hinders exploration of complex, multi-step search strategies. To address
this, we propose Stratified GRPO, whose…
  - Tags: agent, benchmark, tool-use
  - PDF: http://arxiv.org/pdf/2510.06214v1
- [Automated Program Repair of Uncompilable Student Code](http://arxiv.org/abs/2510.06187v1)
  - Authors: Griffin Pitts, Aum Pandya, Darsh Rank, Tirth Bhatt, Muntasir Hoq, Bita Akram
  - Abstract: A significant portion of student programming submissions in CS1 learning
environments are uncompilable, limiting their use in student modeling and
downstream knowledge tracing. Traditional modeling pipelines often exclude
these cases, discarding observations of student learning. This study
investigates automated program repair as a strategy to recover uncompilable
code while preserving students' structural intent for use in student modeling.
Within this framework, we assess large language models (LLMs) as repair agents,
including GPT-5 (OpenAI), Claude 3.5 Haiku (Anthropic), and Gemini 2.5 Flash
(Google), under high- and low-context prompting conditions. Repairs were
evaluated for compilability, edit distance, and preservation of students'
original structure and logic. We find that while…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.06187v1
- [Pushing Test-Time Scaling Limits of Deep Search with Asymmetric
  Verification](http://arxiv.org/abs/2510.06135v1)
  - Authors: Weihao Zeng, Keqing He, Chuqiao Kuang, Xiaoguang Li, Junxian He
  - Abstract: Test-time compute can be scaled both sequentially and in parallel. Sequential
scaling involves lengthening the generation process, while parallel scaling
involves verifying and selecting among multiple candidate outputs. Combining
these two strategies has led to the most powerful AI systems, such as Grok 4
Heavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles),
verifying responses can be substantially easier than generating them. This
property, referred to as \emph{asymmetric verification}, highlights the strong
potential of test-time scaling (TTS). In this work, we study both sequential
and parallel TTS of deep search agents, motivated by the intuition that
verification in this setting is often much easier than generation. In
experiments, we first show that sequential sc…
  - Tags: agent, benchmark
  - PDF: http://arxiv.org/pdf/2510.06135v1
- [Prompt reinforcing for long-term planning of large language models](http://arxiv.org/abs/2510.05921v1)
  - Authors: Hsien-Chin Lin, Benjamin Matthias Ruppik, Carel van Niekerk, Chia-Hao Shen, Michael Heck, Nurul Lubis, Renato Vukovic, Shutong Feng, Milica Gašić
  - Abstract: Large language models (LLMs) have achieved remarkable success in a wide range
of natural language processing tasks and can be adapted through prompting.
However, they remain suboptimal in multi-turn interactions, often relying on
incorrect early assumptions and failing to track user goals over time, which
makes such tasks particularly challenging. Prior works in dialogue systems have
shown that long-term planning is essential for handling interactive tasks. In
this work, we propose a prompt optimisation framework inspired by reinforcement
learning, which enables such planning to take place by only modifying the task
instruction prompt of the LLM-based agent. By generating turn-by-turn feedback
and leveraging experience replay for prompt rewriting, our proposed method
shows significant imp…
  - Tags: agent, planning
  - PDF: http://arxiv.org/pdf/2510.05921v1
- [ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent
  Systems](http://arxiv.org/abs/2510.05746v1)
  - Authors: Bohan Yao, Shiva Krishna Reddy Malay, Vikas Yadav
  - Abstract: Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved
state-of-the-art results on various complex reasoning tasks. Recent works have
proposed techniques to automate the design of MASes, eliminating the need for
manual engineering. However, these techniques perform poorly, often achieving
similar or inferior performance to simple baselines. Furthermore, they require
computationally expensive re-discovery of architectures for each new task
domain and expensive data annotation on domains without existing labeled
validation sets. A critical insight is that simple Chain of Thought (CoT)
reasoning often performs competitively with these complex systems, suggesting
that the fundamental reasoning unit of MASes, CoT, warrants further
investigation. To this end, we present a ne…
  - Tags: agent, multi-agent, reasoning, reflection
  - PDF: http://arxiv.org/pdf/2510.05746v1
- [MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption](http://arxiv.org/abs/2510.05580v1)
  - Authors: Chen Li, Zhantao Yang, Han Zhang, Fangyi Chen, Chenchen Zhu, Anudeepsekhar Bolimera, Marios Savvides
  - Abstract: Vision-Language-Action (VLA) models show promise in embodied reasoning, yet
remain far from true generalists-they often require task-specific fine-tuning,
and generalize poorly to unseen tasks. We propose MetaVLA, a unified,
backbone-agnostic post-training framework for efficient and scalable alignment.
MetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse
target tasks into a single fine-tuning stage while leveraging structurally
diverse auxiliary tasks to improve in-domain generalization. Unlike naive
multi-task SFT, MetaVLA integrates a lightweight meta-learning
mechanism-derived from Attentive Neural Processes-to enable rapid adaptation
from diverse contexts with minimal architectural change or inference overhead.
On the LIBERO benchmark, MetaVLA with six auxili…
  - Tags: agent, benchmark, reasoning
  - PDF: http://arxiv.org/pdf/2510.05580v1
- [Adversarial Reinforcement Learning for Large Language Model Agent Safety](http://arxiv.org/abs/2510.05442v1)
  - Authors: Zizhao Wang, Dingcheng Li, Vaishakh Keshava, Phillip Wallis, Ananth Balashankar, Peter Stone, Lukas Rutishauser
  - Abstract: Large Language Model (LLM) agents can leverage tools such as Google Search to
complete complex tasks. However, this tool usage introduces the risk of
indirect prompt injections, where malicious instructions hidden in tool outputs
can manipulate the agent, posing security risks like data leakage. Current
defense strategies typically rely on fine-tuning LLM agents on datasets of
known attacks. However, the generation of these datasets relies on manually
crafted attack patterns, which limits their diversity and leaves agents
vulnerable to novel prompt injections. To address this limitation, we propose
Adversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework
that leverages adversarial reinforcement learning (RL) by formulating the
problem as a two-player zero-sum game. A…
  - Tags: agent, autonomy, tool-use
  - PDF: http://arxiv.org/pdf/2510.05442v1
- [DeepV: A Model-Agnostic Retrieval-Augmented Framework for Verilog Code
  Generation with a High-Quality Knowledge Base](http://arxiv.org/abs/2510.05327v1)
  - Authors: Zahin Ibnat, Paul E. Calzada, Rasin Mohammed Ihtemam, Sujan Kumar Saha, Jingbo Zhou, Farimah Farahmandi, Mark Tehranipoor
  - Abstract: As large language models (LLMs) continue to be integrated into modern
technology, there has been an increased push towards code generation
applications, which also naturally extends to hardware design automation.
LLM-based solutions for register transfer level (RTL) code generation for
intellectual property (IP) designs have grown, especially with fine-tuned LLMs,
prompt engineering, and agentic approaches becoming popular in literature.
However, a gap has been exposed in these techniques, as they fail to integrate
novel IPs into the model's knowledge base, subsequently resulting in poorly
generated code. Additionally, as general-purpose LLMs continue to improve,
fine-tuned methods on older models will not be able to compete to produce more
accurate and efficient designs. Although some re…
  - Tags: agent, benchmark, retrieval
  - PDF: http://arxiv.org/pdf/2510.05327v1
- [Paper2Video: Automatic Video Generation from Scientific Papers](http://arxiv.org/abs/2510.05096v2)
  - Authors: Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou
  - Abstract: Academic presentation videos have become an essential medium for research
communication, yet producing them remains highly labor-intensive, often
requiring hours of slide design, recording, and editing for a short 2 to 10
minutes video. Unlike natural video, presentation video generation involves
distinctive challenges: inputs from research papers, dense multi-modal
information (text, figures, tables), and the need to coordinate multiple
aligned channels such as slides, subtitles, speech, and human talker. To
address these challenges, we introduce Paper2Video, the first benchmark of 101
research papers paired with author-created presentation videos, slides, and
speaker metadata. We further design four tailored evaluation metrics--Meta
Similarity, PresentArena, PresentQuiz, and IP Memory--…
  - Tags: agent, benchmark, evaluation, memory, multi-agent
  - PDF: http://arxiv.org/pdf/2510.05096v2
- [MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement
  Learning](http://arxiv.org/abs/2510.04935v1)
  - Authors: Guoxin Chen, Zile Qiao, Wenqing Wang, Donglei Yu, Xuanzhong Chen, Hao Sun, Minpeng Liao, Kai Fan, Yong Jiang, Penguin Xie, Wayne Xin Zhao, Ruihua Song, Fei Huang
  - Abstract: Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strateg…
  - Tags: agent, benchmark, multi-agent, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.04935v1
- [A Case for Declarative LLM-friendly Interfaces for Improved Efficiency
  of Computer-Use Agents](http://arxiv.org/abs/2510.04607v1)
  - Authors: Yuan Wang, Mingyu Li, Haibo Chen
  - Abstract: Computer-use agents (CUAs) powered by large language models (LLMs) have
emerged as a promising approach to automating computer tasks, yet they struggle
with graphical user interfaces (GUIs). GUIs, designed for humans, force LLMs to
decompose high-level goals into lengthy, error-prone sequences of fine-grained
actions, resulting in low success rates and an excessive number of LLM calls.
  We propose Goal-Oriented Interface (GOI), a novel abstraction that transforms
existing GUIs into three declarative primitives: access, state, and
observation, which are better suited for LLMs. Our key idea is policy-mechanism
separation: LLMs focus on high-level semantic planning (policy) while GOI
handles low-level navigation and interaction (mechanism). GOI does not require
modifying the application sou…
  - Tags: agent, planning
  - PDF: http://arxiv.org/pdf/2510.04607v1
- [Code World Models for General Game Playing](http://arxiv.org/abs/2510.04542v1)
  - Authors: Wolfgang Lehrach, Daniel Hennes, Miguel Lazaro-Gredilla, Xinghua Lou, Carter Wendelken, Zun Li, Antoine Dedieu, Jordi Grau-Moya, Marc Lanctot, Atil Iscen, John Schultz, Marcus Chiam, Ian Gemp, Piotr Zielinski, Satinder Singh, Kevin P. Murphy
  - Abstract: Large Language Models (LLMs) reasoning abilities are increasingly being
applied to classical board and card games, but the dominant approach --
involving prompting for direct move generation -- has significant drawbacks. It
relies on the model's implicit fragile pattern-matching capabilities, leading
to frequent illegal moves and strategically shallow play. Here we introduce an
alternative approach: We use the LLM to translate natural language rules and
game trajectories into a formal, executable world model represented as Python
code. This generated model -- comprising functions for state transition, legal
move enumeration, and termination checks -- serves as a verifiable simulation
engine for high-performance planning algorithms like Monte Carlo tree search
(MCTS). In addition, we promp…
  - Tags: agent, planning, reasoning
  - PDF: http://arxiv.org/pdf/2510.04542v1
- [Audit the Whisper: Detecting Steganographic Collusion in Multi-Agent
  LLMs](http://arxiv.org/abs/2510.04303v2)
  - Authors: Om Tailor
  - Abstract: Multi-agent deployments of large language models (LLMs) are increasingly
embedded in market, allocation, and governance workflows, yet covert
coordination among agents can silently erode trust and social welfare. Existing
audits are dominated by heuristics that lack theoretical guarantees, struggle
to transfer across tasks, and seldom ship with the infrastructure needed for
independent replication. We introduce Audit the Whisper, a conference-grade
research artifact that spans theory, benchmark design, detection, and
reproducibility. Our contributions are: (i) a channel-capacity analysis showing
how interventions such as paraphrase, rate limiting, and role permutation
impose quantifiable capacity penalties-operationalised via paired-run
Kullback--Leibler diagnostics-that tighten mutual-in…
  - Tags: agent, benchmark, multi-agent, workflow
  - PDF: http://arxiv.org/pdf/2510.04303v2
- [Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic
  Reinforcement Learning](http://arxiv.org/abs/2510.04284v1)
  - Authors: Yunghwei Lai, Kaiming Liu, Ziyue Wang, Weizhi Ma, Yang Liu
  - Abstract: The professionalism of a human doctor in outpatient service depends on two
core abilities: the ability to make accurate medical decisions and the medical
consultation skill to conduct strategic, empathetic patient inquiry. Existing
Large Language Models (LLMs) have achieved remarkable accuracy on medical
decision-making benchmarks. However, they often lack the ability to conduct the
strategic and empathetic consultation, which is essential for real-world
clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor
agent trained to master both of the capabilities by ask high-yield questions
and conduct strategic multi-turn inquiry to guide decision-making. Our
framework introduces three key components: a multi-agent interactive
environment, a two-tiered reward architecture t…
  - Tags: agent, benchmark, evaluation, multi-agent
  - PDF: http://arxiv.org/pdf/2510.04284v1
- [Small Language Models for Agentic Systems: A Survey of Architectures,
  Capabilities, and Deployment Trade offs](http://arxiv.org/abs/2510.03847v1)
  - Authors: Raghav Sharma, Manan Mehta
  - Abstract: Small language models (SLMs; 1-12B params, sometimes up to 20B) are
sufficient and often superior for agentic workloads where the objective is
schema- and API-constrained accuracy rather than open-ended generation. We
synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,
Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,
DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,
StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with
guided decoding libraries (XGrammar, Outlines). We formalize SLM-default,
LLM-fallback systems with uncertainty-aware routing and verifier cascades, and
propose engineering metrics that reflect real production goals: cost per
successful task (CPS), schema validity rate, executable…
  - Tags: agent, evaluation, planning, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.03847v1
- [Trajectory prediction for heterogeneous agents: A performance analysis
  on small and imbalanced datasets](http://arxiv.org/abs/2510.03776v1)
  - Authors: Tiago Rodrigues de Almeida, Yufei Zhu, Andrey Rudenko, Tomasz P. Kucner, Johannes A. Stork, Martin Magnusson, Achim J. Lilienthal
  - Abstract: Robots and other intelligent systems navigating in complex dynamic
environments should predict future actions and intentions of surrounding agents
to reach their goals efficiently and avoid collisions. The dynamics of those
agents strongly depends on their tasks, roles, or observable labels.
Class-conditioned motion prediction is thus an appealing way to reduce forecast
uncertainty and get more accurate predictions for heterogeneous agents.
However, this is hardly explored in the prior art, especially for mobile robots
and in limited data applications. In this paper, we analyse different
class-conditioned trajectory prediction methods on two datasets. We propose a
set of conditional pattern-based and efficient deep learning-based baselines,
and evaluate their performance on robotics and o…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.03776v1
- [Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic
  Program Repair](http://arxiv.org/abs/2510.03217v1)
  - Authors: José Cambronero, Michele Tufano, Sherry Shi, Renyao Wei, Grant Uy, Runxiang Cheng, Chin-Jung Liu, Shiying Pan, Satish Chandra, Pat Rondon
  - Abstract: Agentic Automated Program Repair (APR) is increasingly tackling complex,
repository-level bugs in industry, but ultimately agent-generated patches still
need to be reviewed by a human before committing them to ensure they address
the bug. Showing unlikely patches to developers can lead to substantial noise,
wasting valuable developer time and eroding trust in automated code changes. We
introduce two complementary LLM-based policies to reduce such noise: bug
abstention and patch validation policies. Bug abstention excludes bugs that the
agentic APR system is unlikely to fix. Patch validation rejects patches that
are unlikely to be a good fix for the given bug. We evaluate both policies on
three sets of bugs from Google's codebase, and their candidate patches
generated by an internal agenti…
  - Tags: agent
  - PDF: http://arxiv.org/pdf/2510.03217v1
- [Comparative Analysis of Parameterized Action Actor-Critic Reinforcement
  Learning Algorithms for Web Search Match Plan Generation](http://arxiv.org/abs/2510.03064v1)
  - Authors: Ubayd Bapoo, Clement N Nyirenda
  - Abstract: This study evaluates the performance of Soft Actor Critic (SAC), Greedy Actor
Critic (GAC), and Truncated Quantile Critics (TQC) in high-dimensional
decision-making tasks using fully observable environments. The focus is on
parametrized action (PA) spaces, eliminating the need for recurrent networks,
with benchmarks Platform-v0 and Goal-v0 testing discrete actions linked to
continuous action-parameter spaces. Hyperparameter optimization was performed
with Microsoft NNI, ensuring reproducibility by modifying the codebase for GAC
and TQC. Results show that Parameterized Action Greedy Actor-Critic (PAGAC)
outperformed other algorithms, achieving the fastest training times and highest
returns across benchmarks, completing 5,000 episodes in 41:24 for the Platform
game and 24:04 for the Robot S…
  - Tags: benchmark
  - PDF: http://arxiv.org/pdf/2510.03064v1
- [Beyond the Final Answer: Evaluating the Reasoning Trajectories of
  Tool-Augmented Agents](http://arxiv.org/abs/2510.02837v1)
  - Authors: Wonjoong Kim, Sangwu Park, Yeonjun In, Sein Kim, Dongha Lee, Chanyoung Park
  - Abstract: Although recent tool-augmented benchmarks incorporate complex user requests
and diverse tools, the evaluation methods for most of them remain limited to
answer matching. However, as the number of steps required to resolve a user
request increases, a proper evaluation of an agent's performance must go beyond
the final answer to also assess the problem-solving trajectory, including
previously ignored aspects such as efficiency, hallucination, and adaptivity.
The most straightforward method for evaluating these aspects is to compare an
agent's trajectory with the ground-truth trajectory, but this approach is
fundamentally limited since annotating all valid ground-truth trajectories is
prohibitively expensive. However, a simple LLM-based evaluator struggles to
assess trajectories in detail wi…
  - Tags: agent, benchmark, evaluation, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.02837v1
- [Adversarial Reinforcement Learning for Offensive and Defensive Agents in
  a Simulated Zero-Sum Network Environment](http://arxiv.org/abs/2510.05157v1)
  - Authors: Abrar Shahid, Ibteeker Mahir Ishum, AKM Tahmidul Haque, M Sohel Rahman, A. B. M. Alim Al Islam
  - Abstract: This paper presents a controlled study of adversarial reinforcement learning
in network security through a custom OpenAI Gym environment that models
brute-force attacks and reactive defenses on multi-port services. The
environment captures realistic security trade-offs including background traffic
noise, progressive exploitation mechanics, IP-based evasion tactics, honeypot
traps, and multi-level rate-limiting defenses. Competing attacker and defender
agents are trained using Deep Q-Networks (DQN) within a zero-sum reward
framework, where successful exploits yield large terminal rewards while
incremental actions incur small costs. Through systematic evaluation across
multiple configurations (varying trap detection probabilities, exploitation
difficulty thresholds, and training regimens),…
  - Tags: agent, autonomy, evaluation
  - PDF: http://arxiv.org/pdf/2510.05157v1
- [Apriel-1.5-15b-Thinker](http://arxiv.org/abs/2510.01141v1)
  - Authors: Shruthan Radhakrishna, Aman Tiwari, Aanjaneya Shukla, Masoud Hashemi, Rishabh Maheshwary, Shiva Krishna Reddy Malay, Jash Mehta, Pulkit Pattnaik, Saloni Mittal, Khalil Slimi, Kelechi Ogueji, Akintunde Oladipo, Soham Parikh, Oluwanifemi Bamgbose, Toby Liang, Ahmed Masry, Khyati Mahajan, Sai Rajeswar Mudumba, Vikas Yadav, Sathwik Tejaswi Madhusudhan, Torsten Scholak, Sagar Davasam, Srinivas Sunkara, Nicholas Chapados
  - Abstract: We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights
multimodal reasoning model that achieves frontier-level performance through
training design rather than sheer scale. Starting from Pixtral-12B, we apply a
progressive three-stage methodology: (1) depth upscaling to expand reasoning
capacity without pretraining from scratch, (2) staged continual pre-training
that first develops foundational text and vision understanding, then enhances
visual reasoning through targeted synthetic data generation addressing spatial
structure, compositional understanding, and fine-grained perception, and (3)
high-quality text-only supervised fine-tuning on curated instruction-response
pairs with explicit reasoning traces spanning mathematics, coding, science, and
tool use. Notably, our mode…
  - Tags: benchmark, evaluation, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.01141v1
- [GEM: A Gym for Agentic LLMs](http://arxiv.org/abs/2510.01051v1)
  - Authors: Zichen Liu, Anya Sims, Keyu Duan, Changyu Chen, Simon Yu, Xiangxin Zhou, Haotian Xu, Shaopan Xiong, Bo Liu, Chenmien Tan, Chuen Yang Beh, Weixun Wang, Hao Zhu, Weiyan Shi, Diyi Yang, Michael Shieh, Yee Whye Teh, Wee Sun Lee, Min Lin
  - Abstract: The training paradigm for large language models (LLMs) is moving from static
datasets to experience-based learning, where agents acquire skills via
interacting with complex environments. To facilitate this transition we
introduce GEM (General Experience Maker), an open-source environment simulator
designed for the age of LLMs. Analogous to OpenAI-Gym for traditional
reinforcement learning (RL), GEM provides a standardized framework for the
environment-agent interface, including asynchronous vectorized execution for
high throughput, and flexible wrappers for easy extensibility. GEM also
features a diverse suite of environments, robust integrated tools, and
single-file example scripts demonstrating using GEM with five popular RL
training frameworks. Along with this, we also provide a set of…
  - Tags: agent, benchmark, evaluation, tool-use
  - PDF: http://arxiv.org/pdf/2510.01051v1
- [ACON: Optimizing Context Compression for Long-horizon LLM Agents](http://arxiv.org/abs/2510.00615v2)
  - Authors: Minki Kang, Wei-Ning Chen, Dongge Han, Huseyin A. Inan, Lukas Wutschitz, Yanzhi Chen, Robert Sim, Saravan Rajmohan
  - Abstract: Large language models (LLMs) are increasingly deployed as agents in dynamic,
real-world environments, where success requires both reasoning and effective
tool use. A central challenge for agentic tasks is the growing context length,
as agents must accumulate long histories of actions and observations. This
expansion raises costs and reduces efficiency in long-horizon tasks, yet prior
work on context compression has mostly focused on single-step tasks or narrow
applications. We introduce Agent Context Optimization (ACON), a unified
framework that optimally compresses both environment observations and
interaction histories into concise yet informative condensations. ACON
leverages compression guideline optimization in natural language space: given
paired trajectories where full context succ…
  - Tags: agent, memory, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.00615v2
- [Graph2Eval: Automatic Multimodal Task Generation for Agents via
  Knowledge Graphs](http://arxiv.org/abs/2510.00507v2)
  - Authors: Yurun Chen, Xavier Hu, Yuhan Liu, Ziqi Wang, Zeyi Liao, Lin Chen, Feng Wei, Yuxi Qian, Bo Zheng, Keting Yin, Shengyu Zhang
  - Abstract: As multimodal LLM-driven agents continue to advance in autonomy and
generalization, evaluation based on static datasets can no longer adequately
assess their true capabilities in dynamic environments and diverse tasks.
Existing LLM-based synthetic data methods are largely designed for LLM training
and evaluation, and thus cannot be directly applied to agent tasks that require
tool use and interactive capabilities. While recent studies have explored
automatic agent task generation with LLMs, most efforts remain limited to text
or image analysis, without systematically modeling multi-step interactions in
web environments. To address these challenges, we propose Graph2Eval, a
knowledge graph-based framework that automatically generates both multimodal
document comprehension tasks and web int…
  - Tags: agent, evaluation, multi-agent, reasoning, tool-use
  - PDF: http://arxiv.org/pdf/2510.00507v2

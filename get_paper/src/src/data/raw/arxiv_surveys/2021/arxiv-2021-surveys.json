[
  {
    "arxiv_id": "2112.13675v1",
    "entry_id": "http://arxiv.org/abs/2112.13675v1",
    "title": "A Review on Controllability of Multi-Agent Systems using Switched Network",
    "summary": "Controllability refers to a situation in which a Multi-agent System may be steered from one state to another using specified rules. As a result, there is belief in achieving a given condition by explicit advances. The level of dynamism in the topology and the level of determinism in the environment are two fundamental criteria that determine multi-agent system controllability. The topology of a powerful multi-agent system changes on a regular basis, altering the connections between agents and hence their cooperative effort. This survey focuses on the controllability of MAS in a switching network with a leader that follows the closest neighbour collaboration rule. The leader/pioneer is a single agent that functions as an output to control other agents/members. Because the results of activities are unknown under non-deterministic situations, agents must choose new activities after observing the aftereffects of their prior actions, which causes time delay and limits agent proactivity. Controllability is often achieved in a concentrated manner in the literature, where a certain leader educates supporters how to achieve a specific goal. Controllability has different applications which incorporates managing airplane, vehicle, and robots.",
    "authors": [
      "Javeria Noor"
    ],
    "categories": [
      "cs.MA"
    ],
    "published": "2021-12-27T13:48:51Z",
    "pdf_url": "https://arxiv.org/pdf/2112.13675v1"
  },
  {
    "arxiv_id": "2112.13560v2",
    "entry_id": "http://arxiv.org/abs/2112.13560v2",
    "title": "A Survey of Event-triggered Control for Nonlinear Multiagent Systems with Guaranteed Steady-State Performance",
    "summary": "With the gradual advancement of a novel idea of the distributed control of the multiagent systems, an event-triggered control protocol has received significant research attention, especially in designing the controller for the nonlinear multiagent system. Compared to other widely used control conditions, the event-triggered control of the nonlinear system has a significant capability to improve resource utilization in real-life scenarios such as using and controlling the intelligent control input of each agent. It is worth mentioning that a group of interconnected agents have a network communication topology to transmit the feedback information state across the networked link. The transmission of information among a group of agents ensures that each agent reaches the consensus agreement cooperatively. The cooperative protocol of the distributed control of nonlinear multiagent system also ensures the proper information flow between each agent, irrespective of communication delays, variability of environment, and switching of the communication topology via the event-triggered control protocol. Consequently, event-triggered control for nonlinear multi-agent systems via steady-state performance will be investigated in this paper. The steady-state performances of a nonlinear closed-loop system demonstrate the stabilization, output regulation, and output synchronization problem of the nonlinear system using proper control protocol to achieve a consensus in a multiagent system will also be discussed. Based on the steady-state conditions of the nonlinear system, the consensus agreement among the agents will be realized.",
    "authors": [
      "Gurmu Meseret Debele"
    ],
    "categories": [
      "cs.MA"
    ],
    "published": "2021-12-27T08:10:03Z",
    "pdf_url": "https://arxiv.org/pdf/2112.13560v2"
  },
  {
    "arxiv_id": "2112.12071v1",
    "entry_id": "http://arxiv.org/abs/2112.12071v1",
    "title": "Activity-based and agent-based Transport model of Melbourne (AToM): an open multi-modal transport simulation model for Greater Melbourne",
    "summary": "Agent-based and activity-based models for simulating transportation systems have attracted significant attention in recent years. Few studies, however, include a detailed representation of active modes of transportation - such as walking and cycling - at a city-wide level, where dominating motorised modes are often of primary concern. This paper presents an open workflow for creating a multi-modal agent-based and activity-based transport simulation model, focusing on Greater Melbourne, and including the process of mode choice calibration for the four main travel modes of driving, public transport, cycling and walking. The synthetic population generated and used as an input for the simulation model represented Melbourne's population based on Census 2016, with daily activities and trips based on the Victoria's 2016-18 travel survey data. The road network used in the simulation model includes all public roads accessible via the included travel modes. We compared the output of the simulation model with observations from the real world in terms of mode share, road volume, travel time, and travel distance. Through these comparisons, we showed that our model is suitable for studying mode choice and road usage behaviour of travellers.",
    "authors": [
      "Afshin Jafari",
      "Dhirendra Singh",
      "Alan Both",
      "Mahsa Abdollahyar",
      "Lucy Gunn",
      "Steve Pemberton",
      "Billie Giles-Corti"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "published": "2021-12-16T01:24:33Z",
    "pdf_url": "https://arxiv.org/pdf/2112.12071v1"
  },
  {
    "arxiv_id": "2112.11480v1",
    "entry_id": "http://arxiv.org/abs/2112.11480v1",
    "title": "On the Compression of Natural Language Models",
    "summary": "Deep neural networks are effective feature extractors but they are prohibitively large for deployment scenarios. Due to the huge number of parameters, interpretability of parameters in different layers is not straight-forward. This is why neural networks are sometimes considered black boxes. Although simpler models are easier to explain, finding them is not easy. If found, a sparse network that can fit to a data from scratch would help to interpret parameters of a neural network. To this end, lottery ticket hypothesis states that typical dense neural networks contain a small sparse sub-network that can be trained to a reach similar test accuracy in an equal number of steps. The goal of this work is to assess whether such a trainable subnetwork exists for natural language models (NLM)s. To achieve this goal we will review state-of-the-art compression techniques such as quantization, knowledge distillation, and pruning.",
    "authors": [
      "Saeed Damadi"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-12-13T08:14:21Z",
    "pdf_url": "https://arxiv.org/pdf/2112.11480v1"
  },
  {
    "arxiv_id": "2112.05842v1",
    "entry_id": "http://arxiv.org/abs/2112.05842v1",
    "title": "Revisiting the Boundary between ASR and NLU in the Age of Conversational Dialog Systems",
    "summary": "As more users across the world are interacting with dialog agents in their daily life, there is a need for better speech understanding that calls for renewed attention to the dynamics between research in automatic speech recognition (ASR) and natural language understanding (NLU). We briefly review these research areas and lay out the current relationship between them. In light of the observations we make in this paper, we argue that (1) NLU should be cognizant of the presence of ASR models being used upstream in a dialog system's pipeline, (2) ASR should be able to learn from errors found in NLU, (3) there is a need for end-to-end datasets that provide semantic annotations on spoken input, (4) there should be stronger collaboration between ASR and NLU research communities.",
    "authors": [
      "Manaal Faruqui",
      "Dilek Hakkani-Tür"
    ],
    "categories": [
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2021-12-10T21:54:20Z",
    "pdf_url": "https://arxiv.org/pdf/2112.05842v1"
  },
  {
    "arxiv_id": "2112.04359v1",
    "entry_id": "http://arxiv.org/abs/2112.04359v1",
    "title": "Ethical and social risks of harm from Language Models",
    "summary": "This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences.\n  We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities.\n  In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs.",
    "authors": [
      "Laura Weidinger",
      "John Mellor",
      "Maribeth Rauh",
      "Conor Griffin",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "Myra Cheng",
      "Mia Glaese",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Zac Kenton",
      "Sasha Brown",
      "Will Hawkins",
      "Tom Stepleton",
      "Courtney Biles",
      "Abeba Birhane",
      "Julia Haas",
      "Laura Rimell",
      "Lisa Anne Hendricks",
      "William Isaac",
      "Sean Legassick",
      "Geoffrey Irving",
      "Iason Gabriel"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2021-12-08T16:09:48Z",
    "pdf_url": "https://arxiv.org/pdf/2112.04359v1"
  },
  {
    "arxiv_id": "2112.04145v5",
    "entry_id": "http://arxiv.org/abs/2112.04145v5",
    "title": "A Review for Deep Reinforcement Learning in Atari:Benchmarks, Challenges, and Solutions",
    "summary": "The Arcade Learning Environment (ALE) is proposed as an evaluation platform for empirically assessing the generality of agents across dozens of Atari 2600 games. ALE offers various challenging problems and has drawn significant attention from the deep reinforcement learning (RL) community. From Deep Q-Networks (DQN) to Agent57, RL agents seem to achieve superhuman performance in ALE. However, is this the case? In this paper, to explore this problem, we first review the current evaluation metrics in the Atari benchmarks and then reveal that the current evaluation criteria of achieving superhuman performance are inappropriate, which underestimated the human performance relative to what is possible. To handle those problems and promote the development of RL research, we propose a novel Atari benchmark based on human world records (HWR), which puts forward higher requirements for RL agents on both final performance and learning efficiency. Furthermore, we summarize the state-of-the-art (SOTA) methods in Atari benchmarks and provide benchmark results over new evaluation metrics based on human world records. We concluded that at least four open challenges hinder RL agents from achieving superhuman performance from those new benchmark results. Finally, we also discuss some promising ways to handle those problems.",
    "authors": [
      "Jiajun Fan"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-12-08T06:52:23Z",
    "pdf_url": "https://arxiv.org/pdf/2112.04145v5"
  },
  {
    "arxiv_id": "2112.03210v1",
    "entry_id": "http://arxiv.org/abs/2112.03210v1",
    "title": "Contextual Bandit Applications in Customer Support Bot",
    "summary": "Virtual support agents have grown in popularity as a way for businesses to provide better and more accessible customer service. Some challenges in this domain include ambiguous user queries as well as changing support topics and user behavior (non-stationarity). We do, however, have access to partial feedback provided by the user (clicks, surveys, and other events) which can be leveraged to improve the user experience. Adaptable learning techniques, like contextual bandits, are a natural fit for this problem setting. In this paper, we discuss real-world implementations of contextual bandits (CB) for the Microsoft virtual agent. It includes intent disambiguation based on neural-linear bandits (NLB) and contextual recommendations based on a collection of multi-armed bandits (MAB). Our solutions have been deployed to production and have improved key business metrics of the Microsoft virtual agent, as confirmed by A/B experiments. Results include a relative increase of over 12% in problem resolution rate and relative decrease of over 4% in escalations to a human operator. While our current use cases focus on intent disambiguation and contextual recommendation for support bots, we believe our methods can be extended to other domains.",
    "authors": [
      "Sandra Sajeev",
      "Jade Huang",
      "Nikos Karampatziakis",
      "Matthew Hall",
      "Sebastian Kochman",
      "Weizhu Chen"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2021-12-06T18:07:34Z",
    "pdf_url": "https://arxiv.org/pdf/2112.03210v1"
  },
  {
    "arxiv_id": "2112.01871v1",
    "entry_id": "http://arxiv.org/abs/2112.01871v1",
    "title": "Active Inference in Robotics and Artificial Agents: Survey and Challenges",
    "summary": "Active inference is a mathematical framework which originated in computational neuroscience as a theory of how the brain implements action, perception and learning. Recently, it has been shown to be a promising approach to the problems of state-estimation and control under uncertainty, as well as a foundation for the construction of goal-driven behaviours in robotics and artificial agents in general. Here, we review the state-of-the-art theory and implementations of active inference for state-estimation, control, planning and learning; describing current achievements with a particular focus on robotics. We showcase relevant experiments that illustrate its potential in terms of adaptation, generalization and robustness. Furthermore, we connect this approach with other frameworks and discuss its expected benefits and challenges: a unified framework with functional biological plausibility using variational Bayesian inference.",
    "authors": [
      "Pablo Lanillos",
      "Cristian Meo",
      "Corrado Pezzato",
      "Ajith Anil Meera",
      "Mohamed Baioumy",
      "Wataru Ohata",
      "Alexander Tschantz",
      "Beren Millidge",
      "Martijn Wisse",
      "Christopher L. Buckley",
      "Jun Tani"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-12-03T12:10:26Z",
    "pdf_url": "https://arxiv.org/pdf/2112.01871v1"
  },
  {
    "arxiv_id": "2112.01603v1",
    "entry_id": "http://arxiv.org/abs/2112.01603v1",
    "title": "Neurosymbolic Systems of Perception & Cognition: The Role of Attention",
    "summary": "A cognitive architecture aimed at cumulative learning must provide the necessary information and control structures to allow agents to learn incrementally and autonomously from their experience. This involves managing an agent's goals as well as continuously relating sensory information to these in its perception-cognition information stack. The more varied the environment of a learning agent is, the more general and flexible must be these mechanisms to handle a wider variety of relevant patterns, tasks, and goal structures. While many researchers agree that information at different levels of abstraction likely differs in its makeup and structure and processing mechanisms, agreement on the particulars of such differences is not generally shared in the research community. A binary processing architecture (often referred to as System-1 and System-2) has been proposed as a model of cognitive processing for low- and high-level information, respectively. We posit that cognition is not binary in this way and that knowledge at any level of abstraction involves what we refer to as neurosymbolic information, meaning that data at both high and low levels must contain both symbolic and subsymbolic information. Further, we argue that the main differentiating factor between the processing of high and low levels of data abstraction can be largely attributed to the nature of the involved attention mechanisms. We describe the key arguments behind this view and review relevant evidence from the literature.",
    "authors": [
      "Hugo Latapie",
      "Ozkan Kilic",
      "Kristinn R. Thorisson",
      "Pei Wang",
      "Patrick Hammer"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-12-02T20:53:14Z",
    "pdf_url": "https://arxiv.org/pdf/2112.01603v1"
  },
  {
    "arxiv_id": "2111.15275v1",
    "entry_id": "http://arxiv.org/abs/2111.15275v1",
    "title": "Emotions as abstract evaluation criteria in biological and artificial intelligences",
    "summary": "Biological as well as advanced artificial intelligences (AIs) need to decide which goals to pursue. We review nature's solution to the time allocation problem, which is based on a continuously readjusted categorical weighting mechanism we experience introspectively as emotions. One observes phylogenetically that the available number of emotional states increases hand in hand with the cognitive capabilities of animals and that raising levels of intelligence entail ever larger sets of behavioral options. Our ability to experience a multitude of potentially conflicting feelings is in this view not a leftover of a more primitive heritage, but a generic mechanism for attributing values to behavioral options that can not be specified at birth. In this view, emotions are essential for understanding the mind.\n  For concreteness, we propose and discuss a framework which mimics emotions on a functional level. Based on time allocation via emotional stationarity (TAES), emotions are implemented as abstract criteria, such as satisfaction, challenge and boredom, which serve to evaluate activities that have been carried out. The resulting timeline of experienced emotions is compared with the `character' of the agent, which is defined in terms of a preferred distribution of emotional states. The long-term goal of the agent, to align experience with character, is achieved by optimizing the frequency for selecting individual tasks. Upon optimization, the statistics of emotion experience becomes stationary.",
    "authors": [
      "Claudius Gros"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "published": "2021-11-30T10:49:04Z",
    "pdf_url": "https://arxiv.org/pdf/2111.15275v1"
  },
  {
    "arxiv_id": "2111.14282v2",
    "entry_id": "http://arxiv.org/abs/2111.14282v2",
    "title": "Customer Sentiment Analysis using Weak Supervision for Customer-Agent Chat",
    "summary": "Prior work on sentiment analysis using weak supervision primarily focuses on different reviews such as movies (IMDB), restaurants (Yelp), products (Amazon).~One under-explored field in this regard is customer chat data for a customer-agent chat in customer support due to the lack of availability of free public data. Here, we perform sentiment analysis on customer chat using weak supervision on our in-house dataset. We fine-tune the pre-trained language model (LM) RoBERTa as a sentiment classifier using weak supervision. Our contribution is as follows:1) We show that by using weak sentiment classifiers along with domain-specific lexicon-based rules as Labeling Functions (LF), we can train a fairly accurate customer chat sentiment classifier using weak supervision. 2) We compare the performance of our custom-trained model with off-the-shelf google cloud NLP API for sentiment analysis. We show that by injecting domain-specific knowledge using LFs, even with weak supervision, we can train a model to handle some domain-specific use cases better than off-the-shelf google cloud NLP API. 3) We also present an analysis of how customer sentiment in a chat relates to problem resolution.",
    "authors": [
      "Navdeep Jain"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-11-29T00:58:22Z",
    "pdf_url": "https://arxiv.org/pdf/2111.14282v2"
  },
  {
    "arxiv_id": "2111.14247v2",
    "entry_id": "http://arxiv.org/abs/2111.14247v2",
    "title": "A Survey of Large-Scale Deep Learning Serving System Optimization: Challenges and Opportunities",
    "summary": "Deep Learning (DL) models have achieved superior performance in many application domains, including vision, language, medical, commercial ads, entertainment, etc. With the fast development, both DL applications and the underlying serving hardware have demonstrated strong scaling trends, i.e., Model Scaling and Compute Scaling, for example, the recent pre-trained model with hundreds of billions of parameters with ~TB level memory consumption, as well as the newest GPU accelerators providing hundreds of TFLOPS. With both scaling trends, new problems and challenges emerge in DL inference serving systems, which gradually trends towards Large-scale Deep learning Serving systems (LDS). This survey aims to summarize and categorize the emerging challenges and optimization opportunities for large-scale deep learning serving systems. By providing a novel taxonomy, summarizing the computing paradigms, and elaborating the recent technique advances, we hope that this survey could shed light on new optimization perspectives and motivate novel works in large-scale deep learning system optimization.",
    "authors": [
      "Fuxun Yu",
      "Di Wang",
      "Longfei Shangguan",
      "Minjia Zhang",
      "Xulong Tang",
      "Chenchen Liu",
      "Xiang Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2021-11-28T22:14:10Z",
    "pdf_url": "https://arxiv.org/pdf/2111.14247v2"
  },
  {
    "arxiv_id": "2111.13084v1",
    "entry_id": "http://arxiv.org/abs/2111.13084v1",
    "title": "Towards an Adaptive and Normative Multi-Agent System Metamodel and Language: Existing Approaches and Research Opportunities",
    "summary": "Several Multi-Agent System (MAS) metamodels and languages have been proposed in the literature to support the development of agent-based applications. MAS metamodels are used to capture a collection of concepts the relevant entities and relationships in the MAS domain, which include entities such as agent, message, role, action and plan, and relationships that represent, for example, that a role is responsible for one or more tasks. In addition, to models, MAS modeling languages have also been used to support the development of MASs in a wide variety of domains, including social networking, robotics, security and smart city environments. However, there is a lack of support in these models and languages for abstractions involving norms and adaptations as well as their interactions. This paper presents a survey of some existing metamodels and languages and compares their expressiveness using abstractions related to agents, norms and adaptation. The comparison serves as a basis for the definition of a new MAS metamodeling.",
    "authors": [
      "Marx Viana",
      "Paulo Alencar",
      "Carlos Lucena"
    ],
    "categories": [
      "cs.MA"
    ],
    "published": "2021-11-25T13:48:18Z",
    "pdf_url": "https://arxiv.org/pdf/2111.13084v1"
  },
  {
    "arxiv_id": "2111.11964v1",
    "entry_id": "http://arxiv.org/abs/2111.11964v1",
    "title": "Reviewing continual learning from the perspective of human-level intelligence",
    "summary": "Humans' continual learning (CL) ability is closely related to Stability Versus Plasticity Dilemma that describes how humans achieve ongoing learning capacity and preservation for learned information. The notion of CL has always been present in artificial intelligence (AI) since its births. This paper proposes a comprehensive review of CL. Different from previous reviews that mainly focus on the catastrophic forgetting phenomenon in CL, this paper surveys CL from a more macroscopic perspective based on the Stability Versus Plasticity mechanism. Analogous to biological counterpart, \"smart\" AI agents are supposed to i) remember previously learned information (information retrospection); ii) infer on new information continuously (information prospection:); iii) transfer useful information (information transfer), to achieve high-level CL. According to the taxonomy, evaluation metrics, algorithms, applications as well as some open issues are then introduced. Our main contributions concern i) rechecking CL from the level of artificial general intelligence; ii) providing a detailed and extensive overview on CL topics; iii) presenting some novel ideas on the potential development of CL.",
    "authors": [
      "Yifan Chang",
      "Wenbo Li",
      "Jian Peng",
      "Bo Tang",
      "Yu Kang",
      "Yinjie Lei",
      "Yuanmiao Gui",
      "Qing Zhu",
      "Yu Liu",
      "Haifeng Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2021-11-23T15:56:02Z",
    "pdf_url": "https://arxiv.org/pdf/2111.11964v1"
  },
  {
    "arxiv_id": "2111.11743v1",
    "entry_id": "http://arxiv.org/abs/2111.11743v1",
    "title": "Independent Learning in Stochastic Games",
    "summary": "Reinforcement learning (RL) has recently achieved tremendous successes in many artificial intelligence applications. Many of the forefront applications of RL involve multiple agents, e.g., playing chess and Go games, autonomous driving, and robotics. Unfortunately, the framework upon which classical RL builds is inappropriate for multi-agent learning, as it assumes an agent's environment is stationary and does not take into account the adaptivity of other agents. In this review paper, we present the model of stochastic games for multi-agent learning in dynamic environments. We focus on the development of simple and independent learning dynamics for stochastic games: each agent is myopic and chooses best-response type actions to other agents' strategy without any coordination with her opponent. There has been limited progress on developing convergent best-response type independent learning dynamics for stochastic games. We present our recently proposed simple and independent learning dynamics that guarantee convergence in zero-sum stochastic games, together with a review of other contemporaneous algorithms for dynamic multi-agent learning in this setting. Along the way, we also reexamine some classical results from both the game theory and RL literature, to situate both the conceptual contributions of our independent learning dynamics, and the mathematical novelties of our analysis. We hope this review paper serves as an impetus for the resurgence of studying independent and natural learning dynamics in game theory, for the more challenging settings with a dynamic environment.",
    "authors": [
      "Asuman Ozdaglar",
      "Muhammed O. Sayin",
      "Kaiqing Zhang"
    ],
    "categories": [
      "cs.GT",
      "cs.LG",
      "math.DS"
    ],
    "published": "2021-11-23T09:27:20Z",
    "pdf_url": "https://arxiv.org/pdf/2111.11743v1"
  },
  {
    "arxiv_id": "2111.10501v1",
    "entry_id": "http://arxiv.org/abs/2111.10501v1",
    "title": "Exploring Language Patterns in a Medical Licensure Exam Item Bank",
    "summary": "This study examines the use of natural language processing (NLP) models to evaluate whether language patterns used by item writers in a medical licensure exam might contain evidence of biased or stereotypical language. This type of bias in item language choices can be particularly impactful for items in a medical licensure assessment, as it could pose a threat to content validity and defensibility of test score validity evidence. To the best of our knowledge, this is the first attempt using machine learning (ML) and NLP to explore language bias on a large item bank. Using a prediction algorithm trained on clusters of similar item stems, we demonstrate that our approach can be used to review large item banks for potential biased language or stereotypical patient characteristics in clinical science vignettes. The findings may guide the development of methods to address stereotypical language patterns found in test items and enable an efficient updating of those items, if needed, to reflect contemporary norms, thereby improving the evidence to support the validity of the test scores.",
    "authors": [
      "Swati Padhee",
      "Kimberly Swygert",
      "Ian Micir"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2021-11-20T02:45:35Z",
    "pdf_url": "https://arxiv.org/pdf/2111.10501v1"
  },
  {
    "arxiv_id": "2111.06978v2",
    "entry_id": "http://arxiv.org/abs/2111.06978v2",
    "title": "RLOps: Development Life-cycle of Reinforcement Learning Aided Open RAN",
    "summary": "Radio access network (RAN) technologies continue to evolve, with Open RAN gaining the most recent momentum. In the O-RAN specifications, the RAN intelligent controllers (RICs) are software-defined orchestration and automation functions for the intelligent management of RAN. This article introduces principles for machine learning (ML), in particular, reinforcement learning (RL) applications in the O-RAN stack. Furthermore, we review the state-of-the-art research in wireless networks and cast it onto the RAN framework and the hierarchy of the O-RAN architecture. We provide a taxonomy for the challenges faced by ML/RL models throughout the development life-cycle: from the system specification to production deployment (data acquisition, model design, testing and management, etc.). To address the challenges, we integrate a set of existing MLOps principles with unique characteristics when RL agents are considered. This paper discusses a systematic model development, testing and validation life-cycle, termed: RLOps. We discuss fundamental parts of RLOps, which include: model specification, development, production environment serving, operations monitoring and safety/security. Based on these principles, we propose the best practices for RLOps to achieve an automated and reproducible model development process. At last, a holistic data analytics platform rooted in the O-RAN deployment is designed and implemented, aiming to embrace and fulfil the aforementioned principles and best practices of RLOps.",
    "authors": [
      "Peizheng Li",
      "Jonathan Thomas",
      "Xiaoyang Wang",
      "Ahmed Khalil",
      "Abdelrahim Ahmad",
      "Rui Inacio",
      "Shipra Kapoor",
      "Arjun Parekh",
      "Angela Doufexi",
      "Arman Shojaeifard",
      "Robert Piechocki"
    ],
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "published": "2021-11-12T22:57:09Z",
    "pdf_url": "https://arxiv.org/pdf/2111.06978v2"
  },
  {
    "arxiv_id": "2111.06721v2",
    "entry_id": "http://arxiv.org/abs/2111.06721v2",
    "title": "Causal Multi-Agent Reinforcement Learning: Review and Open Problems",
    "summary": "This paper serves to introduce the reader to the field of multi-agent reinforcement learning (MARL) and its intersection with methods from the study of causality. We highlight key challenges in MARL and discuss these in the context of how causal methods may assist in tackling them. We promote moving toward a 'causality first' perspective on MARL. Specifically, we argue that causality can offer improved safety, interpretability, and robustness, while also providing strong theoretical guarantees for emergent behaviour. We discuss potential solutions for common challenges, and use this context to motivate future research directions.",
    "authors": [
      "St John Grimbly",
      "Jonathan Shock",
      "Arnu Pretorius"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2021-11-12T13:44:31Z",
    "pdf_url": "https://arxiv.org/pdf/2111.06721v2"
  },
  {
    "arxiv_id": "2111.05402v2",
    "entry_id": "http://arxiv.org/abs/2111.05402v2",
    "title": "Cutting a Cake Is Not Always a 'Piece of Cake': A Closer Look at the Foundations of Cake-Cutting Through the Lens of Measure Theory",
    "summary": "Cake-cutting is a playful name for the fair division of a heterogeneous, divisible good among agents, a well-studied problem at the intersection of mathematics, economics, and artificial intelligence. The cake-cutting literature is rich and edifying. However, different model assumptions are made in its many papers, in particular regarding the set of allowed pieces of cake that are to be distributed among the agents and regarding the agents' valuation functions by which they measure these pieces. We survey the commonly used definitions in the cake-cutting literature, highlight their strengths and weaknesses, and make some recommendations on what definitions could be most reasonably used when looking through the lens of measure theory.",
    "authors": [
      "Peter Kern",
      "Daniel Neugebauer",
      "Jörg Rothe",
      "René L. Schilling",
      "Dietrich Stoyan",
      "Robin Weishaupt"
    ],
    "categories": [
      "cs.GT",
      "cs.MA"
    ],
    "published": "2021-11-09T20:18:41Z",
    "pdf_url": "https://arxiv.org/pdf/2111.05402v2"
  },
  {
    "arxiv_id": "2111.04949v2",
    "entry_id": "http://arxiv.org/abs/2111.04949v2",
    "title": "A Survey and Empirical Evaluation of Parallel Deep Learning Frameworks",
    "summary": "The field of deep learning has witnessed a remarkable shift towards extremely compute- and memory-intensive neural networks. These newer larger models have enabled researchers to advance state-of-the-art tools across a variety of fields. This phenomenon has spurred the development of algorithms for distributed training of neural networks over a larger number of hardware accelerators. In this paper, we discuss and compare current state-of-the-art frameworks for large scale distributed deep learning. First, we survey current practices in distributed learning and identify the different types of parallelism used. Then, we present empirical results comparing their performance on large image and language training tasks. Additionally, we address their statistical efficiency and memory consumption behavior. Based on our results, we discuss algorithmic and implementation portions of each framework which hinder performance.",
    "authors": [
      "Daniel Nichols",
      "Siddharth Singh",
      "Shu-Huai Lin",
      "Abhinav Bhatele"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2021-11-09T04:24:42Z",
    "pdf_url": "https://arxiv.org/pdf/2111.04949v2"
  },
  {
    "arxiv_id": "2111.05193v2",
    "entry_id": "http://arxiv.org/abs/2111.05193v2",
    "title": "A Survey on Green Deep Learning",
    "summary": "In recent years, larger and deeper models are springing up and continuously pushing state-of-the-art (SOTA) results across various fields like natural language processing (NLP) and computer vision (CV). However, despite promising results, it needs to be noted that the computations required by SOTA models have been increased at an exponential rate. Massive computations not only have a surprisingly large carbon footprint but also have negative effects on research inclusiveness and deployment on real-world applications.\n  Green deep learning is an increasingly hot research field that appeals to researchers to pay attention to energy usage and carbon emission during model training and inference. The target is to yield novel results with lightweight and efficient technologies. Many technologies can be used to achieve this goal, like model compression and knowledge distillation. This paper focuses on presenting a systematic review of the development of Green deep learning technologies. We classify these approaches into four categories: (1) compact networks, (2) energy-efficient training strategies, (3) energy-efficient inference approaches, and (4) efficient data usage. For each category, we discuss the progress that has been achieved and the unresolved challenges.",
    "authors": [
      "Jingjing Xu",
      "Wangchunshu Zhou",
      "Zhiyi Fu",
      "Hao Zhou",
      "Lei Li"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2021-11-08T16:55:03Z",
    "pdf_url": "https://arxiv.org/pdf/2111.05193v2"
  },
  {
    "arxiv_id": "2111.04466v1",
    "entry_id": "http://arxiv.org/abs/2111.04466v1",
    "title": "Improving Peer Assessment with Graph Convolutional Networks",
    "summary": "Peer assessment systems are emerging in many social and multi-agent settings, such as peer grading in large (online) classes, peer review in conferences, peer art evaluation, etc. However, peer assessments might not be as accurate as expert evaluations, thus rendering these systems unreliable. The reliability of peer assessment systems is influenced by various factors such as assessment ability of peers, their strategic assessment behaviors, and the peer assessment setup (e.g., peer evaluating group work or individual work of others). In this work, we first model peer assessment as multi-relational weighted networks that can express a variety of peer assessment setups, plus capture conflicts of interest and strategic behaviors. Leveraging our peer assessment network model, we introduce a graph convolutional network which can learn assessment patterns and user behaviors to more accurately predict expert evaluations. Our extensive experiments on real and synthetic datasets demonstrate the efficacy of our proposed approach, which outperforms existing peer assessment methods.",
    "authors": [
      "Alireza A. Namanloo",
      "Julie Thorpe",
      "Amirali Salehi-Abari"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2021-11-04T03:43:09Z",
    "pdf_url": "https://arxiv.org/pdf/2111.04466v1"
  },
  {
    "arxiv_id": "2111.01689v2",
    "entry_id": "http://arxiv.org/abs/2111.01689v2",
    "title": "Improving Classifier Training Efficiency for Automatic Cyberbullying Detection with Feature Density",
    "summary": "We study the effectiveness of Feature Density (FD) using different linguistically-backed feature preprocessing methods in order to estimate dataset complexity, which in turn is used to comparatively estimate the potential performance of machine learning (ML) classifiers prior to any training. We hypothesise that estimating dataset complexity allows for the reduction of the number of required experiments iterations. This way we can optimize the resource-intensive training of ML models which is becoming a serious issue due to the increases in available dataset sizes and the ever rising popularity of models based on Deep Neural Networks (DNN). The problem of constantly increasing needs for more powerful computational resources is also affecting the environment due to alarmingly-growing amount of CO2 emissions caused by training of large-scale ML models. The research was conducted on multiple datasets, including popular datasets, such as Yelp business review dataset used for training typical sentiment analysis models, as well as more recent datasets trying to tackle the problem of cyberbullying, which, being a serious social problem, is also a much more sophisticated problem form the point of view of linguistic representation. We use cyberbullying datasets collected for multiple languages, namely English, Japanese and Polish. The difference in linguistic complexity of datasets allows us to additionally discuss the efficacy of linguistically-backed word preprocessing.",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui",
      "Aleksander Smywiński-Pohl",
      "Gniewosz Leliwa",
      "Michal Wroczynski"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2021-11-02T15:48:28Z",
    "pdf_url": "https://arxiv.org/pdf/2111.01689v2"
  },
  {
    "arxiv_id": "2111.01414v1",
    "entry_id": "http://arxiv.org/abs/2111.01414v1",
    "title": "A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots",
    "summary": "In spoken dialogue systems, we aim to deploy artificial intelligence to build automated dialogue agents that can converse with humans. Dialogue systems are increasingly being designed to move beyond just imitating conversation and also improve from such interactions over time. In this survey, we present a broad overview of methods developed to build dialogue systems over the years. Different use cases for dialogue systems ranging from task-based systems to open domain chatbots motivate and necessitate specific systems. Starting from simple rule-based systems, research has progressed towards increasingly complex architectures trained on a massive corpus of datasets, like deep learning systems. Motivated with the intuition of resembling human dialogues, progress has been made towards incorporating emotions into the natural language generator, using reinforcement learning. While we see a trend of highly marginal improvement on some metrics, we find that limited justification exists for the metrics, and evaluation practices are not uniform. To conclude, we flag these concerns and highlight possible research directions.",
    "authors": [
      "Atharv Singh Patlan",
      "Shiven Tripathi",
      "Shubham Korde"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-11-02T08:07:55Z",
    "pdf_url": "https://arxiv.org/pdf/2111.01414v1"
  },
  {
    "arxiv_id": "2111.01243v1",
    "entry_id": "http://arxiv.org/abs/2111.01243v1",
    "title": "Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey",
    "summary": "Large, pre-trained transformer-based language models such as BERT have drastically changed the Natural Language Processing (NLP) field. We present a survey of recent work that uses these large language models to solve NLP tasks via pre-training then fine-tuning, prompting, or text generation approaches. We also present approaches that use pre-trained language models to generate data for training augmentation or other purposes. We conclude with discussions on limitations and suggested directions for future research.",
    "authors": [
      "Bonan Min",
      "Hayley Ross",
      "Elior Sulem",
      "Amir Pouran Ben Veyseh",
      "Thien Huu Nguyen",
      "Oscar Sainz",
      "Eneko Agirre",
      "Ilana Heinz",
      "Dan Roth"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-11-01T20:08:05Z",
    "pdf_url": "https://arxiv.org/pdf/2111.01243v1"
  },
  {
    "arxiv_id": "2110.13484v3",
    "entry_id": "http://arxiv.org/abs/2110.13484v3",
    "title": "Applications of Multi-Agent Reinforcement Learning in Future Internet: A Comprehensive Survey",
    "summary": "Future Internet involves several emerging technologies such as 5G and beyond 5G networks, vehicular networks, unmanned aerial vehicle (UAV) networks, and Internet of Things (IoTs). Moreover, future Internet becomes heterogeneous and decentralized with a large number of involved network entities. Each entity may need to make its local decision to improve the network performance under dynamic and uncertain network environments. Standard learning algorithms such as single-agent Reinforcement Learning (RL) or Deep Reinforcement Learning (DRL) have been recently used to enable each network entity as an agent to learn an optimal decision-making policy adaptively through interacting with the unknown environments. However, such an algorithm fails to model the cooperations or competitions among network entities, and simply treats other entities as a part of the environment that may result in the non-stationarity issue. Multi-agent Reinforcement Learning (MARL) allows each network entity to learn its optimal policy by observing not only the environments, but also other entities' policies. As a result, MARL can significantly improve the learning efficiency of the network entities, and it has been recently used to solve various issues in the emerging networks. In this paper, we thus review the applications of MARL in the emerging networks. In particular, we provide a tutorial of MARL and a comprehensive survey of applications of MARL in next generation Internet. In particular, we first introduce single-agent RL and MARL. Then, we review a number of applications of MARL to solve emerging issues in future Internet. The issues consist of network access, transmit power control, computation offloading, content caching, packet routing, trajectory design for UAV-aided networks, and network security issues.",
    "authors": [
      "Tianxu Li",
      "Kun Zhu",
      "Nguyen Cong Luong",
      "Dusit Niyato",
      "Qihui Wu",
      "Yang Zhang",
      "Bing Chen"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2021-10-26T08:26:55Z",
    "pdf_url": "https://arxiv.org/pdf/2110.13484v3"
  },
  {
    "arxiv_id": "2110.12680v1",
    "entry_id": "http://arxiv.org/abs/2110.12680v1",
    "title": "TODSum: Task-Oriented Dialogue Summarization with State Tracking",
    "summary": "Previous dialogue summarization datasets mainly focus on open-domain chitchat dialogues, while summarization datasets for the broadly used task-oriented dialogue haven't been explored yet. Automatically summarizing such task-oriented dialogues can help a business collect and review needs to improve the service. Besides, previous datasets pay more attention to generate good summaries with higher ROUGE scores, but they hardly understand the structured information of dialogues and ignore the factuality of summaries. In this paper, we introduce a large-scale public Task-Oriented Dialogue Summarization dataset, TODSum, which aims to summarize the key points of the agent completing certain tasks with the user. Compared to existing work, TODSum suffers from severe scattered information issues and requires strict factual consistency, which makes it hard to directly apply recent dialogue summarization models. Therefore, we introduce additional dialogue state knowledge for TODSum to enhance the faithfulness of generated summaries. We hope a better understanding of conversational content helps summarization models generate concise and coherent summaries. Meanwhile, we establish a comprehensive benchmark for TODSum and propose a state-aware structured dialogue summarization model to integrate dialogue state information and dialogue history. Exhaustive experiments and qualitative analysis prove the effectiveness of dialogue structure guidance. Finally, we discuss the current issues of TODSum and potential development directions for future work.",
    "authors": [
      "Lulu Zhao",
      "Fujia Zheng",
      "Keqing He",
      "Weihao Zeng",
      "Yuejie Lei",
      "Huixing Jiang",
      "Wei Wu",
      "Weiran Xu",
      "Jun Guo",
      "Fanyu Meng"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-10-25T06:53:11Z",
    "pdf_url": "https://arxiv.org/pdf/2110.12680v1"
  },
  {
    "arxiv_id": "2110.08527v3",
    "entry_id": "http://arxiv.org/abs/2110.08527v3",
    "title": "An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models",
    "summary": "Recent work has shown pre-trained language models capture social biases from the large amounts of text they are trained on. This has attracted attention to developing techniques that mitigate such biases. In this work, we perform an empirical survey of five recently proposed bias mitigation techniques: Counterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias, and SentenceDebias. We quantify the effectiveness of each technique using three intrinsic bias benchmarks while also measuring the impact of these techniques on a model's language modeling ability, as well as its performance on downstream NLU tasks. We experimentally find that: (1) Self-Debias is the strongest debiasing technique, obtaining improved scores on all bias benchmarks; (2) Current debiasing techniques perform less consistently when mitigating non-gender biases; And (3) improvements on bias benchmarks such as StereoSet and CrowS-Pairs by using debiasing strategies are often accompanied by a decrease in language modeling ability, making it difficult to determine whether the bias mitigation was effective.",
    "authors": [
      "Nicholas Meade",
      "Elinor Poole-Dayan",
      "Siva Reddy"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-10-16T09:40:30Z",
    "pdf_url": "https://arxiv.org/pdf/2110.08527v3"
  },
  {
    "arxiv_id": "2110.01799v1",
    "entry_id": "http://arxiv.org/abs/2110.01799v1",
    "title": "ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts",
    "summary": "Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose \"document-level natural language inference (NLI) for contracts\", a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as \"Some obligations of Agreement may survive termination.\") and a contract, and it is asked to classify whether each hypothesis is \"entailed by\", \"contradicting to\" or \"not mentioned by\" (neutral to) the contract as well as identifying \"evidence\" for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (1) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (2) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.",
    "authors": [
      "Yuta Koreeda",
      "Christopher D. Manning"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-10-05T03:22:31Z",
    "pdf_url": "https://arxiv.org/pdf/2110.01799v1"
  },
  {
    "arxiv_id": "2110.00273v5",
    "entry_id": "http://arxiv.org/abs/2110.00273v5",
    "title": "From SLAM to Situational Awareness: Challenges and Survey",
    "summary": "The capability of a mobile robot to efficiently and safely perform complex missions is limited by its knowledge of the environment, namely the situation. Advanced reasoning, decision-making, and execution skills enable an intelligent agent to act autonomously in unknown environments. Situational Awareness (SA) is a fundamental capability of humans that has been deeply studied in various fields, such as psychology, military, aerospace, and education. Nevertheless, it has yet to be considered in robotics, which has focused on single compartmentalized concepts such as sensing, spatial perception, sensor fusion, state estimation, and Simultaneous Localization and Mapping (SLAM). Hence, the present research aims to connect the broad multidisciplinary existing knowledge to pave the way for a complete SA system for mobile robotics that we deem paramount for autonomy. To this aim, we define the principal components to structure a robotic SA and their area of competence. Accordingly, this paper investigates each aspect of SA, surveying the state-of-the-art robotics algorithms that cover them, and discusses their current limitations. Remarkably, essential aspects of SA are still immature since the current algorithmic development restricts their performance to only specific environments. Nevertheless, Artificial Intelligence (AI), particularly Deep Learning (DL), has brought new methods to bridge the gap that maintains these fields apart from the deployment to real-world scenarios. Furthermore, an opportunity has been discovered to interconnect the vastly fragmented space of robotic comprehension algorithms through the mechanism of Situational Graph (S-Graph), a generalization of the well-known scene graph. Therefore, we finally shape our vision for the future of robotic Situational Awareness by discussing interesting recent research directions.",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Claudio Cimarelli",
      "Ali Tourani",
      "Holger Voos"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2021-10-01T09:00:34Z",
    "pdf_url": "https://arxiv.org/pdf/2110.00273v5"
  },
  {
    "arxiv_id": "2110.00269v5",
    "entry_id": "http://arxiv.org/abs/2110.00269v5",
    "title": "A Survey of Knowledge Enhanced Pre-trained Models",
    "summary": "Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.",
    "authors": [
      "Jian Yang",
      "Xinyu Hu",
      "Gang Xiao",
      "Yulong Shen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-10-01T08:51:58Z",
    "pdf_url": "https://arxiv.org/pdf/2110.00269v5"
  },
  {
    "arxiv_id": "2109.14728v1",
    "entry_id": "http://arxiv.org/abs/2109.14728v1",
    "title": "Collaborative Storytelling with Human Actors and AI Narrators",
    "summary": "Large language models can be used for collaborative storytelling. In this work we report on using GPT-3 \\cite{brown2020language} to co-narrate stories. The AI system must track plot progression and character arcs while the human actors perform scenes. This event report details how a novel conversational agent was employed as creative partner with a team of professional improvisers to explore long-form spontaneous story narration in front of a live public audience. We introduced novel constraints on our language model to produce longer narrative text and tested the model in rehearsals with a team of professional improvisers. We then field tested the model with two live performances for public audiences as part of a live theatre festival in Europe. We surveyed audience members after each performance as well as performers to evaluate how well the AI performed in its role as narrator. Audiences and performers responded positively to AI narration and indicated preference for AI narration over AI characters within a scene. Performers also responded positively to AI narration and expressed enthusiasm for the creative and meaningful novel narrative directions introduced to the scenes. Our findings support improvisational theatre as a useful test-bed to explore how different language models can collaborate with humans in a variety of social contexts.",
    "authors": [
      "Boyd Branch",
      "Piotr Mirowski",
      "Kory W. Mathewson"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2021-09-29T21:21:35Z",
    "pdf_url": "https://arxiv.org/pdf/2109.14728v1"
  },
  {
    "arxiv_id": "2110.01411v1",
    "entry_id": "http://arxiv.org/abs/2110.01411v1",
    "title": "Deep Reinforcement Learning Versus Evolution Strategies: A Comparative Survey",
    "summary": "Deep Reinforcement Learning (DRL) and Evolution Strategies (ESs) have surpassed human-level control in many sequential decision-making problems, yet many open challenges still exist. To get insights into the strengths and weaknesses of DRL versus ESs, an analysis of their respective capabilities and limitations is provided. After presenting their fundamental concepts and algorithms, a comparison is provided on key aspects such as scalability, exploration, adaptation to dynamic environments, and multi-agent learning. Then, the benefits of hybrid algorithms that combine concepts from DRL and ESs are highlighted. Finally, to have an indication about how they compare in real-world applications, a survey of the literature for the set of applications they support is provided.",
    "authors": [
      "Amjad Yousef Majid",
      "Serge Saaybi",
      "Tomas van Rietbergen",
      "Vincent Francois-Lavet",
      "R Venkatesha Prasad",
      "Chris Verhoeven"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-09-28T18:45:30Z",
    "pdf_url": "https://arxiv.org/pdf/2110.01411v1"
  },
  {
    "arxiv_id": "2109.12788v1",
    "entry_id": "http://arxiv.org/abs/2109.12788v1",
    "title": "Multiplicative Position-aware Transformer Models for Language Understanding",
    "summary": "Transformer models, which leverage architectural improvements like self-attention, perform remarkably well on Natural Language Processing (NLP) tasks. The self-attention mechanism is position agnostic. In order to capture positional ordering information, various flavors of absolute and relative position embeddings have been proposed. However, there is no systematic analysis on their contributions and a comprehensive comparison of these methods is missing in the literature. In this paper, we review major existing position embedding methods and compare their accuracy on downstream NLP tasks, using our own implementations. We also propose a novel multiplicative embedding method which leads to superior accuracy when compared to existing methods. Finally, we show that our proposed embedding method, served as a drop-in replacement of the default absolute position embedding, can improve the RoBERTa-base and RoBERTa-large models on SQuAD1.1 and SQuAD2.0 datasets.",
    "authors": [
      "Zhiheng Huang",
      "Davis Liang",
      "Peng Xu",
      "Bing Xiang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-09-27T04:18:32Z",
    "pdf_url": "https://arxiv.org/pdf/2109.12788v1"
  },
  {
    "arxiv_id": "2109.12575v2",
    "entry_id": "http://arxiv.org/abs/2109.12575v2",
    "title": "Paradigm Shift in Natural Language Processing",
    "summary": "In the era of deep learning, modeling for most NLP tasks has converged to several mainstream paradigms. For example, we usually adopt the sequence labeling paradigm to solve a bundle of tasks such as POS-tagging, NER, Chunking, and adopt the classification paradigm to solve tasks like sentiment analysis. With the rapid progress of pre-trained language models, recent years have observed a rising trend of Paradigm Shift, which is solving one NLP task by reformulating it as another one. Paradigm shift has achieved great success on many tasks, becoming a promising way to improve model performance. Moreover, some of these paradigms have shown great potential to unify a large number of NLP tasks, making it possible to build a single model to handle diverse tasks. In this paper, we review such phenomenon of paradigm shifts in recent years, highlighting several paradigms that have the potential to solve different NLP tasks.",
    "authors": [
      "Tianxiang Sun",
      "Xiangyang Liu",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-09-26T11:55:23Z",
    "pdf_url": "https://arxiv.org/pdf/2109.12575v2"
  },
  {
    "arxiv_id": "2109.13232v1",
    "entry_id": "http://arxiv.org/abs/2109.13232v1",
    "title": "Contributions to Large Scale Bayesian Inference and Adversarial Machine Learning",
    "summary": "The rampant adoption of ML methodologies has revealed that models are usually adopted to make decisions without taking into account the uncertainties in their predictions. More critically, they can be vulnerable to adversarial examples. Thus, we believe that developing ML systems that take into account predictive uncertainties and are robust against adversarial examples is a must for critical, real-world tasks. We start with a case study in retailing. We propose a robust implementation of the Nerlove-Arrow model using a Bayesian structural time series model. Its Bayesian nature facilitates incorporating prior information reflecting the manager's views, which can be updated with relevant data. However, this case adopted classical Bayesian techniques, such as the Gibbs sampler. Nowadays, the ML landscape is pervaded with neural networks and this chapter also surveys current developments in this sub-field. Then, we tackle the problem of scaling Bayesian inference to complex models and large data regimes. In the first part, we propose a unifying view of two different Bayesian inference algorithms, Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) and Stein Variational Gradient Descent (SVGD), leading to improved and efficient novel sampling schemes. In the second part, we develop a framework to boost the efficiency of Bayesian inference in probabilistic models by embedding a Markov chain sampler within a variational posterior approximation. After that, we present an alternative perspective on adversarial classification based on adversarial risk analysis, and leveraging the scalable Bayesian approaches from chapter 2. In chapter 4 we turn to reinforcement learning, introducing Threatened Markov Decision Processes, showing the benefits of accounting for adversaries in RL while the agent learns.",
    "authors": [
      "Víctor Gallego"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2021-09-25T23:02:47Z",
    "pdf_url": "https://arxiv.org/pdf/2109.13232v1"
  },
  {
    "arxiv_id": "2109.12343v1",
    "entry_id": "http://arxiv.org/abs/2109.12343v1",
    "title": "Beyond Robustness: A Taxonomy of Approaches towards Resilient Multi-Robot Systems",
    "summary": "Robustness is key to engineering, automation, and science as a whole. However, the property of robustness is often underpinned by costly requirements such as over-provisioning, known uncertainty and predictive models, and known adversaries. These conditions are idealistic, and often not satisfiable. Resilience on the other hand is the capability to endure unexpected disruptions, to recover swiftly from negative events, and bounce back to normality. In this survey article, we analyze how resilience is achieved in networks of agents and multi-robot systems that are able to overcome adversity by leveraging system-wide complementarity, diversity, and redundancy - often involving a reconfiguration of robotic capabilities to provide some key ability that was not present in the system a priori. As society increasingly depends on connected automated systems to provide key infrastructure services (e.g., logistics, transport, and precision agriculture), providing the means to achieving resilient multi-robot systems is paramount. By enumerating the consequences of a system that is not resilient (fragile), we argue that resilience must become a central engineering design consideration. Towards this goal, the community needs to gain clarity on how it is defined, measured, and maintained. We address these questions across foundational robotics domains, spanning perception, control, planning, and learning. One of our key contributions is a formal taxonomy of approaches, which also helps us discuss the defining factors and stressors for a resilient system. Finally, this survey article gives insight as to how resilience may be achieved. Importantly, we highlight open problems that remain to be tackled in order to reap the benefits of resilient robotic systems.",
    "authors": [
      "Amanda Prorok",
      "Matthew Malencia",
      "Luca Carlone",
      "Gaurav S. Sukhatme",
      "Brian M. Sadler",
      "Vijay Kumar"
    ],
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.MA",
      "eess.SY"
    ],
    "published": "2021-09-25T11:25:02Z",
    "pdf_url": "https://arxiv.org/pdf/2109.12343v1"
  },
  {
    "arxiv_id": "2109.10756v4",
    "entry_id": "http://arxiv.org/abs/2109.10756v4",
    "title": "Constrained multi-agent ergodic area surveying control based on finite element approximation of the potential field",
    "summary": "Heat Equation Driven Area Coverage (HEDAC) is a state-of-the-art multi-agent ergodic motion control guided by a gradient of a potential field. A finite element method is hereby implemented to obtain a solution of the Helmholtz partial differential equation, which models the potential field for surveying motion control. This allows us to survey arbitrarily shaped domains and to include obstacles in an elegant and robust manner intrinsic to HEDAC's fundamental idea. For a simple kinematic motion, the obstacles and boundary avoidance constraints are successfully handled by directing the agent motion with the gradient of the potential. However, including additional constraints, such as the minimal clearance distance from stationary and moving obstacles and the minimal path curvature radius, requires further alternations of the control algorithm. We introduce a relatively simple yet robust approach for handling these constraints by formulating a straightforward optimization problem based on collision-free escape route maneuvers. This approach provides a guaranteed collision avoidance mechanism while being computationally inexpensive as a result of the optimization problem partitioning. The proposed motion control is evaluated in three realistic surveying scenarios simulations, showing the effectiveness of the surveying and the robustness of the control algorithm. Furthermore, potential maneuvering difficulties due to improperly defined surveying scenarios are highlighted and we provide guidelines on how to overpass them. The results are promising and indicate real-world applicability of the proposed constrained multi-agent motion control for autonomous surveying and potentially other HEDAC utilizations.",
    "authors": [
      "Stefan Ivić",
      "Ante Sikirica",
      "Bojan Crnković"
    ],
    "categories": [
      "math.OC",
      "cs.MA",
      "cs.RO",
      "eess.SY"
    ],
    "published": "2021-09-22T14:23:20Z",
    "pdf_url": "https://arxiv.org/pdf/2109.10756v4"
  },
  {
    "arxiv_id": "2109.09478v1",
    "entry_id": "http://arxiv.org/abs/2109.09478v1",
    "title": "A Survey of Text Games for Reinforcement Learning informed by Natural Language",
    "summary": "Reinforcement Learning has shown success in a number of complex virtual environments. However, many challenges still exist towards solving problems with natural language as a core component. Interactive Fiction Games (or Text Games) are one such problem type that offer a set of partially observable environments where natural language is required as part of the reinforcement learning solutions.\n  Therefore, this survey's aim is to assist in the development of new Text Game problem settings and solutions for Reinforcement Learning informed by natural language. Specifically, this survey summarises: 1) the challenges introduced in Text Game Reinforcement Learning problems, 2) the generation tools for evaluating Text Games and the subsequent environments generated and, 3) the agent architectures currently applied are compared to provide a systematic review of benchmark methodologies and opportunities for future researchers.",
    "authors": [
      "Philip Osborne",
      "Heido Nõmm",
      "Andre Freitas"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-09-20T12:32:57Z",
    "pdf_url": "https://arxiv.org/pdf/2109.09478v1"
  },
  {
    "arxiv_id": "2109.08270v3",
    "entry_id": "http://arxiv.org/abs/2109.08270v3",
    "title": "Language Models as a Knowledge Source for Cognitive Agents",
    "summary": "Language models (LMs) are sentence-completion engines trained on massive corpora. LMs have emerged as a significant breakthrough in natural-language processing, providing capabilities that go far beyond sentence completion including question answering, summarization, and natural-language inference. While many of these capabilities have potential application to cognitive systems, exploiting language models as a source of task knowledge, especially for task learning, offers significant, near-term benefits. We introduce language models and the various tasks to which they have been applied and then review methods of knowledge extraction from language models. The resulting analysis outlines both the challenges and opportunities for using language models as a new knowledge source for cognitive systems. It also identifies possible ways to improve knowledge extraction from language models using the capabilities provided by cognitive systems. Central to success will be the ability of a cognitive agent to itself learn an abstract model of the knowledge implicit in the LM as well as methods to extract high-quality knowledge effectively and efficiently. To illustrate, we introduce a hypothetical robot agent and describe how language models could extend its task knowledge and improve its performance and the kinds of knowledge and methods the agent can use to exploit the knowledge within a language model.",
    "authors": [
      "Robert E. Wray,",
      "James R. Kirk",
      "John E. Laird"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2021-09-17T01:12:34Z",
    "pdf_url": "https://arxiv.org/pdf/2109.08270v3"
  },
  {
    "arxiv_id": "2109.07576v1",
    "entry_id": "http://arxiv.org/abs/2109.07576v1",
    "title": "\"It doesn't look good for a date\": Transforming Critiques into Preferences for Conversational Recommendation Systems",
    "summary": "Conversations aimed at determining good recommendations are iterative in nature. People often express their preferences in terms of a critique of the current recommendation (e.g., \"It doesn't look good for a date\"), requiring some degree of common sense for a preference to be inferred. In this work, we present a method for transforming a user critique into a positive preference (e.g., \"I prefer more romantic\") in order to retrieve reviews pertaining to potentially better recommendations (e.g., \"Perfect for a romantic dinner\"). We leverage a large neural language model (LM) in a few-shot setting to perform critique-to-preference transformation, and we test two methods for retrieving recommendations: one that matches embeddings, and another that fine-tunes an LM for the task. We instantiate this approach in the restaurant domain and evaluate it using a new dataset of restaurant critiques. In an ablation study, we show that utilizing critique-to-preference transformation improves recommendations, and that there are at least three general cases that explain this improved performance.",
    "authors": [
      "Victor S. Bursztyn",
      "Jennifer Healey",
      "Nedim Lipka",
      "Eunyee Koh",
      "Doug Downey",
      "Larry Birnbaum"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-09-15T21:10:33Z",
    "pdf_url": "https://arxiv.org/pdf/2109.07576v1"
  },
  {
    "arxiv_id": "2109.06668v6",
    "entry_id": "http://arxiv.org/abs/2109.06668v6",
    "title": "Exploration in Deep Reinforcement Learning: From Single-Agent to Multiagent Domain",
    "summary": "Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning (MARL) have achieved significant successes across a wide range of domains, including game AI, autonomous vehicles, robotics, and so on. However, DRL and deep MARL agents are widely known to be sample inefficient that millions of interactions are usually needed even for relatively simple problem settings, thus preventing the wide application and deployment in real-industry scenarios. One bottleneck challenge behind is the well-known exploration problem, i.e., how efficiently exploring the environment and collecting informative experiences that could benefit policy learning towards the optimal ones. This problem becomes more challenging in complex environments with sparse rewards, noisy distractions, long horizons, and non-stationary co-learners. In this paper, we conduct a comprehensive survey on existing exploration methods for both single-agent and multi-agent RL. We start the survey by identifying several key challenges to efficient exploration. Beyond the above two main branches, we also include other notable exploration methods with different ideas and techniques. In addition to algorithmic analysis, we provide a comprehensive and unified empirical comparison of different exploration methods for DRL on a set of commonly used benchmarks. According to our algorithmic and empirical investigation, we finally summarize the open problems of exploration in DRL and deep MARL and point out a few future directions.",
    "authors": [
      "Jianye Hao",
      "Tianpei Yang",
      "Hongyao Tang",
      "Chenjia Bai",
      "Jinyi Liu",
      "Zhaopeng Meng",
      "Peng Liu",
      "Zhen Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2021-09-14T13:16:33Z",
    "pdf_url": "https://arxiv.org/pdf/2109.06668v6"
  },
  {
    "arxiv_id": "2109.03784v1",
    "entry_id": "http://arxiv.org/abs/2109.03784v1",
    "title": "A Survey on Machine Learning Techniques for Auto Labeling of Video, Audio, and Text Data",
    "summary": "Machine learning has been utilized to perform tasks in many different domains such as classification, object detection, image segmentation and natural language analysis. Data labeling has always been one of the most important tasks in machine learning. However, labeling large amounts of data increases the monetary cost in machine learning. As a result, researchers started to focus on reducing data annotation and labeling costs. Transfer learning was designed and widely used as an efficient approach that can reasonably reduce the negative impact of limited data, which in turn, reduces the data preparation cost. Even transferring previous knowledge from a source domain reduces the amount of data needed in a target domain. However, large amounts of annotated data are still demanded to build robust models and improve the prediction accuracy of the model. Therefore, researchers started to pay more attention on auto annotation and labeling. In this survey paper, we provide a review of previous techniques that focuses on optimized data annotation and labeling for video, audio, and text data.",
    "authors": [
      "Shikun Zhang",
      "Omid Jafari",
      "Parth Nagarkar"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2021-09-08T17:15:34Z",
    "pdf_url": "https://arxiv.org/pdf/2109.03784v1"
  },
  {
    "arxiv_id": "2109.03821v1",
    "entry_id": "http://arxiv.org/abs/2109.03821v1",
    "title": "Recommend for a Reason: Unlocking the Power of Unsupervised Aspect-Sentiment Co-Extraction",
    "summary": "Compliments and concerns in reviews are valuable for understanding users' shopping interests and their opinions with respect to specific aspects of certain items. Existing review-based recommenders favor large and complex language encoders that can only learn latent and uninterpretable text representations. They lack explicit user attention and item property modeling, which however could provide valuable information beyond the ability to recommend items. Therefore, we propose a tightly coupled two-stage approach, including an Aspect-Sentiment Pair Extractor (ASPE) and an Attention-Property-aware Rating Estimator (APRE). Unsupervised ASPE mines Aspect-Sentiment pairs (AS-pairs) and APRE predicts ratings using AS-pairs as concrete aspect-level evidence. Extensive experiments on seven real-world Amazon Review Datasets demonstrate that ASPE can effectively extract AS-pairs which enable APRE to deliver superior accuracy over the leading baselines.",
    "authors": [
      "Zeyu Li",
      "Wei Cheng",
      "Reema Kshetramade",
      "John Houser",
      "Haifeng Chen",
      "Wei Wang"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2021-09-07T21:40:56Z",
    "pdf_url": "https://arxiv.org/pdf/2109.03821v1"
  },
  {
    "arxiv_id": "2109.01703v1",
    "entry_id": "http://arxiv.org/abs/2109.01703v1",
    "title": "Will bots take over the supply chain? Revisiting Agent-based supply chain automation",
    "summary": "Agent-based systems have the capability to fuse information from many distributed sources and create better plans faster. This feature makes agent-based systems naturally suitable to address the challenges in Supply Chain Management (SCM). Although agent-based supply chains systems have been proposed since early 2000; industrial uptake of them has been lagging. The reasons quoted include the immaturity of the technology, a lack of interoperability with supply chain information systems, and a lack of trust in Artificial Intelligence (AI). In this paper, we revisit the agent-based supply chain and review the state of the art. We find that agent-based technology has matured, and other supporting technologies that are penetrating supply chains; are filling in gaps, leaving the concept applicable to a wider range of functions. For example, the ubiquity of IoT technology helps agents \"sense\" the state of affairs in a supply chain and opens up new possibilities for automation. Digital ledgers help securely transfer data between third parties, making agent-based information sharing possible, without the need to integrate Enterprise Resource Planning (ERP) systems. Learning functionality in agents enables agents to move beyond automation and towards autonomy. We note this convergence effect through conceptualising an agent-based supply chain framework, reviewing its components, and highlighting research challenges that need to be addressed in moving forward.",
    "authors": [
      "Liming Xu",
      "Stephen Mak",
      "Alexandra Brintrup"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-09-03T18:44:26Z",
    "pdf_url": "https://arxiv.org/pdf/2109.01703v1"
  },
  {
    "arxiv_id": "2109.01182v1",
    "entry_id": "http://arxiv.org/abs/2109.01182v1",
    "title": "COVID-19 Vaccine Hesitancy and Information Diffusion: An Agent-based Modeling Approach",
    "summary": "Despite the unprecedented success in the rapid development of several effective vaccines against the Cov-SARS-2, global vaccination rollout efforts suffer from vaccine distribution inequality and vaccine acceptance, leading to insufficient public immunity provided by the vaccine products. While a major current focus in vaccine acceptance research is how to model and inform vaccine acceptance based on social-demographic parameters, characteristics of vaccine acceptance are not well understood and in particular, it is not known whether and how information diffusion influences vaccine acceptance. This study examines how information diffusion can change vaccine acceptance by developing a comprehensive computational model with an agent-based simulation technique to overcome the modeling and quantification complexity associated with socio-demographics, vaccine types, population statistics, and information diffusion. Our analyses, calibrated by the vaccine acceptance survey data from the provinces and territories of Canada, provide clear evidence that the propagation of information can greatly influence vaccine acceptance rates. The results illustrate that spread of negative messages about the COVID-19 vaccines can cause significant vaccine hesitancy that challenges the goal of a high public immunity provided by the vaccines. Our findings might help solve the vaccine hesitancy problem by focusing more on individuals' opinions and behavior.",
    "authors": [
      "Pooria Taghizadeh Naderi",
      "Ali Asgary",
      "Jude Kong",
      "Jianhong Wu",
      "Fattaneh Taghiyareh"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.MA",
      "cs.SI"
    ],
    "published": "2021-09-02T19:18:36Z",
    "pdf_url": "https://arxiv.org/pdf/2109.01182v1"
  },
  {
    "arxiv_id": "2109.01178v1",
    "entry_id": "http://arxiv.org/abs/2109.01178v1",
    "title": "Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations and Alternative Solution Concepts",
    "summary": "Multi-agent inverse reinforcement learning (MIRL) can be used to learn reward functions from agents in social environments. To model realistic social dynamics, MIRL methods must account for suboptimal human reasoning and behavior. Traditional formalisms of game theory provide computationally tractable behavioral models, but assume agents have unrealistic cognitive capabilities. This research identifies and compares mechanisms in MIRL methods which a) handle noise, biases and heuristics in agent decision making and b) model realistic equilibrium solution concepts. MIRL research is systematically reviewed to identify solutions for these challenges. The methods and results of these studies are analyzed and compared based on factors including performance accuracy, efficiency, and descriptive quality. We found that the primary methods for handling noise, biases and heuristics in MIRL were extensions of Maximum Entropy (MaxEnt) IRL to multi-agent settings. We also found that many successful solution concepts are generalizations of the traditional Nash Equilibrium (NE). These solutions include the correlated equilibrium, logistic stochastic best response equilibrium and entropy regularized mean field NE. Methods which use recursive reasoning or updating also perform well, including the feedback NE and archive multi-agent adversarial IRL. Success in modeling specific biases and heuristics in single-agent IRL and promising results using a Theory of Mind approach in MIRL imply that modeling specific biases and heuristics may be useful. Flexibility and unbiased inference in the identified alternative solution concepts suggest that a solution concept which has both recursive and generalized characteristics may perform well at modeling realistic social interactions.",
    "authors": [
      "Sage Bergerson"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2021-09-02T19:15:29Z",
    "pdf_url": "https://arxiv.org/pdf/2109.01178v1"
  },
  {
    "arxiv_id": "2109.00484v2",
    "entry_id": "http://arxiv.org/abs/2109.00484v2",
    "title": "Impossibility Results in AI: A Survey",
    "summary": "An impossibility theorem demonstrates that a particular problem or set of problems cannot be solved as described in the claim. Such theorems put limits on what is possible to do concerning artificial intelligence, especially the super-intelligent one. As such, these results serve as guidelines, reminders, and warnings to AI safety, AI policy, and governance researchers. These might enable solutions to some long-standing questions in the form of formalizing theories in the framework of constraint satisfaction without committing to one option. We strongly believe this to be the most prudent approach to long-term AI safety initiatives. In this paper, we have categorized impossibility theorems applicable to AI into five mechanism-based categories: deduction, indistinguishability, induction, tradeoffs, and intractability. We found that certain theorems are too specific or have implicit assumptions that limit application. Also, we added new results (theorems) such as the unfairness of explainability, the first explainability-related result in the induction category. The remaining results deal with misalignment between the clones and put a limit to the self-awareness of agents. We concluded that deductive impossibilities deny 100%-guarantees for security. In the end, we give some ideas that hold potential in explainability, controllability, value alignment, ethics, and group decision-making. They can be deepened by further investigation.",
    "authors": [
      "Mario Brcic",
      "Roman V. Yampolskiy"
    ],
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2021-09-01T16:52:13Z",
    "pdf_url": "https://arxiv.org/pdf/2109.00484v2"
  },
  {
    "arxiv_id": "2109.00157v2",
    "entry_id": "http://arxiv.org/abs/2109.00157v2",
    "title": "A Survey of Exploration Methods in Reinforcement Learning",
    "summary": "Exploration is an essential component of reinforcement learning algorithms, where agents need to learn how to predict and control unknown and often stochastic environments. Reinforcement learning agents depend crucially on exploration to obtain informative data for the learning process as the lack of enough information could hinder effective learning. In this article, we provide a survey of modern exploration methods in (Sequential) reinforcement learning, as well as a taxonomy of exploration methods.",
    "authors": [
      "Susan Amin",
      "Maziar Gomrokchi",
      "Harsh Satija",
      "Herke van Hoof",
      "Doina Precup"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-09-01T02:36:14Z",
    "pdf_url": "https://arxiv.org/pdf/2109.00157v2"
  },
  {
    "arxiv_id": "2108.12333v1",
    "entry_id": "http://arxiv.org/abs/2108.12333v1",
    "title": "Integrating Heuristics and Learning in a Computational Architecture for Cognitive Trading",
    "summary": "The successes of Artificial Intelligence in recent years in areas such as image analysis, natural language understanding and strategy games have sparked interest from the world of finance. Specifically, there are high expectations, and ongoing engineering projects, regarding the creation of artificial agents, known as robotic traders, capable of juggling the financial markets with the skill of experienced human traders. Obvious economic implications aside, this is certainly an area of great scientific interest, due to the challenges that such a real context poses to the use of AI techniques. Precisely for this reason, we must be aware that artificial agents capable of operating at such levels are not just round the corner, and that there will be no simple answers, but rather a concurrence of various technologies and methods to the success of the effort. In the course of this article, we review the issues inherent in the design of effective robotic traders as well as the consequently applicable solutions, having in view the general objective of bringing the current state of the art of robo-trading up to the next level of intelligence, which we refer to as Cognitive Trading. Key to our approach is the joining of two methodological and technological directions which, although both deeply rooted in the disciplinary field of artificial intelligence, have so far gone their separate ways: heuristics and learning.",
    "authors": [
      "Remo Pareschi",
      "Federico Zappone"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-08-27T15:09:33Z",
    "pdf_url": "https://arxiv.org/pdf/2108.12333v1"
  },
  {
    "arxiv_id": "2108.11887v2",
    "entry_id": "http://arxiv.org/abs/2108.11887v2",
    "title": "Federated Reinforcement Learning: Techniques, Applications, and Open Challenges",
    "summary": "This paper presents a comprehensive survey of Federated Reinforcement Learning (FRL), an emerging and promising field in Reinforcement Learning (RL). Starting with a tutorial of Federated Learning (FL) and RL, we then focus on the introduction of FRL as a new method with great potential by leveraging the basic idea of FL to improve the performance of RL while preserving data-privacy. According to the distribution characteristics of the agents in the framework, FRL algorithms can be divided into two categories, i.e. Horizontal Federated Reinforcement Learning (HFRL) and Vertical Federated Reinforcement Learning (VFRL). We provide the detailed definitions of each category by formulas, investigate the evolution of FRL from a technical perspective, and highlight its advantages over previous RL algorithms. In addition, the existing works on FRL are summarized by application fields, including edge computing, communication, control optimization, and attack detection. Finally, we describe and discuss several key research directions that are crucial to solving the open problems within FRL.",
    "authors": [
      "Jiaju Qi",
      "Qihao Zhou",
      "Lei Lei",
      "Kan Zheng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-08-26T16:22:49Z",
    "pdf_url": "https://arxiv.org/pdf/2108.11887v2"
  },
  {
    "arxiv_id": "2108.09823v1",
    "entry_id": "http://arxiv.org/abs/2108.09823v1",
    "title": "Embodied AI-Driven Operation of Smart Cities: A Concise Review",
    "summary": "A smart city can be seen as a framework, comprised of Information and Communication Technologies (ICT). An intelligent network of connected devices that collect data with their sensors and transmit them using cloud technologies in order to communicate with other assets in the ecosystem plays a pivotal role in this framework. Maximizing the quality of life of citizens, making better use of resources, cutting costs, and improving sustainability are the ultimate goals that a smart city is after. Hence, data collected from connected devices will continuously get thoroughly analyzed to gain better insights into the services that are being offered across the city; with this goal in mind that they can be used to make the whole system more efficient. Robots and physical machines are inseparable parts of a smart city. Embodied AI is the field of study that takes a deeper look into these and explores how they can fit into real-world environments. It focuses on learning through interaction with the surrounding environment, as opposed to Internet AI which tries to learn from static datasets. Embodied AI aims to train an agent that can See (Computer Vision), Talk (NLP), Navigate and Interact with its environment (Reinforcement Learning), and Reason (General Intelligence), all at the same time. Autonomous driving cars and personal companions are some of the examples that benefit from Embodied AI nowadays. In this paper, we attempt to do a concise review of this field. We will go through its definitions, its characteristics, and its current achievements along with different algorithms, approaches, and solutions that are being used in different components of it (e.g. Vision, NLP, RL). We will then explore all the available simulators and 3D interactable databases that will make the research in this area feasible. Finally, we will address its challenges and identify its potentials for future research.",
    "authors": [
      "Farzan Shenavarmasouleh",
      "Farid Ghareh Mohammadi",
      "M. Hadi Amini",
      "Hamid R. Arabnia"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2021-08-22T19:14:59Z",
    "pdf_url": "https://arxiv.org/pdf/2108.09823v1"
  },
  {
    "arxiv_id": "2108.09003v1",
    "entry_id": "http://arxiv.org/abs/2108.09003v1",
    "title": "Explainable Reinforcement Learning for Broad-XAI: A Conceptual Framework and Survey",
    "summary": "Broad Explainable Artificial Intelligence moves away from interpreting individual decisions based on a single datum and aims to provide integrated explanations from multiple machine learning algorithms into a coherent explanation of an agent's behaviour that is aligned to the communication needs of the explainee. Reinforcement Learning (RL) methods, we propose, provide a potential backbone for the cognitive model required for the development of Broad-XAI. RL represents a suite of approaches that have had increasing success in solving a range of sequential decision-making problems. However, these algorithms all operate as black-box problem solvers, where they obfuscate their decision-making policy through a complex array of values and functions. EXplainable RL (XRL) is relatively recent field of research that aims to develop techniques to extract concepts from the agent's: perception of the environment; intrinsic/extrinsic motivations/beliefs; Q-values, goals and objectives. This paper aims to introduce a conceptual framework, called the Causal XRL Framework (CXF), that unifies the current XRL research and uses RL as a backbone to the development of Broad-XAI. Additionally, we recognise that RL methods have the ability to incorporate a range of technologies to allow agents to adapt to their environment. CXF is designed for the incorporation of many standard RL extensions and integrated with external ontologies and communication facilities so that the agent can answer questions that explain outcomes and justify its decisions.",
    "authors": [
      "Richard Dazeley",
      "Peter Vamplew",
      "Francisco Cruz"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-08-20T05:18:50Z",
    "pdf_url": "https://arxiv.org/pdf/2108.09003v1"
  },
  {
    "arxiv_id": "2108.08411v2",
    "entry_id": "http://arxiv.org/abs/2108.08411v2",
    "title": "FeelsGoodMan: Inferring Semantics of Twitch Neologisms",
    "summary": "Twitch chats pose a unique problem in natural language understanding due to a large presence of neologisms, specifically emotes. There are a total of 8.06 million emotes, over 400k of which were used in the week studied. There is virtually no information on the meaning or sentiment of emotes, and with a constant influx of new emotes and drift in their frequencies, it becomes impossible to maintain an updated manually-labeled dataset. Our paper makes a two fold contribution. First we establish a new baseline for sentiment analysis on Twitch data, outperforming the previous supervised benchmark by 7.9% points. Secondly, we introduce a simple but powerful unsupervised framework based on word embeddings and k-NN to enrich existing models with out-of-vocabulary knowledge. This framework allows us to auto-generate a pseudo-dictionary of emotes and we show that we can nearly match the supervised benchmark above even when injecting such emote knowledge into sentiment classifiers trained on extraneous datasets such as movie reviews or Twitter.",
    "authors": [
      "Pavel Dolin",
      "Luc d'Hauthuille",
      "Andrea Vattani"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-08-18T23:46:46Z",
    "pdf_url": "https://arxiv.org/pdf/2108.08411v2"
  },
  {
    "arxiv_id": "2108.06264v1",
    "entry_id": "http://arxiv.org/abs/2108.06264v1",
    "title": "Bridging the gap between emotion and joint action",
    "summary": "Our daily human life is filled with a myriad of joint action moments, be it children playing, adults working together (i.e., team sports), or strangers navigating through a crowd. Joint action brings individuals (and embodiment of their emotions) together, in space and in time. Yet little is known about how individual emotions propagate through embodied presence in a group, and how joint action changes individual emotion. In fact, the multi-agent component is largely missing from neuroscience-based approaches to emotion, and reversely joint action research has not found a way yet to include emotion as one of the key parameters to model socio-motor interaction. In this review, we first identify the gap and then stockpile evidence showing strong entanglement between emotion and acting together from various branches of sciences. We propose an integrative approach to bridge the gap, highlight five research avenues to do so in behavioral neuroscience and digital sciences, and address some of the key challenges in the area faced by modern societies.",
    "authors": [
      "M. M. N. Bieńkiewicz",
      "A. Smykovskyi",
      "T. Olugbade",
      "S. Janaqi",
      "A. Camurri",
      "N. Bianchi-Berthouze",
      "M. Björkman",
      "B. G. Bardy"
    ],
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "cs.MA",
      "cs.RO",
      "math.DS"
    ],
    "published": "2021-08-13T14:21:37Z",
    "pdf_url": "https://arxiv.org/pdf/2108.06264v1"
  },
  {
    "arxiv_id": "2108.03383v2",
    "entry_id": "http://arxiv.org/abs/2108.03383v2",
    "title": "Artificial Intelligence-Driven Customized Manufacturing Factory: Key Technologies, Applications, and Challenges",
    "summary": "The traditional production paradigm of large batch production does not offer flexibility towards satisfying the requirements of individual customers. A new generation of smart factories is expected to support new multi-variety and small-batch customized production modes. For that, Artificial Intelligence (AI) is enabling higher value-added manufacturing by accelerating the integration of manufacturing and information communication technologies, including computing, communication, and control. The characteristics of a customized smart factory are to include self-perception, operations optimization, dynamic reconfiguration, and intelligent decision-making. The AI technologies will allow manufacturing systems to perceive the environment, adapt to external needs, and extract the processed knowledge, including business models, such as intelligent production, networked collaboration, and extended service models.\n  This paper focuses on the implementation of AI in customized manufacturing (CM). The architecture of an AI-driven customized smart factory is presented. Details of intelligent manufacturing devices, intelligent information interaction, and the construction of a flexible manufacturing line are showcased. The state-of-the-art AI technologies of potential use in CM, i.e., machine learning, multi-agent systems, Internet of Things, big data, and cloud-edge computing are surveyed. The AI-enabled technologies in a customized smart factory are validated with a case study of customized packaging. The experimental results have demonstrated that the AI-assisted CM offers the possibility of higher production flexibility and efficiency. Challenges and solutions related to AI in CM are also discussed.",
    "authors": [
      "Jiafu Wan",
      "Xiaomin Li",
      "Hong-Ning Dai",
      "Andrew Kusiak",
      "Miguel Martínez-García",
      "Di Li"
    ],
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "published": "2021-08-07T07:14:36Z",
    "pdf_url": "https://arxiv.org/pdf/2108.03383v2"
  },
  {
    "arxiv_id": "2108.02998v2",
    "entry_id": "http://arxiv.org/abs/2108.02998v2",
    "title": "AI-based Aortic Vessel Tree Segmentation for Cardiovascular Diseases Treatment: Status Quo",
    "summary": "The aortic vessel tree is composed of the aorta and its branching arteries, and plays a key role in supplying the whole body with blood. Aortic diseases, like aneurysms or dissections, can lead to an aortic rupture, whose treatment with open surgery is highly risky. Therefore, patients commonly undergo drug treatment under constant monitoring, which requires regular inspections of the vessels through imaging. The standard imaging modality for diagnosis and monitoring is computed tomography (CT), which can provide a detailed picture of the aorta and its branching vessels if completed with a contrast agent, called CT angiography (CTA). Optimally, the whole aortic vessel tree geometry from consecutive CTAs is overlaid and compared. This allows not only detection of changes in the aorta, but also of its branches, caused by the primary pathology or newly developed. When performed manually, this reconstruction requires slice by slice contouring, which could easily take a whole day for a single aortic vessel tree, and is therefore not feasible in clinical practice. Automatic or semi-automatic vessel tree segmentation algorithms, however, can complete this task in a fraction of the manual execution time and run in parallel to the clinical routine of the clinicians. In this paper, we systematically review computing techniques for the automatic and semi-automatic segmentation of the aortic vessel tree. The review concludes with an in-depth discussion on how close these state-of-the-art approaches are to an application in clinical practice and how active this research field is, taking into account the number of publications, datasets and challenges.",
    "authors": [
      "Yuan Jin",
      "Antonio Pepe",
      "Jianning Li",
      "Christina Gsaxner",
      "Fen-hua Zhao",
      "Kelsey L. Pomykala",
      "Jens Kleesiek",
      "Alejandro F. Frangi",
      "Jan Egger"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "published": "2021-08-06T08:18:28Z",
    "pdf_url": "https://arxiv.org/pdf/2108.02998v2"
  },
  {
    "arxiv_id": "2108.04087v1",
    "entry_id": "http://arxiv.org/abs/2108.04087v1",
    "title": "Reinforcement Learning for Intelligent Healthcare Systems: A Comprehensive Survey",
    "summary": "The rapid increase in the percentage of chronic disease patients along with the recent pandemic pose immediate threats on healthcare expenditure and elevate causes of death. This calls for transforming healthcare systems away from one-on-one patient treatment into intelligent health systems, to improve services, access and scalability, while reducing costs. Reinforcement Learning (RL) has witnessed an intrinsic breakthrough in solving a variety of complex problems for diverse applications and services. Thus, we conduct in this paper a comprehensive survey of the recent models and techniques of RL that have been developed/used for supporting Intelligent-healthcare (I-health) systems. This paper can guide the readers to deeply understand the state-of-the-art regarding the use of RL in the context of I-health. Specifically, we first present an overview for the I-health systems challenges, architecture, and how RL can benefit these systems. We then review the background and mathematical modeling of different RL, Deep RL (DRL), and multi-agent RL models. After that, we provide a deep literature review for the applications of RL in I-health systems. In particular, three main areas have been tackled, i.e., edge intelligence, smart core network, and dynamic treatment regimes. Finally, we highlight emerging challenges and outline future research directions in driving the future success of RL in I-health systems, which opens the door for exploring some interesting and unsolved problems.",
    "authors": [
      "Alaa Awad Abdellatif",
      "Naram Mhaisen",
      "Zina Chkirbene",
      "Amr Mohamed",
      "Aiman Erbad",
      "Mohsen Guizani"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2021-08-05T18:47:17Z",
    "pdf_url": "https://arxiv.org/pdf/2108.04087v1"
  },
  {
    "arxiv_id": "2108.04359v1",
    "entry_id": "http://arxiv.org/abs/2108.04359v1",
    "title": "Adaptable image quality assessment using meta-reinforcement learning of task amenability",
    "summary": "The performance of many medical image analysis tasks are strongly associated with image data quality. When developing modern deep learning algorithms, rather than relying on subjective (human-based) image quality assessment (IQA), task amenability potentially provides an objective measure of task-specific image quality. To predict task amenability, an IQA agent is trained using reinforcement learning (RL) with a simultaneously optimised task predictor, such as a classification or segmentation neural network. In this work, we develop transfer learning or adaptation strategies to increase the adaptability of both the IQA agent and the task predictor so that they are less dependent on high-quality, expert-labelled training data. The proposed transfer learning strategy re-formulates the original RL problem for task amenability in a meta-reinforcement learning (meta-RL) framework. The resulting algorithm facilitates efficient adaptation of the agent to different definitions of image quality, each with its own Markov decision process environment including different images, labels and an adaptable task predictor. Our work demonstrates that the IQA agents pre-trained on non-expert task labels can be adapted to predict task amenability as defined by expert task labels, using only a small set of expert labels. Using 6644 clinical ultrasound images from 249 prostate cancer patients, our results for image classification and segmentation tasks show that the proposed IQA method can be adapted using data with as few as respective 19.7% and 29.6% expert-reviewed consensus labels and still achieve comparable IQA and task performance, which would otherwise require a training dataset with 100% expert labels.",
    "authors": [
      "Shaheer U. Saeed",
      "Yunguan Fu",
      "Vasilis Stavrinides",
      "Zachary M. C. Baum",
      "Qianye Yang",
      "Mirabela Rusu",
      "Richard E. Fan",
      "Geoffrey A. Sonn",
      "J. Alison Noble",
      "Dean C. Barratt",
      "Yipeng Hu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2021-07-31T11:29:37Z",
    "pdf_url": "https://arxiv.org/pdf/2108.04359v1"
  },
  {
    "arxiv_id": "2107.14316v1",
    "entry_id": "http://arxiv.org/abs/2107.14316v1",
    "title": "Survey of Recent Multi-Agent Reinforcement Learning Algorithms Utilizing Centralized Training",
    "summary": "Much work has been dedicated to the exploration of Multi-Agent Reinforcement Learning (MARL) paradigms implementing a centralized learning with decentralized execution (CLDE) approach to achieve human-like collaboration in cooperative tasks. Here, we discuss variations of centralized training and describe a recent survey of algorithmic approaches. The goal is to explore how different implementations of information sharing mechanism in centralized learning may give rise to distinct group coordinated behaviors in multi-agent systems performing cooperative tasks.",
    "authors": [
      "Piyush K. Sharma",
      "Rolando Fernandez",
      "Erin Zaroukian",
      "Michael Dorothy",
      "Anjon Basak",
      "Derrik E. Asher"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-07-29T20:29:12Z",
    "pdf_url": "https://arxiv.org/pdf/2107.14316v1"
  },
  {
    "arxiv_id": "2107.12603v1",
    "entry_id": "http://arxiv.org/abs/2107.12603v1",
    "title": "Federated Learning Meets Natural Language Processing: A Survey",
    "summary": "Federated Learning aims to learn machine learning models from multiple decentralized edge devices (e.g. mobiles) or servers without sacrificing local data privacy. Recent Natural Language Processing techniques rely on deep learning and large pre-trained language models. However, both big deep neural and language models are trained with huge amounts of data which often lies on the server side. Since text data is widely originated from end users, in this work, we look into recent NLP models and techniques which use federated learning as the learning framework. Our survey discusses major challenges in federated natural language processing, including the algorithm challenges, system challenges as well as the privacy issues. We also provide a critical review of the existing Federated NLP evaluation methods and tools. Finally, we highlight the current research gaps and future directions.",
    "authors": [
      "Ming Liu",
      "Stella Ho",
      "Mengqi Wang",
      "Longxiang Gao",
      "Yuan Jin",
      "He Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2021-07-27T05:07:48Z",
    "pdf_url": "https://arxiv.org/pdf/2107.12603v1"
  },
  {
    "arxiv_id": "2107.11399v1",
    "entry_id": "http://arxiv.org/abs/2107.11399v1",
    "title": "An agent-based model for modal shift in public transport",
    "summary": "Modal shift in public transport as a consequence of a disruption on a line has in some cases unforeseen consequences such as an increase in congestion in the rest of the network. How information is provided to users and their behavior plays a central role in such configurations. We introduce here a simple and stylised agent-based model aimed at understanding the impact of behavioural parameters on modal shift. The model is applied on a case study based on a stated preference survey for a segment of Paris suburban train network. We systematically explore the parameter space and show non-trivial patterns of congestion for some values of discrete choice parameters linked to perceived wait time and congestion. We also apply a genetic optimisation algorithm to the model to search for optimal compromises between congestion in different modes.",
    "authors": [
      "Thibaut Barbet",
      "Amine Nacer-Weill",
      "Changtao Yang",
      "Juste Raimbault"
    ],
    "categories": [
      "cs.MA"
    ],
    "published": "2021-07-23T18:02:24Z",
    "pdf_url": "https://arxiv.org/pdf/2107.11399v1"
  },
  {
    "arxiv_id": "2107.10121v1",
    "entry_id": "http://arxiv.org/abs/2107.10121v1",
    "title": "Peer Selection with Noisy Assessments",
    "summary": "In the peer selection problem a group of agents must select a subset of themselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take a Condorcet view of this aggregation problem, i.e., that there is a ground-truth ordering over the agents and we wish to select the best set of agents, subject to the noisy assessments of the peers. Given this model, some agents may be unreliable, while others might be self-interested, attempting to influence the outcome in their favour. In this paper we extend PeerNomination, the most accurate peer reviewing algorithm to date, into WeightedPeerNomination, which is able to handle noisy and inaccurate agents. To do this, we explicitly formulate assessors' reliability weights in a way that does not violate strategyproofness, and use this information to reweight their scores. We show analytically that a weighting scheme can improve the overall accuracy of the selection significantly. Finally, we implement several instances of reweighting methods and show empirically that our methods are robust in the face of noisy assessments.",
    "authors": [
      "Omer Lev",
      "Nicholas Mattei",
      "Paolo Turrini",
      "Stanislav Zhydkov"
    ],
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2021-07-21T14:47:11Z",
    "pdf_url": "https://arxiv.org/pdf/2107.10121v1"
  },
  {
    "arxiv_id": "2107.05825v1",
    "entry_id": "http://arxiv.org/abs/2107.05825v1",
    "title": "Recent Advances in Leveraging Human Guidance for Sequential Decision-Making Tasks",
    "summary": "A longstanding goal of artificial intelligence is to create artificial agents capable of learning to perform tasks that require sequential decision making. Importantly, while it is the artificial agent that learns and acts, it is still up to humans to specify the particular task to be performed. Classical task-specification approaches typically involve humans providing stationary reward functions or explicit demonstrations of the desired tasks. However, there has recently been a great deal of research energy invested in exploring alternative ways in which humans may guide learning agents that may, e.g., be more suitable for certain tasks or require less human effort. This survey provides a high-level overview of five recent machine learning frameworks that primarily rely on human guidance apart from pre-specified reward functions or conventional, step-by-step action demonstrations. We review the motivation, assumptions, and implementation of each framework, and we discuss possible future research directions.",
    "authors": [
      "Ruohan Zhang",
      "Faraz Torabi",
      "Garrett Warnell",
      "Peter Stone"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-07-13T03:11:04Z",
    "pdf_url": "https://arxiv.org/pdf/2107.05825v1"
  },
  {
    "arxiv_id": "2107.04568v1",
    "entry_id": "http://arxiv.org/abs/2107.04568v1",
    "title": "Deep Learning for Mean Field Games and Mean Field Control with Applications to Finance",
    "summary": "Financial markets and more generally macro-economic models involve a large number of individuals interacting through variables such as prices resulting from the aggregate behavior of all the agents. Mean field games have been introduced to study Nash equilibria for such problems in the limit when the number of players is infinite. The theory has been extensively developed in the past decade, using both analytical and probabilistic tools, and a wide range of applications have been discovered, from economics to crowd motion. More recently the interaction with machine learning has attracted a growing interest. This aspect is particularly relevant to solve very large games with complex structures, in high dimension or with common sources of randomness. In this chapter, we review the literature on the interplay between mean field games and deep learning, with a focus on three families of methods. A special emphasis is given to financial applications.",
    "authors": [
      "René Carmona",
      "Mathieu Laurière"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "q-fin.CP"
    ],
    "published": "2021-07-09T17:40:11Z",
    "pdf_url": "https://arxiv.org/pdf/2107.04568v1"
  },
  {
    "arxiv_id": "2107.04529v1",
    "entry_id": "http://arxiv.org/abs/2107.04529v1",
    "title": "Entropy, Information, and the Updating of Probabilities",
    "summary": "This paper is a review of a particular approach to the method of maximum entropy as a general framework for inference. The discussion emphasizes the pragmatic elements in the derivation. An epistemic notion of information is defined in terms of its relation to the Bayesian beliefs of ideally rational agents. The method of updating from a prior to a posterior probability distribution is designed through an eliminative induction process. The logarithmic relative entropy is singled out as the unique tool for updating that (a) is of universal applicability; (b) that recognizes the value of prior information; and (c) that recognizes the privileged role played by the notion of independence in science. The resulting framework -- the ME method -- can handle arbitrary priors and arbitrary constraints. It includes MaxEnt and Bayes' rule as special cases and, therefore, it unifies entropic and Bayesian methods into a single general inference scheme. The ME method goes beyond the mere selection of a single posterior, but also addresses the question of how much less probable other distributions might be, which provides a direct bridge to the theories of fluctuations and large deviations.",
    "authors": [
      "Ariel Caticha"
    ],
    "categories": [
      "physics.data-an",
      "cs.AI",
      "stat.ME"
    ],
    "published": "2021-07-09T16:27:23Z",
    "pdf_url": "https://arxiv.org/pdf/2107.04529v1"
  },
  {
    "arxiv_id": "2107.04132v1",
    "entry_id": "http://arxiv.org/abs/2107.04132v1",
    "title": "A Systematic Survey of Text Worlds as Embodied Natural Language Environments",
    "summary": "Text Worlds are virtual environments for embodied agents that, unlike 2D or 3D environments, are rendered exclusively using textual descriptions. These environments offer an alternative to higher-fidelity 3D environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich high-level action spaces while controlling for perceptual input. This systematic survey outlines recent developments in tooling, environments, and agent modeling for Text Worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of Text World performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make Text Worlds an attractive general research paradigm for natural language processing.",
    "authors": [
      "Peter A Jansen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-07-08T22:15:16Z",
    "pdf_url": "https://arxiv.org/pdf/2107.04132v1"
  },
  {
    "arxiv_id": "2107.03959v1",
    "entry_id": "http://arxiv.org/abs/2107.03959v1",
    "title": "Privacy Concerns in Chatbot Interactions: When to Trust and When to Worry",
    "summary": "Through advances in their conversational abilities, chatbots have started to request and process an increasing variety of sensitive personal information. The accurate disclosure of sensitive information is essential where it is used to provide advice and support to users in the healthcare and finance sectors. In this study, we explore users' concerns regarding factors associated with the use of sensitive data by chatbot providers. We surveyed a representative sample of 491 British citizens. Our results show that the user concerns focus on deleting personal information and concerns about their data's inappropriate use. We also identified that individuals were concerned about losing control over their data after a conversation with conversational agents. We found no effect from a user's gender or education but did find an effect from the user's age, with those over 45 being more concerned than those under 45. We also considered the factors that engender trust in a chatbot. Our respondents' primary focus was on the chatbot's technical elements, with factors such as the response quality being identified as the most critical factor. We again found no effect from the user's gender or education level; however, when we considered some social factors (e.g. avatars or perceived 'friendliness'), we found those under 45 years old rated these as more important than those over 45. The paper concludes with a discussion of these results within the context of designing inclusive, digital systems that support a wide range of users.",
    "authors": [
      "Rahime Belen Saglam",
      "Jason R. C. Nurse",
      "Duncan Hodges"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2021-07-08T16:31:58Z",
    "pdf_url": "https://arxiv.org/pdf/2107.03959v1"
  },
  {
    "arxiv_id": "2107.03451v3",
    "entry_id": "http://arxiv.org/abs/2107.03451v3",
    "title": "Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling",
    "summary": "Over the last several years, end-to-end neural conversational agents have vastly improved in their ability to carry a chit-chat conversation with humans. However, these models are often trained on large datasets from the internet, and as a result, may learn undesirable behaviors from this data, such as toxic or otherwise harmful language. Researchers must thus wrestle with the issue of how and when to release these models. In this paper, we survey the problem landscape for safety for end-to-end conversational AI and discuss recent and related work. We highlight tensions between values, potential positive impact and potential harms, and provide a framework for making decisions about whether and how to release these models, following the tenets of value-sensitive design. We additionally provide a suite of tools to enable researchers to make better-informed decisions about training and releasing end-to-end conversational AI models.",
    "authors": [
      "Emily Dinan",
      "Gavin Abercrombie",
      "A. Stevie Bergman",
      "Shannon Spruit",
      "Dirk Hovy",
      "Y-Lan Boureau",
      "Verena Rieser"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-07-07T19:25:57Z",
    "pdf_url": "https://arxiv.org/pdf/2107.03451v3"
  },
  {
    "arxiv_id": "2107.03178v1",
    "entry_id": "http://arxiv.org/abs/2107.03178v1",
    "title": "Levels of explainable artificial intelligence for human-aligned conversational explanations",
    "summary": "Over the last few years there has been rapid research growth into eXplainable Artificial Intelligence (XAI) and the closely aligned Interpretable Machine Learning (IML). Drivers for this growth include recent legislative changes and increased investments by industry and governments, along with increased concern from the general public. People are affected by autonomous decisions every day and the public need to understand the decision-making process to accept the outcomes. However, the vast majority of the applications of XAI/IML are focused on providing low-level `narrow' explanations of how an individual decision was reached based on a particular datum. While important, these explanations rarely provide insights into an agent's: beliefs and motivations; hypotheses of other (human, animal or AI) agents' intentions; interpretation of external cultural expectations; or, processes used to generate its own explanation. Yet all of these factors, we propose, are essential to providing the explanatory depth that people require to accept and trust the AI's decision-making. This paper aims to define levels of explanation and describe how they can be integrated to create a human-aligned conversational explanation system. In so doing, this paper will survey current approaches and discuss the integration of different technologies to achieve these levels with Broad eXplainable Artificial Intelligence (Broad-XAI), and thereby move towards high-level `strong' explanations.",
    "authors": [
      "Richard Dazeley",
      "Peter Vamplew",
      "Cameron Foale",
      "Charlotte Young",
      "Sunil Aryal",
      "Francisco Cruz"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2021-07-07T12:19:16Z",
    "pdf_url": "https://arxiv.org/pdf/2107.03178v1"
  },
  {
    "arxiv_id": "2107.00783v2",
    "entry_id": "http://arxiv.org/abs/2107.00783v2",
    "title": "Reinforcement Learning for Feedback-Enabled Cyber Resilience",
    "summary": "Digitization and remote connectivity have enlarged the attack surface and made cyber systems more vulnerable. As attackers become increasingly sophisticated and resourceful, mere reliance on traditional cyber protection, such as intrusion detection, firewalls, and encryption, is insufficient to secure the cyber systems. Cyber resilience provides a new security paradigm that complements inadequate protection with resilience mechanisms. A Cyber-Resilient Mechanism (CRM) adapts to the known or zero-day threats and uncertainties in real-time and strategically responds to them to maintain critical functions of the cyber systems in the event of successful attacks. Feedback architectures play a pivotal role in enabling the online sensing, reasoning, and actuation process of the CRM. Reinforcement Learning (RL) is an essential tool that epitomizes the feedback architectures for cyber resilience. It allows the CRM to provide sequential responses to attacks with limited or without prior knowledge of the environment and the attacker. In this work, we review the literature on RL for cyber resilience and discuss cyber resilience against three major types of vulnerabilities, i.e., posture-related, information-related, and human-related vulnerabilities. We introduce three application domains of CRMs: moving target defense, defensive cyber deception, and assistive human security technologies. The RL algorithms also have vulnerabilities themselves. We explain the three vulnerabilities of RL and present attack models where the attacker targets the information exchanged between the environment and the agent: the rewards, the state observations, and the action commands. We show that the attacker can trick the RL agent into learning a nefarious policy with minimum attacking effort. Lastly, we discuss the future challenges of RL for cyber security and resilience and emerging applications of RL-based CRMs.",
    "authors": [
      "Yunhan Huang",
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "categories": [
      "cs.CR",
      "cs.LG",
      "eess.SY"
    ],
    "published": "2021-07-02T01:08:45Z",
    "pdf_url": "https://arxiv.org/pdf/2107.00783v2"
  },
  {
    "arxiv_id": "2106.15691v2",
    "entry_id": "http://arxiv.org/abs/2106.15691v2",
    "title": "Deep Multiagent Reinforcement Learning: Challenges and Directions",
    "summary": "This paper surveys the field of deep multiagent reinforcement learning. The combination of deep neural networks with reinforcement learning has gained increased traction in recent years and is slowly shifting the focus from single-agent to multiagent environments. Dealing with multiple agents is inherently more complex as (a) the future rewards depend on multiple players' joint actions and (b) the computational complexity increases. We present the most common multiagent problem representations and their main challenges, and identify five research areas that address one or more of these challenges: centralised training and decentralised execution, opponent modelling, communication, efficient coordination, and reward shaping. We find that many computational studies rely on unrealistic assumptions or are not generalisable to other settings; they struggle to overcome the curse of dimensionality or nonstationarity. Approaches from psychology and sociology capture promising relevant behaviours, such as communication and coordination, to help agents achieve better performance in multiagent settings. We suggest that, for multiagent reinforcement learning to be successful, future research should address these challenges with an interdisciplinary approach to open up new possibilities in multiagent reinforcement learning.",
    "authors": [
      "Annie Wong",
      "Thomas Bäck",
      "Anna V. Kononova",
      "Aske Plaat"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.NE"
    ],
    "published": "2021-06-29T19:53:15Z",
    "pdf_url": "https://arxiv.org/pdf/2106.15691v2"
  },
  {
    "arxiv_id": "2106.14835v1",
    "entry_id": "http://arxiv.org/abs/2106.14835v1",
    "title": "Virtual Agents in Live Coding: A Short Review",
    "summary": "AI and live coding has been little explored. This article contributes with a short review of different perspectives of using virtual agents in the practice of live coding looking at past and present as well as pointing to future directions.",
    "authors": [
      "Anna Xambó"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-06-28T16:23:38Z",
    "pdf_url": "https://arxiv.org/pdf/2106.14835v1"
  },
  {
    "arxiv_id": "2106.13755v1",
    "entry_id": "http://arxiv.org/abs/2106.13755v1",
    "title": "Reinforcement Learning for Mean Field Games, with Applications to Economics",
    "summary": "Mean field games (MFG) and mean field control problems (MFC) are frameworks to study Nash equilibria or social optima in games with a continuum of agents. These problems can be used to approximate competitive or cooperative games with a large finite number of agents and have found a broad range of applications, in particular in economics. In recent years, the question of learning in MFG and MFC has garnered interest, both as a way to compute solutions and as a way to model how large populations of learners converge to an equilibrium. Of particular interest is the setting where the agents do not know the model, which leads to the development of reinforcement learning (RL) methods. After reviewing the literature on this topic, we present a two timescale approach with RL for MFG and MFC, which relies on a unified Q-learning algorithm. The main novelty of this method is to simultaneously update an action-value function and a distribution but with different rates, in a model-free fashion. Depending on the ratio of the two learning rates, the algorithm learns either the MFG or the MFC solution. To illustrate this method, we apply it to a mean field problem of accumulated consumption in finite horizon with HARA utility function, and to a trader's optimal liquidation problem.",
    "authors": [
      "Andrea Angiuli",
      "Jean-Pierre Fouque",
      "Mathieu Lauriere"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2021-06-25T16:45:04Z",
    "pdf_url": "https://arxiv.org/pdf/2106.13755v1"
  },
  {
    "arxiv_id": "2106.12177v2",
    "entry_id": "http://arxiv.org/abs/2106.12177v2",
    "title": "Imitation Learning: Progress, Taxonomies and Challenges",
    "summary": "Imitation learning aims to extract knowledge from human experts' demonstrations or artificially created agents in order to replicate their behaviors. Its success has been demonstrated in areas such as video games, autonomous driving, robotic simulations and object manipulation. However, this replicating process could be problematic, such as the performance is highly dependent on the demonstration quality, and most trained agents are limited to perform well in task-specific environments. In this survey, we provide a systematic review on imitation learning. We first introduce the background knowledge from development history and preliminaries, followed by presenting different taxonomies within Imitation Learning and key milestones of the field. We then detail challenges in learning strategies and present research opportunities with learning policy from suboptimal demonstration, voice instructions and other associated optimization schemes.",
    "authors": [
      "Boyuan Zheng",
      "Sunny Verma",
      "Jianlong Zhou",
      "Ivor Tsang",
      "Fang Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "published": "2021-06-23T05:55:33Z",
    "pdf_url": "https://arxiv.org/pdf/2106.12177v2"
  },
  {
    "arxiv_id": "2106.12113v3",
    "entry_id": "http://arxiv.org/abs/2106.12113v3",
    "title": "Conflict Avoidance in Social Navigation -- a Survey",
    "summary": "A major goal in robotics is to enable intelligent mobile robots to operate smoothly in shared human-robot environments. One of the most fundamental capabilities in service of this goal is competent navigation in this ``social\" context. As a result, there has been a recent surge of research on social navigation; and especially as it relates to the handling of conflicts between agents during social navigation. These developments introduce a variety of models and algorithms, however as this research area is inherently interdisciplinary, many of the relevant papers are not comparable and there is no shared standard vocabulary.\n  This survey aims to bridge this gap by introducing such a common language, using it to survey existing work, and highlighting open problems. It starts by defining the boundaries of this survey to a limited, yet highly common type of social navigation - conflict avoidance. Within this proposed scope, this survey introduces a detailed taxonomy of the conflict avoidance components. This survey then maps existing work into this taxonomy, while discussing papers using its framing. Finally, this paper proposes some future research directions and open problems that are currently on the frontier of social navigation to aid ongoing and future research.",
    "authors": [
      "Reuth Mirsky",
      "Xuesu Xiao",
      "Justin Hart",
      "Peter Stone"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2021-06-23T01:10:22Z",
    "pdf_url": "https://arxiv.org/pdf/2106.12113v3"
  },
  {
    "arxiv_id": "2106.09170v1",
    "entry_id": "http://arxiv.org/abs/2106.09170v1",
    "title": "A Survey on Semi-Supervised Learning for Delayed Partially Labelled Data Streams",
    "summary": "Unlabelled data appear in many domains and are particularly relevant to streaming applications, where even though data is abundant, labelled data is rare. To address the learning problems associated with such data, one can ignore the unlabelled data and focus only on the labelled data (supervised learning); use the labelled data and attempt to leverage the unlabelled data (semi-supervised learning); or assume some labels will be available on request (active learning). The first approach is the simplest, yet the amount of labelled data available will limit the predictive performance. The second relies on finding and exploiting the underlying characteristics of the data distribution. The third depends on an external agent to provide the required labels in a timely fashion. This survey pays special attention to methods that leverage unlabelled data in a semi-supervised setting. We also discuss the delayed labelling issue, which impacts both fully supervised and semi-supervised methods. We propose a unified problem setting, discuss the learning guarantees and existing methods, explain the differences between related problem settings. Finally, we review the current benchmarking practices and propose adaptations to enhance them.",
    "authors": [
      "Heitor Murilo Gomes",
      "Maciej Grzenda",
      "Rodrigo Mello",
      "Jesse Read",
      "Minh Huong Le Nguyen",
      "Albert Bifet"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2021-06-16T23:14:20Z",
    "pdf_url": "https://arxiv.org/pdf/2106.09170v1"
  },
  {
    "arxiv_id": "2106.06090v2",
    "entry_id": "http://arxiv.org/abs/2106.06090v2",
    "title": "Graph Neural Networks for Natural Language Processing: A Survey",
    "summary": "Deep learning has become the dominant approach in coping with various tasks in Natural LanguageProcessing (NLP). Although text inputs are typically represented as a sequence of tokens, there isa rich variety of NLP problems that can be best expressed with a graph structure. As a result, thereis a surge of interests in developing new deep learning techniques on graphs for a large numberof NLP tasks. In this survey, we present a comprehensive overview onGraph Neural Networks(GNNs) for Natural Language Processing. We propose a new taxonomy of GNNs for NLP, whichsystematically organizes existing research of GNNs for NLP along three axes: graph construction,graph representation learning, and graph based encoder-decoder models. We further introducea large number of NLP applications that are exploiting the power of GNNs and summarize thecorresponding benchmark datasets, evaluation metrics, and open-source codes. Finally, we discussvarious outstanding challenges for making the full use of GNNs for NLP as well as future researchdirections. To the best of our knowledge, this is the first comprehensive overview of Graph NeuralNetworks for Natural Language Processing.",
    "authors": [
      "Lingfei Wu",
      "Yu Chen",
      "Kai Shen",
      "Xiaojie Guo",
      "Hanning Gao",
      "Shucheng Li",
      "Jian Pei",
      "Bo Long"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-06-10T23:59:26Z",
    "pdf_url": "https://arxiv.org/pdf/2106.06090v2"
  },
  {
    "arxiv_id": "2106.05402v1",
    "entry_id": "http://arxiv.org/abs/2106.05402v1",
    "title": "Deception in Social Learning: A Multi-Agent Reinforcement Learning Perspective",
    "summary": "Within the framework of Multi-Agent Reinforcement Learning, Social Learning is a new class of algorithms that enables agents to reshape the reward function of other agents with the goal of promoting cooperation and achieving higher global rewards in mixed-motive games. However, this new modification allows agents unprecedented access to each other's learning process, which can drastically increase the risk of manipulation when an agent does not realize it is being deceived into adopting policies which are not actually in its own best interest. This research review introduces the problem statement, defines key concepts, critically evaluates existing evidence and addresses open problems that should be addressed in future research.",
    "authors": [
      "Paul Chelarescu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2021-06-09T21:34:11Z",
    "pdf_url": "https://arxiv.org/pdf/2106.05402v1"
  },
  {
    "arxiv_id": "2106.07550v1",
    "entry_id": "http://arxiv.org/abs/2106.07550v1",
    "title": "Attention mechanisms and deep learning for machine vision: A survey of the state of the art",
    "summary": "With the advent of state of the art nature-inspired pure attention based models i.e. transformers, and their success in natural language processing (NLP), their extension to machine vision (MV) tasks was inevitable and much felt. Subsequently, vision transformers (ViTs) were introduced which are giving quite a challenge to the established deep learning based machine vision techniques. However, pure attention based models/architectures like transformers require huge data, large training times and large computational resources. Some recent works suggest that combinations of these two varied fields can prove to build systems which have the advantages of both these fields. Accordingly, this state of the art survey paper is introduced which hopefully will help readers get useful information about this interesting and potential research area. A gentle introduction to attention mechanisms is given, followed by a discussion of the popular attention based deep architectures. Subsequently, the major categories of the intersection of attention mechanisms and deep learning for machine vision (MV) based are discussed. Afterwards, the major algorithms, issues and trends within the scope of the paper are discussed.",
    "authors": [
      "Abdul Mueed Hafiz",
      "Shabir Ahmad Parah",
      "Rouf Ul Alam Bhat"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-06-03T10:23:32Z",
    "pdf_url": "https://arxiv.org/pdf/2106.07550v1"
  },
  {
    "arxiv_id": "2106.00874v2",
    "entry_id": "http://arxiv.org/abs/2106.00874v2",
    "title": "Conversational Question Answering: A Survey",
    "summary": "Question answering (QA) systems provide a way of querying the information available in various formats including, but not limited to, unstructured and structured data in natural languages. It constitutes a considerable part of conversational artificial intelligence (AI) which has led to the introduction of a special research topic on Conversational Question Answering (CQA), wherein a system is required to understand the given context and then engages in multi-turn QA to satisfy the user's information needs. Whilst the focus of most of the existing research work is subjected to single-turn QA, the field of multi-turn QA has recently grasped attention and prominence owing to the availability of large-scale, multi-turn QA datasets and the development of pre-trained language models. With a good amount of models and research papers adding to the literature every year recently, there is a dire need of arranging and presenting the related work in a unified manner to streamline future research. This survey, therefore, is an effort to present a comprehensive review of the state-of-the-art research trends of CQA primarily based on reviewed papers from 2016-2021. Our findings show that there has been a trend shift from single-turn to multi-turn QA which empowers the field of Conversational AI from different perspectives. This survey is intended to provide an epitome for the research community with the hope of laying a strong foundation for the field of CQA.",
    "authors": [
      "Munazza Zaib",
      "Wei Emma Zhang",
      "Quan Z. Sheng",
      "Adnan Mahmood",
      "Yang Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2021-06-02T01:06:34Z",
    "pdf_url": "https://arxiv.org/pdf/2106.00874v2"
  },
  {
    "arxiv_id": "2106.00123v1",
    "entry_id": "http://arxiv.org/abs/2106.00123v1",
    "title": "Deep Reinforcement Learning in Quantitative Algorithmic Trading: A Review",
    "summary": "Algorithmic stock trading has become a staple in today's financial market, the majority of trades being now fully automated. Deep Reinforcement Learning (DRL) agents proved to be to a force to be reckon with in many complex games like Chess and Go. We can look at the stock market historical price series and movements as a complex imperfect information environment in which we try to maximize return - profit and minimize risk. This paper reviews the progress made so far with deep reinforcement learning in the subdomain of AI in finance, more precisely, automated low-frequency quantitative stock trading. Many of the reviewed studies had only proof-of-concept ideals with experiments conducted in unrealistic settings and no real-time trading applications. For the majority of the works, despite all showing statistically significant improvements in performance compared to established baseline strategies, no decent profitability level was obtained. Furthermore, there is a lack of experimental testing in real-time, online trading platforms and a lack of meaningful comparisons between agents built on different types of DRL or human traders. We conclude that DRL in stock trading has showed huge applicability potential rivalling professional traders under strong assumptions, but the research is still in the very early stages of development.",
    "authors": [
      "Tidor-Vlad Pricope"
    ],
    "categories": [
      "cs.LG",
      "q-fin.TR"
    ],
    "published": "2021-05-31T22:26:43Z",
    "pdf_url": "https://arxiv.org/pdf/2106.00123v1"
  },
  {
    "arxiv_id": "2106.08963v1",
    "entry_id": "http://arxiv.org/abs/2106.08963v1",
    "title": "Deep-learning based Tools for Automated Protocol Definition of Advanced Diagnostic Imaging Exams",
    "summary": "Purpose: This study evaluates the effectiveness and impact of automated order-based protocol assignment for magnetic resonance imaging (MRI) exams using natural language processing (NLP) and deep learning (DL).\n  Methods: NLP tools were applied to retrospectively process orders from over 116,000 MRI exams with 200 unique sub-specialized protocols (\"Local\" protocol class). Separate DL models were trained on 70\\% of the processed data for \"Local\" protocols as well as 93 American College of Radiology (\"ACR\") protocols and 48 \"General\" protocols. The DL Models were assessed in an \"auto-protocoling (AP)\" inference mode which returns the top recommendation and in a \"clinical decision support (CDS)\" inference mode which returns up to 10 protocols for radiologist review. The accuracy of each protocol recommendation was computed and analyzed based on the difference between the normalized output score of the corresponding neural net for the top two recommendations.\n  Results: The top predicted protocol in AP mode was correct for 82.8%, 73.8%, and 69.3% of the test cases for \"General\", \"ACR\", and \"Local\" protocol classes, respectively. Higher levels of accuracy over 96% were obtained for all protocol classes in CDS mode. However, at current validation performance levels, the proposed models offer modest, positive, financial impact on large-scale imaging networks.\n  Conclusions: DL-based protocol automation is feasible and can be tuned to route substantial fractions of exams for auto-protocoling, with higher accuracy with more general protocols. Economic analyses of the tested algorithms indicate that improved algorithm performance is required to yield a practical exam auto-protocoling tool for sub-specialized imaging exams.",
    "authors": [
      "Andrew S. Nencka",
      "Mohammad Sherafati",
      "Timothy Goebel",
      "Parag Tolat",
      "Kevin M. Koch"
    ],
    "categories": [
      "cs.LG",
      "eess.IV",
      "physics.med-ph"
    ],
    "published": "2021-05-28T18:50:04Z",
    "pdf_url": "https://arxiv.org/pdf/2106.08963v1"
  },
  {
    "arxiv_id": "2105.11601v2",
    "entry_id": "http://arxiv.org/abs/2105.11601v2",
    "title": "Personalized Transformer for Explainable Recommendation",
    "summary": "Personalization of natural language generation plays a vital role in a large spectrum of tasks, such as explainable recommendation, review summarization and dialog systems. In these tasks, user and item IDs are important identifiers for personalization. Transformer, which is demonstrated with strong language modeling capability, however, is not personalized and fails to make use of the user and item IDs since the ID tokens are not even in the same semantic space as the words. To address this problem, we present a PErsonalized Transformer for Explainable Recommendation (PETER), on which we design a simple and effective learning objective that utilizes the IDs to predict the words in the target explanation, so as to endow the IDs with linguistic meanings and to achieve personalized Transformer. Besides generating explanations, PETER can also make recommendations, which makes it a unified model for the whole recommendation-explanation pipeline. Extensive experiments show that our small unpretrained model outperforms fine-tuned BERT on the generation task, in terms of both effectiveness and efficiency, which highlights the importance and the nice utility of our design.",
    "authors": [
      "Lei Li",
      "Yongfeng Zhang",
      "Li Chen"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-05-25T01:42:47Z",
    "pdf_url": "https://arxiv.org/pdf/2105.11601v2"
  },
  {
    "arxiv_id": "2105.10587v1",
    "entry_id": "http://arxiv.org/abs/2105.10587v1",
    "title": "Techniques Toward Optimizing Viewability in RTB Ad Campaigns Using Reinforcement Learning",
    "summary": "Reinforcement learning (RL) is an effective technique for training decision-making agents through interactions with their environment. The advent of deep learning has been associated with highly notable successes with sequential decision making problems - such as defeating some of the highest-ranked human players at Go. In digital advertising, real-time bidding (RTB) is a common method of allocating advertising inventory through real-time auctions. Bidding strategies need to incorporate logic for dynamically adjusting parameters in order to deliver pre-assigned campaign goals. Here we discuss techniques toward using RL to train bidding agents. As a campaign metric we particularly focused on viewability: the percentage of inventory which goes on to be viewed by an end user.\n  This paper is presented as a survey of techniques and experiments which we developed through the course of this research. We discuss expanding our training data to include edge cases by training on simulated interactions. We discuss the experimental results comparing the performance of several promising RL algorithms, and an approach to hyperparameter optimization of an actor/critic training pipeline through Bayesian optimization. Finally, we present live-traffic tests of some of our RL agents against a rule-based feedback-control approach, demonstrating the potential for this method as well as areas for further improvement. This paper therefore presents an arrangement of our findings in this quickly developing field, and ways that it can be applied to an RTB use case.",
    "authors": [
      "Michael Tashman",
      "John Hoffman",
      "Jiayi Xie",
      "Fengdan Ye",
      "Atefeh Morsali",
      "Lee Winikor",
      "Rouzbeh Gerami"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2021-05-21T21:56:12Z",
    "pdf_url": "https://arxiv.org/pdf/2105.10587v1"
  },
  {
    "arxiv_id": "2105.08310v1",
    "entry_id": "http://arxiv.org/abs/2105.08310v1",
    "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting Exchange via Agent-Based Modelling",
    "summary": "I describe the rationale for, and design of, an agent-based simulation model of a contemporary online sports-betting exchange: such exchanges, closely related to the exchange mechanisms at the heart of major financial markets, have revolutionized the gambling industry in the past 20 years, but gathering sufficiently large quantities of rich and temporally high-resolution data from real exchanges - i.e., the sort of data that is needed in large quantities for Deep Learning - is often very expensive, and sometimes simply impossible; this creates a need for a plausibly realistic synthetic data generator, which is what this simulation now provides. The simulator, named the \"Bristol Betting Exchange\" (BBE), is intended as a common platform, a data-source and experimental test-bed, for researchers studying the application of AI and machine learning (ML) techniques to issues arising in betting exchanges; and, as far as I have been able to determine, BBE is the first of its kind: a free open-source agent-based simulation model consisting not only of a sports-betting exchange, but also a minimal simulation model of racetrack sporting events (e.g., horse-races or car-races) about which bets may be made, and a population of simulated bettors who each form their own private evaluation of odds and place bets on the exchange before and - crucially - during the race itself (i.e., so-called \"in-play\" betting) and whose betting opinions change second-by-second as each race event unfolds. BBE is offered as a proof-of-concept system that enables the generation of large high-resolution data-sets for automated discovery or improvement of profitable strategies for betting on sporting events via the application of AI/ML and advanced data analytics techniques. This paper offers an extensive survey of relevant literature and explains the motivation and design of BBE, and presents brief illustrative results.",
    "authors": [
      "Dave Cliff"
    ],
    "categories": [
      "cs.MA",
      "cs.CE",
      "q-fin.CP",
      "q-fin.TR",
      "stat.ML"
    ],
    "published": "2021-05-18T06:52:08Z",
    "pdf_url": "https://arxiv.org/pdf/2105.08310v1"
  },
  {
    "arxiv_id": "2105.06706v1",
    "entry_id": "http://arxiv.org/abs/2105.06706v1",
    "title": "Building Affordance Relations for Robotic Agents - A Review",
    "summary": "Affordances describe the possibilities for an agent to perform actions with an object. While the significance of the affordance concept has been previously studied from varied perspectives, such as psychology and cognitive science, these approaches are not always sufficient to enable direct transfer, in the sense of implementations, to artificial intelligence (AI)-based systems and robotics. However, many efforts have been made to pragmatically employ the concept of affordances, as it represents great potential for AI agents to effectively bridge perception to action. In this survey, we review and find common ground amongst different strategies that use the concept of affordances within robotic tasks, and build on these methods to provide guidance for including affordances as a mechanism to improve autonomy. To this end, we outline common design choices for building representations of affordance relations, and their implications on the generalisation capabilities of an agent when facing previously unseen scenarios. Finally, we identify and discuss a range of interesting research directions involving affordances that have the potential to improve the capabilities of an AI agent.",
    "authors": [
      "Paola Ardón",
      "Èric Pairet",
      "Katrin S. Lohan",
      "Subramanian Ramamoorthy",
      "Ronald P. A. Petrick"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-05-14T08:35:18Z",
    "pdf_url": "https://arxiv.org/pdf/2105.06706v1"
  },
  {
    "arxiv_id": "2105.06268v1",
    "entry_id": "http://arxiv.org/abs/2105.06268v1",
    "title": "Intelligence and Unambitiousness Using Algorithmic Information Theory",
    "summary": "Algorithmic Information Theory has inspired intractable constructions of general intelligence (AGI), and undiscovered tractable approximations are likely feasible. Reinforcement Learning (RL), the dominant paradigm by which an agent might learn to solve arbitrary solvable problems, gives an agent a dangerous incentive: to gain arbitrary \"power\" in order to intervene in the provision of their own reward. We review the arguments that generally intelligent algorithmic-information-theoretic reinforcement learners such as Hutter's (2005) AIXI would seek arbitrary power, including over us. Then, using an information-theoretic exploration schedule, and a setup inspired by causal influence theory, we present a variant of AIXI which learns to not seek arbitrary power; we call it \"unambitious\". We show that our agent learns to accrue reward at least as well as a human mentor, while relying on that mentor with diminishing probability. And given a formal assumption that we probe empirically, we show that eventually, the agent's world-model incorporates the following true fact: intervening in the \"outside world\" will have no effect on reward acquisition; hence, it has no incentive to shape the outside world.",
    "authors": [
      "Michael K. Cohen",
      "Badri Vellambi",
      "Marcus Hutter"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-05-13T13:10:28Z",
    "pdf_url": "https://arxiv.org/pdf/2105.06268v1"
  },
  {
    "arxiv_id": "2105.02371v1",
    "entry_id": "http://arxiv.org/abs/2105.02371v1",
    "title": "Survey on Multi-Agent Q-Learning frameworks for resource management in wireless sensor network",
    "summary": "This report aims to survey multi-agent Q-Learning algorithms, analyze different game theory frameworks used, address each framework's applications, and report challenges and future directions. The target application for this study is resource management in the wireless sensor network.\n  In the first section, the author provided an introduction regarding the applications of wireless sensor networks. After that, the author presented a summary of the Q-Learning algorithm, a well-known classic solution for model-free reinforcement learning problems.\n  In the third section, the author extended the Q-Learning algorithm for multi-agent scenarios and discussed its challenges.\n  In the fourth section, the author surveyed sets of game-theoretic frameworks that researchers used to address this problem for resource allocation and task scheduling in the wireless sensor networks. Lastly, the author mentioned some interesting open challenges in this domain.",
    "authors": [
      "Arvin Tashakori"
    ],
    "categories": [
      "cs.MA",
      "cs.GT",
      "cs.LG",
      "cs.NI"
    ],
    "published": "2021-05-05T23:43:30Z",
    "pdf_url": "https://arxiv.org/pdf/2105.02371v1"
  },
  {
    "arxiv_id": "2105.01099v8",
    "entry_id": "http://arxiv.org/abs/2105.01099v8",
    "title": "Reinforcement Learning for Ridesharing: An Extended Survey",
    "summary": "In this paper, we present a comprehensive, in-depth survey of the literature on reinforcement learning approaches to decision optimization problems in a typical ridesharing system. Papers on the topics of rideshare matching, vehicle repositioning, ride-pooling, routing, and dynamic pricing are covered. Most of the literature has appeared in the last few years, and several core challenges are to continue to be tackled: model complexity, agent coordination, and joint optimization of multiple levers. Hence, we also introduce popular data sets and open simulation environments to facilitate further research and development. Subsequently, we discuss a number of challenges and opportunities for reinforcement learning research on this important domain.",
    "authors": [
      "Zhiwei Qin",
      "Hongtu Zhu",
      "Jieping Ye"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-05-03T18:09:58Z",
    "pdf_url": "https://arxiv.org/pdf/2105.01099v8"
  },
  {
    "arxiv_id": "2104.11809v1",
    "entry_id": "http://arxiv.org/abs/2104.11809v1",
    "title": "Compilation-based Solvers for Multi-Agent Path Finding: a Survey, Discussion, and Future Opportunities",
    "summary": "Multi-agent path finding (MAPF) attracts considerable attention in artificial intelligence community as well as in robotics, and other fields such as warehouse logistics. The task in the standard MAPF is to find paths through which agents can navigate from their starting positions to specified individual goal positions. The combination of two additional requirements makes the problem computationally challenging: (i) agents must not collide with each other and (ii) the paths must be optimal with respect to some objective. Two major approaches to optimal MAPF solving include (1) dedicated search-based methods, which solve MAPF directly, and (2) compilation-based methods that reduce a MAPF instance to an instance in a different well established formalism, for which an efficient solver exists. The compilation-based MAPF solving can benefit from advancements accumulated during the development of the target solver often decades long. We summarize and compare contemporary compilation-based solvers for MAPF using formalisms like ASP, MIP, and SAT. We show the lessons learned from past developments and current trends in the topic and discuss its wider impact.",
    "authors": [
      "Pavel Surynek"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2021-04-23T20:13:12Z",
    "pdf_url": "https://arxiv.org/pdf/2104.11809v1"
  },
  {
    "arxiv_id": "2104.11153v1",
    "entry_id": "http://arxiv.org/abs/2104.11153v1",
    "title": "Trust as Extended Control: Active Inference and User Feedback During Human-Robot Collaboration",
    "summary": "To interact seamlessly with robots, users must infer the causes of a robot's behavior and be confident about that inference. Hence, trust is a necessary condition for human-robot collaboration (HRC). Despite its crucial role, it is largely unknown how trust emerges, develops, and supports human interactions with nonhuman artefacts. Here, we review the literature on trust, human-robot interaction, human-robot collaboration, and human interaction at large. Early models of trust suggest that trust entails a trade-off between benevolence and competence, while studies of human-to-human interaction emphasize the role of shared behavior and mutual knowledge in the gradual building of trust. We then introduce a model of trust as an agent's best explanation for reliable sensory exchange with an extended motor plant or partner. This model is based on the cognitive neuroscience of active inference and suggests that, in the context of HRC, trust can be cast in terms of virtual control over an artificial agent. In this setting, interactive feedback becomes a necessary component of the trustor's perception-action cycle. The resulting model has important implications for understanding human-robot interaction and collaboration, as it allows the traditional determinants of human trust to be defined in terms of active inference, information exchange and empowerment. Furthermore, this model suggests that boredom and surprise may be used as markers for under and over-reliance on the system. Finally, we examine the role of shared behavior in the genesis of trust, especially in the context of dyadic collaboration, suggesting important consequences for the acceptability and design of human-robot collaborative systems.",
    "authors": [
      "Felix Schoeller",
      "Mark Miller",
      "Roy Salomon",
      "Karl J. Friston"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2021-04-22T16:11:22Z",
    "pdf_url": "https://arxiv.org/pdf/2104.11153v1"
  },
  {
    "arxiv_id": "2104.10810v1",
    "entry_id": "http://arxiv.org/abs/2104.10810v1",
    "title": "A Short Survey of Pre-trained Language Models for Conversational AI-A NewAge in NLP",
    "summary": "Building a dialogue system that can communicate naturally with humans is a challenging yet interesting problem of agent-based computing. The rapid growth in this area is usually hindered by the long-standing problem of data scarcity as these systems are expected to learn syntax, grammar, decision making, and reasoning from insufficient amounts of task-specific dataset. The recently introduced pre-trained language models have the potential to address the issue of data scarcity and bring considerable advantages by generating contextualized word embeddings. These models are considered counterpart of ImageNet in NLP and have demonstrated to capture different facets of language such as hierarchical relations, long-term dependency, and sentiment. In this short survey paper, we discuss the recent progress made in the field of pre-trained language models. We also deliberate that how the strengths of these language models can be leveraged in designing more engaging and more eloquent conversational agents. This paper, therefore, intends to establish whether these pre-trained models can overcome the challenges pertinent to dialogue systems, and how their architecture could be exploited in order to overcome these challenges. Open challenges in the field of dialogue systems have also been deliberated.",
    "authors": [
      "Munazza Zaib",
      "Quan Z. Sheng",
      "Wei Emma Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2021-04-22T01:00:56Z",
    "pdf_url": "https://arxiv.org/pdf/2104.10810v1"
  },
  {
    "arxiv_id": "2104.10429v1",
    "entry_id": "http://arxiv.org/abs/2104.10429v1",
    "title": "Portfolio Search and Optimization for General Strategy Game-Playing",
    "summary": "Portfolio methods represent a simple but efficient type of action abstraction which has shown to improve the performance of search-based agents in a range of strategy games. We first review existing portfolio techniques and propose a new algorithm for optimization and action-selection based on the Rolling Horizon Evolutionary Algorithm. Moreover, a series of variants are developed to solve problems in different aspects. We further analyze the performance of discussed agents in a general strategy game-playing task. For this purpose, we run experiments on three different game-modes of the Stratega framework. For the optimization of the agents' parameters and portfolio sets we study the use of the N-tuple Bandit Evolutionary Algorithm. The resulting portfolio sets suggest a high diversity in play-styles while being able to consistently beat the sample agents. An analysis of the agents' performance shows that the proposed algorithm generalizes well to all game-modes and is able to outperform other portfolio methods.",
    "authors": [
      "Alexander Dockhorn",
      "Jorge Hurtado-Grueso",
      "Dominik Jeurissen",
      "Linjie Xu",
      "Diego Perez-Liebana"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-04-21T09:28:28Z",
    "pdf_url": "https://arxiv.org/pdf/2104.10429v1"
  },
  {
    "arxiv_id": "2104.08301v2",
    "entry_id": "http://arxiv.org/abs/2104.08301v2",
    "title": "Text2App: A Framework for Creating Android Apps from Text Descriptions",
    "summary": "We present Text2App -- a framework that allows users to create functional Android applications from natural language specifications. The conventional method of source code generation tries to generate source code directly, which is impractical for creating complex software. We overcome this limitation by transforming natural language into an abstract intermediate formal language representing an application with a substantially smaller number of tokens. The intermediate formal representation is then compiled into target source codes. This abstraction of programming details allows seq2seq networks to learn complex application structures with less overhead. In order to train sequence models, we introduce a data synthesis method grounded in a human survey. We demonstrate that Text2App generalizes well to unseen combination of app components and it is capable of handling noisy natural language instructions. We explore the possibility of creating applications from highly abstract instructions by coupling our system with GPT-3 -- a large pretrained language model. We perform an extensive human evaluation and identify the capabilities and limitations of our system. The source code, a ready-to-run demo notebook, and a demo video are publicly available at \\url{https://github.com/text2app/Text2App}.",
    "authors": [
      "Masum Hasan",
      "Kazi Sajeed Mehrab",
      "Wasi Uddin Ahmad",
      "Rifat Shahriyar"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-04-16T18:13:10Z",
    "pdf_url": "https://arxiv.org/pdf/2104.08301v2"
  },
  {
    "arxiv_id": "2105.00824v1",
    "entry_id": "http://arxiv.org/abs/2105.00824v1",
    "title": "A Survey of Recent Abstract Summarization Techniques",
    "summary": "This paper surveys several recent abstract summarization methods: T5, Pegasus, and ProphetNet. We implement the systems in two languages: English and Indonesian languages. We investigate the impact of pre-training models (one T5, three Pegasuses, three ProphetNets) on several Wikipedia datasets in English and Indonesian language and compare the results to the Wikipedia systems' summaries. The T5-Large, the Pegasus-XSum, and the ProphetNet-CNNDM provide the best summarization. The most significant factors that influence ROUGE performance are coverage, density, and compression. The higher the scores, the better the summary. Other factors that influence the ROUGE scores are the pre-training goal, the dataset's characteristics, the dataset used for testing the pre-trained model, and the cross-lingual function. Several suggestions to improve this paper's limitation are: 1) assure that the dataset used for the pre-training model must sufficiently large, contains adequate instances for handling cross-lingual purpose; 2) Advanced process (finetuning) shall be reasonable. We recommend using the large dataset consists of comprehensive coverage of topics from many languages before implementing advanced processes such as the train-infer-train procedure to the zero-shot translation in the training stage of the pre-training model.",
    "authors": [
      "Diyah Puspitaningrum"
    ],
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2021-04-15T20:01:34Z",
    "pdf_url": "https://arxiv.org/pdf/2105.00824v1"
  },
  {
    "arxiv_id": "2104.07720v2",
    "entry_id": "http://arxiv.org/abs/2104.07720v2",
    "title": "Ontology-based Feature Selection: A Survey",
    "summary": "The SemanticWeb emerged as an extension to the traditional Web, towards adding meaning to a distributed Web of structured and linked data. At its core, the concept of ontology provides the means to semantically describe and structure information and data and expose it to software and human agents in a machine and human-readable form. For software agents to be realized, it is crucial to develop powerful artificial intelligence and machine learning techniques, able to extract knowledge from information and data sources and represent it in the underlying ontology. This survey aims to provide insight into key aspects of ontology-based knowledge extraction, from various sources such as text, images, databases and human expertise, with emphasis on the task of feature selection. First, some of the most common classification and feature selection algorithms are briefly presented. Then, selected methodologies, which utilize ontologies to represent features and perform feature selection and classification, are described. The presented examples span diverse application domains, e.g., medicine, tourism, mechanical and civil engineering, and demonstrate the feasibility and applicability of such methods.",
    "authors": [
      "Konstantinos Sikelis",
      "George E Tsekouras",
      "Konstantinos I Kotis"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-04-15T19:03:31Z",
    "pdf_url": "https://arxiv.org/pdf/2104.07720v2"
  },
  {
    "arxiv_id": "2104.05861v3",
    "entry_id": "http://arxiv.org/abs/2104.05861v3",
    "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews",
    "summary": "Context: Mobile app reviews written by users on app stores or social media are significant resources for app developers.Analyzing app reviews have proved to be useful for many areas of software engineering (e.g., requirement engineering, testing). Automatic classification of app reviews requires extensive efforts to manually curate a labeled dataset. When the classification purpose changes (e.g. identifying bugs versus usability issues or sentiment), new datasets should be labeled, which prevents the extensibility of the developed models for new desired classes/tasks in practice. Recent pre-trained neural language models (PTM) are trained on large corpora in an unsupervised manner and have found success in solving similar Natural Language Processing problems. However, the applicability of PTMs is not explored for app review classification Objective: We investigate the benefits of PTMs for app review classification compared to the existing models, as well as the transferability of PTMs in multiple settings. Method: We empirically study the accuracy and time efficiency of PTMs compared to prior approaches using six datasets from literature. In addition, we investigate the performance of the PTMs trained on app reviews (i.e. domain-specific PTMs) . We set up different studies to evaluate PTMs in multiple settings: binary vs. multi-class classification, zero-shot classification (when new labels are introduced to the model), multi-task setting, and classification of reviews from different resources. The datasets are manually labeled app review datasets from Google Play Store, Apple App Store, and Twitter data. In all cases, Micro and Macro Precision, Recall, and F1-scores will be used and we will report the time required for training and prediction with the models.",
    "authors": [
      "Mohammad Abdul Hadi",
      "Fatemeh H. Fard"
    ],
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "published": "2021-04-12T23:23:45Z",
    "pdf_url": "https://arxiv.org/pdf/2104.05861v3"
  },
  {
    "arxiv_id": "2104.04670v5",
    "entry_id": "http://arxiv.org/abs/2104.04670v5",
    "title": "Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections",
    "summary": "Large pre-trained language models (LMs) such as GPT-3 have acquired a surprising ability to perform zero-shot learning. For example, to classify sentiment without any training examples, we can \"prompt\" the LM with the review and the label description \"Does the user like this movie?\", and ask whether the next word is \"yes\" or \"no\". However, the next word prediction training objective is still misaligned with the target zero-shot learning objective. To address this weakness, we propose meta-tuning, which directly optimizes the zero-shot learning objective by fine-tuning pre-trained language models on a collection of datasets. We focus on classification tasks, and construct the meta-dataset by aggregating 43 existing datasets and annotating 441 label descriptions in a question-answering (QA) format. When evaluated on unseen tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA zero-shot learning system based on natural language inference. Additionally, increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%, and we forecast that even larger models would perform better. Therefore, measuring zero-shot learning performance on language models out-of-the-box might underestimate their true potential, and community-wide efforts on aggregating datasets and unifying their formats can help build models that answer prompts better.",
    "authors": [
      "Ruiqi Zhong",
      "Kristy Lee",
      "Zheng Zhang",
      "Dan Klein"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-04-10T02:57:22Z",
    "pdf_url": "https://arxiv.org/pdf/2104.04670v5"
  },
  {
    "arxiv_id": "2104.02151v1",
    "entry_id": "http://arxiv.org/abs/2104.02151v1",
    "title": "Distributed Learning in Wireless Networks: Recent Progress and Future Challenges",
    "summary": "The next-generation of wireless networks will enable many machine learning (ML) tools and applications to efficiently analyze various types of data collected by edge devices for inference, autonomy, and decision making purposes. However, due to resource constraints, delay limitations, and privacy challenges, edge devices cannot offload their entire collected datasets to a cloud server for centrally training their ML models or inference purposes. To overcome these challenges, distributed learning and inference techniques have been proposed as a means to enable edge devices to collaboratively train ML models without raw data exchanges, thus reducing the communication overhead and latency as well as improving data privacy. However, deploying distributed learning over wireless networks faces several challenges including the uncertain wireless environment, limited wireless resources (e.g., transmit power and radio spectrum), and hardware resources. This paper provides a comprehensive study of how distributed learning can be efficiently and effectively deployed over wireless edge networks. We present a detailed overview of several emerging distributed learning paradigms, including federated learning, federated distillation, distributed inference, and multi-agent reinforcement learning. For each learning framework, we first introduce the motivation for deploying it over wireless networks. Then, we present a detailed literature review on the use of communication techniques for its efficient deployment. We then introduce an illustrative example to show how to optimize wireless networks to improve its performance. Finally, we introduce future research opportunities. In a nutshell, this paper provides a holistic set of guidelines on how to deploy a broad range of distributed learning frameworks over real-world wireless communication networks.",
    "authors": [
      "Mingzhe Chen",
      "Deniz Gündüz",
      "Kaibin Huang",
      "Walid Saad",
      "Mehdi Bennis",
      "Aneta Vulgarakis Feljan",
      "H. Vincent Poor"
    ],
    "categories": [
      "cs.LG",
      "cs.IT"
    ],
    "published": "2021-04-05T20:57:56Z",
    "pdf_url": "https://arxiv.org/pdf/2104.02151v1"
  },
  {
    "arxiv_id": "2104.10658v1",
    "entry_id": "http://arxiv.org/abs/2104.10658v1",
    "title": "Using GPT-2 to Create Synthetic Data to Improve the Prediction Performance of NLP Machine Learning Classification Models",
    "summary": "Classification Models use input data to predict the likelihood that the subsequent input data will fall into predetermined categories. To perform effective classifications, these models require large datasets for training. It is becoming common practice to utilize synthetic data to boost the performance of Machine Learning Models. It is reported that Shell is using synthetic data to build models to detect problems that rarely occur; for example Shell created synthetic data to help models to identify deteriorating oil lines. It is common practice for Machine Learning Practitioners to generate synthetic data by rotating, flipping, and cropping images to increase the volume of image data to train Convolutional Neural Networks. The purpose of this paper is to explore creating and utilizing synthetic NLP data to improve the performance of Natural Language Processing Machine Learning Classification Models. In this paper I used a Yelp pizza restaurant reviews dataset and transfer learning to fine-tune a pre-trained GPT-2 Transformer Model to generate synthetic pizza reviews data. I then combined this synthetic data with the original genuine data to create a new joint dataset. The new combined model significantly outperformed the original model in accuracy and precision.",
    "authors": [
      "Dewayne Whitfield"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-04-02T20:20:42Z",
    "pdf_url": "https://arxiv.org/pdf/2104.10658v1"
  },
  {
    "arxiv_id": "2103.14797v2",
    "entry_id": "http://arxiv.org/abs/2103.14797v2",
    "title": "Unsupervised Self-Training for Sentiment Analysis of Code-Switched Data",
    "summary": "Sentiment analysis is an important task in understanding social media content like customer reviews, Twitter and Facebook feeds etc. In multilingual communities around the world, a large amount of social media text is characterized by the presence of Code-Switching. Thus, it has become important to build models that can handle code-switched data. However, annotated code-switched data is scarce and there is a need for unsupervised models and algorithms. We propose a general framework called Unsupervised Self-Training and show its applications for the specific use case of sentiment analysis of code-switched data. We use the power of pre-trained BERT models for initialization and fine-tune them in an unsupervised manner, only using pseudo labels produced by zero-shot transfer. We test our algorithm on multiple code-switched languages and provide a detailed analysis of the learning dynamics of the algorithm with the aim of answering the question - `Does our unsupervised model understand the Code-Switched languages or does it just learn its representations?'. Our unsupervised models compete well with their supervised counterparts, with their performance reaching within 1-7\\% (weighted F1 scores) when compared to supervised models trained for a two class problem.",
    "authors": [
      "Akshat Gupta",
      "Sargam Menghani",
      "Sai Krishna Rallabandi",
      "Alan W Black"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2021-03-27T03:23:12Z",
    "pdf_url": "https://arxiv.org/pdf/2103.14797v2"
  },
  {
    "arxiv_id": "2103.14659v1",
    "entry_id": "http://arxiv.org/abs/2103.14659v1",
    "title": "Alignment of Language Agents",
    "summary": "For artificial intelligence to be beneficial to humans the behaviour of AI agents needs to be aligned with what humans want. In this paper we discuss some behavioural issues for language agents, arising from accidental misspecification by the system designer. We highlight some ways that misspecification can occur and discuss some behavioural issues that could arise from misspecification, including deceptive or manipulative language, and review some approaches for avoiding these issues.",
    "authors": [
      "Zachary Kenton",
      "Tom Everitt",
      "Laura Weidinger",
      "Iason Gabriel",
      "Vladimir Mikulik",
      "Geoffrey Irving"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-03-26T18:01:48Z",
    "pdf_url": "https://arxiv.org/pdf/2103.14659v1"
  },
  {
    "arxiv_id": "2103.12820v2",
    "entry_id": "http://arxiv.org/abs/2103.12820v2",
    "title": "A Review & Framework for Modeling Complex Engineered System Development Processes",
    "summary": "Developing complex engineered systems (CES) poses significant challenges for engineers, managers, designers, and businesspeople alike due to the inherent complexity of the systems and contexts involved. Furthermore, experts have expressed great interest in filling the gap in theory about how CES develop. This article begins to address that gap in two ways. First, it reviews the numerous definitions of CES along with existing theory and methods on CES development processes. Then, it proposes the ComplEx System Integrated Utilities Model (CESIUM), a novel framework for exploring how numerous system and development process characteristics may affect the performance of CES. CESIUM creates simulated representations of a system architecture, the corresponding engineering organization, and the new product development process through which the organization designs the system. It does so by representing the system as a network of interdependent artifacts designed by agents. Agents iteratively design their artifacts through optimization and share information with other agents, thereby advancing the CES toward a solution. This paper describes the model, conducts a sensitivity analysis, provides validation, and suggests directions for future study.",
    "authors": [
      "John Meluso",
      "Jesse Austin-Breneman",
      "James P. Bagrow",
      "Laurent Hébert-Dufresne"
    ],
    "categories": [
      "cs.MA",
      "cs.SI",
      "nlin.AO"
    ],
    "published": "2021-03-23T20:12:51Z",
    "pdf_url": "https://arxiv.org/pdf/2103.12820v2"
  },
  {
    "arxiv_id": "2103.11067v1",
    "entry_id": "http://arxiv.org/abs/2103.11067v1",
    "title": "Multi-Agent Algorithms for Collective Behavior: A structural and application-focused atlas",
    "summary": "The goal of this paper is to provide a survey and application-focused atlas of collective behavior coordination algorithms for multi-agent systems.\n  We survey the general family of collective behavior algorithms for multi-agent systems and classify them according to their underlying mathematical structure. In doing so, we aim to capture fundamental mathematical properties of algorithms (e.g., scalability with respect to the number of agents and bandwidth use) and to show how the same algorithm or family of algorithms can be used for multiple tasks and applications.\n  Collectively, this paper provides an application-focused atlas of algorithms for collective behavior of multi-agent systems, with three objectives:\n  1. to act as a tutorial guide to practitioners in the selection of coordination algorithms for a given application;\n  2. to highlight how mathematically similar algorithms can be used for a variety of tasks, ranging from low-level control to high-level coordination;\n  3. to explore the state-of-the-art in the field of control of multi-agent systems and identify areas for future research.",
    "authors": [
      "Federico Rossi",
      "Saptarshi Bandyopadhyay",
      "Michael T. Wolf",
      "Marco Pavone"
    ],
    "categories": [
      "cs.MA",
      "cs.RO"
    ],
    "published": "2021-03-20T00:37:06Z",
    "pdf_url": "https://arxiv.org/pdf/2103.11067v1"
  },
  {
    "arxiv_id": "2103.09656v2",
    "entry_id": "http://arxiv.org/abs/2103.09656v2",
    "title": "Set-to-Sequence Methods in Machine Learning: a Review",
    "summary": "Machine learning on sets towards sequential output is an important and ubiquitous task, with applications ranging from language modeling and meta-learning to multi-agent strategy games and power grid optimization. Combining elements of representation learning and structured prediction, its two primary challenges include obtaining a meaningful, permutation invariant set representation and subsequently utilizing this representation to output a complex target permutation. This paper provides a comprehensive introduction to the field as well as an overview of important machine learning methods tackling both of these key challenges, with a detailed qualitative comparison of selected model architectures.",
    "authors": [
      "Mateusz Jurewicz",
      "Leon Strømberg-Derczynski"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-03-17T13:52:33Z",
    "pdf_url": "https://arxiv.org/pdf/2103.09656v2"
  },
  {
    "arxiv_id": "2103.07492v4",
    "entry_id": "http://arxiv.org/abs/2103.07492v4",
    "title": "Continual Learning for Recurrent Neural Networks: an Empirical Evaluation",
    "summary": "Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications. We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in class-incremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario.",
    "authors": [
      "Andrea Cossu",
      "Antonio Carta",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-03-12T19:25:28Z",
    "pdf_url": "https://arxiv.org/pdf/2103.07492v4"
  },
  {
    "arxiv_id": "2103.07370v2",
    "entry_id": "http://arxiv.org/abs/2103.07370v2",
    "title": "Test case generation for agent-based models: A systematic literature review",
    "summary": "Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a software fault may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential. In this systematic literature review, we answer five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test? Our results show that whilst the majority of techniques are effective for testing functional requirements at the agent and integration levels of abstraction, there are comparatively few techniques capable of testing society-level behaviour. Additionally, we identify a need for more thorough evaluation using realistic case studies that feature challenging properties associated with a typical agent-based model.",
    "authors": [
      "Andrew G. Clark",
      "Neil Walkinshaw",
      "Robert M. Hierons"
    ],
    "categories": [
      "cs.SE",
      "cs.MA"
    ],
    "published": "2021-03-12T16:07:12Z",
    "pdf_url": "https://arxiv.org/pdf/2103.07370v2"
  },
  {
    "arxiv_id": "2103.07356v3",
    "entry_id": "http://arxiv.org/abs/2103.07356v3",
    "title": "Hippocampal formation-inspired probabilistic generative model",
    "summary": "In building artificial intelligence (AI) agents, referring to how brains function in real environments can accelerate development by reducing the design space. In this study, we propose a probabilistic generative model (PGM) for navigation in uncertain environments by integrating the neuroscientific knowledge of hippocampal formation (HF) and the engineering knowledge in robotics and AI, namely, simultaneous localization and mapping (SLAM). We follow the approach of brain reference architecture (BRA) (Yamakawa, 2021) to compose the PGM and outline how to verify the model. To this end, we survey and discuss the relationship between the HF findings and SLAM models. The proposed hippocampal formation-inspired probabilistic generative model (HF-PGM) is designed to be highly consistent with the anatomical structure and functions of the HF. By referencing the brain, we elaborate on the importance of integration of egocentric/allocentric information from the entorhinal cortex to the hippocampus and the use of discrete-event queues.",
    "authors": [
      "Akira Taniguchi",
      "Ayako Fukawa",
      "Hiroshi Yamakawa"
    ],
    "categories": [
      "cs.AI",
      "cs.NE",
      "q-bio.NC"
    ],
    "published": "2021-03-12T15:46:52Z",
    "pdf_url": "https://arxiv.org/pdf/2103.07356v3"
  },
  {
    "arxiv_id": "2103.06443v2",
    "entry_id": "http://arxiv.org/abs/2103.06443v2",
    "title": "Where is your place, Visual Place Recognition?",
    "summary": "Visual Place Recognition (VPR) is often characterized as being able to recognize the same place despite significant changes in appearance and viewpoint. VPR is a key component of Spatial Artificial Intelligence, enabling robotic platforms and intelligent augmentation platforms such as augmented reality devices to perceive and understand the physical world. In this paper, we observe that there are three \"drivers\" that impose requirements on spatially intelligent agents and thus VPR systems: 1) the particular agent including its sensors and computational resources, 2) the operating environment of this agent, and 3) the specific task that the artificial agent carries out. In this paper, we characterize and survey key works in the VPR area considering those drivers, including their place representation and place matching choices. We also provide a new definition of VPR based on the visual overlap -- akin to spatial view cells in the brain -- that enables us to find similarities and differences to other research areas in the robotics and computer vision fields. We identify numerous open challenges and suggest areas that require more in-depth attention in future works.",
    "authors": [
      "Sourav Garg",
      "Tobias Fischer",
      "Michael Milford"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2021-03-11T04:11:04Z",
    "pdf_url": "https://arxiv.org/pdf/2103.06443v2"
  },
  {
    "arxiv_id": "2103.06160v1",
    "entry_id": "http://arxiv.org/abs/2103.06160v1",
    "title": "Using Cognitive Models to Train Warm Start Reinforcement Learning Agents for Human-Computer Interactions",
    "summary": "Reinforcement learning (RL) agents in human-computer interactions applications require repeated user interactions before they can perform well. To address this \"cold start\" problem, we propose a novel approach of using cognitive models to pre-train RL agents before they are applied to real users. After briefly reviewing relevant cognitive models, we present our general methodological approach, followed by two case studies from our previous and ongoing projects. We hope this position paper stimulates conversations between RL, HCI, and cognitive science researchers in order to explore the full potential of the approach.",
    "authors": [
      "Chao Zhang",
      "Shihan Wang",
      "Henk Aarts",
      "Mehdi Dastani"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2021-03-10T16:20:02Z",
    "pdf_url": "https://arxiv.org/pdf/2103.06160v1"
  },
  {
    "arxiv_id": "2103.05796v2",
    "entry_id": "http://arxiv.org/abs/2103.05796v2",
    "title": "Topology Applied to Machine Learning: From Global to Local",
    "summary": "Through the use of examples, we explain one way in which applied topology has evolved since the birth of persistent homology in the early 2000s. The first applications of topology to data emphasized the global shape of a dataset, such as the three-circle model for $3 \\times 3$ pixel patches from natural images, or the configuration space of the cyclo-octane molecule, which is a sphere with a Klein bottle attached via two circles of singularity. In these studies of global shape, short persistent homology bars are disregarded as sampling noise. More recently, however, persistent homology has been used to address questions about the local geometry of data. For instance, how can local geometry be vectorized for use in machine learning problems? Persistent homology and its vectorization methods, including persistence landscapes and persistence images, provide popular techniques for incorporating both local geometry and global topology into machine learning. Our meta-hypothesis is that the short bars are as important as the long bars for many machine learning tasks. In defense of this claim, we survey applications of persistent homology to shape recognition, agent-based modeling, materials science, archaeology, and biology. Additionally, we survey work connecting persistent homology to geometric features of spaces, including curvature and fractal dimension, and various methods that have been used to incorporate persistent homology into machine learning.",
    "authors": [
      "Henry Adams",
      "Michael Moy"
    ],
    "categories": [
      "math.AT",
      "cs.LG"
    ],
    "published": "2021-03-10T00:36:28Z",
    "pdf_url": "https://arxiv.org/pdf/2103.05796v2"
  },
  {
    "arxiv_id": "2103.04918v8",
    "entry_id": "http://arxiv.org/abs/2103.04918v8",
    "title": "A Survey of Embodied AI: From Simulators to Research Tasks",
    "summary": "There has been an emerging paradigm shift from the era of \"internet AI\" to \"embodied AI\", where AI algorithms and agents no longer learn from datasets of images, videos or text curated primarily from the internet. Instead, they learn through interactions with their environments from an egocentric perception similar to humans. Consequently, there has been substantial growth in the demand for embodied AI simulators to support various embodied AI research tasks. This growing interest in embodied AI is beneficial to the greater pursuit of Artificial General Intelligence (AGI), but there has not been a contemporary and comprehensive survey of this field. This paper aims to provide an encyclopedic survey for the field of embodied AI, from its simulators to its research. By evaluating nine current embodied AI simulators with our proposed seven features, this paper aims to understand the simulators in their provision for use in embodied AI research and their limitations. Lastly, this paper surveys the three main research tasks in embodied AI -- visual exploration, visual navigation and embodied question answering (QA), covering the state-of-the-art approaches, evaluation metrics and datasets. Finally, with the new insights revealed through surveying the field, the paper will provide suggestions for simulator-for-task selections and recommendations for the future directions of the field.",
    "authors": [
      "Jiafei Duan",
      "Samson Yu",
      "Hui Li Tan",
      "Hongyuan Zhu",
      "Cheston Tan"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-03-08T17:31:19Z",
    "pdf_url": "https://arxiv.org/pdf/2103.04918v8"
  },
  {
    "arxiv_id": "2102.10757v5",
    "entry_id": "http://arxiv.org/abs/2102.10757v5",
    "title": "Self-Supervised Learning of Graph Neural Networks: A Unified Review",
    "summary": "Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics.",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Jingtun Zhang",
      "Zhengyang Wang",
      "Shuiwang Ji"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2021-02-22T03:43:45Z",
    "pdf_url": "https://arxiv.org/pdf/2102.10757v5"
  },
  {
    "arxiv_id": "2102.07545v2",
    "entry_id": "http://arxiv.org/abs/2102.07545v2",
    "title": "Data-driven Analysis for Understanding Team Sports Behaviors",
    "summary": "Understanding the principles of real-world biological multi-agent behaviors is a current challenge in various scientific and engineering fields. The rules regarding the real-world biological multi-agent behaviors such as team sports are often largely unknown due to their inherently higher-order interactions, cognition, and body dynamics. Estimation of the rules from data, i.e., data-driven approaches such as machine learning, provides an effective way for the analysis of such behaviors. Although most data-driven models have non-linear structures and high prediction performances, it is sometimes hard to interpret them. This survey focuses on data-driven analysis for quantitative understanding of invasion team sports behaviors such as basketball and football, and introduces two main approaches for understanding such multi-agent behaviors: (1) extracting easily interpretable features or rules from data and (2) generating and controlling behaviors in visually-understandable ways. The first approach involves the visualization of learned representations and the extraction of mathematical structures behind the behaviors. The second approach can be used to test hypotheses by simulating and controlling future and counterfactual behaviors. Lastly, the potential practical applications of extracted rules, features, and generated behaviors are discussed. These approaches can contribute to a better understanding of multi-agent behaviors in the real world.",
    "authors": [
      "Keisuke Fujii"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-02-15T13:31:45Z",
    "pdf_url": "https://arxiv.org/pdf/2102.07545v2"
  },
  {
    "arxiv_id": "2102.07166v4",
    "entry_id": "http://arxiv.org/abs/2102.07166v4",
    "title": "Task-oriented Communication Design in Cyber-Physical Systems: A Survey on Theory and Applications",
    "summary": "Communications system design has been traditionally guided by task-agnostic principles, which aim at efficiently transmitting as many correct bits as possible through a given channel. However, in the era of cyber-physical systems, the effectiveness of communications is not dictated simply by the bit rate, but most importantly by the efficient completion of the task in hand, e.g., controlling remotely a robot, automating a production line or collaboratively sensing through a drone swarm. In parallel, it is projected that by 2023, half of the worldwide network connections will be among machines rather than humans. In this context, it is crucial to establish a new paradigm for designing communications strategies for multi-agent cyber-physical systems. This is a daunting task, since it requires a combination of principles from information, communication, control theories and computer science in order to formalize a general framework for task-oriented communication design. In this direction, this paper reviews and structures the relevant theoretical work across a wide range of scientific communities. Subsequently, it proposes a general conceptual framework for task-oriented communication design, along with its specializations according to the targeted use case. Furthermore, it provides a survey of relevant contributions in dominant applications, such as industrial internet of things, multi-UAV systems, tactile internet, autonomous vehicles, distributed learning systems, smart manufacturing plants and 5G and beyond self-organizing networks. Finally, it highlights the most important open research topics from both the theoretical framework and application points of view.",
    "authors": [
      "Arsham Mostaani",
      "Thang X. Vu",
      "Shree Krishna Sharma",
      "Van-Dinh Nguyen",
      "Qi Liao",
      "Symeon Chatzinotas"
    ],
    "categories": [
      "cs.IT",
      "cs.MA"
    ],
    "published": "2021-02-14T14:51:38Z",
    "pdf_url": "https://arxiv.org/pdf/2102.07166v4"
  },
  {
    "arxiv_id": "2102.05757v1",
    "entry_id": "http://arxiv.org/abs/2102.05757v1",
    "title": "Customizing Contextualized Language Models forLegal Document Reviews",
    "summary": "Inspired by the inductive transfer learning on computer vision, many efforts have been made to train contextualized language models that boost the performance of natural language processing tasks. These models are mostly trained on large general-domain corpora such as news, books, or Wikipedia.Although these pre-trained generic language models well perceive the semantic and syntactic essence of a language structure, exploiting them in a real-world domain-specific scenario still needs some practical considerations to be taken into account such as token distribution shifts, inference time, memory, and their simultaneous proficiency in multiple tasks. In this paper, we focus on the legal domain and present how different language model strained on general-domain corpora can be best customized for multiple legal document reviewing tasks. We compare their efficiencies with respect to task performances and present practical considerations.",
    "authors": [
      "Shohreh Shaghaghian",
      "Luna",
      "Feng",
      "Borna Jafarpour",
      "Nicolai Pogrebnyakov"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-02-10T22:14:15Z",
    "pdf_url": "https://arxiv.org/pdf/2102.05757v1"
  },
  {
    "arxiv_id": "2102.05710v1",
    "entry_id": "http://arxiv.org/abs/2102.05710v1",
    "title": "Derivative-Free Reinforcement Learning: A Review",
    "summary": "Reinforcement learning is about learning agent models that make the best sequential decisions in unknown environments. In an unknown environment, the agent needs to explore the environment while exploiting the collected information, which usually forms a sophisticated problem to solve. Derivative-free optimization, meanwhile, is capable of solving sophisticated problems. It commonly uses a sampling-and-updating framework to iteratively improve the solution, where exploration and exploitation are also needed to be well balanced. Therefore, derivative-free optimization deals with a similar core issue as reinforcement learning, and has been introduced in reinforcement learning approaches, under the names of learning classifier systems and neuroevolution/evolutionary reinforcement learning. Although such methods have been developed for decades, recently, derivative-free reinforcement learning exhibits attracting increasing attention. However, recent survey on this topic is still lacking. In this article, we summarize methods of derivative-free reinforcement learning to date, and organize the methods in aspects including parameter updating, model selection, exploration, and parallel/distributed methods. Moreover, we discuss some current limitations and possible future directions, hoping that this article could bring more attentions to this topic and serve as a catalyst for developing novel and efficient approaches.",
    "authors": [
      "Hong Qian",
      "Yang Yu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2021-02-10T19:29:22Z",
    "pdf_url": "https://arxiv.org/pdf/2102.05710v1"
  },
  {
    "arxiv_id": "2102.03588v2",
    "entry_id": "http://arxiv.org/abs/2102.03588v2",
    "title": "An Autonomous Negotiating Agent Framework with Reinforcement Learning Based Strategies and Adaptive Strategy Switching Mechanism",
    "summary": "Despite abundant negotiation strategies in literature, the complexity of automated negotiation forbids a single strategy from being dominant against all others in different negotiation scenarios. To overcome this, one approach is to use mixture of experts, but at the same time, one problem of this method is the selection of experts, as this approach is limited by the competency of the experts selected. Another problem with most negotiation strategies is their incapability of adapting to dynamic variation of the opponent's behaviour within a single negotiation session resulting in poor performance. This work focuses on both, solving the problem of expert selection and adapting to the opponent's behaviour with our Autonomous Negotiating Agent Framework. This framework allows real-time classification of opponent's behaviour and provides a mechanism to select, switch or combine strategies within a single negotiation session. Additionally, our framework has a reviewer component which enables self-enhancement capability by deciding to include new strategies or replace old ones with better strategies periodically. We demonstrate an instance of our framework by implementing maximum entropy reinforcement learning based strategies with a deep learning based opponent classifier. Finally, we evaluate the performance of our agent against state-of-the-art negotiators under varied negotiation scenarios.",
    "authors": [
      "Ayan Sengupta",
      "Yasser Mohammad",
      "Shinji Nakadai"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2021-02-06T14:38:03Z",
    "pdf_url": "https://arxiv.org/pdf/2102.03588v2"
  },
  {
    "arxiv_id": "2102.02928v1",
    "entry_id": "http://arxiv.org/abs/2102.02928v1",
    "title": "Toward a Rational and Ethical Sociotechnical System of Autonomous Vehicles: A Novel Application of Multi-Criteria Decision Analysis",
    "summary": "The expansion of artificial intelligence (AI) and autonomous systems has shown the potential to generate enormous social good while also raising serious ethical and safety concerns. AI technology is increasingly adopted in transportation. A survey of various in-vehicle technologies found that approximately 64% of the respondents used a smartphone application to assist with their travel. The top-used applications were navigation and real-time traffic information systems. Among those who used smartphones during their commutes, the top-used applications were navigation and entertainment. There is a pressing need to address relevant social concerns to allow for the development of systems of intelligent agents that are informed and cognizant of ethical standards. Doing so will facilitate the responsible integration of these systems in society. To this end, we have applied Multi-Criteria Decision Analysis (MCDA) to develop a formal Multi-Attribute Impact Assessment (MAIA) questionnaire for examining the social and ethical issues associated with the uptake of AI. We have focused on the domain of autonomous vehicles (AVs) because of their imminent expansion. However, AVs could serve as a stand-in for any domain where intelligent, autonomous agents interact with humans, either on an individual level (e.g., pedestrians, passengers) or a societal level.",
    "authors": [
      "Veljko Dubljević",
      "George F. List",
      "Jovan Milojevich",
      "Nirav Ajmeri",
      "William Bauer",
      "Munindar P. Singh",
      "Eleni Bardaka",
      "Thomas Birkland",
      "Charles Edwards",
      "Roger Mayer",
      "Ioan Muntean",
      "Thomas Powers",
      "Hesham Rakha",
      "Vance Ricks",
      "M. Shoaib Samandar"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2021-02-04T23:52:31Z",
    "pdf_url": "https://arxiv.org/pdf/2102.02928v1"
  },
  {
    "arxiv_id": "2102.02915v1",
    "entry_id": "http://arxiv.org/abs/2102.02915v1",
    "title": "How to Train Your Robot with Deep Reinforcement Learning; Lessons We've Learned",
    "summary": "Deep reinforcement learning (RL) has emerged as a promising approach for autonomously acquiring complex behaviors from low level sensor observations. Although a large portion of deep RL research has focused on applications in video games and simulated control, which does not connect with the constraints of learning in real environments, deep RL has also demonstrated promise in enabling physical robots to learn complex skills in the real world. At the same time,real world robotics provides an appealing domain for evaluating such algorithms, as it connects directly to how humans learn; as an embodied agent in the real world. Learning to perceive and move in the real world presents numerous challenges, some of which are easier to address than others, and some of which are often not considered in RL research that focuses only on simulated domains. In this review article, we present a number of case studies involving robotic deep RL. Building off of these case studies, we discuss commonly perceived challenges in deep RL and how they have been addressed in these works. We also provide an overview of other outstanding challenges, many of which are unique to the real-world robotics setting and are not often the focus of mainstream RL research. Our goal is to provide a resource both for roboticists and machine learning researchers who are interested in furthering the progress of deep RL in the real world.",
    "authors": [
      "Julian Ibarz",
      "Jie Tan",
      "Chelsea Finn",
      "Mrinal Kalakrishnan",
      "Peter Pastor",
      "Sergey Levine"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2021-02-04T22:09:28Z",
    "pdf_url": "https://arxiv.org/pdf/2102.02915v1"
  },
  {
    "arxiv_id": "2102.02094v2",
    "entry_id": "http://arxiv.org/abs/2102.02094v2",
    "title": "What Do We See in Them? Identifying Dimensions of Partner Models for Speech Interfaces Using a Psycholexical Approach",
    "summary": "Perceptions of system competence and communicative ability, termed partner models, play a significant role in speech interface interaction. Yet we do not know what the core dimensions of this concept are. Taking a psycholexical approach, our paper is the first to identify the key dimensions that define partner models in speech agent interaction. Through a repertory grid study (N=21), a review of key subjective questionnaires, an expert review of resulting word pairs and an online study of 356 user of speech interfaces, we identify three key dimensions that make up a users' partner model: 1) perceptions toward competence and capability; 2) assessment of human-likeness; and 3) a system's perceived cognitive flexibility. We discuss the implications for partner modelling as a concept, emphasising the importance of salience and the dynamic nature of these perceptions.",
    "authors": [
      "Philip R Doyle",
      "Leigh Clark",
      "Benjamin R Cowan"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2021-02-03T14:57:08Z",
    "pdf_url": "https://arxiv.org/pdf/2102.02094v2"
  },
  {
    "arxiv_id": "2102.00875v1",
    "entry_id": "http://arxiv.org/abs/2102.00875v1",
    "title": "Scaling Federated Learning for Fine-tuning of Large Language Models",
    "summary": "Federated learning (FL) is a promising approach to distributed compute, as well as distributed data, and provides a level of privacy and compliance to legal frameworks. This makes FL attractive for both consumer and healthcare applications. While the area is actively being explored, few studies have examined FL in the context of larger language models and there is a lack of comprehensive reviews of robustness across tasks, architectures, numbers of clients, and other relevant factors. In this paper, we explore the fine-tuning of Transformer-based language models in a federated learning setting. We evaluate three popular BERT-variants of different sizes (BERT, ALBERT, and DistilBERT) on a number of text classification tasks such as sentiment analysis and author identification. We perform an extensive sweep over the number of clients, ranging up to 32, to evaluate the impact of distributed compute on task performance in the federated averaging setting. While our findings suggest that the large sizes of the evaluated models are not generally prohibitive to federated training, we found that the different models handle federated averaging to a varying degree. Most notably, DistilBERT converges significantly slower with larger numbers of clients, and under some circumstances, even collapses to chance level performance. Investigating this issue presents an interesting perspective for future research.",
    "authors": [
      "Agrin Hilmkil",
      "Sebastian Callh",
      "Matteo Barbieri",
      "Leon René Sütfeld",
      "Edvin Listo Zec",
      "Olof Mogren"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.DC"
    ],
    "published": "2021-02-01T14:31:39Z",
    "pdf_url": "https://arxiv.org/pdf/2102.00875v1"
  },
  {
    "arxiv_id": "2101.10181v1",
    "entry_id": "http://arxiv.org/abs/2101.10181v1",
    "title": "Machine Learning for the Detection and Identification of Internet of Things (IoT) Devices: A Survey",
    "summary": "The Internet of Things (IoT) is becoming an indispensable part of everyday life, enabling a variety of emerging services and applications. However, the presence of rogue IoT devices has exposed the IoT to untold risks with severe consequences. The first step in securing the IoT is detecting rogue IoT devices and identifying legitimate ones. Conventional approaches use cryptographic mechanisms to authenticate and verify legitimate devices' identities. However, cryptographic protocols are not available in many systems. Meanwhile, these methods are less effective when legitimate devices can be exploited or encryption keys are disclosed. Therefore, non-cryptographic IoT device identification and rogue device detection become efficient solutions to secure existing systems and will provide additional protection to systems with cryptographic protocols. Non-cryptographic approaches require more effort and are not yet adequately investigated. In this paper, we provide a comprehensive survey on machine learning technologies for the identification of IoT devices along with the detection of compromised or falsified ones from the viewpoint of passive surveillance agents or network operators. We classify the IoT device identification and detection into four categories: device-specific pattern recognition, Deep Learning enabled device identification, unsupervised device identification, and abnormal device detection. Meanwhile, we discuss various ML-related enabling technologies for this purpose. These enabling technologies include learning algorithms, feature engineering on network traffic traces and wireless signals, continual learning, and abnormality detection.",
    "authors": [
      "Yongxin Liu",
      "Jian Wang",
      "Jianqiang Li",
      "Shuteng Niu",
      "Houbing Song"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-01-25T15:51:04Z",
    "pdf_url": "https://arxiv.org/pdf/2101.10181v1"
  },
  {
    "arxiv_id": "2101.12047v1",
    "entry_id": "http://arxiv.org/abs/2101.12047v1",
    "title": "Measuring Intelligence and Growth Rate: Variations on Hibbard's Intelligence Measure",
    "summary": "In 2011, Hibbard suggested an intelligence measure for agents who compete in an adversarial sequence prediction game. We argue that Hibbard's idea should actually be considered as two separate ideas: first, that the intelligence of such agents can be measured based on the growth rates of the runtimes of the competitors that they defeat; and second, one specific (somewhat arbitrary) method for measuring said growth rates. Whereas Hibbard's intelligence measure is based on the latter growth-rate-measuring method, we survey other methods for measuring function growth rates, and exhibit the resulting Hibbard-like intelligence measures and taxonomies. Of particular interest, we obtain intelligence taxonomies based on Big-O and Big-Theta notation systems, which taxonomies are novel in that they challenge conventional notions of what an intelligence measure should look like. We discuss how intelligence measurement of sequence predictors can indirectly serve as intelligence measurement for agents with Artificial General Intelligence (AGIs).",
    "authors": [
      "Samuel Alexander",
      "Bill Hibbard"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-01-25T01:54:08Z",
    "pdf_url": "https://arxiv.org/pdf/2101.12047v1"
  },
  {
    "arxiv_id": "2101.09571v6",
    "entry_id": "http://arxiv.org/abs/2101.09571v6",
    "title": "BF++: a language for general-purpose program synthesis",
    "summary": "Most state of the art decision systems based on Reinforcement Learning (RL) are data-driven black-box neural models, where it is often difficult to incorporate expert knowledge into the models or let experts review and validate the learned decision mechanisms. Knowledge-insertion and model review are important requirements in many applications involving human health and safety. One way to bridge the gap between data and knowledge driven systems is program synthesis: replacing a neural network that outputs decisions with a symbolic program generated by a neural network or by means of genetic programming. We propose a new programming language, BF++, designed specifically for automatic programming of agents in a Partially Observable Markov Decision Process (POMDP) setting and apply neural program synthesis to solve standard OpenAI Gym benchmarks.",
    "authors": [
      "Vadim Liventsev",
      "Aki Härmä",
      "Milan Petković"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2021-01-23T19:44:44Z",
    "pdf_url": "https://arxiv.org/pdf/2101.09571v6"
  },
  {
    "arxiv_id": "2101.09241v2",
    "entry_id": "http://arxiv.org/abs/2101.09241v2",
    "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part II: Elicitation of Requirements",
    "summary": "The COVID-19 pandemic has influenced virtually all aspects of our lives. Across the world, countries have applied various mitigation strategies, based on social, political, and technological instruments. We postulate that multi-agent systems can provide a common platform to study (and balance) their essential properties. We also show how to obtain a comprehensive list of the properties by \"distilling\" them from media snippets. Finally, we present a preliminary take on their formal specification, using ideas from multi-agent logics.",
    "authors": [
      "Wojciech Jamroga"
    ],
    "categories": [
      "cs.CY",
      "cs.MA"
    ],
    "published": "2021-01-22T17:52:20Z",
    "pdf_url": "https://arxiv.org/pdf/2101.09241v2"
  },
  {
    "arxiv_id": "2101.04640v2",
    "entry_id": "http://arxiv.org/abs/2101.04640v2",
    "title": "Dimensions of Commonsense Knowledge",
    "summary": "Commonsense knowledge is essential for many AI applications, including those in natural language processing, visual processing, and planning. Consequently, many sources that include commonsense knowledge have been designed and constructed over the past decades. Recently, the focus has been on large text-based sources, which facilitate easier integration with neural (language) models and application to textual tasks, typically at the expense of the semantics of the sources and their harmonization. Efforts to consolidate commonsense knowledge have yielded partial success, with no clear path towards a comprehensive solution. We aim to organize these sources around a common set of dimensions of commonsense knowledge. We survey a wide range of popular commonsense sources with a special focus on their relations. We consolidate these relations into 13 knowledge dimensions. This consolidation allows us to unify the separate sources and to compute indications of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze the impact of each dimension on downstream reasoning tasks that require commonsense knowledge, observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current downstream tasks, while distinctness and lexical knowledge have little impact. These results reveal preferences for some dimensions in current evaluation, and potential neglect of others.",
    "authors": [
      "Filip Ilievski",
      "Alessandro Oltramari",
      "Kaixin Ma",
      "Bin Zhang",
      "Deborah L. McGuinness",
      "Pedro Szekely"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2021-01-12T17:52:39Z",
    "pdf_url": "https://arxiv.org/pdf/2101.04640v2"
  },
  {
    "arxiv_id": "2101.03392v1",
    "entry_id": "http://arxiv.org/abs/2101.03392v1",
    "title": "Generate Natural Language Explanations for Recommendation",
    "summary": "Providing personalized explanations for recommendations can help users to understand the underlying insight of the recommendation results, which is helpful to the effectiveness, transparency, persuasiveness and trustworthiness of recommender systems. Current explainable recommendation models mostly generate textual explanations based on pre-defined sentence templates. However, the expressiveness power of template-based explanation sentences are limited to the pre-defined expressions, and manually defining the expressions require significant human efforts. Motivated by this problem, we propose to generate free-text natural language explanations for personalized recommendation. In particular, we propose a hierarchical sequence-to-sequence model (HSS) for personalized explanation generation. Different from conventional sentence generation in NLP research, a great challenge of explanation generation in e-commerce recommendation is that not all sentences in user reviews are of explanation purpose. To solve the problem, we further propose an auto-denoising mechanism based on topical item feature words for sentence generation. Experiments on various e-commerce product domains show that our approach can not only improve the recommendation accuracy, but also the explanation quality in terms of the offline measures and feature words coverage. This research is one of the initial steps to grant intelligent agents with the ability to explain itself based on natural language sentences.",
    "authors": [
      "Hanxiong Chen",
      "Xu Chen",
      "Shaoyun Shi",
      "Yongfeng Zhang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2021-01-09T17:00:41Z",
    "pdf_url": "https://arxiv.org/pdf/2101.03392v1"
  },
  {
    "arxiv_id": "2101.01169v5",
    "entry_id": "http://arxiv.org/abs/2101.01169v5",
    "title": "Transformers in Vision: A Survey",
    "summary": "Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks e.g., Long short-term memory (LSTM). Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers i.e., self-attention, large-scale pre-training, and bidirectional encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization) and 3D analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works.",
    "authors": [
      "Salman Khan",
      "Muzammal Naseer",
      "Munawar Hayat",
      "Syed Waqas Zamir",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2021-01-04T18:57:24Z",
    "pdf_url": "https://arxiv.org/pdf/2101.01169v5"
  },
  {
    "arxiv_id": "2101.00916v1",
    "entry_id": "http://arxiv.org/abs/2101.00916v1",
    "title": "How to Train Your Agent to Read and Write",
    "summary": "Reading and writing research papers is one of the most privileged abilities that a qualified researcher should master. However, it is difficult for new researchers (\\eg{students}) to fully {grasp} this ability. It would be fascinating if we could train an intelligent agent to help people read and summarize papers, and perhaps even discover and exploit the potential knowledge clues to write novel papers. Although there have been existing works focusing on summarizing (\\emph{i.e.}, reading) the knowledge in a given text or generating (\\emph{i.e.}, writing) a text based on the given knowledge, the ability of simultaneously reading and writing is still under development. Typically, this requires an agent to fully understand the knowledge from the given text materials and generate correct and fluent novel paragraphs, which is very challenging in practice. In this paper, we propose a Deep ReAder-Writer (DRAW) network, which consists of a \\textit{Reader} that can extract knowledge graphs (KGs) from input paragraphs and discover potential knowledge, a graph-to-text \\textit{Writer} that generates a novel paragraph, and a \\textit{Reviewer} that reviews the generated paragraph from three different aspects. Extensive experiments show that our DRAW network outperforms considered baselines and several state-of-the-art methods on AGENDA and M-AGENDA datasets. Our code and supplementary are released at https://github.com/menggehe/DRAW.",
    "authors": [
      "Li Liu",
      "Mengge He",
      "Guanghui Xu",
      "Mingkui Tan",
      "Qi Wu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2021-01-04T12:22:04Z",
    "pdf_url": "https://arxiv.org/pdf/2101.00916v1"
  },
  {
    "arxiv_id": "2101.00240v1",
    "entry_id": "http://arxiv.org/abs/2101.00240v1",
    "title": "A Survey on Deep Reinforcement Learning for Audio-Based Applications",
    "summary": "Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising application in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together the research studies across different speech and music-related areas. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting challenges faced by audio-based DRL agents and highlighting open areas for future research and investigation.",
    "authors": [
      "Siddique Latif",
      "Heriberto Cuayáhuitl",
      "Farrukh Pervez",
      "Fahad Shamshad",
      "Hafiz Shehbaz Ali",
      "Erik Cambria"
    ],
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2021-01-01T14:15:20Z",
    "pdf_url": "https://arxiv.org/pdf/2101.00240v1"
  }
]
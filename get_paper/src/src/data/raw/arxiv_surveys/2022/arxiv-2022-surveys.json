[
  {
    "arxiv_id": "2301.00234v6",
    "entry_id": "http://arxiv.org/abs/2301.00234v6",
    "title": "A Survey on In-context Learning",
    "summary": "With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, prompt designing strategies, and related analysis. Additionally, we explore various ICL application scenarios, such as data engineering and knowledge updating. Finally, we address the challenges of ICL and suggest potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.",
    "authors": [
      "Qingxiu Dong",
      "Lei Li",
      "Damai Dai",
      "Ce Zheng",
      "Jingyuan Ma",
      "Rui Li",
      "Heming Xia",
      "Jingjing Xu",
      "Zhiyong Wu",
      "Tianyu Liu",
      "Baobao Chang",
      "Xu Sun",
      "Lei Li",
      "Zhifang Sui"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-12-31T15:57:09Z",
    "pdf_url": "https://arxiv.org/pdf/2301.00234v6"
  },
  {
    "arxiv_id": "2302.00595v1",
    "entry_id": "http://arxiv.org/abs/2302.00595v1",
    "title": "Stroke-based Rendering: From Heuristics to Deep Learning",
    "summary": "In the last few years, artistic image-making with deep learning models has gained a considerable amount of traction. A large number of these models operate directly in the pixel space and generate raster images. This is however not how most humans would produce artworks, for example, by planning a sequence of shapes and strokes to draw. Recent developments in deep learning methods help to bridge the gap between stroke-based paintings and pixel photo generation. With this survey, we aim to provide a structured introduction and understanding of common challenges and approaches in stroke-based rendering algorithms. These algorithms range from simple rule-based heuristics to stroke optimization and deep reinforcement agents, trained to paint images with differentiable vector graphics and neural rendering.",
    "authors": [
      "Florian Nolte",
      "Andrew Melnik",
      "Helge Ritter"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2022-12-30T05:34:54Z",
    "pdf_url": "https://arxiv.org/pdf/2302.00595v1"
  },
  {
    "arxiv_id": "2212.14164v2",
    "entry_id": "http://arxiv.org/abs/2212.14164v2",
    "title": "On Transforming Reinforcement Learning by Transformer: The Development Trajectory",
    "summary": "Transformer, originally devised for natural language processing, has also attested significant success in computer vision. Thanks to its super expressive power, researchers are investigating ways to deploy transformers to reinforcement learning (RL) and the transformer-based models have manifested their potential in representative RL benchmarks. In this paper, we collect and dissect recent advances on transforming RL by transformer (transformer-based RL or TRL), in order to explore its development trajectory and future trend. We group existing developments in two categories: architecture enhancement and trajectory optimization, and examine the main applications of TRL in robotic manipulation, text-based games, navigation and autonomous driving. For architecture enhancement, these methods consider how to apply the powerful transformer structure to RL problems under the traditional RL framework, which model agents and environments much more precisely than deep RL methods, but they are still limited by the inherent defects of traditional RL algorithms, such as bootstrapping and \"deadly triad\". For trajectory optimization, these methods treat RL problems as sequence modeling and train a joint state-action model over entire trajectories under the behavior cloning framework, which are able to extract policies from static datasets and fully use the long-sequence modeling capability of the transformer. Given these advancements, extensions and challenges in TRL are reviewed and proposals about future direction are discussed. We hope that this survey can provide a detailed introduction to TRL and motivate future research in this rapidly developing field.",
    "authors": [
      "Shengchao Hu",
      "Li Shen",
      "Ya Zhang",
      "Yixin Chen",
      "Dacheng Tao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-12-29T03:15:59Z",
    "pdf_url": "https://arxiv.org/pdf/2212.14164v2"
  },
  {
    "arxiv_id": "2212.10712v3",
    "entry_id": "http://arxiv.org/abs/2212.10712v3",
    "title": "Neighboring State-based Exploration for Reinforcement Learning",
    "summary": "Reinforcement Learning is a powerful tool to model decision-making processes. However, it relies on an exploration-exploitation trade-off that remains an open challenge for many tasks. In this work, we study neighboring state-based, model-free exploration led by the intuition that, for an early-stage agent, considering actions derived from a bounded region of nearby states may lead to better actions when exploring. We propose two algorithms that choose exploratory actions based on a survey of nearby states, and find that one of our methods, $ρ$-explore, consistently outperforms the Double DQN baseline in an discrete environment by 49% in terms of Eval Reward Return.",
    "authors": [
      "Yu-Teng Li",
      "Justin Lin",
      "Jeffery Cheng",
      "Pedro Pachuca"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-12-21T01:23:53Z",
    "pdf_url": "https://arxiv.org/pdf/2212.10712v3"
  },
  {
    "arxiv_id": "2212.10535v2",
    "entry_id": "http://arxiv.org/abs/2212.10535v2",
    "title": "A Survey of Deep Learning for Mathematical Reasoning",
    "summary": "Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.",
    "authors": [
      "Pan Lu",
      "Liang Qiu",
      "Wenhao Yu",
      "Sean Welleck",
      "Kai-Wei Chang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2022-12-20T18:46:16Z",
    "pdf_url": "https://arxiv.org/pdf/2212.10535v2"
  },
  {
    "arxiv_id": "2212.10403v2",
    "entry_id": "http://arxiv.org/abs/2212.10403v2",
    "title": "Towards Reasoning in Large Language Models: A Survey",
    "summary": "Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.",
    "authors": [
      "Jie Huang",
      "Kevin Chen-Chuan Chang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-12-20T16:29:03Z",
    "pdf_url": "https://arxiv.org/pdf/2212.10403v2"
  },
  {
    "arxiv_id": "2212.09420v2",
    "entry_id": "http://arxiv.org/abs/2212.09420v2",
    "title": "Large Language Models Meet NL2Code: A Survey",
    "summary": "The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are \"Large Size, Premium Data, Expert Tuning\". In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sourcing. To the best of our knowledge, this is the first survey of large language models for NL2Code, and we believe it will contribute to the ongoing development of the field.",
    "authors": [
      "Daoguang Zan",
      "Bei Chen",
      "Fengji Zhang",
      "Dianjie Lu",
      "Bingchao Wu",
      "Bei Guan",
      "Yongji Wang",
      "Jian-Guang Lou"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "published": "2022-12-19T12:55:32Z",
    "pdf_url": "https://arxiv.org/pdf/2212.09420v2"
  },
  {
    "arxiv_id": "2212.08966v5",
    "entry_id": "http://arxiv.org/abs/2212.08966v5",
    "title": "Graph Learning and Its Advancements on Large Language Models: A Holistic Survey",
    "summary": "Graph learning is a prevalent domain that endeavors to learn the intricate relationships among nodes and the topological structure of graphs. Over the years, graph learning has transcended from graph theory to graph data mining. With the advent of representation learning, it has attained remarkable performance in diverse scenarios. Owing to its extensive application prospects, graph learning attracts copious attention. While some researchers have accomplished impressive surveys on graph learning, they failed to connect related objectives, methods, and applications in a more coherent way. As a result, they did not encompass current ample scenarios and challenging problems due to the rapid expansion of graph learning. Particularly, large language models have recently had a disruptive effect on human life, but they also show relative weakness in structured scenarios. The question of how to make these models more powerful with graph learning remains open. Our survey focuses on the most recent advancements in integrating graph learning with pre-trained language models, specifically emphasizing their application within the domain of large language models. Different from previous surveys on graph learning, we provide a holistic review that analyzes current works from the perspective of graph structure, and discusses the latest applications, trends, and challenges in graph learning. Specifically, we commence by proposing a taxonomy and then summarize the methods employed in graph learning. We then provide a detailed elucidation of mainstream applications. Finally, we propose future directions.",
    "authors": [
      "Shaopeng Wei",
      "Jun Wang",
      "Yu Zhao",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Fuji Ren",
      "Gang Kou"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-12-17T22:05:07Z",
    "pdf_url": "https://arxiv.org/pdf/2212.08966v5"
  },
  {
    "arxiv_id": "2212.07709v1",
    "entry_id": "http://arxiv.org/abs/2212.07709v1",
    "title": "Classification-Based Opinion Formation Model Embedding Agents' Psychological Traits",
    "summary": "We propose an agent-based opinion formation model characterised by a two-fold novelty. First, we realistically assume that each agent cannot measure the opinion of its neighbours with infinite resolution and accuracy, and hence it can only classify the opinion of others as agreeing much more, or more, or comparably, or less, or much less (than itself) with a given statement. This leads to a classification-based rule for opinion update. Second, we consider three complementary agent traits suggested by significant sociological and psychological research: conformism, radicalism and stubbornness. We rely on World Values Survey data to show that the proposed model has the potential to predict the evolution of opinions in real life: the classification-based approach and complementary agent traits produce rich collective behaviours, such as polarisation, consensus, and clustering, which can yield predicted opinions similar to survey results.",
    "authors": [
      "Carlos Andres Devia",
      "Giulia Giordano"
    ],
    "categories": [
      "cs.SI",
      "cs.MA",
      "eess.SY",
      "math.OC",
      "q-bio.PE"
    ],
    "published": "2022-12-15T10:34:15Z",
    "pdf_url": "https://arxiv.org/pdf/2212.07709v1"
  },
  {
    "arxiv_id": "2212.07126v2",
    "entry_id": "http://arxiv.org/abs/2212.07126v2",
    "title": "Explainability of Text Processing and Retrieval Methods: A Survey",
    "summary": "Deep Learning and Machine Learning based models have become extremely popular in text processing and information retrieval. However, the non-linear structures present inside the networks make these models largely inscrutable. A significant body of research has focused on increasing the transparency of these models. This article provides a broad overview of research on the explainability and interpretability of natural language processing and information retrieval methods. More specifically, we survey approaches that have been applied to explain word embeddings, sequence modeling, attention modules, transformers, BERT, and document ranking. The concluding section suggests some possible directions for future research on this topic.",
    "authors": [
      "Sourav Saha",
      "Debapriyo Majumdar",
      "Mandar Mitra"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-12-14T09:25:49Z",
    "pdf_url": "https://arxiv.org/pdf/2212.07126v2"
  },
  {
    "arxiv_id": "2212.06933v3",
    "entry_id": "http://arxiv.org/abs/2212.06933v3",
    "title": "Paraphrase Identification with Deep Learning: A Review of Datasets and Methods",
    "summary": "The rapid progress of Natural Language Processing (NLP) technologies has led to the widespread availability and effectiveness of text generation tools such as ChatGPT and Claude. While highly useful, these technologies also pose significant risks to the credibility of various media forms if they are employed for paraphrased plagiarism -- one of the most subtle forms of content misuse in scientific literature and general text media. Although automated methods for paraphrase identification have been developed, detecting this type of plagiarism remains challenging due to the inconsistent nature of the datasets used to train these methods. In this article, we examine traditional and contemporary approaches to paraphrase identification, investigating how the under-representation of certain paraphrase types in popular datasets, including those used to train Large Language Models (LLMs), affects the ability to detect plagiarism. We introduce and validate a new refined typology for paraphrases (ReParaphrased, REfined PARAPHRASE typology definitions) to better understand the disparities in paraphrase type representation. Lastly, we propose new directions for future research and dataset development to enhance AI-based paraphrase detection.",
    "authors": [
      "Chao Zhou",
      "Cheng Qiu",
      "Lizhen Liang",
      "Daniel E. Acuna"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2022-12-13T23:06:20Z",
    "pdf_url": "https://arxiv.org/pdf/2212.06933v3"
  },
  {
    "arxiv_id": "2212.06123v3",
    "entry_id": "http://arxiv.org/abs/2212.06123v3",
    "title": "Security of Deep Reinforcement Learning for Autonomous Driving: A Survey",
    "summary": "Reinforcement learning (RL) enables agents to learn optimal behaviors through interaction with their environment and has been increasingly deployed in safety-critical applications, including autonomous driving. Despite its promise, RL is susceptible to attacks designed either to compromise policy learning or to induce erroneous decisions by trained agents. Although the literature on RL security has grown rapidly and several surveys exist, existing categorizations often fall short in guiding the selection of appropriate defenses for specific systems. In this work, we present a comprehensive survey of 86 recent studies on RL security, addressing these limitations by systematically categorizing attacks and defenses according to defined threat models and single- versus multi-agent settings. Furthermore, we examine the relevance and applicability of state-of-the-art attacks and defense mechanisms within the context of autonomous driving, providing insights to inform the design of robust RL systems.",
    "authors": [
      "Ambra Demontis",
      "Srishti Gupta",
      "Maura Pintor",
      "Luca Demetrio",
      "Kathrin Grosse",
      "Hsiao-Ying Lin",
      "Chengfang Fang",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "published": "2022-12-12T18:50:49Z",
    "pdf_url": "https://arxiv.org/pdf/2212.06123v3"
  },
  {
    "arxiv_id": "2212.01681v1",
    "entry_id": "http://arxiv.org/abs/2212.01681v1",
    "title": "Language Models as Agent Models",
    "summary": "Language models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in an outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them -- a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of intentional communication in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents' communicative intentions influence their language. I survey findings from the recent literature showing that -- even in today's non-robust and error-prone models -- LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally.",
    "authors": [
      "Jacob Andreas"
    ],
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "published": "2022-12-03T20:18:16Z",
    "pdf_url": "https://arxiv.org/pdf/2212.01681v1"
  },
  {
    "arxiv_id": "2212.00253v1",
    "entry_id": "http://arxiv.org/abs/2212.00253v1",
    "title": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player Multi-Agent Learning Toolbox",
    "summary": "With the breakthrough of AlphaGo, deep reinforcement learning becomes a recognized technique for solving sequential decision-making problems. Despite its reputation, data inefficiency caused by its trial and error learning mechanism makes deep reinforcement learning hard to be practical in a wide range of areas. Plenty of methods have been developed for sample efficient deep reinforcement learning, such as environment modeling, experience transfer, and distributed modifications, amongst which, distributed deep reinforcement learning has shown its potential in various applications, such as human-computer gaming, and intelligent transportation. In this paper, we conclude the state of this exciting field, by comparing the classical distributed deep reinforcement learning methods, and studying important components to achieve efficient distributed learning, covering single player single agent distributed deep reinforcement learning to the most complex multiple players multiple agents distributed deep reinforcement learning. Furthermore, we review recently released toolboxes that help to realize distributed deep reinforcement learning without many modifications of their non-distributed versions. By analyzing their strengths and weaknesses, a multi-player multi-agent distributed deep reinforcement learning toolbox is developed and released, which is further validated on Wargame, a complex environment, showing usability of the proposed toolbox for multiple players and multiple agents distributed deep reinforcement learning under complex games. Finally, we try to point out challenges and future trends, hoping this brief review can provide a guide or a spark for researchers who are interested in distributed deep reinforcement learning.",
    "authors": [
      "Qiyue Yin",
      "Tongtong Yu",
      "Shengqi Shen",
      "Jun Yang",
      "Meijing Zhao",
      "Kaiqi Huang",
      "Bin Liang",
      "Liang Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2022-12-01T03:39:24Z",
    "pdf_url": "https://arxiv.org/pdf/2212.00253v1"
  },
  {
    "arxiv_id": "2212.00187v1",
    "entry_id": "http://arxiv.org/abs/2212.00187v1",
    "title": "Five Properties of Specific Curiosity You Didn't Know Curious Machines Should Have",
    "summary": "Curiosity for machine agents has been a focus of lively research activity. The study of human and animal curiosity, particularly specific curiosity, has unearthed several properties that would offer important benefits for machine learners, but that have not yet been well-explored in machine intelligence. In this work, we conduct a comprehensive, multidisciplinary survey of the field of animal and machine curiosity. As a principal contribution of this work, we use this survey as a foundation to introduce and define what we consider to be five of the most important properties of specific curiosity: 1) directedness towards inostensible referents, 2) cessation when satisfied, 3) voluntary exposure, 4) transience, and 5) coherent long-term learning. As a second main contribution of this work, we show how these properties may be implemented together in a proof-of-concept reinforcement learning agent: we demonstrate how the properties manifest in the behaviour of this agent in a simple non-episodic grid-world environment that includes curiosity-inducing locations and induced targets of curiosity. As we would hope, our example of a computational specific curiosity agent exhibits short-term directed behaviour while updating long-term preferences to adaptively seek out curiosity-inducing situations. This work, therefore, presents a landmark synthesis and translation of specific curiosity to the domain of machine learning and reinforcement learning and provides a novel view into how specific curiosity operates and in the future might be integrated into the behaviour of goal-seeking, decision-making computational agents in complex environments.",
    "authors": [
      "Nadia M. Ady",
      "Roshan Shariff",
      "Johannes Günther",
      "Patrick M. Pilarski"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-12-01T00:18:56Z",
    "pdf_url": "https://arxiv.org/pdf/2212.00187v1"
  },
  {
    "arxiv_id": "2211.17132v1",
    "entry_id": "http://arxiv.org/abs/2211.17132v1",
    "title": "Targets in Reinforcement Learning to solve Stackelberg Security Games",
    "summary": "Reinforcement Learning (RL) algorithms have been successfully applied to real world situations like illegal smuggling, poaching, deforestation, climate change, airport security, etc. These scenarios can be framed as Stackelberg security games (SSGs) where defenders and attackers compete to control target resources. The algorithm's competency is assessed by which agent is controlling the targets. This review investigates modeling of SSGs in RL with a focus on possible improvements of target representations in RL algorithms.",
    "authors": [
      "Saptarashmi Bandyopadhyay",
      "Chenqi Zhu",
      "Philip Daniel",
      "Joshua Morrison",
      "Ethan Shay",
      "John Dickerson"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA",
      "stat.ML"
    ],
    "published": "2022-11-30T16:08:04Z",
    "pdf_url": "https://arxiv.org/pdf/2211.17132v1"
  },
  {
    "arxiv_id": "2211.15837v1",
    "entry_id": "http://arxiv.org/abs/2211.15837v1",
    "title": "Survey on Self-Supervised Multimodal Representation Learning and Foundation Models",
    "summary": "Deep learning has been the subject of growing interest in recent years. Specifically, a specific type called Multimodal learning has shown great promise for solving a wide range of problems in domains such as language, vision, audio, etc. One promising research direction to improve this further has been learning rich and robust low-dimensional data representation of the high-dimensional world with the help of large-scale datasets present on the internet. Because of its potential to avoid the cost of annotating large-scale datasets, self-supervised learning has been the de facto standard for this task in recent years. This paper summarizes some of the landmark research papers that are directly or indirectly responsible to build the foundation of multimodal self-supervised learning of representation today. The paper goes over the development of representation learning over the last few years for each modality and how they were combined to get a multimodal agent later.",
    "authors": [
      "Sushil Thapa"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GT"
    ],
    "published": "2022-11-29T00:17:43Z",
    "pdf_url": "https://arxiv.org/pdf/2211.15837v1"
  },
  {
    "arxiv_id": "2211.13339v1",
    "entry_id": "http://arxiv.org/abs/2211.13339v1",
    "title": "Robustness Analysis of Deep Learning Models for Population Synthesis",
    "summary": "Deep generative models have become useful for synthetic data generation, particularly population synthesis. The models implicitly learn the probability distribution of a dataset and can draw samples from a distribution. Several models have been proposed, but their performance is only tested on a single cross-sectional sample. The implementation of population synthesis on single datasets is seen as a drawback that needs further studies to explore the robustness of the models on multiple datasets. While comparing with the real data can increase trust and interpretability of the models, techniques to evaluate deep generative models' robustness for population synthesis remain underexplored. In this study, we present bootstrap confidence interval for the deep generative models, an approach that computes efficient confidence intervals for mean errors predictions to evaluate the robustness of the models to multiple datasets. Specifically, we adopt the tabular-based Composite Travel Generative Adversarial Network (CTGAN) and Variational Autoencoder (VAE), to estimate the distribution of the population, by generating agents that have tabular data using several samples over time from the same study area. The models are implemented on multiple travel diaries of Montreal Origin- Destination Survey of 2008, 2013, and 2018 and compare the predictive performance under varying sample sizes from multiple surveys. Results show that the predictive errors of CTGAN have narrower confidence intervals indicating its robustness to multiple datasets of the varying sample sizes when compared to VAE. Again, the evaluation of model robustness against varying sample size shows a minimal decrease in model performance with decrease in sample size. This study directly supports agent-based modelling by enabling finer synthetic generation of populations in a reliable environment.",
    "authors": [
      "Daniel Opoku Mensah",
      "Godwin Badu-Marfo",
      "Bilal Farooq"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-11-23T22:55:55Z",
    "pdf_url": "https://arxiv.org/pdf/2211.13339v1"
  },
  {
    "arxiv_id": "2212.01334v1",
    "entry_id": "http://arxiv.org/abs/2212.01334v1",
    "title": "A Mixed-Method Approach to Determining Contact Matrices in the Cox's Bazar Refugee Settlement",
    "summary": "Contact matrices are an important ingredient in age-structured epidemic models to inform the simulated spread of the disease between sub-groups of the population. These matrices are generally derived using resource-intensive diary-based surveys and few exist in the Global South or tailored to vulnerable populations. In particular, no contact matrices exist for refugee settlements - locations under-served by epidemic models in general. In this paper we present a novel, mixed-method approach, for deriving contact matrices in populations which combines a lightweight, rapidly deployable, survey with an agent-based model of the population informed by census and behavioural data. We use this method to derive the first set of contact matrices for the Cox's Bazar refugee settlement in Bangladesh. The matrices from the refugee settlement show strong banding effects due to different age cut-offs in attendance at certain venues, such as distribution centres and religious sites, as well as the important contribution of the demographic profile of the settlement which was encoded in the model. These can have significant implications to the modelled disease dynamics. To validate our approach, we also apply our method to the population of the UK and compare our derived matrices against well-known contact matrices previously collected using traditional approaches. Overall, our findings demonstrate that our mixed-method approach can address some of the challenges of both the traditional and previously proposed agent-based approaches to deriving contact matrices, and has the potential to be rolled-out in other resource-constrained environments. This work therefore contributes to a broader aim of developing new methods and mechanisms of data collection for modelling disease spread in refugee and IDP settlements and better serving these vulnerable communities.",
    "authors": [
      "Joseph Walker",
      "Joseph Aylett-Bullock",
      "Difu Shi",
      "Allen Gidraf Kahindo Maina",
      "Egmond Samir Evers",
      "Sandra Harlass",
      "Frank Krauss"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.MA",
      "cs.SI",
      "q-bio.PE"
    ],
    "published": "2022-11-22T21:53:33Z",
    "pdf_url": "https://arxiv.org/pdf/2212.01334v1"
  },
  {
    "arxiv_id": "2211.09172v4",
    "entry_id": "http://arxiv.org/abs/2211.09172v4",
    "title": "Deep Emotion Recognition in Textual Conversations: A Survey",
    "summary": "Emotion Recognition in Conversations (ERC) is a key step towards successful human-machine interaction. While the field has seen tremendous advancement in the last few years, new applications and implementation scenarios present novel challenges and opportunities. These range from leveraging the conversational context, speaker, and emotion dynamics modelling, to interpreting common sense expressions, informal language, and sarcasm, addressing challenges of real-time ERC, recognizing emotion causes, different taxonomies across datasets, multilingual ERC, and interpretability. This survey starts by introducing ERC, elaborating on the challenges and opportunities of this task. It proceeds with a description of the emotion taxonomies and a variety of ERC benchmark datasets employing such taxonomies. This is followed by descriptions comparing the most prominent works in ERC with explanations of the neural architectures employed. Then, it provides advisable ERC practices towards better frameworks, elaborating on methods to deal with subjectivity in annotations and modelling and methods to deal with the typically unbalanced ERC datasets. Finally, it presents systematic review tables comparing several works regarding the methods used and their performance. Benchmarking these works highlights resorting to pre-trained Transformer Language Models to extract utterance representations, using Gated and Graph Neural Networks to model the interactions between these utterances, and leveraging Generative Large Language Models to tackle ERC within a generative framework. This survey emphasizes the advantage of leveraging techniques to address unbalanced data, the exploration of mixed emotions, and the benefits of incorporating annotation subjectivity in the learning phase.",
    "authors": [
      "Patrícia Pereira",
      "Helena Moniz",
      "Joao Paulo Carvalho"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-11-16T19:42:31Z",
    "pdf_url": "https://arxiv.org/pdf/2211.09172v4"
  },
  {
    "arxiv_id": "2211.08494v2",
    "entry_id": "http://arxiv.org/abs/2211.08494v2",
    "title": "Who Reviews The Reviewers? A Multi-Level Jury Problem",
    "summary": "We consider the problem of determining a binary ground truth using advice from a group of independent reviewers (experts) who express their guess about a ground truth correctly with some independent probability (competence). In this setting, when all reviewers are competent (competence greater than one-half), the Condorcet Jury Theorem tells us that adding more reviewers increases the overall accuracy, and if all competences are known, then there exists an optimal weighting of the reviewers. However, in practical settings, reviewers may be noisy or incompetent, i.e., competence below half, and the number of experts may be small, so the asymptotic Condorcet Jury Theorem is not practically relevant. In such cases we explore appointing one or more chairs (judges) who determine the weight of each reviewer for aggregation, creating multiple levels. However, these chairs may be unable to correctly identify the competence of the reviewers they oversee, and therefore unable to compute the optimal weighting. We give conditions when a set of chairs is able to weight the reviewers optimally, and depending on the competence distribution of the agents, give results about when it is better to have more chairs or more reviewers. Through numerical simulations we show that in some cases it is better to have more chairs, but in many cases it is better to have more reviewers.",
    "authors": [
      "Ben Abramowitz",
      "Omer Lev",
      "Nicholas Mattei"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.SI",
      "econ.TH"
    ],
    "published": "2022-11-15T20:47:14Z",
    "pdf_url": "https://arxiv.org/pdf/2211.08494v2"
  },
  {
    "arxiv_id": "2211.07369v1",
    "entry_id": "http://arxiv.org/abs/2211.07369v1",
    "title": "A deep learning framework to generate realistic population and mobility data",
    "summary": "Census and Household Travel Survey datasets are regularly collected from households and individuals and provide information on their daily travel behavior with demographic and economic characteristics. These datasets have important applications ranging from travel demand estimation to agent-based modeling. However, they often represent a limited sample of the population due to privacy concerns or are given aggregated. Synthetic data augmentation is a promising avenue in addressing these challenges. In this paper, we propose a framework to generate a synthetic population that includes both socioeconomic features (e.g., age, sex, industry) and trip chains (i.e., activity locations). Our model is tested and compared with other recently proposed models on multiple assessment metrics.",
    "authors": [
      "Eren Arkangil",
      "Mehmet Yildirimoglu",
      "Jiwon Kim",
      "Carlo Prato"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-11-14T14:05:09Z",
    "pdf_url": "https://arxiv.org/pdf/2211.07369v1"
  },
  {
    "arxiv_id": "2211.06665v6",
    "entry_id": "http://arxiv.org/abs/2211.06665v6",
    "title": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges",
    "summary": "Reinforcement Learning (RL) is a popular machine learning paradigm where intelligent agents interact with the environment to fulfill a long-term goal. Driven by the resurgence of deep learning, Deep RL (DRL) has witnessed great success over a wide spectrum of complex control tasks. Despite the encouraging results achieved, the deep neural network-based backbone is widely deemed as a black box that impedes practitioners to trust and employ trained agents in realistic scenarios where high security and reliability are essential. To alleviate this issue, a large volume of literature devoted to shedding light on the inner workings of the intelligent agents has been proposed, by constructing intrinsic interpretability or post-hoc explainability. In this survey, we provide a comprehensive review of existing works on eXplainable RL (XRL) and introduce a new taxonomy where prior works are clearly categorized into model-explaining, reward-explaining, state-explaining, and task-explaining methods. We also review and highlight RL methods that conversely leverage human knowledge to promote learning efficiency and performance of agents while this kind of method is often ignored in XRL field. Some challenges and opportunities in XRL are discussed. This survey intends to provide a high-level summarization of XRL and to motivate future research on more effective XRL solutions. Corresponding open source codes are collected and categorized at https://github.com/Plankson/awesome-explainable-reinforcement-learning.",
    "authors": [
      "Yunpeng Qing",
      "Shunyu Liu",
      "Jie Song",
      "Yang Zhou",
      "Kaixuan Chen",
      "Huiqiong Wang",
      "Mingli Song"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-11-12T13:52:06Z",
    "pdf_url": "https://arxiv.org/pdf/2211.06665v6"
  },
  {
    "arxiv_id": "2211.06009v3",
    "entry_id": "http://arxiv.org/abs/2211.06009v3",
    "title": "What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives",
    "summary": "Intelligent Mesh Generation (IMG) represents a novel and promising field of research, utilizing machine learning techniques to generate meshes. Despite its relative infancy, IMG has significantly broadened the adaptability and practicality of mesh generation techniques, delivering numerous breakthroughs and unveiling potential future pathways. However, a noticeable void exists in the contemporary literature concerning comprehensive surveys of IMG methods. This paper endeavors to fill this gap by providing a systematic and thorough survey of the current IMG landscape. With a focus on 113 preliminary IMG methods, we undertake a meticulous analysis from various angles, encompassing core algorithm techniques and their application scope, agent learning objectives, data types, targeted challenges, as well as advantages and limitations. We have curated and categorized the literature, proposing three unique taxonomies based on key techniques, output mesh unit elements, and relevant input data types. This paper also underscores several promising future research directions and challenges in IMG. To augment reader accessibility, a dedicated IMG project page is available at \\url{https://github.com/xzb030/IMG_Survey}.",
    "authors": [
      "Na Lei",
      "Zezeng Li",
      "Zebin Xu",
      "Ying Li",
      "Xianfeng Gu"
    ],
    "categories": [
      "cs.AI",
      "cs.CG"
    ],
    "published": "2022-11-11T05:24:16Z",
    "pdf_url": "https://arxiv.org/pdf/2211.06009v3"
  },
  {
    "arxiv_id": "2211.06398v1",
    "entry_id": "http://arxiv.org/abs/2211.06398v1",
    "title": "Investigating Fairness Disparities in Peer Review: A Language Model Enhanced Approach",
    "summary": "Double-blind peer review mechanism has become the skeleton of academic research across multiple disciplines including computer science, yet several studies have questioned the quality of peer reviews and raised concerns on potential biases in the process. In this paper, we conduct a thorough and rigorous study on fairness disparities in peer review with the help of large language models (LMs). We collect, assemble, and maintain a comprehensive relational database for the International Conference on Learning Representations (ICLR) conference from 2017 to date by aggregating data from OpenReview, Google Scholar, arXiv, and CSRanking, and extracting high-level features using language models. We postulate and study fairness disparities on multiple protective attributes of interest, including author gender, geography, author, and institutional prestige. We observe that the level of disparity differs and textual features are essential in reducing biases in the predictive modeling. We distill several insights from our analysis on study the peer review process with the help of large LMs. Our database also provides avenues for studying new natural language processing (NLP) methods that facilitate the understanding of the peer review mechanism. We study a concrete example towards automatic machine review systems and provide baseline models for the review generation and scoring tasks such that the database can be used as a benchmark.",
    "authors": [
      "Jiayao Zhang",
      "Hongming Zhang",
      "Zhun Deng",
      "Dan Roth"
    ],
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-11-07T16:19:42Z",
    "pdf_url": "https://arxiv.org/pdf/2211.06398v1"
  },
  {
    "arxiv_id": "2211.03157v4",
    "entry_id": "http://arxiv.org/abs/2211.03157v4",
    "title": "Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control",
    "summary": "Artificial Intelligence (AI) is one of the most transformative technologies of the 21st century. The extent and scope of future AI capabilities remain a key uncertainty, with widespread disagreement on timelines and potential impacts. As nations and technology companies race toward greater complexity and autonomy in AI systems, there are concerns over the extent of integration and oversight of opaque AI decision processes. This is especially true in the subfield of machine learning (ML), where systems learn to optimize objectives without human assistance. Objectives can be imperfectly specified or executed in an unexpected or potentially harmful way. This becomes more concerning as systems increase in power and autonomy, where an abrupt capability jump could result in unexpected shifts in power dynamics or even catastrophic failures. This study presents a hierarchical complex systems framework to model AI risk and provide a template for alternative futures analysis. Survey data were collected from domain experts in the public and private sectors to classify AI impact and likelihood. The results show increased uncertainty over the powerful AI agent scenario, confidence in multiagent environments, and increased concern over AI alignment failures and influence-seeking behavior.",
    "authors": [
      "Kyle A. Kilian",
      "Christopher J. Ventura",
      "Mark M. Bailey"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2022-11-06T15:46:02Z",
    "pdf_url": "https://arxiv.org/pdf/2211.03157v4"
  },
  {
    "arxiv_id": "2211.03005v1",
    "entry_id": "http://arxiv.org/abs/2211.03005v1",
    "title": "Graph Reinforcement Learning Application to Co-operative Decision-Making in Mixed Autonomy Traffic: Framework, Survey, and Challenges",
    "summary": "Proper functioning of connected and automated vehicles (CAVs) is crucial for the safety and efficiency of future intelligent transport systems. Meanwhile, transitioning to fully autonomous driving requires a long period of mixed autonomy traffic, including both CAVs and human-driven vehicles. Thus, collaboration decision-making for CAVs is essential to generate appropriate driving behaviors to enhance the safety and efficiency of mixed autonomy traffic. In recent years, deep reinforcement learning (DRL) has been widely used in solving decision-making problems. However, the existing DRL-based methods have been mainly focused on solving the decision-making of a single CAV. Using the existing DRL-based methods in mixed autonomy traffic cannot accurately represent the mutual effects of vehicles and model dynamic traffic environments. To address these shortcomings, this article proposes a graph reinforcement learning (GRL) approach for multi-agent decision-making of CAVs in mixed autonomy traffic. First, a generic and modular GRL framework is designed. Then, a systematic review of DRL and GRL methods is presented, focusing on the problems addressed in recent research. Moreover, a comparative study on different GRL methods is further proposed based on the designed framework to verify the effectiveness of GRL methods. Results show that the GRL methods can well optimize the performance of multi-agent decision-making for CAVs in mixed autonomy traffic compared to the DRL methods. Finally, challenges and future research directions are summarized. This study can provide a valuable research reference for solving the multi-agent decision-making problems of CAVs in mixed autonomy traffic and can promote the implementation of GRL-based methods into intelligent transportation systems. The source code of our work can be found at https://github.com/Jacklinkk/Graph_CAVs.",
    "authors": [
      "Qi Liu",
      "Xueyuan Li",
      "Zirui Li",
      "Jingda Wu",
      "Guodong Du",
      "Xin Gao",
      "Fan Yang",
      "Shihua Yuan"
    ],
    "categories": [
      "cs.RO",
      "cs.MA"
    ],
    "published": "2022-11-06T01:50:13Z",
    "pdf_url": "https://arxiv.org/pdf/2211.03005v1"
  },
  {
    "arxiv_id": "2211.00385v3",
    "entry_id": "http://arxiv.org/abs/2211.00385v3",
    "title": "Behavioral Intention Prediction in Driving Scenes: A Survey",
    "summary": "In the driving scene, the road agents usually conduct frequent interactions and intention understanding of the surroundings. Ego-agent (each road agent itself) predicts what behavior will be engaged by other road users all the time and expects a shared and consistent understanding for safe movement. Behavioral Intention Prediction (BIP) simulates such a human consideration process and fulfills the early prediction of specific behaviors. Similar to other prediction tasks, such as trajectory prediction, data-driven deep learning methods have taken the primary pipeline in research. The rapid development of BIP inevitably leads to new issues and challenges. To catalyze future research, this work provides a comprehensive review of BIP from the available datasets, key factors and challenges, pedestrian-centric and vehicle-centric BIP approaches, and BIP-aware applications. Based on the investigation, data-driven deep learning approaches have become the primary pipelines. The behavioral intention types are still monotonous in most current datasets and methods (e.g., Crossing (C) and Not Crossing (NC) for pedestrians and Lane Changing (LC) for vehicles) in this field. In addition, for the safe-critical scenarios (e.g., near-crashing situations), current research is limited. Through this investigation, we identify open issues in behavioral intention prediction and suggest possible insights for future research.",
    "authors": [
      "Jianwu Fang",
      "Fan Wang",
      "Jianru Xue",
      "Tat-seng Chua"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2022-11-01T11:07:37Z",
    "pdf_url": "https://arxiv.org/pdf/2211.00385v3"
  },
  {
    "arxiv_id": "2211.00142v1",
    "entry_id": "http://arxiv.org/abs/2211.00142v1",
    "title": "TaTa: A Multilingual Table-to-Text Dataset for African Languages",
    "summary": "Existing data-to-text generation datasets are mostly limited to English. To address this lack of data, we create Table-to-Text in African languages (TaTa), the first large multilingual table-to-text dataset with a focus on African languages. We created TaTa by transcribing figures and accompanying text in bilingual reports by the Demographic and Health Surveys Program, followed by professional translation to make the dataset fully parallel. TaTa includes 8,700 examples in nine languages including four African languages (Hausa, Igbo, Swahili, and Yorùbá) and a zero-shot test language (Russian). We additionally release screenshots of the original figures for future research on multilingual multi-modal approaches. Through an in-depth human evaluation, we show that TaTa is challenging for current models and that less than half the outputs from an mT5-XXL-based model are understandable and attributable to the source data. We further demonstrate that existing metrics perform poorly for TaTa and introduce learned metrics that achieve a high correlation with human judgments. We release all data and annotations at https://github.com/google-research/url-nlp.",
    "authors": [
      "Sebastian Gehrmann",
      "Sebastian Ruder",
      "Vitaly Nikolaev",
      "Jan A. Botha",
      "Michael Chavinda",
      "Ankur Parikh",
      "Clara Rivera"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-10-31T21:05:42Z",
    "pdf_url": "https://arxiv.org/pdf/2211.00142v1"
  },
  {
    "arxiv_id": "2210.16877v1",
    "entry_id": "http://arxiv.org/abs/2210.16877v1",
    "title": "On Rate-Distortion Theory in Capacity-Limited Cognition & Reinforcement Learning",
    "summary": "Throughout the cognitive-science literature, there is widespread agreement that decision-making agents operating in the real world do so under limited information-processing capabilities and without access to unbounded cognitive or computational resources. Prior work has drawn inspiration from this fact and leveraged an information-theoretic model of such behaviors or policies as communication channels operating under a bounded rate constraint. Meanwhile, a parallel line of work also capitalizes on the same principles from rate-distortion theory to formalize capacity-limited decision making through the notion of a learning target, which facilitates Bayesian regret bounds for provably-efficient learning algorithms. In this paper, we aim to elucidate this latter perspective by presenting a brief survey of these information-theoretic models of capacity-limited decision making in biological and artificial agents.",
    "authors": [
      "Dilip Arumugam",
      "Mark K. Ho",
      "Noah D. Goodman",
      "Benjamin Van Roy"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-10-30T16:39:40Z",
    "pdf_url": "https://arxiv.org/pdf/2210.16877v1"
  },
  {
    "arxiv_id": "2210.16144v2",
    "entry_id": "http://arxiv.org/abs/2210.16144v2",
    "title": "Towards trustworthy multi-modal motion prediction: Holistic evaluation and interpretability of outputs",
    "summary": "Predicting the motion of other road agents enables autonomous vehicles to perform safe and efficient path planning. This task is very complex, as the behaviour of road agents depends on many factors and the number of possible future trajectories can be considerable (multi-modal). Most prior approaches proposed to address multi-modal motion prediction are based on complex machine learning systems that have limited interpretability. Moreover, the metrics used in current benchmarks do not evaluate all aspects of the problem, such as the diversity and admissibility of the output. In this work, we aim to advance towards the design of trustworthy motion prediction systems, based on some of the requirements for the design of Trustworthy Artificial Intelligence. We focus on evaluation criteria, robustness, and interpretability of outputs. First, we comprehensively analyse the evaluation metrics, identify the main gaps of current benchmarks, and propose a new holistic evaluation framework. We then introduce a method for the assessment of spatial and temporal robustness by simulating noise in the perception system. To enhance the interpretability of the outputs and generate more balanced results in the proposed evaluation framework, we propose an intent prediction layer that can be attached to multi-modal motion prediction models. The effectiveness of this approach is assessed through a survey that explores different elements in the visualization of the multi-modal trajectories and intentions. The proposed approach and findings make a significant contribution to the development of trustworthy motion prediction systems for autonomous vehicles, advancing the field towards greater safety and reliability.",
    "authors": [
      "Sandra Carrasco Limeros",
      "Sylwia Majchrowska",
      "Joakim Johnander",
      "Christoffer Petersson",
      "Miguel Ángel Sotelo",
      "David Fernández Llorca"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2022-10-28T14:14:22Z",
    "pdf_url": "https://arxiv.org/pdf/2210.16144v2"
  },
  {
    "arxiv_id": "2210.13944v2",
    "entry_id": "http://arxiv.org/abs/2210.13944v2",
    "title": "A Survey on Artificial Intelligence for Music Generation: Agents, Domains and Perspectives",
    "summary": "Music is one of the Gardner's intelligences in his theory of multiple intelligences. How humans perceive and understand music is still being studied and is crucial to develop artificial intelligence models that imitate such processes. Music generation with Artificial Intelligence is an emerging field that is gaining much attention in the recent years. In this paper, we describe how humans compose music and how new AI systems could imitate such process by comparing past and recent advances in the field with music composition techniques. To understand how AI models and algorithms generate music and the potential applications that might appear in the future, we explore, analyze and describe the agents that take part of the music generation process: the datasets, models, interfaces, the users and the generated music. We mention possible applications that might benefit from this field and we also propose new trends and future research directions that could be explored in the future.",
    "authors": [
      "Carlos Hernandez-Olivan",
      "Javier Hernandez-Olivan",
      "Jose R. Beltran"
    ],
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "published": "2022-10-25T11:54:30Z",
    "pdf_url": "https://arxiv.org/pdf/2210.13944v2"
  },
  {
    "arxiv_id": "2210.13767v2",
    "entry_id": "http://arxiv.org/abs/2210.13767v2",
    "title": "Networked Signal and Information Processing",
    "summary": "The article reviews significant advances in networked signal and information processing, which have enabled in the last 25 years extending decision making and inference, optimization, control, and learning to the increasingly ubiquitous environments of distributed agents. As these interacting agents cooperate, new collective behaviors emerge from local decisions and actions. Moreover, and significantly, theory and applications show that networked agents, through cooperation and sharing, are able to match the performance of cloud or federated solutions, while offering the potential for improved privacy, increasing resilience, and saving resources.",
    "authors": [
      "Stefan Vlaski",
      "Soummya Kar",
      "Ali H. Sayed",
      "José M. F. Moura"
    ],
    "categories": [
      "eess.SP",
      "cs.DC",
      "cs.LG",
      "cs.MA",
      "math.OC"
    ],
    "published": "2022-10-25T04:57:34Z",
    "pdf_url": "https://arxiv.org/pdf/2210.13767v2"
  },
  {
    "arxiv_id": "2210.13075v1",
    "entry_id": "http://arxiv.org/abs/2210.13075v1",
    "title": "Hardness in Markov Decision Processes: Theory and Practice",
    "summary": "Meticulously analysing the empirical strengths and weaknesses of reinforcement learning methods in hard (challenging) environments is essential to inspire innovations and assess progress in the field. In tabular reinforcement learning, there is no well-established standard selection of environments to conduct such analysis, which is partially due to the lack of a widespread understanding of the rich theory of hardness of environments. The goal of this paper is to unlock the practical usefulness of this theory through four main contributions. First, we present a systematic survey of the theory of hardness, which also identifies promising research directions. Second, we introduce Colosseum, a pioneering package that enables empirical hardness analysis and implements a principled benchmark composed of environments that are diverse with respect to different measures of hardness. Third, we present an empirical analysis that provides new insights into computable measures. Finally, we benchmark five tabular agents in our newly proposed benchmark. While advancing the theoretical understanding of hardness in non-tabular reinforcement learning remains essential, our contributions in the tabular setting are intended as solid steps towards a principled non-tabular benchmark. Accordingly, we benchmark four agents in non-tabular versions of Colosseum environments, obtaining results that demonstrate the generality of tabular hardness measures.",
    "authors": [
      "Michelangelo Conserva",
      "Paulo Rauber"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-10-24T09:51:31Z",
    "pdf_url": "https://arxiv.org/pdf/2210.13075v1"
  },
  {
    "arxiv_id": "2210.09467v1",
    "entry_id": "http://arxiv.org/abs/2210.09467v1",
    "title": "Adversarial and Safely Scaled Question Generation",
    "summary": "Question generation has recently gained a lot of research interest, especially with the advent of large language models. In and of itself, question generation can be considered 'AI-hard', as there is a lack of unanimously agreed sense of what makes a question 'good' or 'bad'. In this paper, we tackle two fundamental problems in parallel: on one hand, we try to solve the scaling problem, where question-generation and answering applications have to be applied to a massive amount of text without ground truth labeling. The usual approach to solve this problem is to either downsample or summarize. However, there are critical risks of misinformation with these approaches. On the other hand, and related to the misinformation problem, we try to solve the 'safety' problem, as many public institutions rely on a much higher level of accuracy for the content they provide. We introduce an adversarial approach to tackle the question generation safety problem with scale. Specifically, we designed a question-answering system that specifically prunes out unanswerable questions that may be generated, and further increases the quality of the answers that are generated. We build a production-ready, easily-plugged pipeline that can be used on any given body of text, that is scalable and immune from generating any hate speech, profanity, or misinformation. Based on the results, we are able to generate more than six times the number of quality questions generated by the abstractive approach, with a perceived quality being 44% higher, according to a survey of 168 participants.",
    "authors": [
      "Sreehari Sankar",
      "Zhihang Dong"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2022-10-17T22:51:45Z",
    "pdf_url": "https://arxiv.org/pdf/2210.09467v1"
  },
  {
    "arxiv_id": "2210.08050v1",
    "entry_id": "http://arxiv.org/abs/2210.08050v1",
    "title": "Multi-trainer Interactive Reinforcement Learning System",
    "summary": "Interactive reinforcement learning can effectively facilitate the agent training via human feedback. However, such methods often require the human teacher to know what is the correct action that the agent should take. In other words, if the human teacher is not always reliable, then it will not be consistently able to guide the agent through its training. In this paper, we propose a more effective interactive reinforcement learning system by introducing multiple trainers, namely Multi-Trainer Interactive Reinforcement Learning (MTIRL), which could aggregate the binary feedback from multiple non-perfect trainers into a more reliable reward for an agent training in a reward-sparse environment. In particular, our trainer feedback aggregation experiments show that our aggregation method has the best accuracy when compared with the majority voting, the weighted voting, and the Bayesian method. Finally, we conduct a grid-world experiment to show that the policy trained by the MTIRL with the review model is closer to the optimal policy than that without a review model.",
    "authors": [
      "Zhaori Guo",
      "Timothy J. Norman",
      "Enrico H. Gerding"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-10-14T18:32:59Z",
    "pdf_url": "https://arxiv.org/pdf/2210.08050v1"
  },
  {
    "arxiv_id": "2210.13966v3",
    "entry_id": "http://arxiv.org/abs/2210.13966v3",
    "title": "The Debate Over Understanding in AI's Large Language Models",
    "summary": "We survey a current, heated debate in the AI research community on whether large pre-trained language models can be said to \"understand\" language -- and the physical and social situations language encodes -- in any important sense. We describe arguments that have been made for and against such understanding, and key questions for the broader sciences of intelligence that have arisen in light of these arguments. We contend that a new science of intelligence can be developed that will provide insight into distinct modes of understanding, their strengths and limitations, and the challenge of integrating diverse forms of cognition.",
    "authors": [
      "Melanie Mitchell",
      "David C. Krakauer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-10-14T17:04:29Z",
    "pdf_url": "https://arxiv.org/pdf/2210.13966v3"
  },
  {
    "arxiv_id": "2211.13115v1",
    "entry_id": "http://arxiv.org/abs/2211.13115v1",
    "title": "A situated agent-based model to reveal irrigators' options behind their actions under institutional arrangements in Southern France",
    "summary": "There has been little exploration of the explicit simulation of the set of options of actors in agent-based models and its evolution over time. This study proposes to use affordances as intermediate entities between agents' environment and agent actions. We illustrated the approach on a typical gravity-fed network in the South-East of France to explore how the abandonment of traditional sharing of water changes the irrigators' options to irrigate. We simulated a typical dry year irrigation season under two institutional arrangements (i.e. traditional coordination through daily slots and its abandonment). Simulation results are consistent with field surveys, and reveal an increase in the number of internal conflicts among irrigators as the counterpart of the abandonment of traditional sharing of water. They also highlight the consequences of the heterogeneity of the irrigators' interests within the collective institution. The sensitivity analysis of the model allowed identification of optimal modalities of coordination, and a potential compromise between past and current institutional arrangements. The key benefits of using affordances in ABM lie in the study of their population dynamics for characterizing the interaction situations between actors and their environment and for better understanding the model dynamics.",
    "authors": [
      "Bastien Richard",
      "Bruno Bonté",
      "Olivier Barreteau",
      "Isabelle Braud"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.MA"
    ],
    "published": "2022-10-14T08:59:54Z",
    "pdf_url": "https://arxiv.org/pdf/2211.13115v1"
  },
  {
    "arxiv_id": "2210.04988v1",
    "entry_id": "http://arxiv.org/abs/2210.04988v1",
    "title": "Simulating Coverage Path Planning with Roomba",
    "summary": "Coverage Path Planning involves visiting every unoccupied state in an environment with obstacles. In this paper, we explore this problem in environments which are initially unknown to the agent, for purposes of simulating the task of a vacuum cleaning robot. A survey of prior work reveals sparse effort in applying learning to solve this problem. In this paper, we explore modeling a Cover Path Planning problem using Deep Reinforcement Learning, and compare it with the performance of the built-in algorithm of the Roomba, a popular vacuum cleaning robot.",
    "authors": [
      "Robert Chuchro"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2022-10-10T19:50:44Z",
    "pdf_url": "https://arxiv.org/pdf/2210.04988v1"
  },
  {
    "arxiv_id": "2210.04520v1",
    "entry_id": "http://arxiv.org/abs/2210.04520v1",
    "title": "Continual task learning in natural and artificial agents",
    "summary": "How do humans and other animals learn new tasks? A wave of brain recording studies has investigated how neural representations change during task learning, with a focus on how tasks can be acquired and coded in ways that minimise mutual interference. We review recent work that has explored the geometry and dimensionality of neural task representations in neocortex, and computational models that have exploited these findings to understand how the brain may partition knowledge between tasks. We discuss how ideas from machine learning, including those that combine supervised and unsupervised learning, are helping neuroscientists understand how natural tasks are learned and coded in biological brains.",
    "authors": [
      "Timo Flesch",
      "Andrew Saxe",
      "Christopher Summerfield"
    ],
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "published": "2022-10-10T09:36:08Z",
    "pdf_url": "https://arxiv.org/pdf/2210.04520v1"
  },
  {
    "arxiv_id": "2210.03649v1",
    "entry_id": "http://arxiv.org/abs/2210.03649v1",
    "title": "How to Enable Uncertainty Estimation in Proximal Policy Optimization",
    "summary": "While deep reinforcement learning (RL) agents have showcased strong results across many domains, a major concern is their inherent opaqueness and the safety of such systems in real-world use cases. To overcome these issues, we need agents that can quantify their uncertainty and detect out-of-distribution (OOD) states. Existing uncertainty estimation techniques, like Monte-Carlo Dropout or Deep Ensembles, have not seen widespread adoption in on-policy deep RL. We posit that this is due to two reasons: concepts like uncertainty and OOD states are not well defined compared to supervised learning, especially for on-policy RL methods. Secondly, available implementations and comparative studies for uncertainty estimation methods in RL have been limited. To overcome the first gap, we propose definitions of uncertainty and OOD for Actor-Critic RL algorithms, namely, proximal policy optimization (PPO), and present possible applicable measures. In particular, we discuss the concepts of value and policy uncertainty. The second point is addressed by implementing different uncertainty estimation methods and comparing them across a number of environments. The OOD detection performance is evaluated via a custom evaluation benchmark of in-distribution (ID) and OOD states for various RL environments. We identify a trade-off between reward and OOD detection performance. To overcome this, we formulate a Pareto optimization problem in which we simultaneously optimize for reward and OOD detection performance. We show experimentally that the recently proposed method of Masksembles strikes a favourable balance among the survey methods, enabling high-quality uncertainty estimation and OOD detection while matching the performance of original RL agents.",
    "authors": [
      "Eugene Bykovets",
      "Yannick Metz",
      "Mennatallah El-Assady",
      "Daniel A. Keim",
      "Joachim M. Buhmann"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "published": "2022-10-07T15:56:59Z",
    "pdf_url": "https://arxiv.org/pdf/2210.03649v1"
  },
  {
    "arxiv_id": "2210.03259v1",
    "entry_id": "http://arxiv.org/abs/2210.03259v1",
    "title": "Considerations for Task Allocation in Human-Robot Teams",
    "summary": "In human-robot teams where agents collaborate together, there needs to be a clear allocation of tasks to agents. Task allocation can aid in achieving the presumed benefits of human-robot teams, such as improved team performance. Many task allocation methods have been proposed that include factors such as agent capability, availability, workload, fatigue, and task and domain-specific parameters. In this paper, selected work on task allocation is reviewed. In addition, some areas for continued and further consideration in task allocation are discussed. These areas include level of collaboration, novel tasks, unknown and dynamic agent capabilities, negotiation and fairness, and ethics. Where applicable, we also mention some of our work on task allocation. Through continued efforts and considerations in task allocation, human-robot teaming can be improved.",
    "authors": [
      "Arsha Ali",
      "Dawn M. Tilbury",
      "Lionel P. Robert"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2022-10-06T23:57:23Z",
    "pdf_url": "https://arxiv.org/pdf/2210.03259v1"
  },
  {
    "arxiv_id": "2210.02769v1",
    "entry_id": "http://arxiv.org/abs/2210.02769v1",
    "title": "Artificial virtuous agents in a multiagent tragedy of the commons",
    "summary": "Although virtue ethics has repeatedly been proposed as a suitable framework for the development of artificial moral agents (AMAs), it has been proven difficult to approach from a computational perspective. In this work, we present the first technical implementation of artificial virtuous agents (AVAs) in moral simulations. First, we review previous conceptual and technical work in artificial virtue ethics and describe a functionalistic path to AVAs based on dispositional virtues, bottom-up learning, and top-down eudaimonic reward. We then provide the details of a technical implementation in a moral simulation based on a tragedy of the commons scenario. The experimental results show how the AVAs learn to tackle cooperation problems while exhibiting core features of their theoretical counterpart, including moral character, dispositional virtues, learning from experience, and the pursuit of eudaimonia. Ultimately, we argue that virtue ethics provides a compelling path toward morally excellent machines and that our work provides an important starting point for such endeavors.",
    "authors": [
      "Jakob Stenseke"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-10-06T09:12:41Z",
    "pdf_url": "https://arxiv.org/pdf/2210.02769v1"
  },
  {
    "arxiv_id": "2209.15259v2",
    "entry_id": "http://arxiv.org/abs/2209.15259v2",
    "title": "On the Impossible Safety of Large AI Models",
    "summary": "Large AI Models (LAIMs), of which large language models are the most prominent recent example, showcase some impressive performance. However they have been empirically found to pose serious security issues. This paper systematizes our knowledge about the fundamental impossibility of building arbitrarily accurate and secure machine learning models. More precisely, we identify key challenging features of many of today's machine learning settings. Namely, high accuracy seems to require memorizing large training datasets, which are often user-generated and highly heterogeneous, with both sensitive information and fake users. We then survey statistical lower bounds that, we argue, constitute a compelling case against the possibility of designing high-accuracy LAIMs with strong security guarantees.",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Lê-Nguyên Hoang",
      "Rafael Pinot",
      "Sébastien Rouault",
      "John Stephan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2022-09-30T06:36:49Z",
    "pdf_url": "https://arxiv.org/pdf/2209.15259v2"
  },
  {
    "arxiv_id": "2209.15166v1",
    "entry_id": "http://arxiv.org/abs/2209.15166v1",
    "title": "Reward Shaping for User Satisfaction in a REINFORCE Recommender",
    "summary": "How might we design Reinforcement Learning (RL)-based recommenders that encourage aligning user trajectories with the underlying user satisfaction? Three research questions are key: (1) measuring user satisfaction, (2) combatting sparsity of satisfaction signals, and (3) adapting the training of the recommender agent to maximize satisfaction. For measurement, it has been found that surveys explicitly asking users to rate their experience with consumed items can provide valuable orthogonal information to the engagement/interaction data, acting as a proxy to the underlying user satisfaction. For sparsity, i.e, only being able to observe how satisfied users are with a tiny fraction of user-item interactions, imputation models can be useful in predicting satisfaction level for all items users have consumed. For learning satisfying recommender policies, we postulate that reward shaping in RL recommender agents is powerful for driving satisfying user experiences. Putting everything together, we propose to jointly learn a policy network and a satisfaction imputation network: The role of the imputation network is to learn which actions are satisfying to the user; while the policy network, built on top of REINFORCE, decides which items to recommend, with the reward utilizing the imputed satisfaction. We use both offline analysis and live experiments in an industrial large-scale recommendation platform to demonstrate the promise of our approach for satisfying user experiences.",
    "authors": [
      "Konstantina Christakopoulou",
      "Can Xu",
      "Sai Zhang",
      "Sriraj Badam",
      "Trevor Potter",
      "Daniel Li",
      "Hao Wan",
      "Xinyang Yi",
      "Ya Le",
      "Chris Berg",
      "Eric Bencomo Dixon",
      "Ed H. Chi",
      "Minmin Chen"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-09-30T01:29:12Z",
    "pdf_url": "https://arxiv.org/pdf/2209.15166v1"
  },
  {
    "arxiv_id": "2209.07065v1",
    "entry_id": "http://arxiv.org/abs/2209.07065v1",
    "title": "CommunityLM: Probing Partisan Worldviews from Language Models",
    "summary": "As political attitudes have diverged ideologically in the United States, political speech has diverged lingusitically. The ever-widening polarization between the US political parties is accelerated by an erosion of mutual understanding between them. We aim to make these communities more comprehensible to each other with a framework that probes community-specific responses to the same survey questions using community language models CommunityLM. In our framework we identify committed partisan members for each community on Twitter and fine-tune LMs on the tweets authored by them. We then assess the worldviews of the two groups using prompt-based probing of their corresponding LMs, with prompts that elicit opinions about public figures and groups surveyed by the American National Election Studies (ANES) 2020 Exploratory Testing Survey. We compare the responses generated by the LMs to the ANES survey results, and find a level of alignment that greatly exceeds several baseline methods. Our work aims to show that we can use community LMs to query the worldview of any group of people given a sufficiently large sample of their social media discussions or media diet.",
    "authors": [
      "Hang Jiang",
      "Doug Beeferman",
      "Brandon Roy",
      "Deb Roy"
    ],
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-09-15T05:52:29Z",
    "pdf_url": "https://arxiv.org/pdf/2209.07065v1"
  },
  {
    "arxiv_id": "2209.06899v1",
    "entry_id": "http://arxiv.org/abs/2209.06899v1",
    "title": "Out of One, Many: Using Language Models to Simulate Human Samples",
    "summary": "We propose and explore the possibility that language models can be studied as effective proxies for specific human sub-populations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the \"algorithmic bias\" within one such tool -- the GPT-3 language model -- is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property \"algorithmic fidelity\" and explore its extent in GPT-3. We create \"silicon samples\" by conditioning the model on thousands of socio-demographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and socio-cultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.",
    "authors": [
      "Lisa P. Argyle",
      "Ethan C. Busby",
      "Nancy Fulda",
      "Joshua Gubler",
      "Christopher Rytting",
      "David Wingate"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2022-09-14T19:53:32Z",
    "pdf_url": "https://arxiv.org/pdf/2209.06899v1"
  },
  {
    "arxiv_id": "2209.05948v3",
    "entry_id": "http://arxiv.org/abs/2209.05948v3",
    "title": "Don't Complete It! Preventing Unhelpful Code Completion for Productive and Sustainable Neural Code Completion Systems",
    "summary": "Currently, large pre-trained language models are widely applied in neural code completion systems. Though large code models significantly outperform their smaller counterparts, around 70\\% of displayed code completions from Github Copilot are not accepted by developers. Being reviewed but not accepted, their help to developer productivity is considerably limited and may conversely aggravate the workload of developers, as the code completions are automatically and actively generated in state-of-the-art code completion systems as developers type out once the service is enabled. Even worse, considering the high cost of the large code models, it is a huge waste of computing resources and energy, which severely goes against the sustainable development principle of AI technologies. However, such waste has never been realized, not to mention effectively addressed, in the research community for neural code completion. Hence, preventing such unhelpful code completions from happening in a cost-friendly way is of urgent need. To fill this significant gap, we first investigate the prompts of unhelpful code completions, called \"low-return prompts\". We empirically identify four observable patterns in low-return prompts, each lacking necessary information, making it difficult to address through enhancements to the model's accuracy alone. This demonstrates the feasibility of identifying such low-return prompts based on the prompts themselves. Motivated by this finding, we propose an early-rejection mechanism to turn down low-return prompts by foretelling the code completion qualities. The prompts that are estimated to receive unhelpful code completions will not be sent to the model. Furthermore, we investigated five types of estimators to demonstrate the feasibility of the mechanism. The experimental results show that the estimator can reject 20% of code completion requests with a 97.4% Precision.",
    "authors": [
      "Zhensu Sun",
      "Xiaoning Du",
      "Fu Song",
      "Shangwen Wang",
      "Mingze Ni",
      "Li Li",
      "David Lo"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2022-09-13T12:43:41Z",
    "pdf_url": "https://arxiv.org/pdf/2209.05948v3"
  },
  {
    "arxiv_id": "2209.03859v1",
    "entry_id": "http://arxiv.org/abs/2209.03859v1",
    "title": "A Survey on Large-Population Systems and Scalable Multi-Agent Reinforcement Learning",
    "summary": "The analysis and control of large-population systems is of great interest to diverse areas of research and engineering, ranging from epidemiology over robotic swarms to economics and finance. An increasingly popular and effective approach to realizing sequential decision-making in multi-agent systems is through multi-agent reinforcement learning, as it allows for an automatic and model-free analysis of highly complex systems. However, the key issue of scalability complicates the design of control and reinforcement learning algorithms particularly in systems with large populations of agents. While reinforcement learning has found resounding empirical success in many scenarios with few agents, problems with many agents quickly become intractable and necessitate special consideration. In this survey, we will shed light on current approaches to tractably understanding and analyzing large-population systems, both through multi-agent reinforcement learning and through adjacent areas of research such as mean-field games, collective intelligence, or complex network theory. These classically independent subject areas offer a variety of approaches to understanding or modeling large-population systems, which may be of great use for the formulation of tractable MARL algorithms in the future. Finally, we survey potential areas of application for large-scale control and identify fruitful future applications of learning algorithms in practical systems. We hope that our survey could provide insight and future directions to junior and senior researchers in theoretical and applied sciences alike.",
    "authors": [
      "Kai Cui",
      "Anam Tahir",
      "Gizem Ekinci",
      "Ahmed Elshamanhory",
      "Yannick Eich",
      "Mengguang Li",
      "Heinz Koeppl"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-09-08T14:58:50Z",
    "pdf_url": "https://arxiv.org/pdf/2209.03859v1"
  },
  {
    "arxiv_id": "2209.02552v3",
    "entry_id": "http://arxiv.org/abs/2209.02552v3",
    "title": "From Black Boxes to Conversations: Incorporating XAI in a Conversational Agent",
    "summary": "The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank, which we extend by quality-controlled paraphrases, to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation methods may support other researchers in providing the necessary information to address users' demands. To facilitate future work, we release our source code and data.",
    "authors": [
      "Van Bach Nguyen",
      "Jörg Schlötterer",
      "Christin Seifert"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-09-06T15:01:06Z",
    "pdf_url": "https://arxiv.org/pdf/2209.02552v3"
  },
  {
    "arxiv_id": "2209.01667v1",
    "entry_id": "http://arxiv.org/abs/2209.01667v1",
    "title": "A Review of Sparse Expert Models in Deep Learning",
    "summary": "Sparse expert models are a thirty-year old concept re-emerging as a popular architecture in deep learning. This class of architecture encompasses Mixture-of-Experts, Switch Transformers, Routing Networks, BASE layers, and others, all with the unifying idea that each example is acted on by a subset of the parameters. By doing so, the degree of sparsity decouples the parameter count from the compute per example allowing for extremely large, but efficient models. The resulting models have demonstrated significant improvements across diverse domains such as natural language processing, computer vision, and speech recognition. We review the concept of sparse expert models, provide a basic description of the common algorithms, contextualize the advances in the deep learning era, and conclude by highlighting areas for future work.",
    "authors": [
      "William Fedus",
      "Jeff Dean",
      "Barret Zoph"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2022-09-04T18:00:29Z",
    "pdf_url": "https://arxiv.org/pdf/2209.01667v1"
  },
  {
    "arxiv_id": "2208.14426v1",
    "entry_id": "http://arxiv.org/abs/2208.14426v1",
    "title": "Correct-by-Construction Runtime Enforcement in AI -- A Survey",
    "summary": "Runtime enforcement refers to the theories, techniques, and tools for enforcing correct behavior with respect to a formal specification of systems at runtime. In this paper, we are interested in techniques for constructing runtime enforcers for the concrete application domain of enforcing safety in AI. We discuss how safety is traditionally handled in the field of AI and how more formal guarantees on the safety of a self-learning agent can be given by integrating a runtime enforcer. We survey a selection of work on such enforcers, where we distinguish between approaches for discrete and continuous action spaces. The purpose of this paper is to foster a better understanding of advantages and limitations of different enforcement techniques, focusing on the specific challenges that arise due to their application in AI. Finally, we present some open challenges and avenues for future work.",
    "authors": [
      "Bettina Könighofer",
      "Roderick Bloem",
      "Rüdiger Ehlers",
      "Christian Pek"
    ],
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "published": "2022-08-30T17:45:38Z",
    "pdf_url": "https://arxiv.org/pdf/2208.14426v1"
  },
  {
    "arxiv_id": "2208.12328v1",
    "entry_id": "http://arxiv.org/abs/2208.12328v1",
    "title": "Autonomous Unmanned Aerial Vehicle Navigation using Reinforcement Learning: A Systematic Review",
    "summary": "There is an increasing demand for using Unmanned Aerial Vehicle (UAV), known as drones, in different applications such as packages delivery, traffic monitoring, search and rescue operations, and military combat engagements. In all of these applications, the UAV is used to navigate the environment autonomously - without human interaction, perform specific tasks and avoid obstacles. Autonomous UAV navigation is commonly accomplished using Reinforcement Learning (RL), where agents act as experts in a domain to navigate the environment while avoiding obstacles. Understanding the navigation environment and algorithmic limitations plays an essential role in choosing the appropriate RL algorithm to solve the navigation problem effectively. Consequently, this study first identifies the main UAV navigation tasks and discusses navigation frameworks and simulation software. Next, RL algorithms are classified and discussed based on the environment, algorithm characteristics, abilities, and applications in different UAV navigation problems, which will help the practitioners and researchers select the appropriate RL algorithms for their UAV navigation use cases. Moreover, identified gaps and opportunities will drive UAV navigation research.",
    "authors": [
      "Fadi AlMahamid",
      "Katarina Grolinger"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2022-08-25T20:04:11Z",
    "pdf_url": "https://arxiv.org/pdf/2208.12328v1"
  },
  {
    "arxiv_id": "2208.11981v2",
    "entry_id": "http://arxiv.org/abs/2208.11981v2",
    "title": "On Reality and the Limits of Language Data: Aligning LLMs with Human Norms",
    "summary": "Recent advancements in Large Language Models (LLMs) harness linguistic associations in vast natural language data for practical applications. However, their ability to understand the physical world using only language data remains a question. After reviewing existing protocols, we explore this question using a novel and tightly controlled reasoning test (ART) and compare human norms against versions of GPT-3. Our findings highlight the categories of common-sense relations models that could learn directly from data and areas of weakness. GPT-3 offers evidence for verbal reasoning on a par with human subjects for several relations including Synonymy, Antonymy, and Default inheritance, Without reinforcement learning from human judgements, it appears GPT-3 performs at the lower end of the reference interval for Has-part and Contained-in. Weaknesses were observed also in affordance characteristics through Necessary-quality, Order-of-size and Order-of-intensity. Combining LLMs with symbolic world grounding is a promising direction to address associative learning.",
    "authors": [
      "Nigel H. Collier",
      "Fangyu Liu",
      "Ehsan Shareghi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-08-25T10:21:23Z",
    "pdf_url": "https://arxiv.org/pdf/2208.11981v2"
  },
  {
    "arxiv_id": "2208.11857v2",
    "entry_id": "http://arxiv.org/abs/2208.11857v2",
    "title": "Shortcut Learning of Large Language Models in Natural Language Understanding",
    "summary": "Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly affected their generalizability and adversarial robustness. In this paper, we provide a review of recent developments that address the shortcut learning and robustness challenge of LLMs. We first introduce the concepts of shortcut learning of language models. We then introduce methods to identify shortcut learning behavior in language models, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we discuss key research challenges and potential research directions in order to advance the field of LLMs.",
    "authors": [
      "Mengnan Du",
      "Fengxiang He",
      "Na Zou",
      "Dacheng Tao",
      "Xia Hu"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-08-25T03:51:39Z",
    "pdf_url": "https://arxiv.org/pdf/2208.11857v2"
  },
  {
    "arxiv_id": "2208.09052v1",
    "entry_id": "http://arxiv.org/abs/2208.09052v1",
    "title": "A Review of Uncertainty for Deep Reinforcement Learning",
    "summary": "Uncertainty is ubiquitous in games, both in the agents playing games and often in the games themselves. Working with uncertainty is therefore an important component of successful deep reinforcement learning agents. While there has been substantial effort and progress in understanding and working with uncertainty for supervised learning, the body of literature for uncertainty aware deep reinforcement learning is less developed. While many of the same problems regarding uncertainty in neural networks for supervised learning remain for reinforcement learning, there are additional sources of uncertainty due to the nature of an interactable environment. In this work, we provide an overview motivating and presenting existing techniques in uncertainty aware deep reinforcement learning. These works show empirical benefits on a variety of reinforcement learning tasks. This work serves to help to centralize the disparate results and promote future research in this area.",
    "authors": [
      "Owen Lockwood",
      "Mei Si"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-08-18T20:42:19Z",
    "pdf_url": "https://arxiv.org/pdf/2208.09052v1"
  },
  {
    "arxiv_id": "2208.08731v1",
    "entry_id": "http://arxiv.org/abs/2208.08731v1",
    "title": "Intelligent problem-solving as integrated hierarchical reinforcement learning",
    "summary": "According to cognitive psychology and related disciplines, the development of complex problem-solving behaviour in biological agents depends on hierarchical cognitive mechanisms. Hierarchical reinforcement learning is a promising computational approach that may eventually yield comparable problem-solving behaviour in artificial agents and robots. However, to date the problem-solving abilities of many human and non-human animals are clearly superior to those of artificial systems. Here, we propose steps to integrate biologically inspired hierarchical mechanisms to enable advanced problem-solving skills in artificial agents. Therefore, we first review the literature in cognitive psychology to highlight the importance of compositional abstraction and predictive processing. Then we relate the gained insights with contemporary hierarchical reinforcement learning methods. Interestingly, our results suggest that all identified cognitive mechanisms have been implemented individually in isolated computational architectures, raising the question of why there exists no single unifying architecture that integrates them. As our final contribution, we address this question by providing an integrative perspective on the computational challenges to develop such a unifying architecture. We expect our results to guide the development of more sophisticated cognitively inspired hierarchical machine learning architectures.",
    "authors": [
      "Manfred Eppe",
      "Christian Gumbsch",
      "Matthias Kerzel",
      "Phuong D. H. Nguyen",
      "Martin V. Butz",
      "Stefan Wermter"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2022-08-18T09:28:03Z",
    "pdf_url": "https://arxiv.org/pdf/2208.08731v1"
  },
  {
    "arxiv_id": "2208.08035v2",
    "entry_id": "http://arxiv.org/abs/2208.08035v2",
    "title": "EGCR: Explanation Generation for Conversational Recommendation",
    "summary": "Growing attention has been paid in Conversational Recommendation System (CRS), which works as a conversation-based and recommendation task-oriented tool to provide items of interest and explore user preference. However, existing work in CRS fails to explicitly show the reasoning logic to users and the whole CRS still remains a black box. Therefore we propose a novel end-to-end framework named Explanation Generation for Conversational Recommendation (EGCR) based on generating explanations for conversational agents to explain why they make the action. EGCR incorporates user reviews to enhance the item representation and increase the informativeness of the whole conversation. To the best of our knowledge, this is the first framework for explainable conversational recommendation on real-world datasets. Moreover, we evaluate EGCR on one benchmark conversational recommendation datasets and achieve better performance on both recommendation accuracy and conversation quality than other state-of-the art models. Finally, extensive experiments demonstrate that generated explanations are not only having high quality and explainability, but also making CRS more trustworthy. We will make our code available to contribute to the CRS community",
    "authors": [
      "Bingbing Wen",
      "Xiaoning Bu",
      "Chirag Shah"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-08-17T02:30:41Z",
    "pdf_url": "https://arxiv.org/pdf/2208.08035v2"
  },
  {
    "arxiv_id": "2208.07811v2",
    "entry_id": "http://arxiv.org/abs/2208.07811v2",
    "title": "Towards Informed Design and Validation Assistance in Computer Games Using Imitation Learning",
    "summary": "In games, as in and many other domains, design validation and testing is a huge challenge as systems are growing in size and manual testing is becoming infeasible. This paper proposes a new approach to automated game validation and testing. Our method leverages a data-driven imitation learning technique, which requires little effort and time and no knowledge of machine learning or programming, that designers can use to efficiently train game testing agents. We investigate the validity of our approach through a user study with industry experts. The survey results show that our method is indeed a valid approach to game validation and that data-driven programming would be a useful aid to reducing effort and increasing quality of modern playtesting. The survey also highlights several open challenges. With the help of the most recent literature, we analyze the identified challenges and propose future research directions suitable for supporting and maximizing the utility of our approach.",
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Konrad Tollmar",
      "Andrew D. Bagdanov",
      "Linus Gisslén"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-08-15T11:08:44Z",
    "pdf_url": "https://arxiv.org/pdf/2208.07811v2"
  },
  {
    "arxiv_id": "2208.05446v2",
    "entry_id": "http://arxiv.org/abs/2208.05446v2",
    "title": "CoditT5: Pretraining for Source Code and Natural Language Editing",
    "summary": "Pretrained language models have been shown to be effective in many software-related generation tasks; however, they are not well-suited for editing tasks as they are not designed to reason about edits. To address this, we propose a novel pretraining objective which explicitly models edits and use it to build CoditT5, a large language model for software-related editing tasks that is pretrained on large amounts of source code and natural language comments. We fine-tune it on various downstream editing tasks, including comment updating, bug fixing, and automated code review. By outperforming standard generation-based models, we demonstrate the generalizability of our approach and its suitability for editing tasks. We also show how a standard generation model and our edit-based model can complement one another through simple reranking strategies, with which we achieve state-of-the-art performance for the three downstream editing tasks.",
    "authors": [
      "Jiyang Zhang",
      "Sheena Panthaplackel",
      "Pengyu Nie",
      "Junyi Jessy Li",
      "Milos Gligoric"
    ],
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "published": "2022-08-10T16:59:40Z",
    "pdf_url": "https://arxiv.org/pdf/2208.05446v2"
  },
  {
    "arxiv_id": "2208.00636v2",
    "entry_id": "http://arxiv.org/abs/2208.00636v2",
    "title": "Interacting with next-phrase suggestions: How suggestion systems aid and influence the cognitive processes of writing",
    "summary": "Writing with next-phrase suggestions powered by large language models is becoming more pervasive by the day. However, research to understand writers' interaction and decision-making processes while engaging with such systems is still emerging. We conducted a qualitative study to shed light on writers' cognitive processes while writing with next-phrase suggestion systems. To do so, we recruited 14 amateur writers to write two reviews each, one without suggestions and one with suggestions. Additionally, we also positively and negatively biased the suggestion system to get a diverse range of instances where writers' opinions and the bias in the language model align or misalign to varying degrees. We found that writers interact with next-phrase suggestions in various complex ways: Writers abstracted and extracted multiple parts of the suggestions and incorporated them within their writing, even when they disagreed with the suggestion as a whole; along with evaluating the suggestions on various criteria. The suggestion system also had various effects on the writing process, such as altering the writer's usual writing plans, leading to higher levels of distraction etc. Based on our qualitative analysis using the cognitive process model of writing by Hayes as a lens, we propose a theoretical model of 'writer-suggestion interaction' for writing with GPT-2 (and causal language models in general) for a movie review writing task, followed by directions for future research and design.",
    "authors": [
      "Advait Bhat",
      "Saaket Agashe",
      "Niharika Mohile",
      "Parth Oberoi",
      "Ravi Jangir",
      "Anirudha Joshi"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2022-08-01T06:49:07Z",
    "pdf_url": "https://arxiv.org/pdf/2208.00636v2"
  },
  {
    "arxiv_id": "2208.00391v1",
    "entry_id": "http://arxiv.org/abs/2208.00391v1",
    "title": "An Experimental Study on Learning Correlated Equilibrium in Routing Games",
    "summary": "We study route choice in a repeated routing game where an uncertain state of nature determines link latency functions, and agents receive private route recommendation. The state is sampled in an i.i.d. manner in every round from a publicly known distribution, and the recommendations are generated by a randomization policy whose mapping from the state is known publicly. In a one-shot setting, the agents are said to obey recommendation if it gives the smallest travel time in a posteriori expectation. A plausible extension to repeated setting is that the likelihood of following recommendation in a round is related to regret from previous rounds. If the regret is of satisficing type with respect to a default choice and is averaged over past rounds and over all agents, then the asymptotic outcome under an obedient recommendation policy coincides with the one-shot outcome. We report findings from an experiment with one participant at a time engaged in repeated route choice decision on computer. In every round, the participant is shown travel time distribution for each route, a route recommendation generated by an obedient policy, and a rating suggestive of average experience of previous participants with the quality of recommendation. Upon entering route choice, the actual travel times are revealed. The participant evaluates the quality of recommendation by submitting a review. This is combined with historical reviews to update rating for the next round. Data analysis from 33 participants each with 100 rounds suggests moderate negative correlation between the display rating and the average regret, and a strong positive correlation between the rating and the likelihood of following recommendation. Overall, under obedient recommendation policy, the rating converges close to its maximum value by the end of the experiments in conjunction with very high frequency of following recommendations.",
    "authors": [
      "Yixian Zhu",
      "Ketan Savla"
    ],
    "categories": [
      "cs.GT",
      "cs.HC",
      "cs.IR",
      "cs.LG",
      "eess.SY"
    ],
    "published": "2022-07-31T08:17:01Z",
    "pdf_url": "https://arxiv.org/pdf/2208.00391v1"
  },
  {
    "arxiv_id": "2207.07730v2",
    "entry_id": "http://arxiv.org/abs/2207.07730v2",
    "title": "How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition",
    "summary": "A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.",
    "authors": [
      "Jorge A. Mendez",
      "Eric Eaton"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-07-15T19:53:20Z",
    "pdf_url": "https://arxiv.org/pdf/2207.07730v2"
  },
  {
    "arxiv_id": "2207.06415v1",
    "entry_id": "http://arxiv.org/abs/2207.06415v1",
    "title": "The Free Energy Principle for Perception and Action: A Deep Learning Perspective",
    "summary": "The free energy principle, and its corollary active inference, constitute a bio-inspired theory that assumes biological agents act to remain in a restricted set of preferred states of the world, i.e., they minimize their free energy. Under this principle, biological agents learn a generative model of the world and plan actions in the future that will maintain the agent in an homeostatic state that satisfies its preferences. This framework lends itself to being realized in silico, as it comprehends important aspects that make it computationally affordable, such as variational inference and amortized planning. In this work, we investigate the tool of deep learning to design and realize artificial agents based on active inference, presenting a deep-learning oriented presentation of the free energy principle, surveying works that are relevant in both machine learning and active inference areas, and discussing the design choices that are involved in the implementation process. This manuscript probes newer perspectives for the active inference framework, grounding its theoretical aspects into more pragmatic affairs, offering a practical guide to active inference newcomers and a starting point for deep learning practitioners that would like to investigate implementations of the free energy principle.",
    "authors": [
      "Pietro Mazzaglia",
      "Tim Verbelen",
      "Ozan Çatal",
      "Bart Dhoedt"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "published": "2022-07-13T11:07:03Z",
    "pdf_url": "https://arxiv.org/pdf/2207.06415v1"
  },
  {
    "arxiv_id": "2207.02851v1",
    "entry_id": "http://arxiv.org/abs/2207.02851v1",
    "title": "Tensor networks in machine learning",
    "summary": "A tensor network is a type of decomposition used to express and approximate large arrays of data. A given data-set, quantum state or higher dimensional multi-linear map is factored and approximated by a composition of smaller multi-linear maps. This is reminiscent to how a Boolean function might be decomposed into a gate array: this represents a special case of tensor decomposition, in which the tensor entries are replaced by 0, 1 and the factorisation becomes exact. The collection of associated techniques are called, tensor network methods: the subject developed independently in several distinct fields of study, which have more recently become interrelated through the language of tensor networks. The tantamount questions in the field relate to expressability of tensor networks and the reduction of computational overheads. A merger of tensor networks with machine learning is natural. On the one hand, machine learning can aid in determining a factorization of a tensor network approximating a data set. On the other hand, a given tensor network structure can be viewed as a machine learning model. Herein the tensor network parameters are adjusted to learn or classify a data-set. In this survey we recover the basics of tensor networks and explain the ongoing effort to develop the theory of tensor networks in machine learning.",
    "authors": [
      "Richik Sengupta",
      "Soumik Adhikary",
      "Ivan Oseledets",
      "Jacob Biamonte"
    ],
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-07-06T18:00:00Z",
    "pdf_url": "https://arxiv.org/pdf/2207.02851v1"
  },
  {
    "arxiv_id": "2207.02100v1",
    "entry_id": "http://arxiv.org/abs/2207.02100v1",
    "title": "Generating Game Levels of Diverse Behaviour Engagement",
    "summary": "Recent years, there has been growing interests in experience-driven procedural level generation. Various metrics have been formulated to model player experience and help generate personalised levels. In this work, we question whether experience metrics can adapt to agents with different personas. We start by reviewing existing metrics for evaluating game levels. Then, focusing on platformer games, we design a framework integrating various agents and evaluation metrics. Experimental studies on \\emph{Super Mario Bros.} indicate that using the same evaluation metrics but agents with different personas can generate levels for particular persona. It implies that, for simple games, using a game-playing agent of specific player archetype as a level tester is probably all we need to generate levels of diverse behaviour engagement.",
    "authors": [
      "Keyuan Zhang",
      "Jiayu Bai",
      "Jialin Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-07-05T15:08:12Z",
    "pdf_url": "https://arxiv.org/pdf/2207.02100v1"
  },
  {
    "arxiv_id": "2206.14355v1",
    "entry_id": "http://arxiv.org/abs/2206.14355v1",
    "title": "EBMs vs. CL: Exploring Self-Supervised Visual Pretraining for Visual Question Answering",
    "summary": "The availability of clean and diverse labeled data is a major roadblock for training models on complex tasks such as visual question answering (VQA). The extensive work on large vision-and-language models has shown that self-supervised learning is effective for pretraining multimodal interactions. In this technical report, we focus on visual representations. We review and evaluate self-supervised methods to leverage unlabeled images and pretrain a model, which we then fine-tune on a custom VQA task that allows controlled evaluation and diagnosis. We compare energy-based models (EBMs) with contrastive learning (CL). While EBMs are growing in popularity, they lack an evaluation on downstream tasks. We find that both EBMs and CL can learn representations from unlabeled images that enable training a VQA model on very little annotated data. In a simple setting similar to CLEVR, we find that CL representations also improve systematic generalization, and even match the performance of representations from a larger, supervised, ImageNet-pretrained model. However, we find EBMs to be difficult to train because of instabilities and high variability in their results. Although EBMs prove useful for OOD detection, other results on supervised energy-based training and uncertainty calibration are largely negative. Overall, CL currently seems a preferable option over EBMs.",
    "authors": [
      "Violetta Shevchenko",
      "Ehsan Abbasnejad",
      "Anthony Dick",
      "Anton van den Hengel",
      "Damien Teney"
    ],
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-06-29T01:44:23Z",
    "pdf_url": "https://arxiv.org/pdf/2206.14355v1"
  },
  {
    "arxiv_id": "2206.11319v1",
    "entry_id": "http://arxiv.org/abs/2206.11319v1",
    "title": "Graph-Based Multi-Robot Path Finding and Planning",
    "summary": "Purpose of Review\n  Planning collision-free paths for multiple robots is important for real-world multi-robot systems and has been studied as an optimization problem on graphs, called Multi-Agent Path Finding (MAPF). This review surveys different categories of classic and state-of-the-art MAPF algorithms and different research attempts to tackle the challenges of generalizing MAPF techniques to real-world scenarios.\n  Recent Findings\n  Solving MAPF problems optimally is computationally challenging. Recent advances have resulted in MAPF algorithms that can compute collision-free paths for hundreds of robots and thousands of navigation tasks in seconds of runtime. Many variants of MAPF have been formalized to adapt MAPF techniques to different real-world requirements, such as considerations of robot kinematics, online optimization for real-time systems, and the integration of task assignment and path planning.\n  Summary\n  Algorithmic techniques for MAPF problems have addressed important aspects of several multi-robot applications, including automated warehouse fulfillment and sortation, automated train scheduling, and navigation of non-holonomic robots and quadcopters. This showcases their potential for real-world applications of large-scale multi-robot systems.",
    "authors": [
      "Hang Ma"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2022-06-22T18:47:00Z",
    "pdf_url": "https://arxiv.org/pdf/2206.11319v1"
  },
  {
    "arxiv_id": "2206.09360v1",
    "entry_id": "http://arxiv.org/abs/2206.09360v1",
    "title": "Modeling Transformative AI Risks (MTAIR) Project -- Summary Report",
    "summary": "This report outlines work by the Modeling Transformative AI Risk (MTAIR) project, an attempt to map out the key hypotheses, uncertainties, and disagreements in debates about catastrophic risks from advanced AI, and the relationships between them. This builds on an earlier diagram by Ben Cottier and Rohin Shah which laid out some of the crucial disagreements (\"cruxes\") visually, with some explanation. Based on an extensive literature review and engagement with experts, the report explains a model of the issues involved, and the initial software-based implementation that can incorporate probability estimates or other quantitative factors to enable exploration, planning, and/or decision support. By gathering information from various debates and discussions into a single more coherent presentation, we hope to enable better discussions and debates about the issues involved.\n  The model starts with a discussion of reasoning via analogies and general prior beliefs about artificial intelligence. Following this, it lays out a model of different paths and enabling technologies for high-level machine intelligence, and a model of how advances in the capabilities of these systems might proceed, including debates about self-improvement, discontinuous improvements, and the possibility of distributed, non-agentic high-level intelligence or slower improvements. The model also looks specifically at the question of learned optimization, and whether machine learning systems will create mesa-optimizers. The impact of different safety research on the previous sets of questions is then examined, to understand whether and how research could be useful in enabling safer systems. Finally, we discuss a model of different failure modes and loss of control or takeover scenarios.",
    "authors": [
      "Sam Clarke",
      "Ben Cottier",
      "Aryeh Englander",
      "Daniel Eth",
      "David Manheim",
      "Samuel Dylan Martin",
      "Issa Rice"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-06-19T09:11:23Z",
    "pdf_url": "https://arxiv.org/pdf/2206.09360v1"
  },
  {
    "arxiv_id": "2206.09328v1",
    "entry_id": "http://arxiv.org/abs/2206.09328v1",
    "title": "A Survey on Model-based Reinforcement Learning",
    "summary": "Reinforcement learning (RL) solves sequential decision-making problems via a trial-and-error process interacting with the environment. While RL achieves outstanding success in playing complex video games that allow huge trial-and-error, making errors is always undesired in the real world. To improve the sample efficiency and thus reduce the errors, model-based reinforcement learning (MBRL) is believed to be a promising direction, which builds environment models in which the trial-and-errors can take place without real costs. In this survey, we take a review of MBRL with a focus on the recent progress in deep RL. For non-tabular environments, there is always a generalization error between the learned environment model and the real environment. As such, it is of great importance to analyze the discrepancy between policy training in the environment model and that in the real environment, which in turn guides the algorithm design for better model learning, model usage, and policy training. Besides, we also discuss the recent advances of model-based techniques in other forms of RL, including offline RL, goal-conditioned RL, multi-agent RL, and meta-RL. Moreover, we discuss the applicability and advantages of MBRL in real-world tasks. Finally, we end this survey by discussing the promising prospects for the future development of MBRL. We think that MBRL has great potential and advantages in real-world applications that were overlooked, and we hope this survey could attract more research on MBRL.",
    "authors": [
      "Fan-Ming Luo",
      "Tian Xu",
      "Hang Lai",
      "Xiong-Hui Chen",
      "Weinan Zhang",
      "Yang Yu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-06-19T05:28:03Z",
    "pdf_url": "https://arxiv.org/pdf/2206.09328v1"
  },
  {
    "arxiv_id": "2206.08446v1",
    "entry_id": "http://arxiv.org/abs/2206.08446v1",
    "title": "Methods for Estimating and Improving Robustness of Language Models",
    "summary": "Despite their outstanding performance, large language models (LLMs) suffer notorious flaws related to their preference for simple, surface-level textual relations over full semantic complexity of the problem. This proposal investigates a common denominator of this problem in their weak ability to generalise outside of the training domain. We survey diverse research directions providing estimations of model generalisation ability and find that incorporating some of these measures in the training objectives leads to enhanced distributional robustness of neural models. Based on these findings, we present future research directions towards enhancing the robustness of LLMs.",
    "authors": [
      "Michal Štefánik"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-06-16T21:02:53Z",
    "pdf_url": "https://arxiv.org/pdf/2206.08446v1"
  },
  {
    "arxiv_id": "2206.08781v2",
    "entry_id": "http://arxiv.org/abs/2206.08781v2",
    "title": "Reinforcement Learning for Economic Policy: A New Frontier?",
    "summary": "Agent-based computational economics is a field with a rich academic history, yet one which has struggled to enter mainstream policy design toolboxes, plagued by the challenges associated with representing a complex and dynamic reality. The field of Reinforcement Learning (RL), too, has a rich history, and has recently been at the centre of several exponential developments. Modern RL implementations have been able to achieve unprecedented levels of sophistication, handling previously unthinkable degrees of complexity. This review surveys the historical barriers of classical agent-based techniques in economic modelling, and contemplates whether recent developments in RL can overcome any of them.",
    "authors": [
      "Callum Rhys Tilbury"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "econ.GN"
    ],
    "published": "2022-06-16T10:35:26Z",
    "pdf_url": "https://arxiv.org/pdf/2206.08781v2"
  },
  {
    "arxiv_id": "2206.05625v2",
    "entry_id": "http://arxiv.org/abs/2206.05625v2",
    "title": "Exploring the Intersection between Neural Architecture Search and Continual Learning",
    "summary": "Despite the significant advances achieved in Artificial Neural Networks (ANNs), their design process remains notoriously tedious, depending primarily on intuition, experience and trial-and-error. This human-dependent process is often time-consuming and prone to errors. Furthermore, the models are generally bound to their training contexts, with no considerations to their surrounding environments. Continual adaptiveness and automation of neural networks is of paramount importance to several domains where model accessibility is limited after deployment (e.g IoT devices, self-driving vehicles, etc.). Additionally, even accessible models require frequent maintenance post-deployment to overcome issues such as Concept/Data Drift, which can be cumbersome and restrictive. By leveraging and combining approaches from Neural Architecture Search (NAS) and Continual Learning (CL), more robust and adaptive agents can be developed. This study conducts the first extensive review on the intersection between NAS and CL, formalizing the prospective Continually-Adaptive Neural Networks (CANNs) paradigm and outlining research directions for lifelong autonomous ANNs.",
    "authors": [
      "Mohamed Shahawy",
      "Elhadj Benkhelifa",
      "David White"
    ],
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "published": "2022-06-11T22:26:53Z",
    "pdf_url": "https://arxiv.org/pdf/2206.05625v2"
  },
  {
    "arxiv_id": "2206.05395v2",
    "entry_id": "http://arxiv.org/abs/2206.05395v2",
    "title": "Why is constrained neural language generation particularly challenging?",
    "summary": "Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce fluent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally define and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging field, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research.",
    "authors": [
      "Cristina Garbacea",
      "Qiaozhu Mei"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-06-11T02:07:33Z",
    "pdf_url": "https://arxiv.org/pdf/2206.05395v2"
  },
  {
    "arxiv_id": "2206.05224v2",
    "entry_id": "http://arxiv.org/abs/2206.05224v2",
    "title": "A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction",
    "summary": "The recent advances of deep learning have dramatically changed how machine learning, especially in the domain of natural language processing, can be applied to legal domain. However, this shift to the data-driven approaches calls for larger and more diverse datasets, which are nevertheless still small in number, especially in non-English languages. Here we present the first large-scale benchmark of Korean legal AI datasets, LBOX OPEN, that consists of one legal corpus, two classification tasks, two legal judgement prediction (LJP) tasks, and one summarization task. The legal corpus consists of 147k Korean precedents (259M tokens), of which 63k are sentenced in last 4 years and 96k are from the first and the second level courts in which factual issues are reviewed. The two classification tasks are case names (11.3k) and statutes (2.8k) prediction from the factual description of individual cases. The LJP tasks consist of (1) 10.5k criminal examples where the model is asked to predict fine amount, imprisonment with labor, and imprisonment without labor ranges for the given facts, and (2) 4.7k civil examples where the inputs are facts and claim for relief and outputs are the degrees of claim acceptance. The summarization task consists of the Supreme Court precedents and the corresponding summaries (20k). We also release realistic variants of the datasets by extending the domain (1) to infrequent case categories in case name (31k examples) and statute (17.7k) classification tasks, and (2) to long input sequences in the summarization task (51k). Finally, we release LCUBE, the first Korean legal language model trained on the legal corpus from this study. Given the uniqueness of the Law of South Korea and the diversity of the legal tasks covered in this work, we believe that LBOX OPEN contributes to the multilinguality of global legal research. LBOX OPEN and LCUBE will be publicly available.",
    "authors": [
      "Wonseok Hwang",
      "Dongjun Lee",
      "Kyoungyeon Cho",
      "Hanuhl Lee",
      "Minjoon Seo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-06-10T16:51:45Z",
    "pdf_url": "https://arxiv.org/pdf/2206.05224v2"
  },
  {
    "arxiv_id": "2206.03031v2",
    "entry_id": "http://arxiv.org/abs/2206.03031v2",
    "title": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
    "summary": "Designing and implementing explainable systems is seen as the next step towards increasing user trust in, acceptance of and reliance on Artificial Intelligence (AI) systems. While explaining choices made by black-box algorithms such as machine learning and deep learning has occupied most of the limelight, systems that attempt to explain decisions (even simple ones) in the context of social choice are steadily catching up. In this paper, we provide a comprehensive survey of explainability in mechanism design, a domain characterized by economically motivated agents and often having no single choice that maximizes all individual utility functions. We discuss the main properties and goals of explainability in mechanism design, distinguishing them from those of Explainable AI in general. This discussion is followed by a thorough review of the challenges one may face when working on Explainable Mechanism Design and propose a few solution concepts to those.",
    "authors": [
      "Sharadhi Alape Suryanarayana",
      "David Sarne",
      "Sarit Kraus"
    ],
    "categories": [
      "cs.MA"
    ],
    "published": "2022-06-07T06:08:53Z",
    "pdf_url": "https://arxiv.org/pdf/2206.03031v2"
  },
  {
    "arxiv_id": "2206.02196v1",
    "entry_id": "http://arxiv.org/abs/2206.02196v1",
    "title": "Machine learning applications for electricity market agent-based models: A systematic literature review",
    "summary": "The electricity market has a vital role to play in the decarbonisation of the energy system. However, the electricity market is made up of many different variables and data inputs. These variables and data inputs behave in sometimes unpredictable ways which can not be predicted a-priori. It has therefore been suggested that agent-based simulations are used to better understand the dynamics of the electricity market. Agent-based models provide the opportunity to integrate machine learning and artificial intelligence to add intelligence, make better forecasts and control the power market in better and more efficient ways. In this systematic literature review, we review 55 papers published between 2016 and 2021 which focus on machine learning applied to agent-based electricity market models. We find that research clusters around popular topics, such as bidding strategies. However, there exists a long-tail of different research applications that could benefit from the high intensity research from the more investigated applications.",
    "authors": [
      "Alexander J. M. Kell",
      "Stephen McGough",
      "Matthew Forshaw"
    ],
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "published": "2022-06-05T14:52:26Z",
    "pdf_url": "https://arxiv.org/pdf/2206.02196v1"
  },
  {
    "arxiv_id": "2206.01092v2",
    "entry_id": "http://arxiv.org/abs/2206.01092v2",
    "title": "Innovations in Integrating Machine Learning and Agent-Based Modeling of Biomedical Systems",
    "summary": "Agent-based modeling (ABM) is a well-established paradigm for simulating complex systems via interactions between constituent entities. Machine learning (ML) refers to approaches whereby statistical algorithms 'learn' from data on their own, without imposing a priori theories of system behavior. Biological systems -- from molecules, to cells, to entire organisms -- consist of vast numbers of entities, governed by complex webs of interactions that span many spatiotemporal scales and exhibit nonlinearity, stochasticity and intricate coupling between entities. The macroscopic properties and collective dynamics of such systems are difficult to capture via continuum modelling and mean-field formalisms. ABM takes a 'bottom-up' approach that obviates these difficulties by enabling one to easily propose and test a set of well-defined 'rules' to be applied to the individual entities (agents) in a system. Evaluating a system and propagating its state over discrete time-steps effectively simulates the system, allowing observables to be computed and system properties to be analyzed. Because the rules that govern an ABM can be difficult to abstract and formulate from experimental data, there is an opportunity to use ML to help infer optimal, system-specific ABM rules. Once such rule-sets are devised, ABM calculations can generate a wealth of data, and ML can be applied there too -- e.g., to probe statistical measures that meaningfully describe a system's stochastic properties. As an example of synergy in the other direction (from ABM to ML), ABM simulations can generate realistic datasets for training ML algorithms (e.g., for regularization, to mitigate overfitting). In these ways, one can envision various synergistic ABM$\\rightleftharpoons$ML loops. This review summarizes how ABM and ML have been integrated in contexts that span spatiotemporal scales, from cellular to population-level epidemiology.",
    "authors": [
      "Nikita Sivakumar",
      "Cameron Mura",
      "Shayn M. Peirce"
    ],
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "cs.MA",
      "q-bio.CB"
    ],
    "published": "2022-06-02T15:19:09Z",
    "pdf_url": "https://arxiv.org/pdf/2206.01092v2"
  },
  {
    "arxiv_id": "2205.10032v1",
    "entry_id": "http://arxiv.org/abs/2205.10032v1",
    "title": "Survey on Fair Reinforcement Learning: Theory and Practice",
    "summary": "Fairness-aware learning aims at satisfying various fairness constraints in addition to the usual performance criteria via data-driven machine learning techniques. Most of the research in fairness-aware learning employs the setting of fair-supervised learning. However, many dynamic real-world applications can be better modeled using sequential decision-making problems and fair reinforcement learning provides a more suitable alternative for addressing these problems. In this article, we provide an extensive overview of fairness approaches that have been implemented via a reinforcement learning (RL) framework. We discuss various practical applications in which RL methods have been applied to achieve a fair solution with high accuracy. We further include various facets of the theory of fair reinforcement learning, organizing them into single-agent RL, multi-agent RL, long-term fairness via RL, and offline learning. Moreover, we highlight a few major issues to explore in order to advance the field of fair-RL, namely - i) correcting societal biases, ii) feasibility of group fairness or individual fairness, and iii) explainability in RL. Our work is beneficial for both researchers and practitioners as we discuss articles providing mathematical guarantees as well as articles with empirical studies on real-world problems.",
    "authors": [
      "Pratik Gajane",
      "Akrati Saxena",
      "Maryam Tavakol",
      "George Fletcher",
      "Mykola Pechenizkiy"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-05-20T09:07:28Z",
    "pdf_url": "https://arxiv.org/pdf/2205.10032v1"
  },
  {
    "arxiv_id": "2205.08772v1",
    "entry_id": "http://arxiv.org/abs/2205.08772v1",
    "title": "Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification",
    "summary": "Cross-domain sentiment classification (CDSC) aims to use the transferable semantics learned from the source domain to predict the sentiment of reviews in the unlabeled target domain. Existing studies in this task attach more attention to the sequence modeling of sentences while largely ignoring the rich domain-invariant semantics embedded in graph structures (i.e., the part-of-speech tags and dependency relations). As an important aspect of exploring characteristics of language comprehension, adaptive graph representations have played an essential role in recent years. To this end, in the paper, we aim to explore the possibility of learning invariant semantic features from graph-like structures in CDSC. Specifically, we present Graph Adaptive Semantic Transfer (GAST) model, an adaptive syntactic graph embedding method that is able to learn domain-invariant semantics from both word sequences and syntactic graphs. More specifically, we first raise a POS-Transformer module to extract sequential semantic features from the word sequences as well as the part-of-speech tags. Then, we design a Hybrid Graph Attention (HGAT) module to generate syntax-based semantic features by considering the transferable dependency relations. Finally, we devise an Integrated aDaptive Strategy (IDS) to guide the joint learning process of both modules. Extensive experiments on four public datasets indicate that GAST achieves comparable effectiveness to a range of state-of-the-art models.",
    "authors": [
      "Kai Zhang",
      "Qi Liu",
      "Zhenya Huang",
      "Mingyue Cheng",
      "Kun Zhang",
      "Mengdi Zhang",
      "Wei Wu",
      "Enhong Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2022-05-18T07:47:01Z",
    "pdf_url": "https://arxiv.org/pdf/2205.08772v1"
  },
  {
    "arxiv_id": "2205.06485v1",
    "entry_id": "http://arxiv.org/abs/2205.06485v1",
    "title": "Modeling Human Behavior Part I -- Learning and Belief Approaches",
    "summary": "There is a clear desire to model and comprehend human behavior. Trends in research covering this topic show a clear assumption that many view human reasoning as the presupposed standard in artificial reasoning. As such, topics such as game theory, theory of mind, machine learning, etc. all integrate concepts which are assumed components of human reasoning. These serve as techniques to attempt to both replicate and understand the behaviors of humans. In addition, next generation autonomous and adaptive systems will largely include AI agents and humans working together as teams. To make this possible, autonomous agents will require the ability to embed practical models of human behavior, which allow them not only to replicate human models as a technique to \"learn\", but to to understand the actions of users and anticipate their behavior, so as to truly operate in symbiosis with them. The main objective of this paper it to provide a succinct yet systematic review of the most important approaches in two areas dealing with quantitative models of human behaviors. Specifically, we focus on (i) techniques which learn a model or policy of behavior through exploration and feedback, such as Reinforcement Learning, and (ii) directly model mechanisms of human reasoning, such as beliefs and bias, without going necessarily learning via trial-and-error.",
    "authors": [
      "Andrew Fuchs",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-05-13T07:33:49Z",
    "pdf_url": "https://arxiv.org/pdf/2205.06485v1"
  },
  {
    "arxiv_id": "2205.03854v1",
    "entry_id": "http://arxiv.org/abs/2205.03854v1",
    "title": "Introduction to Soar",
    "summary": "This paper is the recommended initial reading for a functional overview of Soar, version 9.6. It includes an abstract overview of the architectural structure of Soar including its processing, memories, learning modules, their interfaces, and the representations of knowledge used by those modules. From there it describes the processing supported by those modules, including decision making, impasses and substates, procedure learning via chunking, reinforcement learning, semantic memory, episodic memory, and spatial-visual reasoning. It then reviews the levels of decision making and variety of learning in Soar, and analysis of Soar as an architecture supporting general human-level AI. Following the references is an appendix that contains short descriptions of recent Soar agents and a glossary of the terminology we use in describing Soar.",
    "authors": [
      "John E. Laird"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-05-08T12:44:51Z",
    "pdf_url": "https://arxiv.org/pdf/2205.03854v1"
  },
  {
    "arxiv_id": "2205.03824v1",
    "entry_id": "http://arxiv.org/abs/2205.03824v1",
    "title": "A Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Research Challenges",
    "summary": "Artificial Intelligence (AI) is a fast-growing research and development (R&D) discipline which is attracting increasing attention because of its promises to bring vast benefits for consumers and businesses, with considerable benefits promised in productivity growth and innovation. To date it has reported significant accomplishments in many areas that have been deemed as challenging for machines, ranging from computer vision, natural language processing, audio analysis to smart sensing and many others. The technical trend in realizing the successes has been towards increasing complex and large size AI models so as to solve more complex problems at superior performance and robustness. This rapid progress, however, has taken place at the expense of substantial environmental costs and resources. Besides, debates on the societal impacts of AI, such as fairness, safety and privacy, have continued to grow in intensity. These issues have presented major concerns pertaining to the sustainable development of AI. In this work, we review major trends in machine learning approaches that can address the sustainability problem of AI. Specifically, we examine emerging AI methodologies and algorithms for addressing the sustainability issue of AI in two major aspects, i.e., environmental sustainability and social sustainability of AI. We will also highlight the major limitations of existing studies and propose potential research challenges and directions for the development of next generation of sustainable AI techniques. We believe that this technical review can help to promote a sustainable development of AI R&D activities for the research community.",
    "authors": [
      "Zhenghua Chen",
      "Min Wu",
      "Alvin Chan",
      "Xiaoli Li",
      "Yew-Soon Ong"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-05-08T09:38:35Z",
    "pdf_url": "https://arxiv.org/pdf/2205.03824v1"
  },
  {
    "arxiv_id": "2205.02987v1",
    "entry_id": "http://arxiv.org/abs/2205.02987v1",
    "title": "Tell Me Something That Will Help Me Trust You: A Survey of Trust Calibration in Human-Agent Interaction",
    "summary": "When a human receives a prediction or recommended course of action from an intelligent agent, what additional information, beyond the prediction or recommendation itself, does the human require from the agent to decide whether to trust or reject the prediction or recommendation? In this paper we survey literature in the area of trust between a single human supervisor and a single agent subordinate to determine the nature and extent of this additional information and to characterize it into a taxonomy that can be leveraged by future researchers and intelligent agent practitioners. By examining this question from a human-centered, information-focused point of view, we can begin to compare and contrast different implementations and also provide insight and directions for future work.",
    "authors": [
      "George J. Cancro",
      "Shimei Pan",
      "James Foulds"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2022-05-06T02:41:08Z",
    "pdf_url": "https://arxiv.org/pdf/2205.02987v1"
  },
  {
    "arxiv_id": "2205.01759v2",
    "entry_id": "http://arxiv.org/abs/2205.01759v2",
    "title": "Explain and Conquer: Personalised Text-based Reviews to Achieve Transparency",
    "summary": "There are many contexts in which dyadic data are present. Social networks are a well-known example. In these contexts, pairs of elements are linked building a network that reflects interactions. Explaining why these relationships are established is essential to obtain transparency, an increasingly important notion. These explanations are often presented using text, thanks to the spread of the natural language understanding tasks. Our aim is to represent and explain pairs established by any agent (e.g., a recommender system or a paid promotion mechanism), so that text-based personalisation is taken into account. We have focused on the TripAdvisor platform, considering the applicability to other dyadic data contexts. The items are a subset of users and restaurants and the interactions the reviews posted by these users. We propose the PTER (Personalised TExt-based Reviews) model. We predict, from the available reviews for a given restaurant, those that fit to the specific user interactions. PTER leverages the BERT (Bidirectional Encoders Representations from Transformers) transformer-encoder model. We customised a deep neural network following the feature-based approach, presenting a LTR (Learning To Rank) downstream task. We carried out several comparisons of our proposal with a random baseline and other models of the state of the art, following the EXTRA (EXplanaTion RAnking) benchmark. Our method outperforms other collaborative filtering proposals.",
    "authors": [
      "Iñigo López-Riobóo Botana",
      "Verónica Bolón-Canedo",
      "Bertha Guijarro-Berdiñas",
      "Amparo Alonso-Betanzos"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.SI"
    ],
    "published": "2022-05-03T20:04:32Z",
    "pdf_url": "https://arxiv.org/pdf/2205.01759v2"
  },
  {
    "arxiv_id": "2205.00824v1",
    "entry_id": "http://arxiv.org/abs/2205.00824v1",
    "title": "Exploration in Deep Reinforcement Learning: A Survey",
    "summary": "This paper reviews exploration techniques in deep reinforcement learning. Exploration techniques are of primary importance when solving sparse reward problems. In sparse reward problems, the reward is rare, which means that the agent will not find the reward often by acting randomly. In such a scenario, it is challenging for reinforcement learning to learn rewards and actions association. Thus more sophisticated exploration methods need to be devised. This review provides a comprehensive overview of existing exploration approaches, which are categorized based on the key contributions as follows reward novel states, reward diverse behaviours, goal-based methods, probabilistic methods, imitation-based methods, safe exploration and random-based methods. Then, the unsolved challenges are discussed to provide valuable future research directions. Finally, the approaches of different categories are compared in terms of complexity, computational effort and overall performance.",
    "authors": [
      "Pawel Ladosz",
      "Lilian Weng",
      "Minwoo Kim",
      "Hyondong Oh"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-05-02T12:03:44Z",
    "pdf_url": "https://arxiv.org/pdf/2205.00824v1"
  },
  {
    "arxiv_id": "2205.00473v2",
    "entry_id": "http://arxiv.org/abs/2205.00473v2",
    "title": "A Survey on Distributed Online Optimization and Game",
    "summary": "Distributed online optimization and game have been increasingly researched in the last decade, mostly motivated by its wide applications in sensor networks, robotics (e.g., distributed target tracking and formation control), smart grids, deep learning, and so forth. In these problems, there is a network of agents who may be cooperative (i.e., distributed online optimization) or noncooperative (i.e., online game) through local information exchanges. And the local cost function of each agent is often time-varying in dynamic and even adversarial environments. At each time, a decision must be made by each agent based on historical information at hand without knowing future information on cost functions. For these problems, a comprehensive survey is still lacking. This paper aims to provide a thorough overview of distributed online optimization and game from the perspective of problem settings, communication, computation, algorithms, and performances. In addition, some potential future directions are also discussed.",
    "authors": [
      "Xiuxian Li",
      "Lihua Xie",
      "Na Li"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2022-05-01T14:10:26Z",
    "pdf_url": "https://arxiv.org/pdf/2205.00473v2"
  },
  {
    "arxiv_id": "2204.12443v2",
    "entry_id": "http://arxiv.org/abs/2204.12443v2",
    "title": "A review of Federated Learning in Intrusion Detection Systems for IoT",
    "summary": "Intrusion detection systems are evolving into intelligent systems that perform data analysis searching for anomalies in their environment. The development of deep learning technologies opened the door to build more complex and effective threat detection models. However, training those models may be computationally infeasible in most Internet of Things devices. Current approaches rely on powerful centralized servers that receive data from all their parties -- violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. To mitigate these issues, Federated Learning emerged as a promising approach where different agents collaboratively train a shared model, neither exposing training data to others nor requiring a compute-intensive centralized infrastructure. This paper focuses on the application of Federated Learning approaches in the field of Intrusion Detection. Both technologies are described in detail and current scientific progress is reviewed and categorized. Finally, the paper highlights the limitations present in recent works and presents some future directions for this technology.",
    "authors": [
      "Aitor Belenguer",
      "Javier Navaridas",
      "Jose A. Pascual"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-04-26T17:00:07Z",
    "pdf_url": "https://arxiv.org/pdf/2204.12443v2"
  },
  {
    "arxiv_id": "2204.12037v8",
    "entry_id": "http://arxiv.org/abs/2204.12037v8",
    "title": "Causal Reasoning Meets Visual Representation Learning: A Prospective Study",
    "summary": "Visual representation learning is ubiquitous in various real-world applications, including visual comprehension, video understanding, multi-modal analysis, human-computer interaction, and urban computing. Due to the emergence of huge amounts of multi-modal heterogeneous spatial/temporal/spatial-temporal data in big data era, the lack of interpretability, robustness, and out-of-distribution generalization are becoming the challenges of the existing visual models. The majority of the existing methods tend to fit the original data/variable distributions and ignore the essential causal relations behind the multi-modal knowledge, which lacks unified guidance and analysis about why modern visual representation learning methods easily collapse into data bias and have limited generalization and cognitive abilities. Inspired by the strong inference ability of human-level agents, recent years have therefore witnessed great effort in developing causal reasoning paradigms to realize robust representation and model learning with good cognitive ability. In this paper, we conduct a comprehensive review of existing causal reasoning methods for visual representation learning, covering fundamental theories, models, and datasets. The limitations of current methods and datasets are also discussed. Moreover, we propose some prospective challenges, opportunities, and future research directions for benchmarking causal reasoning algorithms in visual representation learning. This paper aims to provide a comprehensive overview of this emerging field, attract attention, encourage discussions, bring to the forefront the urgency of developing novel causal reasoning methods, publicly available benchmarks, and consensus-building standards for reliable visual representation learning and related real-world applications more efficiently.",
    "authors": [
      "Yang Liu",
      "Yushen Wei",
      "Hong Yan",
      "Guanbin Li",
      "Liang Lin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "published": "2022-04-26T02:22:28Z",
    "pdf_url": "https://arxiv.org/pdf/2204.12037v8"
  },
  {
    "arxiv_id": "2204.10365v1",
    "entry_id": "http://arxiv.org/abs/2204.10365v1",
    "title": "Towards an Enhanced Understanding of Bias in Pre-trained Neural Language Models: A Survey with Special Emphasis on Affective Bias",
    "summary": "The remarkable progress in Natural Language Processing (NLP) brought about by deep learning, particularly with the recent advent of large pre-trained neural language models, is brought into scrutiny as several studies began to discuss and report potential biases in NLP applications. Bias in NLP is found to originate from latent historical biases encoded by humans into textual data which gets perpetuated or even amplified by NLP algorithm. We present a survey to comprehend bias in large pre-trained language models, analyze the stages at which they occur in these models, and various ways in which these biases could be quantified and mitigated. Considering wide applicability of textual affective computing based downstream tasks in real-world systems such as business, healthcare, education, etc., we give a special emphasis on investigating bias in the context of affect (emotion) i.e., Affective Bias, in large pre-trained language models. We present a summary of various bias evaluation corpora that help to aid future research and discuss challenges in the research on bias in pre-trained language models. We believe that our attempt to draw a comprehensive view of bias in pre-trained language models, and especially the exploration of affective bias will be highly beneficial to researchers interested in this evolving field.",
    "authors": [
      "Anoop K.",
      "Manjary P. Gangan",
      "Deepak P.",
      "Lajish V. L"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-04-21T18:51:19Z",
    "pdf_url": "https://arxiv.org/pdf/2204.10365v1"
  },
  {
    "arxiv_id": "2204.10358v1",
    "entry_id": "http://arxiv.org/abs/2204.10358v1",
    "title": "Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework",
    "summary": "Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence (AI) that focuses on methods for solving off-nominal, or anomalous problems in autonomous systems. Despite many advancements in planning and learning, resolving novel problems or adapting existing knowledge to a new context, especially in cases where the environment may change in unpredictable ways post deployment, remains a limiting factor in the safe and useful integration of intelligent systems. The emergence of increasingly autonomous systems dictates the necessity for AI agents to deal with environmental uncertainty through creativity. To stimulate further research in CPS, we present a definition and a framework of CPS, which we adopt to categorize existing AI methods in this field. Our framework consists of four main components of a CPS problem, namely, 1) problem formulation, 2) knowledge representation, 3) method of knowledge manipulation, and 4) method of evaluation. We conclude our survey with open research questions, and suggested directions for the future.",
    "authors": [
      "Evana Gizzi",
      "Lakshmi Nair",
      "Sonia Chernova",
      "Jivko Sinapov"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-04-21T18:31:44Z",
    "pdf_url": "https://arxiv.org/pdf/2204.10358v1"
  },
  {
    "arxiv_id": "2204.10063v1",
    "entry_id": "http://arxiv.org/abs/2204.10063v1",
    "title": "Resilient robot teams: a review integrating decentralised control, change-detection, and learning",
    "summary": "Purpose of review: This paper reviews opportunities and challenges for decentralised control, change-detection, and learning in the context of resilient robot teams.\n  Recent findings: Exogenous fault detection methods can provide a generic detection or a specific diagnosis with a recovery solution. Robot teams can perform active and distributed sensing for detecting changes in the environment, including identifying and tracking dynamic anomalies, as well as collaboratively mapping dynamic environments. Resilient methods for decentralised control have been developed in learning perception-action-communication loops, multi-agent reinforcement learning, embodied evolution, offline evolution with online adaptation, explicit task allocation, and stigmergy in swarm robotics.\n  Summary: Remaining challenges for resilient robot teams are integrating change-detection and trial-and-error learning methods, obtaining reliable performance evaluations under constrained evaluation time, improving the safety of resilient robot teams, theoretical results demonstrating rapid adaptation to given environmental perturbations, and designing realistic and compelling case studies.",
    "authors": [
      "David M. Bossens",
      "Sarvapali Ramchurn",
      "Danesh Tarapore"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2022-04-21T12:51:27Z",
    "pdf_url": "https://arxiv.org/pdf/2204.10063v1"
  },
  {
    "arxiv_id": "2204.09140v2",
    "entry_id": "http://arxiv.org/abs/2204.09140v2",
    "title": "Multi-hop Question Answering",
    "summary": "The task of Question Answering (QA) has attracted significant research interest for long. Its relevance to language understanding and knowledge retrieval tasks, along with the simple setting makes the task of QA crucial for strong AI systems. Recent success on simple QA tasks has shifted the focus to more complex settings. Among these, Multi-Hop QA (MHQA) is one of the most researched tasks over the recent years. In broad terms, MHQA is the task of answering natural language questions that involve extracting and combining multiple pieces of information and doing multiple steps of reasoning. An example of a multi-hop question would be \"The Argentine PGA Championship record holder has won how many tournaments worldwide?\". Answering the question would need two pieces of information: \"Who is the record holder for Argentine PGA Championship tournaments?\" and \"How many tournaments did [Answer of Sub Q1] win?\". The ability to answer multi-hop questions and perform multi step reasoning can significantly improve the utility of NLP systems. Consequently, the field has seen a surge with high quality datasets, models and evaluation strategies. The notion of 'multiple hops' is somewhat abstract which results in a large variety of tasks that require multi-hop reasoning. This leads to different datasets and models that differ significantly from each other and makes the field challenging to generalize and survey. We aim to provide a general and formal definition of the MHQA task, and organize and summarize existing MHQA frameworks. We also outline some best practices for building MHQA datasets. This book provides a systematic and thorough introduction as well as the structuring of the existing attempts to this highly interesting, yet quite challenging task.",
    "authors": [
      "Vaibhav Mavi",
      "Anubhav Jangra",
      "Adam Jatowt"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2022-04-19T21:55:18Z",
    "pdf_url": "https://arxiv.org/pdf/2204.09140v2"
  },
  {
    "arxiv_id": "2204.06031v1",
    "entry_id": "http://arxiv.org/abs/2204.06031v1",
    "title": "A Review on Language Models as Knowledge Bases",
    "summary": "Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.",
    "authors": [
      "Badr AlKhamissi",
      "Millicent Li",
      "Asli Celikyilmaz",
      "Mona Diab",
      "Marjan Ghazvininejad"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-04-12T18:35:23Z",
    "pdf_url": "https://arxiv.org/pdf/2204.06031v1"
  },
  {
    "arxiv_id": "2204.04859v1",
    "entry_id": "http://arxiv.org/abs/2204.04859v1",
    "title": "A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges",
    "summary": "Legal judgment prediction (LJP) applies Natural Language Processing (NLP) techniques to predict judgment results based on fact descriptions automatically. Recently, large-scale public datasets and advances in NLP research have led to increasing interest in LJP. Despite a clear gap between machine and human performance, impressive results have been achieved in various benchmark datasets. In this paper, to address the current lack of comprehensive survey of existing LJP tasks, datasets, models and evaluations, (1) we analyze 31 LJP datasets in 6 languages, present their construction process and define a classification method of LJP with 3 different attributes; (2) we summarize 14 evaluation metrics under four categories for different outputs of LJP tasks; (3) we review 12 legal-domain pretrained models in 3 languages and highlight 3 major research directions for LJP; (4) we show the state-of-art results for 8 representative datasets from different court cases and discuss the open challenges. This paper can provide up-to-date and comprehensive reviews to help readers understand the status of LJP. We hope to facilitate both NLP researchers and legal professionals for further joint efforts in this problem.",
    "authors": [
      "Junyun Cui",
      "Xiaoyu Shen",
      "Feiping Nie",
      "Zheng Wang",
      "Jinglong Wang",
      "Yulong Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-04-11T04:06:28Z",
    "pdf_url": "https://arxiv.org/pdf/2204.04859v1"
  },
  {
    "arxiv_id": "2204.03516v1",
    "entry_id": "http://arxiv.org/abs/2204.03516v1",
    "title": "Distributed Reinforcement Learning for Robot Teams: A Review",
    "summary": "Purpose of review: Recent advances in sensing, actuation, and computation have opened the door to multi-robot systems consisting of hundreds/thousands of robots, with promising applications to automated manufacturing, disaster relief, harvesting, last-mile delivery, port/airport operations, or search and rescue. The community has leveraged model-free multi-agent reinforcement learning (MARL) to devise efficient, scalable controllers for multi-robot systems (MRS). This review aims to provide an analysis of the state-of-the-art in distributed MARL for multi-robot cooperation.\n  Recent findings: Decentralized MRS face fundamental challenges, such as non-stationarity and partial observability. Building upon the \"centralized training, decentralized execution\" paradigm, recent MARL approaches include independent learning, centralized critic, value decomposition, and communication learning approaches. Cooperative behaviors are demonstrated through AI benchmarks and fundamental real-world robotic capabilities such as multi-robot motion/path planning.\n  Summary: This survey reports the challenges surrounding decentralized model-free MARL for multi-robot cooperation and existing classes of approaches. We present benchmarks and robotic applications along with a discussion on current open avenues for research.",
    "authors": [
      "Yutong Wang",
      "Mehul Damani",
      "Pamela Wang",
      "Yuhong Cao",
      "Guillaume Sartoretti"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2022-04-07T15:34:19Z",
    "pdf_url": "https://arxiv.org/pdf/2204.03516v1"
  },
  {
    "arxiv_id": "2204.01544v1",
    "entry_id": "http://arxiv.org/abs/2204.01544v1",
    "title": "Automated generalisation of buildings using CartAGen platform",
    "summary": "In this paper, we present a methodology to automatically derive the generalised representations of buildings at scales 1:25K, 1:50K, and to delineate the urban area for 1:250K scale representation. These generalised representations are derived from 1:10K scale. The automatic generalisation processes are realised using the specific algorithms and the generalisation models available in the CartAGen (CARTographic Agent GENeralisation) platform. The CartAGen is an open source map generalisation platform developed by IGN France. The proposed methodology in this paper is evaluated using the data products available from the Ordnance Survey, UK, and the Survey of India, India. This study investigates the applicability of the CartAGen platform for generalising the data products which have been excluded from the investigations by IGN France. This paper discusses the modifications required for such data products.",
    "authors": [
      "Jagadish Boodala",
      "Onkar Dikshit",
      "Nagarajan Balasubramanian"
    ],
    "categories": [
      "cs.MA",
      "cs.DB"
    ],
    "published": "2022-04-04T14:51:29Z",
    "pdf_url": "https://arxiv.org/pdf/2204.01544v1"
  },
  {
    "arxiv_id": "2204.01467v1",
    "entry_id": "http://arxiv.org/abs/2204.01467v1",
    "title": "On scientific understanding with artificial intelligence",
    "summary": "Imagine an oracle that correctly predicts the outcome of every particle physics experiment, the products of every chemical reaction, or the function of every protein. Such an oracle would revolutionize science and technology as we know them. However, as scientists, we would not be satisfied with the oracle itself. We want more. We want to comprehend how the oracle conceived these predictions. This feat, denoted as scientific understanding, has frequently been recognized as the essential aim of science. Now, the ever-growing power of computers and artificial intelligence poses one ultimate question: How can advanced artificial systems contribute to scientific understanding or achieve it autonomously?\n  We are convinced that this is not a mere technical question but lies at the core of science. Therefore, here we set out to answer where we are and where we can go from here. We first seek advice from the philosophy of science to understand scientific understanding. Then we review the current state of the art, both from literature and by collecting dozens of anecdotes from scientists about how they acquired new conceptual understanding with the help of computers. Those combined insights help us to define three dimensions of android-assisted scientific understanding: The android as a I) computational microscope, II) resource of inspiration and the ultimate, not yet existent III) agent of understanding. For each dimension, we explain new avenues to push beyond the status quo and unleash the full power of artificial intelligence's contribution to the central aim of science. We hope our perspective inspires and focuses research towards androids that get new scientific understanding and ultimately bring us closer to true artificial scientists.",
    "authors": [
      "Mario Krenn",
      "Robert Pollice",
      "Si Yue Guo",
      "Matteo Aldeghi",
      "Alba Cervera-Lierta",
      "Pascal Friederich",
      "Gabriel dos Passos Gomes",
      "Florian Häse",
      "Adrian Jinich",
      "AkshatKumar Nigam",
      "Zhenpeng Yao",
      "Alán Aspuru-Guzik"
    ],
    "categories": [
      "cs.CY",
      "cs.LG",
      "physics.chem-ph"
    ],
    "published": "2022-04-04T13:45:13Z",
    "pdf_url": "https://arxiv.org/pdf/2204.01467v1"
  },
  {
    "arxiv_id": "2203.13366v7",
    "entry_id": "http://arxiv.org/abs/2203.13366v7",
    "title": "Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)",
    "summary": "For a long time, different recommendation tasks typically require designing task-specific architectures and training objectives. As a result, it is hard to transfer the learned knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches, e.g., a sequential recommendation model can hardly be applied or transferred to a review generation method. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called \"Pretrain, Personalized Prompt, and Predict Paradigm\" (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format -- natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation based on prompts. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several recommendation benchmarks, we conduct experiments to show the effectiveness of P5. We release the source code at https://github.com/jeykigung/P5.",
    "authors": [
      "Shijie Geng",
      "Shuchang Liu",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Yongfeng Zhang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-03-24T22:13:23Z",
    "pdf_url": "https://arxiv.org/pdf/2203.13366v7"
  },
  {
    "arxiv_id": "2203.12667v3",
    "entry_id": "http://arxiv.org/abs/2203.12667v3",
    "title": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions",
    "summary": "A long-term goal of AI research is to build intelligent agents that can communicate with humans in natural language, perceive the environment, and perform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental and interdisciplinary research topic towards this goal, and receives increasing attention from natural language processing, computer vision, robotics, and machine learning communities. In this paper, we review contemporary studies in the emerging field of VLN, covering tasks, evaluation metrics, methods, etc. Through structured analysis of current progress and challenges, we highlight the limitations of current VLN and opportunities for future work. This paper serves as a thorough reference for the VLN research community.",
    "authors": [
      "Jing Gu",
      "Eliana Stefani",
      "Qi Wu",
      "Jesse Thomason",
      "Xin Eric Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-03-22T16:58:10Z",
    "pdf_url": "https://arxiv.org/pdf/2203.12667v3"
  },
  {
    "arxiv_id": "2203.10603v1",
    "entry_id": "http://arxiv.org/abs/2203.10603v1",
    "title": "Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects",
    "summary": "Significant advances have recently been achieved in Multi-Agent Reinforcement Learning (MARL) which tackles sequential decision-making problems involving multiple participants. However, MARL requires a tremendous number of samples for effective training. On the other hand, model-based methods have been shown to achieve provable advantages of sample efficiency. However, the attempts of model-based methods to MARL have just started very recently. This paper presents a review of the existing research on model-based MARL, including theoretical analyses, algorithms, and applications, and analyzes the advantages and potential of model-based MARL. Specifically, we provide a detailed taxonomy of the algorithms and point out the pros and cons for each algorithm according to the challenges inherent to multi-agent scenarios. We also outline promising directions for future development of this field.",
    "authors": [
      "Xihuai Wang",
      "Zhicheng Zhang",
      "Weinan Zhang"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-03-20T17:24:47Z",
    "pdf_url": "https://arxiv.org/pdf/2203.10603v1"
  },
  {
    "arxiv_id": "2204.03570v1",
    "entry_id": "http://arxiv.org/abs/2204.03570v1",
    "title": "Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand",
    "summary": "As the demand for mobility in our society seems to increase, the various issues centered on urban mobility are among those that worry most city inhabitants in this planet. For instance, how to go from A to B in an efficient (but also less stressful) way? These questions and concerns have not changed even during the covid-19 pandemic; on the contrary, as the current stand, people who are avoiding public transportation are only contributing to an increase in the vehicular traffic. The are of intelligent transportation systems (ITS) aims at investigating how to employ information and communication technologies to problems related to transportation. This may mean monitoring and managing the infrastructure (e.g., traffic roads, traffic signals, etc.). However, currently, ITS is also targeting the management of demand. In this panorama, artificial intelligence plays an important role, especially with the advances in machine learning that translates in the use of computational vision, connected and autonomous vehicles, agent-based simulation, among others. In the present work, a survey of several works developed by our group are discussed in a holistic perspective, i.e., they cover not only the supply side (as commonly found in ITS works), but also the demand side, and, in an novel perspective, the integration of both.",
    "authors": [
      "Ana L. C. Bazzan"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-03-18T14:37:33Z",
    "pdf_url": "https://arxiv.org/pdf/2204.03570v1"
  },
  {
    "arxiv_id": "2203.09095v2",
    "entry_id": "http://arxiv.org/abs/2203.09095v2",
    "title": "Automating Code Review Activities by Large-Scale Pre-training",
    "summary": "Code review is an essential part to software development lifecycle since it aims at guaranteeing the quality of codes. Modern code review activities necessitate developers viewing, understanding and even running the programs to assess logic, functionality, latency, style and other factors. It turns out that developers have to spend far too much time reviewing the code of their peers. Accordingly, it is in significant demand to automate the code review process. In this research, we focus on utilizing pre-training techniques for the tasks in the code review scenario. We collect a large-scale dataset of real-world code changes and code reviews from open-source projects in nine of the most popular programming languages. To better understand code diffs and reviews, we propose CodeReviewer, a pre-trained model that utilizes four pre-training tasks tailored specifically for the code review scenario. To evaluate our model, we focus on three key tasks related to code review activities, including code change quality estimation, review comment generation and code refinement. Furthermore, we establish a high-quality benchmark dataset based on our collected data for these three tasks and conduct comprehensive experiments on it. The experimental results demonstrate that our model outperforms the previous state-of-the-art pre-training approaches in all tasks. Further analysis show that our proposed pre-training tasks and the multilingual pre-training dataset benefit the model on the understanding of code changes and reviews.",
    "authors": [
      "Zhiyu Li",
      "Shuai Lu",
      "Daya Guo",
      "Nan Duan",
      "Shailesh Jannu",
      "Grant Jenks",
      "Deep Majumder",
      "Jared Green",
      "Alexey Svyatkovskiy",
      "Shengyu Fu",
      "Neel Sundaresan"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2022-03-17T05:40:13Z",
    "pdf_url": "https://arxiv.org/pdf/2203.09095v2"
  },
  {
    "arxiv_id": "2203.08975v2",
    "entry_id": "http://arxiv.org/abs/2203.08975v2",
    "title": "A Survey of Multi-Agent Deep Reinforcement Learning with Communication",
    "summary": "Communication is an effective mechanism for coordinating the behaviors of multiple agents, broadening their views of the environment, and to support their collaborations. In the field of multi-agent deep reinforcement learning (MADRL), agents can improve the overall learning performance and achieve their objectives by communication. Agents can communicate various types of messages, either to all agents or to specific agent groups, or conditioned on specific constraints. With the growing body of research work in MADRL with communication (Comm-MADRL), there is a lack of a systematic and structural approach to distinguish and classify existing Comm-MADRL approaches. In this paper, we survey recent works in the Comm-MADRL field and consider various aspects of communication that can play a role in designing and developing multi-agent reinforcement learning systems. With these aspects in mind, we propose 9 dimensions along which Comm-MADRL approaches can be analyzed, developed, and compared. By projecting existing works into the multi-dimensional space, we discover interesting trends. We also propose some novel directions for designing future Comm-MADRL systems through exploring possible combinations of the dimensions.",
    "authors": [
      "Changxi Zhu",
      "Mehdi Dastani",
      "Shihan Wang"
    ],
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "published": "2022-03-16T22:39:46Z",
    "pdf_url": "https://arxiv.org/pdf/2203.08975v2"
  },
  {
    "arxiv_id": "2203.08760v1",
    "entry_id": "http://arxiv.org/abs/2203.08760v1",
    "title": "Incorporating Multi-Agent Systems Technology in Power and Energy Systems of Bangladesh: A Feasibility Study",
    "summary": "The power sector of Bangladesh is presently experiencing essential changes as demand for power services is increasing with rising population and economic development. With a gradual shift from a rigidly centralized structure to a more decentralized and fluid setup, fundamentally because of the enormous advancement of distributed renewable energy sources, the future power system of the nation requires new control strategies to work efficiently and sustainably in the face of evolving conditions and constraints. Multi-Agent Systems (MAS) technology has attributes that meet these prerequisites of modern power systems and has been shown to be effective in dealing with its distributed and complex nature. This is a literature-based feasibility study to explore whether MAS technology is suited to be applied in the context of Bangladesh. For this preliminary paper, we look at the topic from a holistic perspective and conduct a meta-review to curate common applications of Multi-Agent System-based concepts, tools and algorithms on the power and energy sector. We also identify the top challenges of this domain in Bangladesh and connect the potential MAS-based solutions to address each challenge. Our qualitative assessment is motivated to provide a starting point for local researchers eager to experiment with MAS technology for application in Bangladesh.",
    "authors": [
      "Syed Redwan Md Hassan",
      "Nazmul Hasan",
      "Mohammad Ali Siddique",
      "K. M Solaiman Fahim",
      "Rummana Rahman",
      "Lamia Iftekhar"
    ],
    "categories": [
      "eess.SY",
      "cs.MA"
    ],
    "published": "2022-03-16T17:17:11Z",
    "pdf_url": "https://arxiv.org/pdf/2203.08760v1"
  },
  {
    "arxiv_id": "2203.11016v2",
    "entry_id": "http://arxiv.org/abs/2203.11016v2",
    "title": "Linking Theories and Methods in Cognitive Sciences via Joint Embedding of the Scientific Literature: The Example of Cognitive Control",
    "summary": "Traditionally, theory and practice of Cognitive Control are linked via literature reviews by human domain experts. This approach, however, is inadequate to track the ever-growing literature. It may also be biased, and yield redundancies and confusion.\n  Here we present an alternative approach. We performed automated text analyses on a large body of scientific texts to create a joint representation of tasks and constructs. More specifically, 385,705 scientific abstracts were first mapped into an embedding space using a transformers-based language model. Document embeddings were then used to identify a task-construct graph embedding that grounds constructs on tasks and supports nuanced meaning of the constructs by taking advantage of constrained random walks in the graph.\n  This joint task-construct graph embedding, can be queried to generate task batteries targeting specific constructs, may reveal knowledge gaps in the literature, and inspire new tasks and novel hypotheses.",
    "authors": [
      "Morteza Ansarinia",
      "Paul Schrater",
      "Pedro Cardoso-Leite"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "q-bio.NC"
    ],
    "published": "2022-03-16T11:03:09Z",
    "pdf_url": "https://arxiv.org/pdf/2203.11016v2"
  },
  {
    "arxiv_id": "2203.07785v1",
    "entry_id": "http://arxiv.org/abs/2203.07785v1",
    "title": "The Ghost in the Machine has an American accent: value conflict in GPT-3",
    "summary": "The alignment problem in the context of large language models must consider the plurality of human values in our world. Whilst there are many resonant and overlapping values amongst the world's cultures, there are also many conflicting, yet equally valid, values. It is important to observe which cultural values a model exhibits, particularly when there is a value conflict between input prompts and generated outputs. We discuss how the co-creation of language and cultural value impacts large language models (LLMs). We explore the constitution of the training data for GPT-3 and compare that to the world's language and internet access demographics, as well as to reported statistical profiles of dominant values in some Nation-states. We stress tested GPT-3 with a range of value-rich texts representing several languages and nations; including some with values orthogonal to dominant US public opinion as reported by the World Values Survey. We observed when values embedded in the input text were mutated in the generated outputs and noted when these conflicting values were more aligned with reported dominant US values. Our discussion of these results uses a moral value pluralism (MVP) lens to better understand these value mutations. Finally, we provide recommendations for how our work may contribute to other current work in the field.",
    "authors": [
      "Rebecca L Johnson",
      "Giada Pistilli",
      "Natalia Menédez-González",
      "Leslye Denisse Dias Duran",
      "Enrico Panai",
      "Julija Kalpokiene",
      "Donald Jay Bertulfo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-03-15T11:06:54Z",
    "pdf_url": "https://arxiv.org/pdf/2203.07785v1"
  },
  {
    "arxiv_id": "2203.07676v2",
    "entry_id": "http://arxiv.org/abs/2203.07676v2",
    "title": "An Introduction to Multi-Agent Reinforcement Learning and Review of its Application to Autonomous Mobility",
    "summary": "Many scenarios in mobility and traffic involve multiple different agents that need to cooperate to find a joint solution. Recent advances in behavioral planning use Reinforcement Learning to find effective and performant behavior strategies. However, as autonomous vehicles and vehicle-to-X communications become more mature, solutions that only utilize single, independent agents leave potential performance gains on the road. Multi-Agent Reinforcement Learning (MARL) is a research field that aims to find optimal solutions for multiple agents that interact with each other. This work aims to give an overview of the field to researchers in autonomous mobility. We first explain MARL and introduce important concepts. Then, we discuss the central paradigms that underlie MARL algorithms, and give an overview of state-of-the-art methods and ideas in each paradigm. With this background, we survey applications of MARL in autonomous mobility scenarios and give an overview of existing scenarios and implementations.",
    "authors": [
      "Lukas M. Schmidt",
      "Johanna Brosig",
      "Axel Plinge",
      "Bjoern M. Eskofier",
      "Christopher Mutschler"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2022-03-15T06:40:28Z",
    "pdf_url": "https://arxiv.org/pdf/2203.07676v2"
  },
  {
    "arxiv_id": "2204.03503v1",
    "entry_id": "http://arxiv.org/abs/2204.03503v1",
    "title": "Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers",
    "summary": "Automated short answer grading (ASAG) has gained attention in education as a means to scale educational tasks to the growing number of students. Recent progress in Natural Language Processing and Machine Learning has largely influenced the field of ASAG, of which we survey the recent research advancements. We complement previous surveys by providing a comprehensive analysis of recently published methods that deploy deep learning approaches. In particular, we focus our analysis on the transition from hand engineered features to representation learning approaches, which learn representative features for the task at hand automatically from large corpora of data. We structure our analysis of deep learning methods along three categories: word embeddings, sequential models, and attention-based methods. Deep learning impacted ASAG differently than other fields of NLP, as we noticed that the learned representations alone do not contribute to achieve the best results, but they rather show to work in a complementary way with hand-engineered features. The best performance are indeed achieved by methods that combine the carefully hand-engineered features with the power of the semantic descriptions provided by the latest models, like transformers architectures. We identify challenges and provide an outlook on research direction that can be addressed in the future",
    "authors": [
      "Stefan Haller",
      "Adina Aldea",
      "Christin Seifert",
      "Nicola Strisciuglio"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-03-11T13:47:08Z",
    "pdf_url": "https://arxiv.org/pdf/2204.03503v1"
  },
  {
    "arxiv_id": "2203.04735v1",
    "entry_id": "http://arxiv.org/abs/2203.04735v1",
    "title": "A Survey on Reinforcement Learning Methods in Character Animation",
    "summary": "Reinforcement Learning is an area of Machine Learning focused on how agents can be trained to make sequential decisions, and achieve a particular goal within an arbitrary environment. While learning, they repeatedly take actions based on their observation of the environment, and receive appropriate rewards which define the objective. This experience is then used to progressively improve the policy controlling the agent's behavior, typically represented by a neural network. This trained module can then be reused for similar problems, which makes this approach promising for the animation of autonomous, yet reactive characters in simulators, video games or virtual reality environments. This paper surveys the modern Deep Reinforcement Learning methods and discusses their possible applications in Character Animation, from skeletal control of a single, physically-based character to navigation controllers for individual agents and virtual crowds. It also describes the practical side of training DRL systems, comparing the different frameworks available to build such agents.",
    "authors": [
      "Ariel Kwiatkowski",
      "Eduardo Alvarado",
      "Vicky Kalogeiton",
      "C. Karen Liu",
      "Julien Pettré",
      "Michiel van de Panne",
      "Marie-Paule Cani"
    ],
    "categories": [
      "cs.GR",
      "cs.LG"
    ],
    "published": "2022-03-07T23:39:00Z",
    "pdf_url": "https://arxiv.org/pdf/2203.04735v1"
  },
  {
    "arxiv_id": "2203.02121v2",
    "entry_id": "http://arxiv.org/abs/2203.02121v2",
    "title": "Adversarial Patterns: Building Robust Android Malware Classifiers",
    "summary": "Machine learning models are increasingly being adopted across various fields, such as medicine, business, autonomous vehicles, and cybersecurity, to analyze vast amounts of data, detect patterns, and make predictions or recommendations. In the field of cybersecurity, these models have made significant improvements in malware detection. However, despite their ability to understand complex patterns from unstructured data, these models are susceptible to adversarial attacks that perform slight modifications in malware samples, leading to misclassification from malignant to benign. Numerous defense approaches have been proposed to either detect such adversarial attacks or improve model robustness. These approaches have resulted in a multitude of attack and defense techniques and the emergence of a field known as `adversarial machine learning.' In this survey paper, we provide a comprehensive review of adversarial machine learning in the context of Android malware classifiers. Android is the most widely used operating system globally and is an easy target for malicious agents. The paper first presents an extensive background on Android malware classifiers, followed by an examination of the latest advancements in adversarial attacks and defenses. Finally, the paper provides guidelines for designing robust malware classifiers and outlines research directions for the future.",
    "authors": [
      "Dipkamal Bhusal",
      "Nidhi Rastogi"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2022-03-04T03:47:08Z",
    "pdf_url": "https://arxiv.org/pdf/2203.02121v2"
  },
  {
    "arxiv_id": "2203.01922v1",
    "entry_id": "http://arxiv.org/abs/2203.01922v1",
    "title": "Vision-Language Intelligence: Tasks, Representation Learning, and Large Models",
    "summary": "This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing.",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Yi-Fan Zhang",
      "Shilong Liu",
      "Jian Guo",
      "Lionel M. Ni",
      "PengChuan Zhang",
      "Lei Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-03-03T18:54:59Z",
    "pdf_url": "https://arxiv.org/pdf/2203.01922v1"
  },
  {
    "arxiv_id": "2203.01387v3",
    "entry_id": "http://arxiv.org/abs/2203.01387v3",
    "title": "A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems",
    "summary": "With the widespread adoption of deep learning, reinforcement learning (RL) has experienced a dramatic increase in popularity, scaling to previously intractable problems, such as playing complex games from pixel observations, sustaining conversations with humans, and controlling robotic agents. However, there is still a wide range of domains inaccessible to RL due to the high cost and danger of interacting with the environment. Offline RL is a paradigm that learns exclusively from static datasets of previously collected interactions, making it feasible to extract policies from large and diverse training datasets. Effective offline RL algorithms have a much wider range of applications than online RL, being particularly appealing for real-world applications, such as education, healthcare, and robotics. In this work, we contribute with a unifying taxonomy to classify offline RL methods. Furthermore, we provide a comprehensive review of the latest algorithmic breakthroughs in the field using a unified notation as well as a review of existing benchmarks' properties and shortcomings. Additionally, we provide a figure that summarizes the performance of each method and class of methods on different dataset properties, equipping researchers with the tools to decide which type of algorithm is best suited for the problem at hand and identify which classes of algorithms look the most promising. Finally, we provide our perspective on open problems and propose future research directions for this rapidly growing field.",
    "authors": [
      "Rafael Figueiredo Prudencio",
      "Marcos R. O. A. Maximo",
      "Esther Luna Colombini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2022-03-02T20:05:11Z",
    "pdf_url": "https://arxiv.org/pdf/2203.01387v3"
  },
  {
    "arxiv_id": "2202.13852v4",
    "entry_id": "http://arxiv.org/abs/2202.13852v4",
    "title": "Hyperbolic Graph Neural Networks: A Review of Methods and Applications",
    "summary": "Graph representation learning in Euclidean space, despite its widespread adoption and proven utility in many domains, often struggles to effectively capture the inherent hierarchical and complex relational structures prevalent in real-world data, particularly for datasets exhibiting a highly non-Euclidean latent anatomy or power-law distributions. Hyperbolic geometry, with its constant negative curvature and exponential growth property, naturally accommodates such structures, offering a promising alternative for learning rich graph representations. This survey paper provides a comprehensive review of the rapidly evolving field of Hyperbolic Graph Learning (HGL). We systematically categorize and analyze existing methods broadly dividing them into (1) hyperbolic graph embedding-based techniques, (2) graph neural network-based hyperbolic models, and (3) emerging paradigms. Beyond methodologies, we extensively discuss diverse applications of HGL across multiple domains, including recommender systems, knowledge graphs, bioinformatics, and other relevant scenarios, demonstrating the broad applicability and effectiveness of hyperbolic geometry in real-world graph learning tasks. Most importantly, we identify several key challenges that serve as directions for advancing HGL, including handling complex data structures, developing geometry-aware learning objectives, ensuring trustworthy and scalable implementations, and integrating with foundation models, e.g., large language models. We highlight promising research opportunities in this exciting interdisciplinary area. A comprehensive repository can be found at https://github.com/digailab/awesome-hyperbolic-graph-learning.",
    "authors": [
      "Menglin Yang",
      "Min Zhou",
      "Tong Zhang",
      "Jiahong Liu",
      "Zhihao Li",
      "Lujia Pan",
      "Hui Xiong",
      "Irwin King"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-02-28T15:08:48Z",
    "pdf_url": "https://arxiv.org/pdf/2202.13852v4"
  },
  {
    "arxiv_id": "2202.10587v2",
    "entry_id": "http://arxiv.org/abs/2202.10587v2",
    "title": "Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer",
    "summary": "Machine learning, notably deep learning, has significantly propelled molecular investigations within the biochemical sphere. Traditionally, modeling for such research has centered around a handful of paradigms. For instance, the prediction paradigm is frequently deployed for tasks such as molecular property prediction. To enhance the generation and decipherability of purely data-driven models, scholars have integrated biochemical domain knowledge into these molecular study models. This integration has sparked a surge in paradigm transfer, which is solving one molecular learning task by reformulating it as another one. With the emergence of Large Language Models, these paradigms have demonstrated an escalating trend towards harmonized unification. In this work, we delineate a literature survey focused on knowledge-informed molecular learning from the perspective of paradigm transfer. We classify the paradigms, scrutinize their methodologies, and dissect the contribution of domain knowledge. Moreover, we encapsulate prevailing trends and identify intriguing avenues for future exploration in molecular learning.",
    "authors": [
      "Yin Fang",
      "Zhuo Chen",
      "Xiaohui Fan",
      "Ningyu Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "published": "2022-02-17T06:18:02Z",
    "pdf_url": "https://arxiv.org/pdf/2202.10587v2"
  },
  {
    "arxiv_id": "2202.08444v1",
    "entry_id": "http://arxiv.org/abs/2202.08444v1",
    "title": "A Survey on Deep Reinforcement Learning-based Approaches for Adaptation and Generalization",
    "summary": "Deep Reinforcement Learning (DRL) aims to create intelligent agents that can learn to solve complex problems efficiently in a real-world environment. Typically, two learning goals: adaptation and generalization are used for baselining DRL algorithm's performance on different tasks and domains. This paper presents a survey on the recent developments in DRL-based approaches for adaptation and generalization. We begin by formulating these goals in the context of task and domain. Then we review the recent works under those approaches and discuss future research directions through which DRL algorithms' adaptability and generalizability can be enhanced and potentially make them applicable to a broad range of real-world problems.",
    "authors": [
      "Pamul Yadav",
      "Ashutosh Mishra",
      "Junyong Lee",
      "Shiho Kim"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2022-02-17T04:29:08Z",
    "pdf_url": "https://arxiv.org/pdf/2202.08444v1"
  },
  {
    "arxiv_id": "2202.08434v1",
    "entry_id": "http://arxiv.org/abs/2202.08434v1",
    "title": "A Survey of Explainable Reinforcement Learning",
    "summary": "Explainable reinforcement learning (XRL) is an emerging subfield of explainable machine learning that has attracted considerable attention in recent years. The goal of XRL is to elucidate the decision-making process of learning agents in sequential decision-making settings. In this survey, we propose a novel taxonomy for organizing the XRL literature that prioritizes the RL setting. We overview techniques according to this taxonomy. We point out gaps in the literature, which we use to motivate and outline a roadmap for future work.",
    "authors": [
      "Stephanie Milani",
      "Nicholay Topin",
      "Manuela Veloso",
      "Fei Fang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-02-17T03:45:09Z",
    "pdf_url": "https://arxiv.org/pdf/2202.08434v1"
  },
  {
    "arxiv_id": "2202.10450v3",
    "entry_id": "http://arxiv.org/abs/2202.10450v3",
    "title": "A Survey of Ad Hoc Teamwork Research",
    "summary": "Ad hoc teamwork is the research problem of designing agents that can collaborate with new teammates without prior coordination. This survey makes a two-fold contribution: First, it provides a structured description of the different facets of the ad hoc teamwork problem. Second, it discusses the progress that has been made in the field so far, and identifies the immediate and long-term open problems that need to be addressed in ad hoc teamwork.",
    "authors": [
      "Reuth Mirsky",
      "Ignacio Carlucho",
      "Arrasy Rahman",
      "Elliot Fosong",
      "William Macke",
      "Mohan Sridharan",
      "Peter Stone",
      "Stefano V. Albrecht"
    ],
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2022-02-16T18:16:27Z",
    "pdf_url": "https://arxiv.org/pdf/2202.10450v3"
  },
  {
    "arxiv_id": "2202.08063v6",
    "entry_id": "http://arxiv.org/abs/2202.08063v6",
    "title": "Information Extraction in Low-Resource Scenarios: Survey and Perspective",
    "summary": "Information Extraction (IE) seeks to derive structured information from unstructured texts, often facing challenges in low-resource scenarios due to data scarcity and unseen classes. This paper presents a review of neural approaches to low-resource IE from \\emph{traditional} and \\emph{LLM-based} perspectives, systematically categorizing them into a fine-grained taxonomy. Then we conduct empirical study on LLM-based methods compared with previous state-of-the-art models, and discover that (1) well-tuned LMs are still predominant; (2) tuning open-resource LLMs and ICL with GPT family is promising in general; (3) the optimal LLM-based technical solution for low-resource IE can be task-dependent. In addition, we discuss low-resource IE with LLMs, highlight promising applications, and outline potential research directions. This survey aims to foster understanding of this field, inspire new ideas, and encourage widespread applications in both academia and industry.",
    "authors": [
      "Shumin Deng",
      "Yubo Ma",
      "Ningyu Zhang",
      "Yixin Cao",
      "Bryan Hooi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2022-02-16T13:44:00Z",
    "pdf_url": "https://arxiv.org/pdf/2202.08063v6"
  },
  {
    "arxiv_id": "2202.10336v1",
    "entry_id": "http://arxiv.org/abs/2202.10336v1",
    "title": "Artificial Intelligence for the Metaverse: A Survey",
    "summary": "Along with the massive growth of the Internet from the 1990s until now, various innovative technologies have been created to bring users breathtaking experiences with more virtual interactions in cyberspace. Many virtual environments with thousands of services and applications, from social networks to virtual gaming worlds, have been developed with immersive experience and digital transformation, but most are incoherent instead of being integrated into a platform. In this context, metaverse, a term formed by combining meta and universe, has been introduced as a shared virtual world that is fueled by many emerging technologies, such as fifth-generation networks and beyond, virtual reality, and artificial intelligence (AI). Among such technologies, AI has shown the great importance of processing big data to enhance immersive experience and enable human-like intelligence of virtual agents. In this survey, we make a beneficial effort to explore the role of AI in the foundation and development of the metaverse. We first deliver a preliminary of AI, including machine learning algorithms and deep learning architectures, and its role in the metaverse. We then convey a comprehensive investigation of AI-based methods concerning six technical aspects that have potentials for the metaverse: natural language processing, machine vision, blockchain, networking, digital twin, and neural interface, and being potential for the metaverse. Subsequently, several AI-aided applications, such as healthcare, manufacturing, smart cities, and gaming, are studied to be deployed in the virtual worlds. Finally, we conclude the key contribution of this survey and open some future research directions in AI for the metaverse.",
    "authors": [
      "Thien Huynh-The",
      "Quoc-Viet Pham",
      "Xuan-Qui Pham",
      "Thanh Thi Nguyen",
      "Zhu Han",
      "Dong-Seong Kim"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-02-15T03:34:56Z",
    "pdf_url": "https://arxiv.org/pdf/2202.10336v1"
  },
  {
    "arxiv_id": "2202.07138v2",
    "entry_id": "http://arxiv.org/abs/2202.07138v2",
    "title": "Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge",
    "summary": "Natural language processing (NLP) aims at investigating the interactions between agents and humans, processing and analyzing large amounts of natural language data. Large-scale language models play an important role in current natural language processing. However, the challenges of explainability and complexity come along with the developments of language models. One way is to introduce logical relations and rules into natural language processing models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to these two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing effectively improves the communication between human and intelligent agents. This paper outlines the commons and relations between AI planning and natural language processing, argues that each of them can effectively impact on the other one by five areas: (1) planning-based text understanding, (2) planning-based natural language processing, (3) planning-based explainability, (4) text-based human-robot interaction, and (5) applications. We also explore some potential future issues between AI planning and natural language processing. To the best of our knowledge, this survey is the first work that addresses the deep connections between AI planning and Natural language processing.",
    "authors": [
      "Kebing Jin",
      "Hankz Hankui Zhuo"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2022-02-15T02:19:09Z",
    "pdf_url": "https://arxiv.org/pdf/2202.07138v2"
  },
  {
    "arxiv_id": "2202.07101v2",
    "entry_id": "http://arxiv.org/abs/2202.07101v2",
    "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
    "summary": "Effectively scaling large Transformer models is a main driver of recent advances in natural language processing. Dynamic neural networks, as an emerging research direction, are capable of scaling up neural networks with sub-linear increases in computation and time by dynamically adjusting their computational path based on the input. Dynamic neural networks could be a promising solution to the growing parameter numbers of pretrained language models, allowing both model pretraining with trillions of parameters and faster inference on mobile devices. In this survey, we summarize progress of three types of dynamic neural networks in NLP: skimming, mixture of experts, and early exit. We also highlight current challenges in dynamic neural networks and directions for future research.",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-02-15T00:13:05Z",
    "pdf_url": "https://arxiv.org/pdf/2202.07101v2"
  },
  {
    "arxiv_id": "2202.03164v1",
    "entry_id": "http://arxiv.org/abs/2202.03164v1",
    "title": "Conversational Agents: Theory and Applications",
    "summary": "In this chapter, we provide a review of conversational agents (CAs), discussing chatbots, intended for casual conversation with a user, as well as task-oriented agents that generally engage in discussions intended to reach one or several specific goals, often (but not always) within a specific domain. We also consider the concept of embodied conversational agents, briefly reviewing aspects such as character animation and speech processing. The many different approaches for representing dialogue in CAs are discussed in some detail, along with methods for evaluating such agents, emphasizing the important topics of accountability and interpretability. A brief historical overview is given, followed by an extensive overview of various applications, especially in the fields of health and education. We end the chapter by discussing benefits and potential risks regarding the societal impact of current and future CA technology.",
    "authors": [
      "Mattias Wahde",
      "Marco Virgolin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-02-07T13:48:14Z",
    "pdf_url": "https://arxiv.org/pdf/2202.03164v1"
  },
  {
    "arxiv_id": "2202.02294v1",
    "entry_id": "http://arxiv.org/abs/2202.02294v1",
    "title": "Pre-Trained Neural Language Models for Automatic Mobile App User Feedback Answer Generation",
    "summary": "Studies show that developers' answers to the mobile app users' feedbacks on app stores can increase the apps' star rating. To help app developers generate answers that are related to the users' issues, recent studies develop models to generate the answers automatically. Aims: The app response generation models use deep neural networks and require training data. Pre-Trained neural language Models (PTM) used in Natural Language Processing (NLP) take advantage of the information they learned from a large corpora in an unsupervised manner, and can reduce the amount of required training data. In this paper, we evaluate PTMs to generate replies to the mobile app user feedbacks. Method: We train a Transformer model from scratch and fine-tune two PTMs to evaluate the generated responses, which are compared to RRGEN, a current app response model. We also evaluate the models with different portions of the training data. Results: The results on a large dataset evaluated by automatic metrics show that PTMs obtain lower scores than the baselines. However, our human evaluation confirms that PTMs can generate more relevant and meaningful responses to the posted feedbacks. Moreover, the performance of PTMs has less drop compared to other models when the amount of training data is reduced to 1/3. Conclusion: PTMs are useful in generating responses to app reviews and are more robust models to the amount of training data provided. However, the prediction time is 19X than RRGEN. This study can provide new avenues for research in adapting the PTMs for analyzing mobile app user feedbacks. Index Terms-mobile app user feedback analysis, neural pre-trained language models, automatic answer generation",
    "authors": [
      "Yue Cao",
      "Fatemeh H. Fard"
    ],
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2022-02-04T18:26:55Z",
    "pdf_url": "https://arxiv.org/pdf/2202.02294v1"
  },
  {
    "arxiv_id": "2202.01924v3",
    "entry_id": "http://arxiv.org/abs/2202.01924v3",
    "title": "Zero-Shot Aspect-Based Sentiment Analysis",
    "summary": "Aspect-based sentiment analysis (ABSA) typically requires in-domain annotated data for supervised training/fine-tuning. It is a big challenge to scale ABSA to a large number of new domains. This paper aims to train a unified model that can perform zero-shot ABSA without using any annotated data for a new domain. We propose a method called contrastive post-training on review Natural Language Inference (CORN). Later ABSA tasks can be cast into NLI for zero-shot transfer. We evaluate CORN on ABSA tasks, ranging from aspect extraction (AE), aspect sentiment classification (ASC), to end-to-end aspect-based sentiment analysis (E2E ABSA), which show ABSA can be conducted without any human annotated ABSA data.",
    "authors": [
      "Lei Shu",
      "Hu Xu",
      "Bing Liu",
      "Jiahua Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-02-04T00:51:46Z",
    "pdf_url": "https://arxiv.org/pdf/2202.01924v3"
  },
  {
    "arxiv_id": "2201.11410v4",
    "entry_id": "http://arxiv.org/abs/2201.11410v4",
    "title": "Reinforcement Learning-Empowered Mobile Edge Computing for 6G Edge Intelligence",
    "summary": "Mobile edge computing (MEC) is considered a novel paradigm for computation-intensive and delay-sensitive tasks in fifth generation (5G) networks and beyond. However, its uncertainty, referred to as dynamic and randomness, from the mobile device, wireless channel, and edge network sides, results in high-dimensional, nonconvex, nonlinear, and NP-hard optimization problems. Thanks to the evolved reinforcement learning (RL), upon iteratively interacting with the dynamic and random environment, its trained agent can intelligently obtain the optimal policy in MEC. Furthermore, its evolved versions, such as deep RL (DRL), can achieve higher convergence speed efficiency and learning accuracy based on the parametric approximation for the large-scale state-action space. This paper provides a comprehensive research review on RL-enabled MEC and offers insight for development in this area. More importantly, associated with free mobility, dynamic channels, and distributed services, the MEC challenges that can be solved by different kinds of RL algorithms are identified, followed by how they can be solved by RL solutions in diverse mobile applications. Finally, the open challenges are discussed to provide helpful guidance for future research in RL training and learning MEC.",
    "authors": [
      "Peng Wei",
      "Kun Guo",
      "Ye Li",
      "Jue Wang",
      "Wei Feng",
      "Shi Jin",
      "Ning Ge",
      "Ying-Chang Liang"
    ],
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.NI"
    ],
    "published": "2022-01-27T10:02:54Z",
    "pdf_url": "https://arxiv.org/pdf/2201.11410v4"
  },
  {
    "arxiv_id": "2201.08300v1",
    "entry_id": "http://arxiv.org/abs/2201.08300v1",
    "title": "From Psychological Curiosity to Artificial Curiosity: Curiosity-Driven Learning in Artificial Intelligence Tasks",
    "summary": "Psychological curiosity plays a significant role in human intelligence to enhance learning through exploration and information acquisition. In the Artificial Intelligence (AI) community, artificial curiosity provides a natural intrinsic motivation for efficient learning as inspired by human cognitive development; meanwhile, it can bridge the existing gap between AI research and practical application scenarios, such as overfitting, poor generalization, limited training samples, high computational cost, etc. As a result, curiosity-driven learning (CDL) has become increasingly popular, where agents are self-motivated to learn novel knowledge. In this paper, we first present a comprehensive review on the psychological study of curiosity and summarize a unified framework for quantifying curiosity as well as its arousal mechanism. Based on the psychological principle, we further survey the literature of existing CDL methods in the fields of Reinforcement Learning, Recommendation, and Classification, where both advantages and disadvantages as well as future work are discussed. As a result, this work provides fruitful insights for future CDL research and yield possible directions for further improvement.",
    "authors": [
      "Chenyu Sun",
      "Hangwei Qian",
      "Chunyan Miao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-01-20T17:07:03Z",
    "pdf_url": "https://arxiv.org/pdf/2201.08300v1"
  },
  {
    "arxiv_id": "2201.08299v3",
    "entry_id": "http://arxiv.org/abs/2201.08299v3",
    "title": "Goal-Conditioned Reinforcement Learning: Problems and Solutions",
    "summary": "Goal-conditioned reinforcement learning (GCRL), related to a set of complex RL problems, trains an agent to achieve different goals under particular scenarios. Compared to the standard RL solutions that learn a policy solely depending on the states or observations, GCRL additionally requires the agent to make decisions according to different goals. In this survey, we provide a comprehensive overview of the challenges and algorithms for GCRL. Firstly, we answer what the basic problems are studied in this field. Then, we explain how goals are represented and present how existing solutions are designed from different points of view. Finally, we make the conclusion and discuss potential future prospects that recent researches focus on.",
    "authors": [
      "Minghuan Liu",
      "Menghui Zhu",
      "Weinan Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-01-20T17:06:42Z",
    "pdf_url": "https://arxiv.org/pdf/2201.08299v3"
  },
  {
    "arxiv_id": "2201.07040v2",
    "entry_id": "http://arxiv.org/abs/2201.07040v2",
    "title": "Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals",
    "summary": "Publicly accessible benchmarks that allow for assessing and comparing model performances are important drivers of progress in artificial intelligence (AI). While recent advances in AI capabilities hold the potential to transform medical practice by assisting and augmenting the cognitive processes of healthcare professionals, the coverage of clinically relevant tasks by AI benchmarks is largely unclear. Furthermore, there is a lack of systematized meta-information that allows clinical AI researchers to quickly determine accessibility, scope, content and other characteristics of datasets and benchmark datasets relevant to the clinical domain.\n  To address these issues, we curated and released a comprehensive catalogue of datasets and benchmarks pertaining to the broad domain of clinical and biomedical natural language processing (NLP), based on a systematic review of literature and online resources. A total of 450 NLP datasets were manually systematized and annotated with rich metadata, such as targeted tasks, clinical applicability, data types, performance metrics, accessibility and licensing information, and availability of data splits. We then compared tasks covered by AI benchmark datasets with relevant tasks that medical practitioners reported as highly desirable targets for automation in a previous empirical study.\n  Our analysis indicates that AI benchmarks of direct clinical relevance are scarce and fail to cover most work activities that clinicians want to see addressed. In particular, tasks associated with routine documentation and patient data administration workflows are not represented despite significant associated workloads. Thus, currently available AI benchmarks are improperly aligned with desired targets for AI automation in clinical settings, and novel benchmarks should be created to fill these gaps.",
    "authors": [
      "Kathrin Blagec",
      "Jakob Kraiger",
      "Wolfgang Frühwirt",
      "Matthias Samwald"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2022-01-18T15:05:28Z",
    "pdf_url": "https://arxiv.org/pdf/2201.07040v2"
  },
  {
    "arxiv_id": "2201.05464v1",
    "entry_id": "http://arxiv.org/abs/2201.05464v1",
    "title": "Bayesian sense of time in biological and artificial brains",
    "summary": "Enquiries concerning the underlying mechanisms and the emergent properties of a biological brain have a long history of theoretical postulates and experimental findings. Today, the scientific community tends to converge to a single interpretation of the brain's cognitive underpinnings -- that it is a Bayesian inference machine. This contemporary view has naturally been a strong driving force in recent developments around computational and cognitive neurosciences. Of particular interest is the brain's ability to process the passage of time -- one of the fundamental dimensions of our experience. How can we explain empirical data on human time perception using the Bayesian brain hypothesis? Can we replicate human estimation biases using Bayesian models? What insights can the agent-based machine learning models provide for the study of this subject? In this chapter, we review some of the recent advancements in the field of time perception and discuss the role of Bayesian processing in the construction of temporal models.",
    "authors": [
      "Zafeirios Fountas",
      "Alexey Zakharov"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2022-01-14T14:05:30Z",
    "pdf_url": "https://arxiv.org/pdf/2201.05464v1"
  },
  {
    "arxiv_id": "2201.03916v2",
    "entry_id": "http://arxiv.org/abs/2201.03916v2",
    "title": "Automated Reinforcement Learning (AutoRL): A Survey and Open Problems",
    "summary": "The combination of Reinforcement Learning (RL) with deep learning has led to a series of impressive feats, with many believing (deep) RL provides a path towards generally capable agents. However, the success of RL agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use RL for new problems, while also limits its full potential. In many other areas of machine learning, AutoML has shown it is possible to automate such design choices and has also yielded promising initial results when applied to RL. However, Automated Reinforcement Learning (AutoRL) involves not only standard applications of AutoML but also includes additional challenges unique to RL, that naturally produce a different set of methods. As such, AutoRL has been emerging as an important area of research in RL, providing promise in a variety of applications from RNA design to playing games such as Go. Given the diversity of methods and environments considered in RL, much of the research has been conducted in distinct subfields, ranging from meta-learning to evolution. In this survey we seek to unify the field of AutoRL, we provide a common taxonomy, discuss each area in detail and pose open problems which would be of interest to researchers going forward.",
    "authors": [
      "Jack Parker-Holder",
      "Raghu Rajan",
      "Xingyou Song",
      "André Biedenkapp",
      "Yingjie Miao",
      "Theresa Eimer",
      "Baohe Zhang",
      "Vu Nguyen",
      "Roberto Calandra",
      "Aleksandra Faust",
      "Frank Hutter",
      "Marius Lindauer"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2022-01-11T12:41:43Z",
    "pdf_url": "https://arxiv.org/pdf/2201.03916v2"
  },
  {
    "arxiv_id": "2201.03904v2",
    "entry_id": "http://arxiv.org/abs/2201.03904v2",
    "title": "pymdp: A Python library for active inference in discrete state spaces",
    "summary": "Active inference is an account of cognition and behavior in complex systems which brings together action, perception, and learning under the theoretical mantle of Bayesian inference. Active inference has seen growing applications in academic research, especially in fields that seek to model human or animal behavior. While in recent years, some of the code arising from the active inference literature has been written in open source languages like Python and Julia, to-date, the most popular software for simulating active inference agents is the DEM toolbox of SPM, a MATLAB library originally developed for the statistical analysis and modelling of neuroimaging data. Increasing interest in active inference, manifested both in terms of sheer number as well as diversifying applications across scientific disciplines, has thus created a need for generic, widely-available, and user-friendly code for simulating active inference in open-source scientific computing languages like Python. The Python package we present here, pymdp (see https://github.com/infer-actively/pymdp), represents a significant step in this direction: namely, we provide the first open-source package for simulating active inference with partially-observable Markov Decision Processes or POMDPs. We review the package's structure and explain its advantages like modular design and customizability, while providing in-text code blocks along the way to demonstrate how it can be used to build and run active inference processes with ease. We developed pymdp to increase the accessibility and exposure of the active inference framework to researchers, engineers, and developers with diverse disciplinary backgrounds. In the spirit of open-source software, we also hope that it spurs new innovation, development, and collaboration in the growing active inference community.",
    "authors": [
      "Conor Heins",
      "Beren Millidge",
      "Daphne Demekas",
      "Brennan Klein",
      "Karl Friston",
      "Iain Couzin",
      "Alexander Tschantz"
    ],
    "categories": [
      "cs.AI",
      "cs.MS",
      "q-bio.NC"
    ],
    "published": "2022-01-11T12:18:44Z",
    "pdf_url": "https://arxiv.org/pdf/2201.03904v2"
  },
  {
    "arxiv_id": "2201.02950v1",
    "entry_id": "http://arxiv.org/abs/2201.02950v1",
    "title": "Arguments about Highly Reliable Agent Designs as a Useful Path to Artificial Intelligence Safety",
    "summary": "Several different approaches exist for ensuring the safety of future Transformative Artificial Intelligence (TAI) or Artificial Superintelligence (ASI) systems, and proponents of different approaches have made different and debated claims about the importance or usefulness of their work in the near term, and for future systems. Highly Reliable Agent Designs (HRAD) is one of the most controversial and ambitious approaches, championed by the Machine Intelligence Research Institute, among others, and various arguments have been made about whether and how it reduces risks from future AI systems. In order to reduce confusion in the debate about AI safety, here we build on a previous discussion by Rice which collects and presents four central arguments which are used to justify HRAD as a path towards safety of AI systems.\n  We have titled the arguments (1) incidental utility,(2) deconfusion, (3) precise specification, and (4) prediction. Each of these makes different, partly conflicting claims about how future AI systems can be risky. We have explained the assumptions and claims based on a review of published and informal literature, along with consultation with experts who have stated positions on the topic. Finally, we have briefly outlined arguments against each approach and against the agenda overall.",
    "authors": [
      "Issa Rice",
      "David Manheim"
    ],
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2022-01-09T07:42:37Z",
    "pdf_url": "https://arxiv.org/pdf/2201.02950v1"
  },
  {
    "arxiv_id": "2201.05460v2",
    "entry_id": "http://arxiv.org/abs/2201.05460v2",
    "title": "Impact of Stop Sets on Stopping Active Learning for Text Classification",
    "summary": "Active learning is an increasingly important branch of machine learning and a powerful technique for natural language processing. The main advantage of active learning is its potential to reduce the amount of labeled data needed to learn high-performing models. A vital aspect of an effective active learning algorithm is the determination of when to stop obtaining additional labeled data. Several leading state-of-the-art stopping methods use a stop set to help make this decision. However, there has been relatively less attention given to the choice of stop set than to the stopping algorithms that are applied on the stop set. Different choices of stop sets can lead to significant differences in stopping method performance. We investigate the impact of different stop set choices on different stopping methods. This paper shows the choice of the stop set can have a significant impact on the performance of stopping methods and the impact is different for stability-based methods from that on confidence-based methods. Furthermore, the unbiased representative stop sets suggested by original authors of methods work better than the systematically biased stop sets used in recently published work, and stopping methods based on stabilizing predictions have stronger performance than confidence-based stopping methods when unbiased representative stop sets are used. We provide the largest quantity of experimental results on the impact of stop sets to date. The findings are important for helping to illuminate the impact of this important aspect of stopping methods that has been under-considered in recently published work and that can have a large practical impact on the performance of stopping methods for important semantic computing applications such as technology assisted review and text classification more broadly.",
    "authors": [
      "Luke Kurlandski",
      "Michael Bloodgood"
    ],
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2022-01-08T18:59:15Z",
    "pdf_url": "https://arxiv.org/pdf/2201.05460v2"
  },
  {
    "arxiv_id": "2201.06953v1",
    "entry_id": "http://arxiv.org/abs/2201.06953v1",
    "title": "Knowledge Tracing: A Survey",
    "summary": "Humans ability to transfer knowledge through teaching is one of the essential aspects for human intelligence. A human teacher can track the knowledge of students to customize the teaching on students needs. With the rise of online education platforms, there is a similar need for machines to track the knowledge of students and tailor their learning experience. This is known as the Knowledge Tracing (KT) problem in the literature. Effectively solving the KT problem would unlock the potential of computer-aided education applications such as intelligent tutoring systems, curriculum learning, and learning materials' recommendation. Moreover, from a more general viewpoint, a student may represent any kind of intelligent agents including both human and artificial agents. Thus, the potential of KT can be extended to any machine teaching application scenarios which seek for customizing the learning experience for a student agent (i.e., a machine learning model). In this paper, we provide a comprehensive and systematic review for the KT literature. We cover a broad range of methods starting from the early attempts to the recent state-of-the-art methods using deep learning, while highlighting the theoretical aspects of models and the characteristics of benchmark datasets. Besides these, we shed light on key modelling differences between closely related methods and summarize them in an easy-to-understand format. Finally, we discuss current research gaps in the KT literature and possible future research and application directions.",
    "authors": [
      "Ghodai Abdelrahman",
      "Qing Wang",
      "Bernardo Pereira Nunes"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2022-01-08T13:59:48Z",
    "pdf_url": "https://arxiv.org/pdf/2201.06953v1"
  },
  {
    "arxiv_id": "2201.02734v1",
    "entry_id": "http://arxiv.org/abs/2201.02734v1",
    "title": "Building Human-like Communicative Intelligence: A Grounded Perspective",
    "summary": "Modern Artificial Intelligence (AI) systems excel at diverse tasks, from image classification to strategy games, even outperforming humans in many of these domains. After making astounding progress in language learning in the recent decade, AI systems, however, seem to approach the ceiling that does not reflect important aspects of human communicative capacities. Unlike human learners, communicative AI systems often fail to systematically generalize to new data, suffer from sample inefficiency, fail to capture common-sense semantic knowledge, and do not translate to real-world communicative situations. Cognitive Science offers several insights on how AI could move forward from this point. This paper aims to: (1) suggest that the dominant cognitively-inspired AI directions, based on nativist and symbolic paradigms, lack necessary substantiation and concreteness to guide progress in modern AI, and (2) articulate an alternative, \"grounded\", perspective on AI advancement, inspired by Embodied, Embedded, Extended, and Enactive Cognition (4E) research. I review results on 4E research lines in Cognitive Science to distinguish the main aspects of naturalistic learning conditions that play causal roles for human language development. I then use this analysis to propose a list of concrete, implementable components for building \"grounded\" linguistic intelligence. These components include embodying machines in a perception-action cycle, equipping agents with active exploration mechanisms so they can build their own curriculum, allowing agents to gradually develop motor abilities to promote piecemeal language development, and endowing the agents with adaptive feedback from their physical and social environment. I hope that these ideas can direct AI research towards building machines that develop human-like language abilities through their experiences with the world.",
    "authors": [
      "Marina Dubova"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2022-01-02T01:43:24Z",
    "pdf_url": "https://arxiv.org/pdf/2201.02734v1"
  }
]